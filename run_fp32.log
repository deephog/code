&&&& RUNNING TensorRT.trtexec [TensorRT v8400] # trtexec --onnx=effnetb2.onnx --verbose --noDataTransfers --separateProfileRun --dumpProfile --useCudaGraph
[03/27/2022-19:09:34] [I] === Model Options ===
[03/27/2022-19:09:34] [I] Format: ONNX
[03/27/2022-19:09:34] [I] Model: effnetb2.onnx
[03/27/2022-19:09:34] [I] Output:
[03/27/2022-19:09:34] [I] === Build Options ===
[03/27/2022-19:09:34] [I] Max batch: explicit batch
[03/27/2022-19:09:34] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[03/27/2022-19:09:34] [I] minTiming: 1
[03/27/2022-19:09:34] [I] avgTiming: 8
[03/27/2022-19:09:34] [I] Precision: FP32
[03/27/2022-19:09:34] [I] LayerPrecisions: 
[03/27/2022-19:09:34] [I] Calibration: 
[03/27/2022-19:09:34] [I] Refit: Disabled
[03/27/2022-19:09:34] [I] Sparsity: Disabled
[03/27/2022-19:09:34] [I] Safe mode: Disabled
[03/27/2022-19:09:34] [I] DirectIO mode: Disabled
[03/27/2022-19:09:34] [I] Restricted mode: Disabled
[03/27/2022-19:09:34] [I] Save engine: 
[03/27/2022-19:09:34] [I] Load engine: 
[03/27/2022-19:09:34] [I] Profiling verbosity: 0
[03/27/2022-19:09:34] [I] Tactic sources: Using default tactic sources
[03/27/2022-19:09:34] [I] timingCacheMode: local
[03/27/2022-19:09:34] [I] timingCacheFile: 
[03/27/2022-19:09:34] [I] Input(s)s format: fp32:CHW
[03/27/2022-19:09:34] [I] Output(s)s format: fp32:CHW
[03/27/2022-19:09:34] [I] Input build shapes: model
[03/27/2022-19:09:34] [I] Input calibration shapes: model
[03/27/2022-19:09:34] [I] === System Options ===
[03/27/2022-19:09:34] [I] Device: 0
[03/27/2022-19:09:34] [I] DLACore: 
[03/27/2022-19:09:34] [I] Plugins:
[03/27/2022-19:09:34] [I] === Inference Options ===
[03/27/2022-19:09:34] [I] Batch: Explicit
[03/27/2022-19:09:34] [I] Input inference shapes: model
[03/27/2022-19:09:34] [I] Iterations: 10
[03/27/2022-19:09:34] [I] Duration: 3s (+ 200ms warm up)
[03/27/2022-19:09:34] [I] Sleep time: 0ms
[03/27/2022-19:09:34] [I] Idle time: 0ms
[03/27/2022-19:09:34] [I] Streams: 1
[03/27/2022-19:09:34] [I] ExposeDMA: Disabled
[03/27/2022-19:09:34] [I] Data transfers: Disabled
[03/27/2022-19:09:34] [I] Spin-wait: Disabled
[03/27/2022-19:09:34] [I] Multithreading: Disabled
[03/27/2022-19:09:34] [I] CUDA Graph: Enabled
[03/27/2022-19:09:34] [I] Separate profiling: Enabled
[03/27/2022-19:09:34] [I] Time Deserialize: Disabled
[03/27/2022-19:09:34] [I] Time Refit: Disabled
[03/27/2022-19:09:34] [I] Skip inference: Disabled
[03/27/2022-19:09:34] [I] Inputs:
[03/27/2022-19:09:34] [I] === Reporting Options ===
[03/27/2022-19:09:34] [I] Verbose: Enabled
[03/27/2022-19:09:34] [I] Averages: 10 inferences
[03/27/2022-19:09:34] [I] Percentile: 99
[03/27/2022-19:09:34] [I] Dump refittable layers:Disabled
[03/27/2022-19:09:34] [I] Dump output: Disabled
[03/27/2022-19:09:34] [I] Profile: Enabled
[03/27/2022-19:09:34] [I] Export timing to JSON file: 
[03/27/2022-19:09:34] [I] Export output to JSON file: 
[03/27/2022-19:09:34] [I] Export profile to JSON file: 
[03/27/2022-19:09:34] [I] 
[03/27/2022-19:09:34] [I] === Device Information ===
[03/27/2022-19:09:34] [I] Selected Device: NVIDIA TITAN Xp
[03/27/2022-19:09:34] [I] Compute Capability: 6.1
[03/27/2022-19:09:34] [I] SMs: 30
[03/27/2022-19:09:34] [I] Compute Clock Rate: 1.582 GHz
[03/27/2022-19:09:34] [I] Device Global Memory: 12193 MiB
[03/27/2022-19:09:34] [I] Shared Memory per SM: 96 KiB
[03/27/2022-19:09:34] [I] Memory Bus Width: 384 bits (ECC disabled)
[03/27/2022-19:09:34] [I] Memory Clock Rate: 5.705 GHz
[03/27/2022-19:09:34] [I] 
[03/27/2022-19:09:34] [I] TensorRT version: 8.4.0
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::Proposal version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::Split version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[03/27/2022-19:09:34] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 2
[03/27/2022-19:09:35] [I] [TRT] [MemUsageChange] Init CUDA: CPU +195, GPU +0, now: CPU 203, GPU 630 (MiB)
[03/27/2022-19:09:36] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 223 MiB, GPU 630 MiB
[03/27/2022-19:09:36] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 230 MiB, GPU 632 MiB
[03/27/2022-19:09:36] [I] Start parsing network model
[03/27/2022-19:09:37] [I] [TRT] ----------------------------------------------------------------
[03/27/2022-19:09:37] [I] [TRT] Input filename:   effnetb2.onnx
[03/27/2022-19:09:37] [I] [TRT] ONNX IR version:  0.0.7
[03/27/2022-19:09:37] [I] [TRT] Opset version:    11
[03/27/2022-19:09:37] [I] [TRT] Producer name:    pytorch
[03/27/2022-19:09:37] [I] [TRT] Producer version: 1.11
[03/27/2022-19:09:37] [I] [TRT] Domain:           
[03/27/2022-19:09:37] [I] [TRT] Model version:    0
[03/27/2022-19:09:37] [I] [TRT] Doc string:       
[03/27/2022-19:09:37] [I] [TRT] ----------------------------------------------------------------
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::Split version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[03/27/2022-19:09:38] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 2
[03/27/2022-19:09:38] [V] [TRT] Adding network input: x_orig with dtype: float32, dimensions: (4, 3, 1280, 720)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: x_orig for ONNX tensor: x_orig
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder1.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder1.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder1.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder1.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder1.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder1.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder1.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder1.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.2.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.2.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.2.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder2.2.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.2.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.2.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.2.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder3.2.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.2.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.2.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.2.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.2.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.3.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.3.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.3.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder4.3.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.2.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.2.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.2.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.2.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.3.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.3.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.3.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder5.3.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.2.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.2.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.2.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.2.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.3.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.3.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.3.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.3.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.4.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.4.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.4.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder6.4.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder7.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder7.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder7.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder7.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder7.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder7.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder7.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: encoder7.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: outconv1.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: outconv1.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: convfilter.box_filter.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: convfilter.conv_a.6.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: convfilter.compress.weight
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: convfilter.compress.bias
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1357
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1358
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1360
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1361
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1363
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1364
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1366
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1367
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1369
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1370
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1372
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1373
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1375
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1376
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1378
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1379
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1381
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1382
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1384
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1385
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1387
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1388
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1390
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1391
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1393
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1394
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1396
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1397
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1399
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1400
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1402
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1403
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1405
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1406
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1408
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1409
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1411
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1412
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1414
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1415
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1417
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1418
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1420
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1421
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1423
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1424
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1426
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1427
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1429
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1430
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1432
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1433
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1435
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1436
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1438
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1439
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1441
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1442
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1444
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1445
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1447
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1448
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1450
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1451
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1453
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1454
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1456
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1457
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1459
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1460
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1462
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1463
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1465
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1466
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1468
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1469
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1471
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1472
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1474
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1475
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1477
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1478
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1480
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1481
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1483
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1484
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1486
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1487
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1489
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1490
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1492
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1493
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1495
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1496
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1498
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1499
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1501
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1502
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1504
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1505
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1507
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1508
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1510
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1511
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1513
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1514
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1516
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1517
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1519
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1520
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1522
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1523
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1525
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1526
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1528
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1529
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1531
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1532
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1534
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1535
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1537
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1538
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1540
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1541
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1543
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1544
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1546
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1547
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1549
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1550
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1552
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1553
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1555
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1556
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1558
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1559
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1561
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1562
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1564
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1565
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1567
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1568
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1570
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1571
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1573
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1574
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1576
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1577
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1579
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1580
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1582
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1583
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1585
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1586
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1588
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1589
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1591
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1592
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1594
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1595
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1597
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1598
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1600
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1601
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1603
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1604
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1606
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1607
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1609
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1610
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1612
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1613
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1615
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1616
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1618
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1619
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1621
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1622
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1624
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1625
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1627
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1628
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1630
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1631
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1633
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1634
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1636
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1637
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1639
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1640
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1642
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1643
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1645
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1646
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1648
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1649
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1651
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1652
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1654
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1655
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1657
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1658
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1660
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1661
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1663
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1664
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1665
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1666
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1667
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1668
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1669
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1670
[03/27/2022-19:09:38] [V] [TRT] Importing initializer: 1671
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Shape_0 [Shape]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: x_orig
[03/27/2022-19:09:38] [V] [TRT] Shape_0 [Shape] inputs: [x_orig -> (4, 3, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Shape_0 for ONNX node: Shape_0
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 745 for ONNX tensor: 745
[03/27/2022-19:09:38] [V] [TRT] Shape_0 [Shape] outputs: [745 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_1 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_1 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_1 [Constant] outputs: [746 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_2 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_2 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_2 [Constant] outputs: [747 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_3 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_3 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_3 [Constant] outputs: [748 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Slice_4 [Slice]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 745
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 747
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 748
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 746
[03/27/2022-19:09:38] [V] [TRT] Slice_4 [Slice] inputs: [745 -> (4)[INT32]], [747 -> (1)[INT32]], [748 -> (1)[INT32]], [746 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Slice_4 for ONNX node: Slice_4
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 749 for ONNX tensor: 749
[03/27/2022-19:09:38] [V] [TRT] Slice_4 [Slice] outputs: [749 -> (2)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_5 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 749
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1665
[03/27/2022-19:09:38] [V] [TRT] Concat_5 [Concat] inputs: [749 -> (2)[INT32]], [1665 -> (2)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: 1665 for ONNX node: 1665
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_5 for ONNX node: Concat_5
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 751 for ONNX tensor: 751
[03/27/2022-19:09:38] [V] [TRT] Concat_5 [Concat] outputs: [751 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_6 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_6 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_6 [Constant] outputs: [752 -> ()[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_7 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_7 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_7 [Constant] outputs: [753 -> ()[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Resize_8 [Resize]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: x_orig
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 752
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 753
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 751
[03/27/2022-19:09:38] [V] [TRT] Resize_8 [Resize] inputs: [x_orig -> (4, 3, 1280, 720)[FLOAT]], [752 -> ()[FLOAT]], [753 -> ()[FLOAT]], [751 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Resize_8 for ONNX node: Resize_8
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 754 for ONNX tensor: 754
[03/27/2022-19:09:38] [V] [TRT] Resize_8 [Resize] outputs: [754 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_9 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 754
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1357
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1358
[03/27/2022-19:09:38] [V] [TRT] Conv_9 [Conv] inputs: [754 -> (4, 3, 256, 256)[FLOAT]], [1357 -> (32, 3, 3, 3)[FLOAT]], [1358 -> (32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_9 for ONNX node: Conv_9
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 32
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 32, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1356 for ONNX tensor: 1356
[03/27/2022-19:09:38] [V] [TRT] Conv_9 [Conv] outputs: [1356 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_10 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1356
[03/27/2022-19:09:38] [V] [TRT] Relu_10 [Relu] inputs: [1356 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_10 for ONNX node: Relu_10
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 757 for ONNX tensor: 757
[03/27/2022-19:09:38] [V] [TRT] Relu_10 [Relu] outputs: [757 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_11 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 757
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1360
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1361
[03/27/2022-19:09:38] [V] [TRT] Conv_11 [Conv] inputs: [757 -> (4, 32, 256, 256)[FLOAT]], [1360 -> (32, 1, 3, 3)[FLOAT]], [1361 -> (32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 32, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_11 for ONNX node: Conv_11
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 32
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 32, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1359 for ONNX tensor: 1359
[03/27/2022-19:09:38] [V] [TRT] Conv_11 [Conv] outputs: [1359 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_12 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1359
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_12 [Sigmoid] inputs: [1359 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_12 for ONNX node: Sigmoid_12
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 760 for ONNX tensor: 760
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_12 [Sigmoid] outputs: [760 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_13 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1359
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 760
[03/27/2022-19:09:38] [V] [TRT] Mul_13 [Mul] inputs: [1359 -> (4, 32, 256, 256)[FLOAT]], [760 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_13 for ONNX node: Mul_13
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 761 for ONNX tensor: 761
[03/27/2022-19:09:38] [V] [TRT] Mul_13 [Mul] outputs: [761 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_14 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 761
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_14 [ReduceMean] inputs: [761 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_14 for ONNX node: ReduceMean_14
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 762 for ONNX tensor: 762
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_14 [ReduceMean] outputs: [762 -> (4, 32, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_15 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 762
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder1.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder1.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_15 [Conv] inputs: [762 -> (4, 32, 1, 1)[FLOAT]], [encoder1.0.se.conv_reduce.weight -> (8, 32, 1, 1)[FLOAT]], [encoder1.0.se.conv_reduce.bias -> (8)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 32, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_15 for ONNX node: Conv_15
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 8
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 8, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 763 for ONNX tensor: 763
[03/27/2022-19:09:38] [V] [TRT] Conv_15 [Conv] outputs: [763 -> (4, 8, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_16 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 763
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_16 [Sigmoid] inputs: [763 -> (4, 8, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_16 for ONNX node: Sigmoid_16
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 764 for ONNX tensor: 764
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_16 [Sigmoid] outputs: [764 -> (4, 8, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_17 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 763
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 764
[03/27/2022-19:09:38] [V] [TRT] Mul_17 [Mul] inputs: [763 -> (4, 8, 1, 1)[FLOAT]], [764 -> (4, 8, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_17 for ONNX node: Mul_17
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 765 for ONNX tensor: 765
[03/27/2022-19:09:38] [V] [TRT] Mul_17 [Mul] outputs: [765 -> (4, 8, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_18 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 765
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder1.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder1.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_18 [Conv] inputs: [765 -> (4, 8, 1, 1)[FLOAT]], [encoder1.0.se.conv_expand.weight -> (32, 8, 1, 1)[FLOAT]], [encoder1.0.se.conv_expand.bias -> (32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 8, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_18 for ONNX node: Conv_18
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 32
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 32, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 766 for ONNX tensor: 766
[03/27/2022-19:09:38] [V] [TRT] Conv_18 [Conv] outputs: [766 -> (4, 32, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_19 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 766
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_19 [Sigmoid] inputs: [766 -> (4, 32, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_19 for ONNX node: Sigmoid_19
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 767 for ONNX tensor: 767
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_19 [Sigmoid] outputs: [767 -> (4, 32, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_20 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 761
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 767
[03/27/2022-19:09:38] [V] [TRT] Mul_20 [Mul] inputs: [761 -> (4, 32, 256, 256)[FLOAT]], [767 -> (4, 32, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_20 for ONNX node: Mul_20
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 768 for ONNX tensor: 768
[03/27/2022-19:09:38] [V] [TRT] Mul_20 [Mul] outputs: [768 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_21 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 768
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1363
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1364
[03/27/2022-19:09:38] [V] [TRT] Conv_21 [Conv] inputs: [768 -> (4, 32, 256, 256)[FLOAT]], [1363 -> (16, 32, 1, 1)[FLOAT]], [1364 -> (16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 32, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_21 for ONNX node: Conv_21
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 16
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1362 for ONNX tensor: 1362
[03/27/2022-19:09:38] [V] [TRT] Conv_21 [Conv] outputs: [1362 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_22 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1362
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1366
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1367
[03/27/2022-19:09:38] [V] [TRT] Conv_22 [Conv] inputs: [1362 -> (4, 16, 256, 256)[FLOAT]], [1366 -> (16, 1, 3, 3)[FLOAT]], [1367 -> (16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_22 for ONNX node: Conv_22
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 16
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1365 for ONNX tensor: 1365
[03/27/2022-19:09:38] [V] [TRT] Conv_22 [Conv] outputs: [1365 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_23 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1365
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_23 [Sigmoid] inputs: [1365 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_23 for ONNX node: Sigmoid_23
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 773 for ONNX tensor: 773
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_23 [Sigmoid] outputs: [773 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_24 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1365
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 773
[03/27/2022-19:09:38] [V] [TRT] Mul_24 [Mul] inputs: [1365 -> (4, 16, 256, 256)[FLOAT]], [773 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_24 for ONNX node: Mul_24
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 774 for ONNX tensor: 774
[03/27/2022-19:09:38] [V] [TRT] Mul_24 [Mul] outputs: [774 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_25 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 774
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_25 [ReduceMean] inputs: [774 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_25 for ONNX node: ReduceMean_25
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 775 for ONNX tensor: 775
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_25 [ReduceMean] outputs: [775 -> (4, 16, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_26 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 775
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder1.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder1.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_26 [Conv] inputs: [775 -> (4, 16, 1, 1)[FLOAT]], [encoder1.1.se.conv_reduce.weight -> (4, 16, 1, 1)[FLOAT]], [encoder1.1.se.conv_reduce.bias -> (4)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 16, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_26 for ONNX node: Conv_26
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 4
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 4, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 776 for ONNX tensor: 776
[03/27/2022-19:09:38] [V] [TRT] Conv_26 [Conv] outputs: [776 -> (4, 4, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_27 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 776
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_27 [Sigmoid] inputs: [776 -> (4, 4, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_27 for ONNX node: Sigmoid_27
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 777 for ONNX tensor: 777
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_27 [Sigmoid] outputs: [777 -> (4, 4, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_28 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 776
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 777
[03/27/2022-19:09:38] [V] [TRT] Mul_28 [Mul] inputs: [776 -> (4, 4, 1, 1)[FLOAT]], [777 -> (4, 4, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_28 for ONNX node: Mul_28
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 778 for ONNX tensor: 778
[03/27/2022-19:09:38] [V] [TRT] Mul_28 [Mul] outputs: [778 -> (4, 4, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_29 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 778
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder1.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder1.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_29 [Conv] inputs: [778 -> (4, 4, 1, 1)[FLOAT]], [encoder1.1.se.conv_expand.weight -> (16, 4, 1, 1)[FLOAT]], [encoder1.1.se.conv_expand.bias -> (16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 4, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_29 for ONNX node: Conv_29
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 16
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 16, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 779 for ONNX tensor: 779
[03/27/2022-19:09:38] [V] [TRT] Conv_29 [Conv] outputs: [779 -> (4, 16, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_30 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 779
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_30 [Sigmoid] inputs: [779 -> (4, 16, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_30 for ONNX node: Sigmoid_30
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 780 for ONNX tensor: 780
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_30 [Sigmoid] outputs: [780 -> (4, 16, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_31 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 774
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 780
[03/27/2022-19:09:38] [V] [TRT] Mul_31 [Mul] inputs: [774 -> (4, 16, 256, 256)[FLOAT]], [780 -> (4, 16, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_31 for ONNX node: Mul_31
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 781 for ONNX tensor: 781
[03/27/2022-19:09:38] [V] [TRT] Mul_31 [Mul] outputs: [781 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_32 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 781
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1369
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1370
[03/27/2022-19:09:38] [V] [TRT] Conv_32 [Conv] inputs: [781 -> (4, 16, 256, 256)[FLOAT]], [1369 -> (16, 16, 1, 1)[FLOAT]], [1370 -> (16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_32 for ONNX node: Conv_32
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 16
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1368 for ONNX tensor: 1368
[03/27/2022-19:09:38] [V] [TRT] Conv_32 [Conv] outputs: [1368 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_33 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1368
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1362
[03/27/2022-19:09:38] [V] [TRT] Add_33 [Add] inputs: [1368 -> (4, 16, 256, 256)[FLOAT]], [1362 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_33 for ONNX node: Add_33
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 784 for ONNX tensor: 784
[03/27/2022-19:09:38] [V] [TRT] Add_33 [Add] outputs: [784 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_34 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 784
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1372
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1373
[03/27/2022-19:09:38] [V] [TRT] Conv_34 [Conv] inputs: [784 -> (4, 16, 256, 256)[FLOAT]], [1372 -> (96, 16, 1, 1)[FLOAT]], [1373 -> (96)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_34 for ONNX node: Conv_34
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 96
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 96, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1371 for ONNX tensor: 1371
[03/27/2022-19:09:38] [V] [TRT] Conv_34 [Conv] outputs: [1371 -> (4, 96, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_35 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1371
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_35 [Sigmoid] inputs: [1371 -> (4, 96, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_35 for ONNX node: Sigmoid_35
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 787 for ONNX tensor: 787
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_35 [Sigmoid] outputs: [787 -> (4, 96, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_36 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1371
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 787
[03/27/2022-19:09:38] [V] [TRT] Mul_36 [Mul] inputs: [1371 -> (4, 96, 256, 256)[FLOAT]], [787 -> (4, 96, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_36 for ONNX node: Mul_36
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 788 for ONNX tensor: 788
[03/27/2022-19:09:38] [V] [TRT] Mul_36 [Mul] outputs: [788 -> (4, 96, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_37 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 788
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1375
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1376
[03/27/2022-19:09:38] [V] [TRT] Conv_37 [Conv] inputs: [788 -> (4, 96, 256, 256)[FLOAT]], [1375 -> (96, 1, 3, 3)[FLOAT]], [1376 -> (96)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 96, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_37 for ONNX node: Conv_37
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 96
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 96, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1374 for ONNX tensor: 1374
[03/27/2022-19:09:38] [V] [TRT] Conv_37 [Conv] outputs: [1374 -> (4, 96, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_38 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1374
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_38 [Sigmoid] inputs: [1374 -> (4, 96, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_38 for ONNX node: Sigmoid_38
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 791 for ONNX tensor: 791
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_38 [Sigmoid] outputs: [791 -> (4, 96, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_39 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1374
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 791
[03/27/2022-19:09:38] [V] [TRT] Mul_39 [Mul] inputs: [1374 -> (4, 96, 128, 128)[FLOAT]], [791 -> (4, 96, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_39 for ONNX node: Mul_39
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 792 for ONNX tensor: 792
[03/27/2022-19:09:38] [V] [TRT] Mul_39 [Mul] outputs: [792 -> (4, 96, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_40 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 792
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_40 [ReduceMean] inputs: [792 -> (4, 96, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_40 for ONNX node: ReduceMean_40
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 793 for ONNX tensor: 793
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_40 [ReduceMean] outputs: [793 -> (4, 96, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_41 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 793
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_41 [Conv] inputs: [793 -> (4, 96, 1, 1)[FLOAT]], [encoder2.0.se.conv_reduce.weight -> (4, 96, 1, 1)[FLOAT]], [encoder2.0.se.conv_reduce.bias -> (4)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 96, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_41 for ONNX node: Conv_41
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 4
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 4, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 794 for ONNX tensor: 794
[03/27/2022-19:09:38] [V] [TRT] Conv_41 [Conv] outputs: [794 -> (4, 4, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_42 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 794
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_42 [Sigmoid] inputs: [794 -> (4, 4, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_42 for ONNX node: Sigmoid_42
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 795 for ONNX tensor: 795
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_42 [Sigmoid] outputs: [795 -> (4, 4, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_43 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 794
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 795
[03/27/2022-19:09:38] [V] [TRT] Mul_43 [Mul] inputs: [794 -> (4, 4, 1, 1)[FLOAT]], [795 -> (4, 4, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_43 for ONNX node: Mul_43
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 796 for ONNX tensor: 796
[03/27/2022-19:09:38] [V] [TRT] Mul_43 [Mul] outputs: [796 -> (4, 4, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_44 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 796
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_44 [Conv] inputs: [796 -> (4, 4, 1, 1)[FLOAT]], [encoder2.0.se.conv_expand.weight -> (96, 4, 1, 1)[FLOAT]], [encoder2.0.se.conv_expand.bias -> (96)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 4, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_44 for ONNX node: Conv_44
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 96
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 96, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 797 for ONNX tensor: 797
[03/27/2022-19:09:38] [V] [TRT] Conv_44 [Conv] outputs: [797 -> (4, 96, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_45 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 797
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_45 [Sigmoid] inputs: [797 -> (4, 96, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_45 for ONNX node: Sigmoid_45
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 798 for ONNX tensor: 798
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_45 [Sigmoid] outputs: [798 -> (4, 96, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_46 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 792
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 798
[03/27/2022-19:09:38] [V] [TRT] Mul_46 [Mul] inputs: [792 -> (4, 96, 128, 128)[FLOAT]], [798 -> (4, 96, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_46 for ONNX node: Mul_46
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 799 for ONNX tensor: 799
[03/27/2022-19:09:38] [V] [TRT] Mul_46 [Mul] outputs: [799 -> (4, 96, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_47 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 799
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1378
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1379
[03/27/2022-19:09:38] [V] [TRT] Conv_47 [Conv] inputs: [799 -> (4, 96, 128, 128)[FLOAT]], [1378 -> (24, 96, 1, 1)[FLOAT]], [1379 -> (24)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 96, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_47 for ONNX node: Conv_47
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 24
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 24, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1377 for ONNX tensor: 1377
[03/27/2022-19:09:38] [V] [TRT] Conv_47 [Conv] outputs: [1377 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_48 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1377
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1381
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1382
[03/27/2022-19:09:38] [V] [TRT] Conv_48 [Conv] inputs: [1377 -> (4, 24, 128, 128)[FLOAT]], [1381 -> (144, 24, 1, 1)[FLOAT]], [1382 -> (144)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 24, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_48 for ONNX node: Conv_48
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 144
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 144, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1380 for ONNX tensor: 1380
[03/27/2022-19:09:38] [V] [TRT] Conv_48 [Conv] outputs: [1380 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_49 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1380
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_49 [Sigmoid] inputs: [1380 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_49 for ONNX node: Sigmoid_49
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 804 for ONNX tensor: 804
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_49 [Sigmoid] outputs: [804 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_50 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1380
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 804
[03/27/2022-19:09:38] [V] [TRT] Mul_50 [Mul] inputs: [1380 -> (4, 144, 128, 128)[FLOAT]], [804 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_50 for ONNX node: Mul_50
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 805 for ONNX tensor: 805
[03/27/2022-19:09:38] [V] [TRT] Mul_50 [Mul] outputs: [805 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_51 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 805
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1384
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1385
[03/27/2022-19:09:38] [V] [TRT] Conv_51 [Conv] inputs: [805 -> (4, 144, 128, 128)[FLOAT]], [1384 -> (144, 1, 3, 3)[FLOAT]], [1385 -> (144)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 144, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_51 for ONNX node: Conv_51
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 144
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 144, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1383 for ONNX tensor: 1383
[03/27/2022-19:09:38] [V] [TRT] Conv_51 [Conv] outputs: [1383 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_52 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1383
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_52 [Sigmoid] inputs: [1383 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_52 for ONNX node: Sigmoid_52
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 808 for ONNX tensor: 808
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_52 [Sigmoid] outputs: [808 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_53 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1383
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 808
[03/27/2022-19:09:38] [V] [TRT] Mul_53 [Mul] inputs: [1383 -> (4, 144, 128, 128)[FLOAT]], [808 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_53 for ONNX node: Mul_53
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 809 for ONNX tensor: 809
[03/27/2022-19:09:38] [V] [TRT] Mul_53 [Mul] outputs: [809 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_54 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 809
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_54 [ReduceMean] inputs: [809 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_54 for ONNX node: ReduceMean_54
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 810 for ONNX tensor: 810
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_54 [ReduceMean] outputs: [810 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_55 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 810
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_55 [Conv] inputs: [810 -> (4, 144, 1, 1)[FLOAT]], [encoder2.1.se.conv_reduce.weight -> (6, 144, 1, 1)[FLOAT]], [encoder2.1.se.conv_reduce.bias -> (6)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 144, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_55 for ONNX node: Conv_55
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 6
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 6, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 811 for ONNX tensor: 811
[03/27/2022-19:09:38] [V] [TRT] Conv_55 [Conv] outputs: [811 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_56 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 811
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_56 [Sigmoid] inputs: [811 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_56 for ONNX node: Sigmoid_56
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 812 for ONNX tensor: 812
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_56 [Sigmoid] outputs: [812 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_57 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 811
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 812
[03/27/2022-19:09:38] [V] [TRT] Mul_57 [Mul] inputs: [811 -> (4, 6, 1, 1)[FLOAT]], [812 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_57 for ONNX node: Mul_57
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 813 for ONNX tensor: 813
[03/27/2022-19:09:38] [V] [TRT] Mul_57 [Mul] outputs: [813 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_58 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 813
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_58 [Conv] inputs: [813 -> (4, 6, 1, 1)[FLOAT]], [encoder2.1.se.conv_expand.weight -> (144, 6, 1, 1)[FLOAT]], [encoder2.1.se.conv_expand.bias -> (144)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 6, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_58 for ONNX node: Conv_58
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 144
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 144, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 814 for ONNX tensor: 814
[03/27/2022-19:09:38] [V] [TRT] Conv_58 [Conv] outputs: [814 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_59 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 814
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_59 [Sigmoid] inputs: [814 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_59 for ONNX node: Sigmoid_59
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 815 for ONNX tensor: 815
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_59 [Sigmoid] outputs: [815 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_60 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 809
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 815
[03/27/2022-19:09:38] [V] [TRT] Mul_60 [Mul] inputs: [809 -> (4, 144, 128, 128)[FLOAT]], [815 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_60 for ONNX node: Mul_60
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 816 for ONNX tensor: 816
[03/27/2022-19:09:38] [V] [TRT] Mul_60 [Mul] outputs: [816 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_61 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 816
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1387
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1388
[03/27/2022-19:09:38] [V] [TRT] Conv_61 [Conv] inputs: [816 -> (4, 144, 128, 128)[FLOAT]], [1387 -> (24, 144, 1, 1)[FLOAT]], [1388 -> (24)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 144, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_61 for ONNX node: Conv_61
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 24
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 24, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1386 for ONNX tensor: 1386
[03/27/2022-19:09:38] [V] [TRT] Conv_61 [Conv] outputs: [1386 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_62 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1386
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1377
[03/27/2022-19:09:38] [V] [TRT] Add_62 [Add] inputs: [1386 -> (4, 24, 128, 128)[FLOAT]], [1377 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_62 for ONNX node: Add_62
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 819 for ONNX tensor: 819
[03/27/2022-19:09:38] [V] [TRT] Add_62 [Add] outputs: [819 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_63 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 819
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1390
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1391
[03/27/2022-19:09:38] [V] [TRT] Conv_63 [Conv] inputs: [819 -> (4, 24, 128, 128)[FLOAT]], [1390 -> (144, 24, 1, 1)[FLOAT]], [1391 -> (144)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 24, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_63 for ONNX node: Conv_63
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 144
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 144, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1389 for ONNX tensor: 1389
[03/27/2022-19:09:38] [V] [TRT] Conv_63 [Conv] outputs: [1389 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_64 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1389
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_64 [Sigmoid] inputs: [1389 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_64 for ONNX node: Sigmoid_64
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 822 for ONNX tensor: 822
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_64 [Sigmoid] outputs: [822 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_65 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1389
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 822
[03/27/2022-19:09:38] [V] [TRT] Mul_65 [Mul] inputs: [1389 -> (4, 144, 128, 128)[FLOAT]], [822 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_65 for ONNX node: Mul_65
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 823 for ONNX tensor: 823
[03/27/2022-19:09:38] [V] [TRT] Mul_65 [Mul] outputs: [823 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_66 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 823
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1393
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1394
[03/27/2022-19:09:38] [V] [TRT] Conv_66 [Conv] inputs: [823 -> (4, 144, 128, 128)[FLOAT]], [1393 -> (144, 1, 3, 3)[FLOAT]], [1394 -> (144)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 144, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_66 for ONNX node: Conv_66
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 144
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 144, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1392 for ONNX tensor: 1392
[03/27/2022-19:09:38] [V] [TRT] Conv_66 [Conv] outputs: [1392 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_67 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1392
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_67 [Sigmoid] inputs: [1392 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_67 for ONNX node: Sigmoid_67
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 826 for ONNX tensor: 826
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_67 [Sigmoid] outputs: [826 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_68 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1392
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 826
[03/27/2022-19:09:38] [V] [TRT] Mul_68 [Mul] inputs: [1392 -> (4, 144, 128, 128)[FLOAT]], [826 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_68 for ONNX node: Mul_68
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 827 for ONNX tensor: 827
[03/27/2022-19:09:38] [V] [TRT] Mul_68 [Mul] outputs: [827 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_69 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 827
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_69 [ReduceMean] inputs: [827 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_69 for ONNX node: ReduceMean_69
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 828 for ONNX tensor: 828
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_69 [ReduceMean] outputs: [828 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_70 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 828
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.2.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.2.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_70 [Conv] inputs: [828 -> (4, 144, 1, 1)[FLOAT]], [encoder2.2.se.conv_reduce.weight -> (6, 144, 1, 1)[FLOAT]], [encoder2.2.se.conv_reduce.bias -> (6)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 144, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_70 for ONNX node: Conv_70
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 6
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 6, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 829 for ONNX tensor: 829
[03/27/2022-19:09:38] [V] [TRT] Conv_70 [Conv] outputs: [829 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_71 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 829
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_71 [Sigmoid] inputs: [829 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_71 for ONNX node: Sigmoid_71
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 830 for ONNX tensor: 830
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_71 [Sigmoid] outputs: [830 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_72 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 829
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 830
[03/27/2022-19:09:38] [V] [TRT] Mul_72 [Mul] inputs: [829 -> (4, 6, 1, 1)[FLOAT]], [830 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_72 for ONNX node: Mul_72
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 831 for ONNX tensor: 831
[03/27/2022-19:09:38] [V] [TRT] Mul_72 [Mul] outputs: [831 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_73 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 831
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.2.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder2.2.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_73 [Conv] inputs: [831 -> (4, 6, 1, 1)[FLOAT]], [encoder2.2.se.conv_expand.weight -> (144, 6, 1, 1)[FLOAT]], [encoder2.2.se.conv_expand.bias -> (144)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 6, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_73 for ONNX node: Conv_73
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 144
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 144, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 832 for ONNX tensor: 832
[03/27/2022-19:09:38] [V] [TRT] Conv_73 [Conv] outputs: [832 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_74 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 832
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_74 [Sigmoid] inputs: [832 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_74 for ONNX node: Sigmoid_74
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 833 for ONNX tensor: 833
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_74 [Sigmoid] outputs: [833 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_75 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 827
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 833
[03/27/2022-19:09:38] [V] [TRT] Mul_75 [Mul] inputs: [827 -> (4, 144, 128, 128)[FLOAT]], [833 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_75 for ONNX node: Mul_75
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 834 for ONNX tensor: 834
[03/27/2022-19:09:38] [V] [TRT] Mul_75 [Mul] outputs: [834 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_76 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 834
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1396
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1397
[03/27/2022-19:09:38] [V] [TRT] Conv_76 [Conv] inputs: [834 -> (4, 144, 128, 128)[FLOAT]], [1396 -> (24, 144, 1, 1)[FLOAT]], [1397 -> (24)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 144, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_76 for ONNX node: Conv_76
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 24
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 24, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1395 for ONNX tensor: 1395
[03/27/2022-19:09:38] [V] [TRT] Conv_76 [Conv] outputs: [1395 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_77 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1395
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 819
[03/27/2022-19:09:38] [V] [TRT] Add_77 [Add] inputs: [1395 -> (4, 24, 128, 128)[FLOAT]], [819 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_77 for ONNX node: Add_77
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 837 for ONNX tensor: 837
[03/27/2022-19:09:38] [V] [TRT] Add_77 [Add] outputs: [837 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_78 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 837
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1399
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1400
[03/27/2022-19:09:38] [V] [TRT] Conv_78 [Conv] inputs: [837 -> (4, 24, 128, 128)[FLOAT]], [1399 -> (144, 24, 1, 1)[FLOAT]], [1400 -> (144)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 24, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_78 for ONNX node: Conv_78
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 144
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 144, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1398 for ONNX tensor: 1398
[03/27/2022-19:09:38] [V] [TRT] Conv_78 [Conv] outputs: [1398 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_79 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1398
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_79 [Sigmoid] inputs: [1398 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_79 for ONNX node: Sigmoid_79
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 840 for ONNX tensor: 840
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_79 [Sigmoid] outputs: [840 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_80 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1398
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 840
[03/27/2022-19:09:38] [V] [TRT] Mul_80 [Mul] inputs: [1398 -> (4, 144, 128, 128)[FLOAT]], [840 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_80 for ONNX node: Mul_80
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 841 for ONNX tensor: 841
[03/27/2022-19:09:38] [V] [TRT] Mul_80 [Mul] outputs: [841 -> (4, 144, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_81 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 841
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1402
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1403
[03/27/2022-19:09:38] [V] [TRT] Conv_81 [Conv] inputs: [841 -> (4, 144, 128, 128)[FLOAT]], [1402 -> (144, 1, 5, 5)[FLOAT]], [1403 -> (144)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 144, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_81 for ONNX node: Conv_81
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (2, 2), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 144
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 144, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1401 for ONNX tensor: 1401
[03/27/2022-19:09:38] [V] [TRT] Conv_81 [Conv] outputs: [1401 -> (4, 144, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_82 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1401
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_82 [Sigmoid] inputs: [1401 -> (4, 144, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_82 for ONNX node: Sigmoid_82
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 844 for ONNX tensor: 844
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_82 [Sigmoid] outputs: [844 -> (4, 144, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_83 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1401
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 844
[03/27/2022-19:09:38] [V] [TRT] Mul_83 [Mul] inputs: [1401 -> (4, 144, 64, 64)[FLOAT]], [844 -> (4, 144, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_83 for ONNX node: Mul_83
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 845 for ONNX tensor: 845
[03/27/2022-19:09:38] [V] [TRT] Mul_83 [Mul] outputs: [845 -> (4, 144, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_84 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 845
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_84 [ReduceMean] inputs: [845 -> (4, 144, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_84 for ONNX node: ReduceMean_84
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 846 for ONNX tensor: 846
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_84 [ReduceMean] outputs: [846 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_85 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 846
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_85 [Conv] inputs: [846 -> (4, 144, 1, 1)[FLOAT]], [encoder3.0.se.conv_reduce.weight -> (6, 144, 1, 1)[FLOAT]], [encoder3.0.se.conv_reduce.bias -> (6)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 144, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_85 for ONNX node: Conv_85
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 6
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 6, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 847 for ONNX tensor: 847
[03/27/2022-19:09:38] [V] [TRT] Conv_85 [Conv] outputs: [847 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_86 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 847
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_86 [Sigmoid] inputs: [847 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_86 for ONNX node: Sigmoid_86
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 848 for ONNX tensor: 848
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_86 [Sigmoid] outputs: [848 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_87 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 847
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 848
[03/27/2022-19:09:38] [V] [TRT] Mul_87 [Mul] inputs: [847 -> (4, 6, 1, 1)[FLOAT]], [848 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_87 for ONNX node: Mul_87
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 849 for ONNX tensor: 849
[03/27/2022-19:09:38] [V] [TRT] Mul_87 [Mul] outputs: [849 -> (4, 6, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_88 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 849
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_88 [Conv] inputs: [849 -> (4, 6, 1, 1)[FLOAT]], [encoder3.0.se.conv_expand.weight -> (144, 6, 1, 1)[FLOAT]], [encoder3.0.se.conv_expand.bias -> (144)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 6, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_88 for ONNX node: Conv_88
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 144
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 144, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 850 for ONNX tensor: 850
[03/27/2022-19:09:38] [V] [TRT] Conv_88 [Conv] outputs: [850 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_89 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 850
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_89 [Sigmoid] inputs: [850 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_89 for ONNX node: Sigmoid_89
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 851 for ONNX tensor: 851
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_89 [Sigmoid] outputs: [851 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_90 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 845
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 851
[03/27/2022-19:09:38] [V] [TRT] Mul_90 [Mul] inputs: [845 -> (4, 144, 64, 64)[FLOAT]], [851 -> (4, 144, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_90 for ONNX node: Mul_90
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 852 for ONNX tensor: 852
[03/27/2022-19:09:38] [V] [TRT] Mul_90 [Mul] outputs: [852 -> (4, 144, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_91 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 852
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1405
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1406
[03/27/2022-19:09:38] [V] [TRT] Conv_91 [Conv] inputs: [852 -> (4, 144, 64, 64)[FLOAT]], [1405 -> (48, 144, 1, 1)[FLOAT]], [1406 -> (48)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 144, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_91 for ONNX node: Conv_91
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 48
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 48, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1404 for ONNX tensor: 1404
[03/27/2022-19:09:38] [V] [TRT] Conv_91 [Conv] outputs: [1404 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_92 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1404
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1408
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1409
[03/27/2022-19:09:38] [V] [TRT] Conv_92 [Conv] inputs: [1404 -> (4, 48, 64, 64)[FLOAT]], [1408 -> (288, 48, 1, 1)[FLOAT]], [1409 -> (288)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 48, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_92 for ONNX node: Conv_92
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 288
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 288, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1407 for ONNX tensor: 1407
[03/27/2022-19:09:38] [V] [TRT] Conv_92 [Conv] outputs: [1407 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_93 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1407
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_93 [Sigmoid] inputs: [1407 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_93 for ONNX node: Sigmoid_93
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 857 for ONNX tensor: 857
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_93 [Sigmoid] outputs: [857 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_94 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1407
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 857
[03/27/2022-19:09:38] [V] [TRT] Mul_94 [Mul] inputs: [1407 -> (4, 288, 64, 64)[FLOAT]], [857 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_94 for ONNX node: Mul_94
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 858 for ONNX tensor: 858
[03/27/2022-19:09:38] [V] [TRT] Mul_94 [Mul] outputs: [858 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_95 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 858
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1411
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1412
[03/27/2022-19:09:38] [V] [TRT] Conv_95 [Conv] inputs: [858 -> (4, 288, 64, 64)[FLOAT]], [1411 -> (288, 1, 5, 5)[FLOAT]], [1412 -> (288)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 288, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_95 for ONNX node: Conv_95
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 288
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 288, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1410 for ONNX tensor: 1410
[03/27/2022-19:09:38] [V] [TRT] Conv_95 [Conv] outputs: [1410 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_96 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1410
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_96 [Sigmoid] inputs: [1410 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_96 for ONNX node: Sigmoid_96
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 861 for ONNX tensor: 861
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_96 [Sigmoid] outputs: [861 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_97 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1410
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 861
[03/27/2022-19:09:38] [V] [TRT] Mul_97 [Mul] inputs: [1410 -> (4, 288, 64, 64)[FLOAT]], [861 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_97 for ONNX node: Mul_97
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 862 for ONNX tensor: 862
[03/27/2022-19:09:38] [V] [TRT] Mul_97 [Mul] outputs: [862 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_98 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 862
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_98 [ReduceMean] inputs: [862 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_98 for ONNX node: ReduceMean_98
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 863 for ONNX tensor: 863
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_98 [ReduceMean] outputs: [863 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_99 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 863
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_99 [Conv] inputs: [863 -> (4, 288, 1, 1)[FLOAT]], [encoder3.1.se.conv_reduce.weight -> (12, 288, 1, 1)[FLOAT]], [encoder3.1.se.conv_reduce.bias -> (12)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 288, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_99 for ONNX node: Conv_99
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 12
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 12, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 864 for ONNX tensor: 864
[03/27/2022-19:09:38] [V] [TRT] Conv_99 [Conv] outputs: [864 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_100 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 864
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_100 [Sigmoid] inputs: [864 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_100 for ONNX node: Sigmoid_100
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 865 for ONNX tensor: 865
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_100 [Sigmoid] outputs: [865 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_101 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 864
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 865
[03/27/2022-19:09:38] [V] [TRT] Mul_101 [Mul] inputs: [864 -> (4, 12, 1, 1)[FLOAT]], [865 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_101 for ONNX node: Mul_101
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 866 for ONNX tensor: 866
[03/27/2022-19:09:38] [V] [TRT] Mul_101 [Mul] outputs: [866 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_102 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 866
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_102 [Conv] inputs: [866 -> (4, 12, 1, 1)[FLOAT]], [encoder3.1.se.conv_expand.weight -> (288, 12, 1, 1)[FLOAT]], [encoder3.1.se.conv_expand.bias -> (288)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 12, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_102 for ONNX node: Conv_102
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 288
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 288, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 867 for ONNX tensor: 867
[03/27/2022-19:09:38] [V] [TRT] Conv_102 [Conv] outputs: [867 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_103 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 867
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_103 [Sigmoid] inputs: [867 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_103 for ONNX node: Sigmoid_103
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 868 for ONNX tensor: 868
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_103 [Sigmoid] outputs: [868 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_104 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 862
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 868
[03/27/2022-19:09:38] [V] [TRT] Mul_104 [Mul] inputs: [862 -> (4, 288, 64, 64)[FLOAT]], [868 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_104 for ONNX node: Mul_104
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 869 for ONNX tensor: 869
[03/27/2022-19:09:38] [V] [TRT] Mul_104 [Mul] outputs: [869 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_105 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 869
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1414
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1415
[03/27/2022-19:09:38] [V] [TRT] Conv_105 [Conv] inputs: [869 -> (4, 288, 64, 64)[FLOAT]], [1414 -> (48, 288, 1, 1)[FLOAT]], [1415 -> (48)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 288, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_105 for ONNX node: Conv_105
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 48
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 48, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1413 for ONNX tensor: 1413
[03/27/2022-19:09:38] [V] [TRT] Conv_105 [Conv] outputs: [1413 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_106 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1413
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1404
[03/27/2022-19:09:38] [V] [TRT] Add_106 [Add] inputs: [1413 -> (4, 48, 64, 64)[FLOAT]], [1404 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_106 for ONNX node: Add_106
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 872 for ONNX tensor: 872
[03/27/2022-19:09:38] [V] [TRT] Add_106 [Add] outputs: [872 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_107 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 872
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1417
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1418
[03/27/2022-19:09:38] [V] [TRT] Conv_107 [Conv] inputs: [872 -> (4, 48, 64, 64)[FLOAT]], [1417 -> (288, 48, 1, 1)[FLOAT]], [1418 -> (288)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 48, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_107 for ONNX node: Conv_107
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 288
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 288, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1416 for ONNX tensor: 1416
[03/27/2022-19:09:38] [V] [TRT] Conv_107 [Conv] outputs: [1416 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_108 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1416
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_108 [Sigmoid] inputs: [1416 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_108 for ONNX node: Sigmoid_108
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 875 for ONNX tensor: 875
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_108 [Sigmoid] outputs: [875 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_109 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1416
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 875
[03/27/2022-19:09:38] [V] [TRT] Mul_109 [Mul] inputs: [1416 -> (4, 288, 64, 64)[FLOAT]], [875 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_109 for ONNX node: Mul_109
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 876 for ONNX tensor: 876
[03/27/2022-19:09:38] [V] [TRT] Mul_109 [Mul] outputs: [876 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_110 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 876
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1420
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1421
[03/27/2022-19:09:38] [V] [TRT] Conv_110 [Conv] inputs: [876 -> (4, 288, 64, 64)[FLOAT]], [1420 -> (288, 1, 5, 5)[FLOAT]], [1421 -> (288)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 288, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_110 for ONNX node: Conv_110
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 288
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 288, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1419 for ONNX tensor: 1419
[03/27/2022-19:09:38] [V] [TRT] Conv_110 [Conv] outputs: [1419 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_111 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1419
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_111 [Sigmoid] inputs: [1419 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_111 for ONNX node: Sigmoid_111
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 879 for ONNX tensor: 879
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_111 [Sigmoid] outputs: [879 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_112 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1419
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 879
[03/27/2022-19:09:38] [V] [TRT] Mul_112 [Mul] inputs: [1419 -> (4, 288, 64, 64)[FLOAT]], [879 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_112 for ONNX node: Mul_112
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 880 for ONNX tensor: 880
[03/27/2022-19:09:38] [V] [TRT] Mul_112 [Mul] outputs: [880 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_113 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 880
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_113 [ReduceMean] inputs: [880 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_113 for ONNX node: ReduceMean_113
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 881 for ONNX tensor: 881
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_113 [ReduceMean] outputs: [881 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_114 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 881
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.2.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.2.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_114 [Conv] inputs: [881 -> (4, 288, 1, 1)[FLOAT]], [encoder3.2.se.conv_reduce.weight -> (12, 288, 1, 1)[FLOAT]], [encoder3.2.se.conv_reduce.bias -> (12)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 288, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_114 for ONNX node: Conv_114
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 12
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 12, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 882 for ONNX tensor: 882
[03/27/2022-19:09:38] [V] [TRT] Conv_114 [Conv] outputs: [882 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_115 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 882
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_115 [Sigmoid] inputs: [882 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_115 for ONNX node: Sigmoid_115
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 883 for ONNX tensor: 883
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_115 [Sigmoid] outputs: [883 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_116 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 882
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 883
[03/27/2022-19:09:38] [V] [TRT] Mul_116 [Mul] inputs: [882 -> (4, 12, 1, 1)[FLOAT]], [883 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_116 for ONNX node: Mul_116
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 884 for ONNX tensor: 884
[03/27/2022-19:09:38] [V] [TRT] Mul_116 [Mul] outputs: [884 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_117 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 884
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.2.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder3.2.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_117 [Conv] inputs: [884 -> (4, 12, 1, 1)[FLOAT]], [encoder3.2.se.conv_expand.weight -> (288, 12, 1, 1)[FLOAT]], [encoder3.2.se.conv_expand.bias -> (288)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 12, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_117 for ONNX node: Conv_117
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 288
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 288, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 885 for ONNX tensor: 885
[03/27/2022-19:09:38] [V] [TRT] Conv_117 [Conv] outputs: [885 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_118 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 885
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_118 [Sigmoid] inputs: [885 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_118 for ONNX node: Sigmoid_118
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 886 for ONNX tensor: 886
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_118 [Sigmoid] outputs: [886 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_119 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 880
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 886
[03/27/2022-19:09:38] [V] [TRT] Mul_119 [Mul] inputs: [880 -> (4, 288, 64, 64)[FLOAT]], [886 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_119 for ONNX node: Mul_119
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 887 for ONNX tensor: 887
[03/27/2022-19:09:38] [V] [TRT] Mul_119 [Mul] outputs: [887 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_120 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 887
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1423
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1424
[03/27/2022-19:09:38] [V] [TRT] Conv_120 [Conv] inputs: [887 -> (4, 288, 64, 64)[FLOAT]], [1423 -> (48, 288, 1, 1)[FLOAT]], [1424 -> (48)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 288, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_120 for ONNX node: Conv_120
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 48
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 48, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1422 for ONNX tensor: 1422
[03/27/2022-19:09:38] [V] [TRT] Conv_120 [Conv] outputs: [1422 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_121 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1422
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 872
[03/27/2022-19:09:38] [V] [TRT] Add_121 [Add] inputs: [1422 -> (4, 48, 64, 64)[FLOAT]], [872 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_121 for ONNX node: Add_121
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 890 for ONNX tensor: 890
[03/27/2022-19:09:38] [V] [TRT] Add_121 [Add] outputs: [890 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_122 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 890
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1426
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1427
[03/27/2022-19:09:38] [V] [TRT] Conv_122 [Conv] inputs: [890 -> (4, 48, 64, 64)[FLOAT]], [1426 -> (288, 48, 1, 1)[FLOAT]], [1427 -> (288)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 48, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_122 for ONNX node: Conv_122
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 288
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 288, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1425 for ONNX tensor: 1425
[03/27/2022-19:09:38] [V] [TRT] Conv_122 [Conv] outputs: [1425 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_123 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1425
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_123 [Sigmoid] inputs: [1425 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_123 for ONNX node: Sigmoid_123
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 893 for ONNX tensor: 893
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_123 [Sigmoid] outputs: [893 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_124 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1425
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 893
[03/27/2022-19:09:38] [V] [TRT] Mul_124 [Mul] inputs: [1425 -> (4, 288, 64, 64)[FLOAT]], [893 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_124 for ONNX node: Mul_124
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 894 for ONNX tensor: 894
[03/27/2022-19:09:38] [V] [TRT] Mul_124 [Mul] outputs: [894 -> (4, 288, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_125 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 894
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1429
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1430
[03/27/2022-19:09:38] [V] [TRT] Conv_125 [Conv] inputs: [894 -> (4, 288, 64, 64)[FLOAT]], [1429 -> (288, 1, 3, 3)[FLOAT]], [1430 -> (288)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 288, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_125 for ONNX node: Conv_125
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 288
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 288, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1428 for ONNX tensor: 1428
[03/27/2022-19:09:38] [V] [TRT] Conv_125 [Conv] outputs: [1428 -> (4, 288, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_126 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1428
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_126 [Sigmoid] inputs: [1428 -> (4, 288, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_126 for ONNX node: Sigmoid_126
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 897 for ONNX tensor: 897
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_126 [Sigmoid] outputs: [897 -> (4, 288, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_127 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1428
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 897
[03/27/2022-19:09:38] [V] [TRT] Mul_127 [Mul] inputs: [1428 -> (4, 288, 32, 32)[FLOAT]], [897 -> (4, 288, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_127 for ONNX node: Mul_127
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 898 for ONNX tensor: 898
[03/27/2022-19:09:38] [V] [TRT] Mul_127 [Mul] outputs: [898 -> (4, 288, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_128 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 898
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_128 [ReduceMean] inputs: [898 -> (4, 288, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_128 for ONNX node: ReduceMean_128
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 899 for ONNX tensor: 899
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_128 [ReduceMean] outputs: [899 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_129 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 899
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_129 [Conv] inputs: [899 -> (4, 288, 1, 1)[FLOAT]], [encoder4.0.se.conv_reduce.weight -> (12, 288, 1, 1)[FLOAT]], [encoder4.0.se.conv_reduce.bias -> (12)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 288, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_129 for ONNX node: Conv_129
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 12
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 12, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 900 for ONNX tensor: 900
[03/27/2022-19:09:38] [V] [TRT] Conv_129 [Conv] outputs: [900 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_130 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 900
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_130 [Sigmoid] inputs: [900 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_130 for ONNX node: Sigmoid_130
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 901 for ONNX tensor: 901
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_130 [Sigmoid] outputs: [901 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_131 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 900
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 901
[03/27/2022-19:09:38] [V] [TRT] Mul_131 [Mul] inputs: [900 -> (4, 12, 1, 1)[FLOAT]], [901 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_131 for ONNX node: Mul_131
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 902 for ONNX tensor: 902
[03/27/2022-19:09:38] [V] [TRT] Mul_131 [Mul] outputs: [902 -> (4, 12, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_132 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 902
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_132 [Conv] inputs: [902 -> (4, 12, 1, 1)[FLOAT]], [encoder4.0.se.conv_expand.weight -> (288, 12, 1, 1)[FLOAT]], [encoder4.0.se.conv_expand.bias -> (288)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 12, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_132 for ONNX node: Conv_132
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 288
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 288, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 903 for ONNX tensor: 903
[03/27/2022-19:09:38] [V] [TRT] Conv_132 [Conv] outputs: [903 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_133 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 903
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_133 [Sigmoid] inputs: [903 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_133 for ONNX node: Sigmoid_133
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 904 for ONNX tensor: 904
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_133 [Sigmoid] outputs: [904 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_134 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 898
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 904
[03/27/2022-19:09:38] [V] [TRT] Mul_134 [Mul] inputs: [898 -> (4, 288, 32, 32)[FLOAT]], [904 -> (4, 288, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_134 for ONNX node: Mul_134
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 905 for ONNX tensor: 905
[03/27/2022-19:09:38] [V] [TRT] Mul_134 [Mul] outputs: [905 -> (4, 288, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_135 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 905
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1432
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1433
[03/27/2022-19:09:38] [V] [TRT] Conv_135 [Conv] inputs: [905 -> (4, 288, 32, 32)[FLOAT]], [1432 -> (88, 288, 1, 1)[FLOAT]], [1433 -> (88)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 288, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_135 for ONNX node: Conv_135
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 88
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 88, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1431 for ONNX tensor: 1431
[03/27/2022-19:09:38] [V] [TRT] Conv_135 [Conv] outputs: [1431 -> (4, 88, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_136 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1431
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1435
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1436
[03/27/2022-19:09:38] [V] [TRT] Conv_136 [Conv] inputs: [1431 -> (4, 88, 32, 32)[FLOAT]], [1435 -> (528, 88, 1, 1)[FLOAT]], [1436 -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 88, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_136 for ONNX node: Conv_136
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1434 for ONNX tensor: 1434
[03/27/2022-19:09:38] [V] [TRT] Conv_136 [Conv] outputs: [1434 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_137 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1434
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_137 [Sigmoid] inputs: [1434 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_137 for ONNX node: Sigmoid_137
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 910 for ONNX tensor: 910
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_137 [Sigmoid] outputs: [910 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_138 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1434
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 910
[03/27/2022-19:09:38] [V] [TRT] Mul_138 [Mul] inputs: [1434 -> (4, 528, 32, 32)[FLOAT]], [910 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_138 for ONNX node: Mul_138
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 911 for ONNX tensor: 911
[03/27/2022-19:09:38] [V] [TRT] Mul_138 [Mul] outputs: [911 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_139 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 911
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1438
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1439
[03/27/2022-19:09:38] [V] [TRT] Conv_139 [Conv] inputs: [911 -> (4, 528, 32, 32)[FLOAT]], [1438 -> (528, 1, 3, 3)[FLOAT]], [1439 -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_139 for ONNX node: Conv_139
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1437 for ONNX tensor: 1437
[03/27/2022-19:09:38] [V] [TRT] Conv_139 [Conv] outputs: [1437 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_140 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1437
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_140 [Sigmoid] inputs: [1437 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_140 for ONNX node: Sigmoid_140
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 914 for ONNX tensor: 914
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_140 [Sigmoid] outputs: [914 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_141 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1437
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 914
[03/27/2022-19:09:38] [V] [TRT] Mul_141 [Mul] inputs: [1437 -> (4, 528, 32, 32)[FLOAT]], [914 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_141 for ONNX node: Mul_141
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 915 for ONNX tensor: 915
[03/27/2022-19:09:38] [V] [TRT] Mul_141 [Mul] outputs: [915 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_142 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 915
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_142 [ReduceMean] inputs: [915 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_142 for ONNX node: ReduceMean_142
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 916 for ONNX tensor: 916
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_142 [ReduceMean] outputs: [916 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_143 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 916
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_143 [Conv] inputs: [916 -> (4, 528, 1, 1)[FLOAT]], [encoder4.1.se.conv_reduce.weight -> (22, 528, 1, 1)[FLOAT]], [encoder4.1.se.conv_reduce.bias -> (22)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_143 for ONNX node: Conv_143
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 22
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 22, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 917 for ONNX tensor: 917
[03/27/2022-19:09:38] [V] [TRT] Conv_143 [Conv] outputs: [917 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_144 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 917
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_144 [Sigmoid] inputs: [917 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_144 for ONNX node: Sigmoid_144
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 918 for ONNX tensor: 918
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_144 [Sigmoid] outputs: [918 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_145 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 917
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 918
[03/27/2022-19:09:38] [V] [TRT] Mul_145 [Mul] inputs: [917 -> (4, 22, 1, 1)[FLOAT]], [918 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_145 for ONNX node: Mul_145
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 919 for ONNX tensor: 919
[03/27/2022-19:09:38] [V] [TRT] Mul_145 [Mul] outputs: [919 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_146 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 919
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_146 [Conv] inputs: [919 -> (4, 22, 1, 1)[FLOAT]], [encoder4.1.se.conv_expand.weight -> (528, 22, 1, 1)[FLOAT]], [encoder4.1.se.conv_expand.bias -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 22, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_146 for ONNX node: Conv_146
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 920 for ONNX tensor: 920
[03/27/2022-19:09:38] [V] [TRT] Conv_146 [Conv] outputs: [920 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_147 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 920
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_147 [Sigmoid] inputs: [920 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_147 for ONNX node: Sigmoid_147
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 921 for ONNX tensor: 921
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_147 [Sigmoid] outputs: [921 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_148 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 915
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 921
[03/27/2022-19:09:38] [V] [TRT] Mul_148 [Mul] inputs: [915 -> (4, 528, 32, 32)[FLOAT]], [921 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_148 for ONNX node: Mul_148
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 922 for ONNX tensor: 922
[03/27/2022-19:09:38] [V] [TRT] Mul_148 [Mul] outputs: [922 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_149 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 922
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1441
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1442
[03/27/2022-19:09:38] [V] [TRT] Conv_149 [Conv] inputs: [922 -> (4, 528, 32, 32)[FLOAT]], [1441 -> (88, 528, 1, 1)[FLOAT]], [1442 -> (88)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_149 for ONNX node: Conv_149
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 88
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 88, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1440 for ONNX tensor: 1440
[03/27/2022-19:09:38] [V] [TRT] Conv_149 [Conv] outputs: [1440 -> (4, 88, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_150 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1440
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1431
[03/27/2022-19:09:38] [V] [TRT] Add_150 [Add] inputs: [1440 -> (4, 88, 32, 32)[FLOAT]], [1431 -> (4, 88, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_150 for ONNX node: Add_150
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 925 for ONNX tensor: 925
[03/27/2022-19:09:38] [V] [TRT] Add_150 [Add] outputs: [925 -> (4, 88, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_151 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 925
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1444
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1445
[03/27/2022-19:09:38] [V] [TRT] Conv_151 [Conv] inputs: [925 -> (4, 88, 32, 32)[FLOAT]], [1444 -> (528, 88, 1, 1)[FLOAT]], [1445 -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 88, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_151 for ONNX node: Conv_151
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1443 for ONNX tensor: 1443
[03/27/2022-19:09:38] [V] [TRT] Conv_151 [Conv] outputs: [1443 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_152 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1443
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_152 [Sigmoid] inputs: [1443 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_152 for ONNX node: Sigmoid_152
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 928 for ONNX tensor: 928
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_152 [Sigmoid] outputs: [928 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_153 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1443
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 928
[03/27/2022-19:09:38] [V] [TRT] Mul_153 [Mul] inputs: [1443 -> (4, 528, 32, 32)[FLOAT]], [928 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_153 for ONNX node: Mul_153
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 929 for ONNX tensor: 929
[03/27/2022-19:09:38] [V] [TRT] Mul_153 [Mul] outputs: [929 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_154 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 929
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1447
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1448
[03/27/2022-19:09:38] [V] [TRT] Conv_154 [Conv] inputs: [929 -> (4, 528, 32, 32)[FLOAT]], [1447 -> (528, 1, 3, 3)[FLOAT]], [1448 -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_154 for ONNX node: Conv_154
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1446 for ONNX tensor: 1446
[03/27/2022-19:09:38] [V] [TRT] Conv_154 [Conv] outputs: [1446 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_155 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1446
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_155 [Sigmoid] inputs: [1446 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_155 for ONNX node: Sigmoid_155
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 932 for ONNX tensor: 932
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_155 [Sigmoid] outputs: [932 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_156 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1446
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 932
[03/27/2022-19:09:38] [V] [TRT] Mul_156 [Mul] inputs: [1446 -> (4, 528, 32, 32)[FLOAT]], [932 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_156 for ONNX node: Mul_156
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 933 for ONNX tensor: 933
[03/27/2022-19:09:38] [V] [TRT] Mul_156 [Mul] outputs: [933 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_157 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 933
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_157 [ReduceMean] inputs: [933 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_157 for ONNX node: ReduceMean_157
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 934 for ONNX tensor: 934
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_157 [ReduceMean] outputs: [934 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_158 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 934
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.2.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.2.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_158 [Conv] inputs: [934 -> (4, 528, 1, 1)[FLOAT]], [encoder4.2.se.conv_reduce.weight -> (22, 528, 1, 1)[FLOAT]], [encoder4.2.se.conv_reduce.bias -> (22)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_158 for ONNX node: Conv_158
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 22
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 22, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 935 for ONNX tensor: 935
[03/27/2022-19:09:38] [V] [TRT] Conv_158 [Conv] outputs: [935 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_159 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 935
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_159 [Sigmoid] inputs: [935 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_159 for ONNX node: Sigmoid_159
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 936 for ONNX tensor: 936
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_159 [Sigmoid] outputs: [936 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_160 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 935
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 936
[03/27/2022-19:09:38] [V] [TRT] Mul_160 [Mul] inputs: [935 -> (4, 22, 1, 1)[FLOAT]], [936 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_160 for ONNX node: Mul_160
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 937 for ONNX tensor: 937
[03/27/2022-19:09:38] [V] [TRT] Mul_160 [Mul] outputs: [937 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_161 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 937
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.2.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.2.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_161 [Conv] inputs: [937 -> (4, 22, 1, 1)[FLOAT]], [encoder4.2.se.conv_expand.weight -> (528, 22, 1, 1)[FLOAT]], [encoder4.2.se.conv_expand.bias -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 22, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_161 for ONNX node: Conv_161
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 938 for ONNX tensor: 938
[03/27/2022-19:09:38] [V] [TRT] Conv_161 [Conv] outputs: [938 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_162 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 938
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_162 [Sigmoid] inputs: [938 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_162 for ONNX node: Sigmoid_162
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 939 for ONNX tensor: 939
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_162 [Sigmoid] outputs: [939 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_163 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 933
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 939
[03/27/2022-19:09:38] [V] [TRT] Mul_163 [Mul] inputs: [933 -> (4, 528, 32, 32)[FLOAT]], [939 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_163 for ONNX node: Mul_163
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 940 for ONNX tensor: 940
[03/27/2022-19:09:38] [V] [TRT] Mul_163 [Mul] outputs: [940 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_164 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 940
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1450
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1451
[03/27/2022-19:09:38] [V] [TRT] Conv_164 [Conv] inputs: [940 -> (4, 528, 32, 32)[FLOAT]], [1450 -> (88, 528, 1, 1)[FLOAT]], [1451 -> (88)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_164 for ONNX node: Conv_164
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 88
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 88, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1449 for ONNX tensor: 1449
[03/27/2022-19:09:38] [V] [TRT] Conv_164 [Conv] outputs: [1449 -> (4, 88, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_165 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1449
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 925
[03/27/2022-19:09:38] [V] [TRT] Add_165 [Add] inputs: [1449 -> (4, 88, 32, 32)[FLOAT]], [925 -> (4, 88, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_165 for ONNX node: Add_165
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 943 for ONNX tensor: 943
[03/27/2022-19:09:38] [V] [TRT] Add_165 [Add] outputs: [943 -> (4, 88, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_166 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 943
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1453
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1454
[03/27/2022-19:09:38] [V] [TRT] Conv_166 [Conv] inputs: [943 -> (4, 88, 32, 32)[FLOAT]], [1453 -> (528, 88, 1, 1)[FLOAT]], [1454 -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 88, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_166 for ONNX node: Conv_166
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1452 for ONNX tensor: 1452
[03/27/2022-19:09:38] [V] [TRT] Conv_166 [Conv] outputs: [1452 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_167 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1452
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_167 [Sigmoid] inputs: [1452 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_167 for ONNX node: Sigmoid_167
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 946 for ONNX tensor: 946
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_167 [Sigmoid] outputs: [946 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_168 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1452
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 946
[03/27/2022-19:09:38] [V] [TRT] Mul_168 [Mul] inputs: [1452 -> (4, 528, 32, 32)[FLOAT]], [946 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_168 for ONNX node: Mul_168
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 947 for ONNX tensor: 947
[03/27/2022-19:09:38] [V] [TRT] Mul_168 [Mul] outputs: [947 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_169 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 947
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1456
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1457
[03/27/2022-19:09:38] [V] [TRT] Conv_169 [Conv] inputs: [947 -> (4, 528, 32, 32)[FLOAT]], [1456 -> (528, 1, 3, 3)[FLOAT]], [1457 -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_169 for ONNX node: Conv_169
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1455 for ONNX tensor: 1455
[03/27/2022-19:09:38] [V] [TRT] Conv_169 [Conv] outputs: [1455 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_170 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1455
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_170 [Sigmoid] inputs: [1455 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_170 for ONNX node: Sigmoid_170
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 950 for ONNX tensor: 950
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_170 [Sigmoid] outputs: [950 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_171 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1455
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 950
[03/27/2022-19:09:38] [V] [TRT] Mul_171 [Mul] inputs: [1455 -> (4, 528, 32, 32)[FLOAT]], [950 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_171 for ONNX node: Mul_171
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 951 for ONNX tensor: 951
[03/27/2022-19:09:38] [V] [TRT] Mul_171 [Mul] outputs: [951 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_172 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 951
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_172 [ReduceMean] inputs: [951 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_172 for ONNX node: ReduceMean_172
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 952 for ONNX tensor: 952
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_172 [ReduceMean] outputs: [952 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_173 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 952
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.3.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.3.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_173 [Conv] inputs: [952 -> (4, 528, 1, 1)[FLOAT]], [encoder4.3.se.conv_reduce.weight -> (22, 528, 1, 1)[FLOAT]], [encoder4.3.se.conv_reduce.bias -> (22)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_173 for ONNX node: Conv_173
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 22
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 22, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 953 for ONNX tensor: 953
[03/27/2022-19:09:38] [V] [TRT] Conv_173 [Conv] outputs: [953 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_174 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 953
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_174 [Sigmoid] inputs: [953 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_174 for ONNX node: Sigmoid_174
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 954 for ONNX tensor: 954
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_174 [Sigmoid] outputs: [954 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_175 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 953
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 954
[03/27/2022-19:09:38] [V] [TRT] Mul_175 [Mul] inputs: [953 -> (4, 22, 1, 1)[FLOAT]], [954 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_175 for ONNX node: Mul_175
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 955 for ONNX tensor: 955
[03/27/2022-19:09:38] [V] [TRT] Mul_175 [Mul] outputs: [955 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_176 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 955
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.3.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder4.3.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_176 [Conv] inputs: [955 -> (4, 22, 1, 1)[FLOAT]], [encoder4.3.se.conv_expand.weight -> (528, 22, 1, 1)[FLOAT]], [encoder4.3.se.conv_expand.bias -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 22, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_176 for ONNX node: Conv_176
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 956 for ONNX tensor: 956
[03/27/2022-19:09:38] [V] [TRT] Conv_176 [Conv] outputs: [956 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_177 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 956
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_177 [Sigmoid] inputs: [956 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_177 for ONNX node: Sigmoid_177
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 957 for ONNX tensor: 957
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_177 [Sigmoid] outputs: [957 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_178 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 951
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 957
[03/27/2022-19:09:38] [V] [TRT] Mul_178 [Mul] inputs: [951 -> (4, 528, 32, 32)[FLOAT]], [957 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_178 for ONNX node: Mul_178
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 958 for ONNX tensor: 958
[03/27/2022-19:09:38] [V] [TRT] Mul_178 [Mul] outputs: [958 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_179 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 958
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1459
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1460
[03/27/2022-19:09:38] [V] [TRT] Conv_179 [Conv] inputs: [958 -> (4, 528, 32, 32)[FLOAT]], [1459 -> (88, 528, 1, 1)[FLOAT]], [1460 -> (88)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_179 for ONNX node: Conv_179
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 88
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 88, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1458 for ONNX tensor: 1458
[03/27/2022-19:09:38] [V] [TRT] Conv_179 [Conv] outputs: [1458 -> (4, 88, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_180 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1458
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 943
[03/27/2022-19:09:38] [V] [TRT] Add_180 [Add] inputs: [1458 -> (4, 88, 32, 32)[FLOAT]], [943 -> (4, 88, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_180 for ONNX node: Add_180
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 961 for ONNX tensor: 961
[03/27/2022-19:09:38] [V] [TRT] Add_180 [Add] outputs: [961 -> (4, 88, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_181 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 961
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1462
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1463
[03/27/2022-19:09:38] [V] [TRT] Conv_181 [Conv] inputs: [961 -> (4, 88, 32, 32)[FLOAT]], [1462 -> (528, 88, 1, 1)[FLOAT]], [1463 -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 88, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_181 for ONNX node: Conv_181
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1461 for ONNX tensor: 1461
[03/27/2022-19:09:38] [V] [TRT] Conv_181 [Conv] outputs: [1461 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_182 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1461
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_182 [Sigmoid] inputs: [1461 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_182 for ONNX node: Sigmoid_182
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 964 for ONNX tensor: 964
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_182 [Sigmoid] outputs: [964 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_183 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1461
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 964
[03/27/2022-19:09:38] [V] [TRT] Mul_183 [Mul] inputs: [1461 -> (4, 528, 32, 32)[FLOAT]], [964 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_183 for ONNX node: Mul_183
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 965 for ONNX tensor: 965
[03/27/2022-19:09:38] [V] [TRT] Mul_183 [Mul] outputs: [965 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_184 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 965
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1465
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1466
[03/27/2022-19:09:38] [V] [TRT] Conv_184 [Conv] inputs: [965 -> (4, 528, 32, 32)[FLOAT]], [1465 -> (528, 1, 5, 5)[FLOAT]], [1466 -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_184 for ONNX node: Conv_184
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1464 for ONNX tensor: 1464
[03/27/2022-19:09:38] [V] [TRT] Conv_184 [Conv] outputs: [1464 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_185 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1464
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_185 [Sigmoid] inputs: [1464 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_185 for ONNX node: Sigmoid_185
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 968 for ONNX tensor: 968
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_185 [Sigmoid] outputs: [968 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_186 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1464
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 968
[03/27/2022-19:09:38] [V] [TRT] Mul_186 [Mul] inputs: [1464 -> (4, 528, 32, 32)[FLOAT]], [968 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_186 for ONNX node: Mul_186
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 969 for ONNX tensor: 969
[03/27/2022-19:09:38] [V] [TRT] Mul_186 [Mul] outputs: [969 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_187 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 969
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_187 [ReduceMean] inputs: [969 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_187 for ONNX node: ReduceMean_187
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 970 for ONNX tensor: 970
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_187 [ReduceMean] outputs: [970 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_188 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 970
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_188 [Conv] inputs: [970 -> (4, 528, 1, 1)[FLOAT]], [encoder5.0.se.conv_reduce.weight -> (22, 528, 1, 1)[FLOAT]], [encoder5.0.se.conv_reduce.bias -> (22)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_188 for ONNX node: Conv_188
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 22
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 22, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 971 for ONNX tensor: 971
[03/27/2022-19:09:38] [V] [TRT] Conv_188 [Conv] outputs: [971 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_189 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 971
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_189 [Sigmoid] inputs: [971 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_189 for ONNX node: Sigmoid_189
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 972 for ONNX tensor: 972
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_189 [Sigmoid] outputs: [972 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_190 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 971
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 972
[03/27/2022-19:09:38] [V] [TRT] Mul_190 [Mul] inputs: [971 -> (4, 22, 1, 1)[FLOAT]], [972 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_190 for ONNX node: Mul_190
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 973 for ONNX tensor: 973
[03/27/2022-19:09:38] [V] [TRT] Mul_190 [Mul] outputs: [973 -> (4, 22, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_191 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 973
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_191 [Conv] inputs: [973 -> (4, 22, 1, 1)[FLOAT]], [encoder5.0.se.conv_expand.weight -> (528, 22, 1, 1)[FLOAT]], [encoder5.0.se.conv_expand.bias -> (528)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 22, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_191 for ONNX node: Conv_191
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 528
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 528, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 974 for ONNX tensor: 974
[03/27/2022-19:09:38] [V] [TRT] Conv_191 [Conv] outputs: [974 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_192 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 974
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_192 [Sigmoid] inputs: [974 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_192 for ONNX node: Sigmoid_192
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 975 for ONNX tensor: 975
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_192 [Sigmoid] outputs: [975 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_193 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 969
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 975
[03/27/2022-19:09:38] [V] [TRT] Mul_193 [Mul] inputs: [969 -> (4, 528, 32, 32)[FLOAT]], [975 -> (4, 528, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_193 for ONNX node: Mul_193
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 976 for ONNX tensor: 976
[03/27/2022-19:09:38] [V] [TRT] Mul_193 [Mul] outputs: [976 -> (4, 528, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_194 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 976
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1468
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1469
[03/27/2022-19:09:38] [V] [TRT] Conv_194 [Conv] inputs: [976 -> (4, 528, 32, 32)[FLOAT]], [1468 -> (120, 528, 1, 1)[FLOAT]], [1469 -> (120)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 528, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_194 for ONNX node: Conv_194
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 120
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1467 for ONNX tensor: 1467
[03/27/2022-19:09:38] [V] [TRT] Conv_194 [Conv] outputs: [1467 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_195 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1467
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1471
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1472
[03/27/2022-19:09:38] [V] [TRT] Conv_195 [Conv] inputs: [1467 -> (4, 120, 32, 32)[FLOAT]], [1471 -> (720, 120, 1, 1)[FLOAT]], [1472 -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_195 for ONNX node: Conv_195
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1470 for ONNX tensor: 1470
[03/27/2022-19:09:38] [V] [TRT] Conv_195 [Conv] outputs: [1470 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_196 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1470
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_196 [Sigmoid] inputs: [1470 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_196 for ONNX node: Sigmoid_196
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 981 for ONNX tensor: 981
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_196 [Sigmoid] outputs: [981 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_197 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1470
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 981
[03/27/2022-19:09:38] [V] [TRT] Mul_197 [Mul] inputs: [1470 -> (4, 720, 32, 32)[FLOAT]], [981 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_197 for ONNX node: Mul_197
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 982 for ONNX tensor: 982
[03/27/2022-19:09:38] [V] [TRT] Mul_197 [Mul] outputs: [982 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_198 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 982
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1474
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1475
[03/27/2022-19:09:38] [V] [TRT] Conv_198 [Conv] inputs: [982 -> (4, 720, 32, 32)[FLOAT]], [1474 -> (720, 1, 5, 5)[FLOAT]], [1475 -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_198 for ONNX node: Conv_198
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1473 for ONNX tensor: 1473
[03/27/2022-19:09:38] [V] [TRT] Conv_198 [Conv] outputs: [1473 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_199 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1473
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_199 [Sigmoid] inputs: [1473 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_199 for ONNX node: Sigmoid_199
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 985 for ONNX tensor: 985
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_199 [Sigmoid] outputs: [985 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_200 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1473
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 985
[03/27/2022-19:09:38] [V] [TRT] Mul_200 [Mul] inputs: [1473 -> (4, 720, 32, 32)[FLOAT]], [985 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_200 for ONNX node: Mul_200
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 986 for ONNX tensor: 986
[03/27/2022-19:09:38] [V] [TRT] Mul_200 [Mul] outputs: [986 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_201 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 986
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_201 [ReduceMean] inputs: [986 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_201 for ONNX node: ReduceMean_201
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 987 for ONNX tensor: 987
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_201 [ReduceMean] outputs: [987 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_202 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 987
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_202 [Conv] inputs: [987 -> (4, 720, 1, 1)[FLOAT]], [encoder5.1.se.conv_reduce.weight -> (30, 720, 1, 1)[FLOAT]], [encoder5.1.se.conv_reduce.bias -> (30)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_202 for ONNX node: Conv_202
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 30
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 30, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 988 for ONNX tensor: 988
[03/27/2022-19:09:38] [V] [TRT] Conv_202 [Conv] outputs: [988 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_203 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 988
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_203 [Sigmoid] inputs: [988 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_203 for ONNX node: Sigmoid_203
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 989 for ONNX tensor: 989
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_203 [Sigmoid] outputs: [989 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_204 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 988
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 989
[03/27/2022-19:09:38] [V] [TRT] Mul_204 [Mul] inputs: [988 -> (4, 30, 1, 1)[FLOAT]], [989 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_204 for ONNX node: Mul_204
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 990 for ONNX tensor: 990
[03/27/2022-19:09:38] [V] [TRT] Mul_204 [Mul] outputs: [990 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_205 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 990
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_205 [Conv] inputs: [990 -> (4, 30, 1, 1)[FLOAT]], [encoder5.1.se.conv_expand.weight -> (720, 30, 1, 1)[FLOAT]], [encoder5.1.se.conv_expand.bias -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 30, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_205 for ONNX node: Conv_205
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 991 for ONNX tensor: 991
[03/27/2022-19:09:38] [V] [TRT] Conv_205 [Conv] outputs: [991 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_206 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 991
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_206 [Sigmoid] inputs: [991 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_206 for ONNX node: Sigmoid_206
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 992 for ONNX tensor: 992
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_206 [Sigmoid] outputs: [992 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_207 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 986
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 992
[03/27/2022-19:09:38] [V] [TRT] Mul_207 [Mul] inputs: [986 -> (4, 720, 32, 32)[FLOAT]], [992 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_207 for ONNX node: Mul_207
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 993 for ONNX tensor: 993
[03/27/2022-19:09:38] [V] [TRT] Mul_207 [Mul] outputs: [993 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_208 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 993
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1477
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1478
[03/27/2022-19:09:38] [V] [TRT] Conv_208 [Conv] inputs: [993 -> (4, 720, 32, 32)[FLOAT]], [1477 -> (120, 720, 1, 1)[FLOAT]], [1478 -> (120)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_208 for ONNX node: Conv_208
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 120
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1476 for ONNX tensor: 1476
[03/27/2022-19:09:38] [V] [TRT] Conv_208 [Conv] outputs: [1476 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_209 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1476
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1467
[03/27/2022-19:09:38] [V] [TRT] Add_209 [Add] inputs: [1476 -> (4, 120, 32, 32)[FLOAT]], [1467 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_209 for ONNX node: Add_209
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 996 for ONNX tensor: 996
[03/27/2022-19:09:38] [V] [TRT] Add_209 [Add] outputs: [996 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_210 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 996
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1480
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1481
[03/27/2022-19:09:38] [V] [TRT] Conv_210 [Conv] inputs: [996 -> (4, 120, 32, 32)[FLOAT]], [1480 -> (720, 120, 1, 1)[FLOAT]], [1481 -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_210 for ONNX node: Conv_210
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1479 for ONNX tensor: 1479
[03/27/2022-19:09:38] [V] [TRT] Conv_210 [Conv] outputs: [1479 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_211 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1479
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_211 [Sigmoid] inputs: [1479 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_211 for ONNX node: Sigmoid_211
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 999 for ONNX tensor: 999
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_211 [Sigmoid] outputs: [999 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_212 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1479
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 999
[03/27/2022-19:09:38] [V] [TRT] Mul_212 [Mul] inputs: [1479 -> (4, 720, 32, 32)[FLOAT]], [999 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_212 for ONNX node: Mul_212
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1000 for ONNX tensor: 1000
[03/27/2022-19:09:38] [V] [TRT] Mul_212 [Mul] outputs: [1000 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_213 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1000
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1483
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1484
[03/27/2022-19:09:38] [V] [TRT] Conv_213 [Conv] inputs: [1000 -> (4, 720, 32, 32)[FLOAT]], [1483 -> (720, 1, 5, 5)[FLOAT]], [1484 -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_213 for ONNX node: Conv_213
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1482 for ONNX tensor: 1482
[03/27/2022-19:09:38] [V] [TRT] Conv_213 [Conv] outputs: [1482 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_214 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1482
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_214 [Sigmoid] inputs: [1482 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_214 for ONNX node: Sigmoid_214
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1003 for ONNX tensor: 1003
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_214 [Sigmoid] outputs: [1003 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_215 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1482
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1003
[03/27/2022-19:09:38] [V] [TRT] Mul_215 [Mul] inputs: [1482 -> (4, 720, 32, 32)[FLOAT]], [1003 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_215 for ONNX node: Mul_215
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1004 for ONNX tensor: 1004
[03/27/2022-19:09:38] [V] [TRT] Mul_215 [Mul] outputs: [1004 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_216 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1004
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_216 [ReduceMean] inputs: [1004 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_216 for ONNX node: ReduceMean_216
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1005 for ONNX tensor: 1005
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_216 [ReduceMean] outputs: [1005 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_217 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1005
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.2.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.2.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_217 [Conv] inputs: [1005 -> (4, 720, 1, 1)[FLOAT]], [encoder5.2.se.conv_reduce.weight -> (30, 720, 1, 1)[FLOAT]], [encoder5.2.se.conv_reduce.bias -> (30)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_217 for ONNX node: Conv_217
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 30
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 30, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1006 for ONNX tensor: 1006
[03/27/2022-19:09:38] [V] [TRT] Conv_217 [Conv] outputs: [1006 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_218 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1006
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_218 [Sigmoid] inputs: [1006 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_218 for ONNX node: Sigmoid_218
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1007 for ONNX tensor: 1007
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_218 [Sigmoid] outputs: [1007 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_219 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1006
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1007
[03/27/2022-19:09:38] [V] [TRT] Mul_219 [Mul] inputs: [1006 -> (4, 30, 1, 1)[FLOAT]], [1007 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_219 for ONNX node: Mul_219
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1008 for ONNX tensor: 1008
[03/27/2022-19:09:38] [V] [TRT] Mul_219 [Mul] outputs: [1008 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_220 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1008
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.2.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.2.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_220 [Conv] inputs: [1008 -> (4, 30, 1, 1)[FLOAT]], [encoder5.2.se.conv_expand.weight -> (720, 30, 1, 1)[FLOAT]], [encoder5.2.se.conv_expand.bias -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 30, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_220 for ONNX node: Conv_220
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1009 for ONNX tensor: 1009
[03/27/2022-19:09:38] [V] [TRT] Conv_220 [Conv] outputs: [1009 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_221 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1009
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_221 [Sigmoid] inputs: [1009 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_221 for ONNX node: Sigmoid_221
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1010 for ONNX tensor: 1010
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_221 [Sigmoid] outputs: [1010 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_222 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1004
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1010
[03/27/2022-19:09:38] [V] [TRT] Mul_222 [Mul] inputs: [1004 -> (4, 720, 32, 32)[FLOAT]], [1010 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_222 for ONNX node: Mul_222
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1011 for ONNX tensor: 1011
[03/27/2022-19:09:38] [V] [TRT] Mul_222 [Mul] outputs: [1011 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_223 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1011
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1486
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1487
[03/27/2022-19:09:38] [V] [TRT] Conv_223 [Conv] inputs: [1011 -> (4, 720, 32, 32)[FLOAT]], [1486 -> (120, 720, 1, 1)[FLOAT]], [1487 -> (120)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_223 for ONNX node: Conv_223
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 120
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1485 for ONNX tensor: 1485
[03/27/2022-19:09:38] [V] [TRT] Conv_223 [Conv] outputs: [1485 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_224 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1485
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 996
[03/27/2022-19:09:38] [V] [TRT] Add_224 [Add] inputs: [1485 -> (4, 120, 32, 32)[FLOAT]], [996 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_224 for ONNX node: Add_224
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1014 for ONNX tensor: 1014
[03/27/2022-19:09:38] [V] [TRT] Add_224 [Add] outputs: [1014 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_225 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1014
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1489
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1490
[03/27/2022-19:09:38] [V] [TRT] Conv_225 [Conv] inputs: [1014 -> (4, 120, 32, 32)[FLOAT]], [1489 -> (720, 120, 1, 1)[FLOAT]], [1490 -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_225 for ONNX node: Conv_225
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1488 for ONNX tensor: 1488
[03/27/2022-19:09:38] [V] [TRT] Conv_225 [Conv] outputs: [1488 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_226 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1488
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_226 [Sigmoid] inputs: [1488 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_226 for ONNX node: Sigmoid_226
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1017 for ONNX tensor: 1017
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_226 [Sigmoid] outputs: [1017 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_227 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1488
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1017
[03/27/2022-19:09:38] [V] [TRT] Mul_227 [Mul] inputs: [1488 -> (4, 720, 32, 32)[FLOAT]], [1017 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_227 for ONNX node: Mul_227
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1018 for ONNX tensor: 1018
[03/27/2022-19:09:38] [V] [TRT] Mul_227 [Mul] outputs: [1018 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_228 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1018
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1492
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1493
[03/27/2022-19:09:38] [V] [TRT] Conv_228 [Conv] inputs: [1018 -> (4, 720, 32, 32)[FLOAT]], [1492 -> (720, 1, 5, 5)[FLOAT]], [1493 -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_228 for ONNX node: Conv_228
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1491 for ONNX tensor: 1491
[03/27/2022-19:09:38] [V] [TRT] Conv_228 [Conv] outputs: [1491 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_229 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1491
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_229 [Sigmoid] inputs: [1491 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_229 for ONNX node: Sigmoid_229
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1021 for ONNX tensor: 1021
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_229 [Sigmoid] outputs: [1021 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_230 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1491
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1021
[03/27/2022-19:09:38] [V] [TRT] Mul_230 [Mul] inputs: [1491 -> (4, 720, 32, 32)[FLOAT]], [1021 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_230 for ONNX node: Mul_230
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1022 for ONNX tensor: 1022
[03/27/2022-19:09:38] [V] [TRT] Mul_230 [Mul] outputs: [1022 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_231 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1022
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_231 [ReduceMean] inputs: [1022 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_231 for ONNX node: ReduceMean_231
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1023 for ONNX tensor: 1023
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_231 [ReduceMean] outputs: [1023 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_232 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1023
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.3.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.3.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_232 [Conv] inputs: [1023 -> (4, 720, 1, 1)[FLOAT]], [encoder5.3.se.conv_reduce.weight -> (30, 720, 1, 1)[FLOAT]], [encoder5.3.se.conv_reduce.bias -> (30)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_232 for ONNX node: Conv_232
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 30
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 30, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1024 for ONNX tensor: 1024
[03/27/2022-19:09:38] [V] [TRT] Conv_232 [Conv] outputs: [1024 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_233 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1024
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_233 [Sigmoid] inputs: [1024 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_233 for ONNX node: Sigmoid_233
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1025 for ONNX tensor: 1025
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_233 [Sigmoid] outputs: [1025 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_234 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1024
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1025
[03/27/2022-19:09:38] [V] [TRT] Mul_234 [Mul] inputs: [1024 -> (4, 30, 1, 1)[FLOAT]], [1025 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_234 for ONNX node: Mul_234
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1026 for ONNX tensor: 1026
[03/27/2022-19:09:38] [V] [TRT] Mul_234 [Mul] outputs: [1026 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_235 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1026
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.3.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder5.3.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_235 [Conv] inputs: [1026 -> (4, 30, 1, 1)[FLOAT]], [encoder5.3.se.conv_expand.weight -> (720, 30, 1, 1)[FLOAT]], [encoder5.3.se.conv_expand.bias -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 30, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_235 for ONNX node: Conv_235
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1027 for ONNX tensor: 1027
[03/27/2022-19:09:38] [V] [TRT] Conv_235 [Conv] outputs: [1027 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_236 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1027
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_236 [Sigmoid] inputs: [1027 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_236 for ONNX node: Sigmoid_236
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1028 for ONNX tensor: 1028
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_236 [Sigmoid] outputs: [1028 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_237 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1022
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1028
[03/27/2022-19:09:38] [V] [TRT] Mul_237 [Mul] inputs: [1022 -> (4, 720, 32, 32)[FLOAT]], [1028 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_237 for ONNX node: Mul_237
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1029 for ONNX tensor: 1029
[03/27/2022-19:09:38] [V] [TRT] Mul_237 [Mul] outputs: [1029 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_238 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1029
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1495
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1496
[03/27/2022-19:09:38] [V] [TRT] Conv_238 [Conv] inputs: [1029 -> (4, 720, 32, 32)[FLOAT]], [1495 -> (120, 720, 1, 1)[FLOAT]], [1496 -> (120)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_238 for ONNX node: Conv_238
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 120
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1494 for ONNX tensor: 1494
[03/27/2022-19:09:38] [V] [TRT] Conv_238 [Conv] outputs: [1494 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_239 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1494
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1014
[03/27/2022-19:09:38] [V] [TRT] Add_239 [Add] inputs: [1494 -> (4, 120, 32, 32)[FLOAT]], [1014 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_239 for ONNX node: Add_239
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1032 for ONNX tensor: 1032
[03/27/2022-19:09:38] [V] [TRT] Add_239 [Add] outputs: [1032 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_240 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1032
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1498
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1499
[03/27/2022-19:09:38] [V] [TRT] Conv_240 [Conv] inputs: [1032 -> (4, 120, 32, 32)[FLOAT]], [1498 -> (720, 120, 1, 1)[FLOAT]], [1499 -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_240 for ONNX node: Conv_240
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1497 for ONNX tensor: 1497
[03/27/2022-19:09:38] [V] [TRT] Conv_240 [Conv] outputs: [1497 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_241 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1497
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_241 [Sigmoid] inputs: [1497 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_241 for ONNX node: Sigmoid_241
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1035 for ONNX tensor: 1035
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_241 [Sigmoid] outputs: [1035 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_242 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1497
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1035
[03/27/2022-19:09:38] [V] [TRT] Mul_242 [Mul] inputs: [1497 -> (4, 720, 32, 32)[FLOAT]], [1035 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_242 for ONNX node: Mul_242
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1036 for ONNX tensor: 1036
[03/27/2022-19:09:38] [V] [TRT] Mul_242 [Mul] outputs: [1036 -> (4, 720, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_243 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1036
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1501
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1502
[03/27/2022-19:09:38] [V] [TRT] Conv_243 [Conv] inputs: [1036 -> (4, 720, 32, 32)[FLOAT]], [1501 -> (720, 1, 5, 5)[FLOAT]], [1502 -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_243 for ONNX node: Conv_243
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (2, 2), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1500 for ONNX tensor: 1500
[03/27/2022-19:09:38] [V] [TRT] Conv_243 [Conv] outputs: [1500 -> (4, 720, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_244 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1500
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_244 [Sigmoid] inputs: [1500 -> (4, 720, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_244 for ONNX node: Sigmoid_244
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1039 for ONNX tensor: 1039
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_244 [Sigmoid] outputs: [1039 -> (4, 720, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_245 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1500
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1039
[03/27/2022-19:09:38] [V] [TRT] Mul_245 [Mul] inputs: [1500 -> (4, 720, 16, 16)[FLOAT]], [1039 -> (4, 720, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_245 for ONNX node: Mul_245
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1040 for ONNX tensor: 1040
[03/27/2022-19:09:38] [V] [TRT] Mul_245 [Mul] outputs: [1040 -> (4, 720, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_246 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1040
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_246 [ReduceMean] inputs: [1040 -> (4, 720, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_246 for ONNX node: ReduceMean_246
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1041 for ONNX tensor: 1041
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_246 [ReduceMean] outputs: [1041 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_247 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1041
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_247 [Conv] inputs: [1041 -> (4, 720, 1, 1)[FLOAT]], [encoder6.0.se.conv_reduce.weight -> (30, 720, 1, 1)[FLOAT]], [encoder6.0.se.conv_reduce.bias -> (30)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_247 for ONNX node: Conv_247
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 30
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 30, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1042 for ONNX tensor: 1042
[03/27/2022-19:09:38] [V] [TRT] Conv_247 [Conv] outputs: [1042 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_248 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1042
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_248 [Sigmoid] inputs: [1042 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_248 for ONNX node: Sigmoid_248
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1043 for ONNX tensor: 1043
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_248 [Sigmoid] outputs: [1043 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_249 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1042
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1043
[03/27/2022-19:09:38] [V] [TRT] Mul_249 [Mul] inputs: [1042 -> (4, 30, 1, 1)[FLOAT]], [1043 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_249 for ONNX node: Mul_249
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1044 for ONNX tensor: 1044
[03/27/2022-19:09:38] [V] [TRT] Mul_249 [Mul] outputs: [1044 -> (4, 30, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_250 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1044
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_250 [Conv] inputs: [1044 -> (4, 30, 1, 1)[FLOAT]], [encoder6.0.se.conv_expand.weight -> (720, 30, 1, 1)[FLOAT]], [encoder6.0.se.conv_expand.bias -> (720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 30, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_250 for ONNX node: Conv_250
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 720
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 720, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1045 for ONNX tensor: 1045
[03/27/2022-19:09:38] [V] [TRT] Conv_250 [Conv] outputs: [1045 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_251 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1045
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_251 [Sigmoid] inputs: [1045 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_251 for ONNX node: Sigmoid_251
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1046 for ONNX tensor: 1046
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_251 [Sigmoid] outputs: [1046 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_252 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1040
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1046
[03/27/2022-19:09:38] [V] [TRT] Mul_252 [Mul] inputs: [1040 -> (4, 720, 16, 16)[FLOAT]], [1046 -> (4, 720, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_252 for ONNX node: Mul_252
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1047 for ONNX tensor: 1047
[03/27/2022-19:09:38] [V] [TRT] Mul_252 [Mul] outputs: [1047 -> (4, 720, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_253 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1047
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1504
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1505
[03/27/2022-19:09:38] [V] [TRT] Conv_253 [Conv] inputs: [1047 -> (4, 720, 16, 16)[FLOAT]], [1504 -> (208, 720, 1, 1)[FLOAT]], [1505 -> (208)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 720, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_253 for ONNX node: Conv_253
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 208
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 208, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1503 for ONNX tensor: 1503
[03/27/2022-19:09:38] [V] [TRT] Conv_253 [Conv] outputs: [1503 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_254 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1503
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1507
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1508
[03/27/2022-19:09:38] [V] [TRT] Conv_254 [Conv] inputs: [1503 -> (4, 208, 16, 16)[FLOAT]], [1507 -> (1248, 208, 1, 1)[FLOAT]], [1508 -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 208, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_254 for ONNX node: Conv_254
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1506 for ONNX tensor: 1506
[03/27/2022-19:09:38] [V] [TRT] Conv_254 [Conv] outputs: [1506 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_255 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1506
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_255 [Sigmoid] inputs: [1506 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_255 for ONNX node: Sigmoid_255
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1052 for ONNX tensor: 1052
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_255 [Sigmoid] outputs: [1052 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_256 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1506
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1052
[03/27/2022-19:09:38] [V] [TRT] Mul_256 [Mul] inputs: [1506 -> (4, 1248, 16, 16)[FLOAT]], [1052 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_256 for ONNX node: Mul_256
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1053 for ONNX tensor: 1053
[03/27/2022-19:09:38] [V] [TRT] Mul_256 [Mul] outputs: [1053 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_257 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1053
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1510
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1511
[03/27/2022-19:09:38] [V] [TRT] Conv_257 [Conv] inputs: [1053 -> (4, 1248, 16, 16)[FLOAT]], [1510 -> (1248, 1, 5, 5)[FLOAT]], [1511 -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_257 for ONNX node: Conv_257
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1509 for ONNX tensor: 1509
[03/27/2022-19:09:38] [V] [TRT] Conv_257 [Conv] outputs: [1509 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_258 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1509
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_258 [Sigmoid] inputs: [1509 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_258 for ONNX node: Sigmoid_258
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1056 for ONNX tensor: 1056
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_258 [Sigmoid] outputs: [1056 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_259 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1509
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1056
[03/27/2022-19:09:38] [V] [TRT] Mul_259 [Mul] inputs: [1509 -> (4, 1248, 16, 16)[FLOAT]], [1056 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_259 for ONNX node: Mul_259
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1057 for ONNX tensor: 1057
[03/27/2022-19:09:38] [V] [TRT] Mul_259 [Mul] outputs: [1057 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_260 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1057
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_260 [ReduceMean] inputs: [1057 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_260 for ONNX node: ReduceMean_260
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1058 for ONNX tensor: 1058
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_260 [ReduceMean] outputs: [1058 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_261 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1058
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_261 [Conv] inputs: [1058 -> (4, 1248, 1, 1)[FLOAT]], [encoder6.1.se.conv_reduce.weight -> (52, 1248, 1, 1)[FLOAT]], [encoder6.1.se.conv_reduce.bias -> (52)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_261 for ONNX node: Conv_261
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 52
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 52, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1059 for ONNX tensor: 1059
[03/27/2022-19:09:38] [V] [TRT] Conv_261 [Conv] outputs: [1059 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_262 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1059
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_262 [Sigmoid] inputs: [1059 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_262 for ONNX node: Sigmoid_262
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1060 for ONNX tensor: 1060
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_262 [Sigmoid] outputs: [1060 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_263 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1059
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1060
[03/27/2022-19:09:38] [V] [TRT] Mul_263 [Mul] inputs: [1059 -> (4, 52, 1, 1)[FLOAT]], [1060 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_263 for ONNX node: Mul_263
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1061 for ONNX tensor: 1061
[03/27/2022-19:09:38] [V] [TRT] Mul_263 [Mul] outputs: [1061 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_264 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1061
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_264 [Conv] inputs: [1061 -> (4, 52, 1, 1)[FLOAT]], [encoder6.1.se.conv_expand.weight -> (1248, 52, 1, 1)[FLOAT]], [encoder6.1.se.conv_expand.bias -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 52, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_264 for ONNX node: Conv_264
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1062 for ONNX tensor: 1062
[03/27/2022-19:09:38] [V] [TRT] Conv_264 [Conv] outputs: [1062 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_265 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1062
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_265 [Sigmoid] inputs: [1062 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_265 for ONNX node: Sigmoid_265
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1063 for ONNX tensor: 1063
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_265 [Sigmoid] outputs: [1063 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_266 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1057
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1063
[03/27/2022-19:09:38] [V] [TRT] Mul_266 [Mul] inputs: [1057 -> (4, 1248, 16, 16)[FLOAT]], [1063 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_266 for ONNX node: Mul_266
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1064 for ONNX tensor: 1064
[03/27/2022-19:09:38] [V] [TRT] Mul_266 [Mul] outputs: [1064 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_267 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1064
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1513
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1514
[03/27/2022-19:09:38] [V] [TRT] Conv_267 [Conv] inputs: [1064 -> (4, 1248, 16, 16)[FLOAT]], [1513 -> (208, 1248, 1, 1)[FLOAT]], [1514 -> (208)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_267 for ONNX node: Conv_267
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 208
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 208, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1512 for ONNX tensor: 1512
[03/27/2022-19:09:38] [V] [TRT] Conv_267 [Conv] outputs: [1512 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_268 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1512
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1503
[03/27/2022-19:09:38] [V] [TRT] Add_268 [Add] inputs: [1512 -> (4, 208, 16, 16)[FLOAT]], [1503 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_268 for ONNX node: Add_268
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1067 for ONNX tensor: 1067
[03/27/2022-19:09:38] [V] [TRT] Add_268 [Add] outputs: [1067 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_269 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1067
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1516
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1517
[03/27/2022-19:09:38] [V] [TRT] Conv_269 [Conv] inputs: [1067 -> (4, 208, 16, 16)[FLOAT]], [1516 -> (1248, 208, 1, 1)[FLOAT]], [1517 -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 208, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_269 for ONNX node: Conv_269
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1515 for ONNX tensor: 1515
[03/27/2022-19:09:38] [V] [TRT] Conv_269 [Conv] outputs: [1515 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_270 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1515
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_270 [Sigmoid] inputs: [1515 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_270 for ONNX node: Sigmoid_270
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1070 for ONNX tensor: 1070
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_270 [Sigmoid] outputs: [1070 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_271 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1515
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1070
[03/27/2022-19:09:38] [V] [TRT] Mul_271 [Mul] inputs: [1515 -> (4, 1248, 16, 16)[FLOAT]], [1070 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_271 for ONNX node: Mul_271
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1071 for ONNX tensor: 1071
[03/27/2022-19:09:38] [V] [TRT] Mul_271 [Mul] outputs: [1071 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_272 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1071
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1519
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1520
[03/27/2022-19:09:38] [V] [TRT] Conv_272 [Conv] inputs: [1071 -> (4, 1248, 16, 16)[FLOAT]], [1519 -> (1248, 1, 5, 5)[FLOAT]], [1520 -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_272 for ONNX node: Conv_272
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1518 for ONNX tensor: 1518
[03/27/2022-19:09:38] [V] [TRT] Conv_272 [Conv] outputs: [1518 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_273 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1518
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_273 [Sigmoid] inputs: [1518 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_273 for ONNX node: Sigmoid_273
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1074 for ONNX tensor: 1074
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_273 [Sigmoid] outputs: [1074 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_274 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1518
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1074
[03/27/2022-19:09:38] [V] [TRT] Mul_274 [Mul] inputs: [1518 -> (4, 1248, 16, 16)[FLOAT]], [1074 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_274 for ONNX node: Mul_274
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1075 for ONNX tensor: 1075
[03/27/2022-19:09:38] [V] [TRT] Mul_274 [Mul] outputs: [1075 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_275 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1075
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_275 [ReduceMean] inputs: [1075 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_275 for ONNX node: ReduceMean_275
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1076 for ONNX tensor: 1076
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_275 [ReduceMean] outputs: [1076 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_276 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1076
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.2.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.2.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_276 [Conv] inputs: [1076 -> (4, 1248, 1, 1)[FLOAT]], [encoder6.2.se.conv_reduce.weight -> (52, 1248, 1, 1)[FLOAT]], [encoder6.2.se.conv_reduce.bias -> (52)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_276 for ONNX node: Conv_276
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 52
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 52, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1077 for ONNX tensor: 1077
[03/27/2022-19:09:38] [V] [TRT] Conv_276 [Conv] outputs: [1077 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_277 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1077
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_277 [Sigmoid] inputs: [1077 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_277 for ONNX node: Sigmoid_277
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1078 for ONNX tensor: 1078
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_277 [Sigmoid] outputs: [1078 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_278 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1077
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1078
[03/27/2022-19:09:38] [V] [TRT] Mul_278 [Mul] inputs: [1077 -> (4, 52, 1, 1)[FLOAT]], [1078 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_278 for ONNX node: Mul_278
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1079 for ONNX tensor: 1079
[03/27/2022-19:09:38] [V] [TRT] Mul_278 [Mul] outputs: [1079 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_279 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1079
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.2.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.2.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_279 [Conv] inputs: [1079 -> (4, 52, 1, 1)[FLOAT]], [encoder6.2.se.conv_expand.weight -> (1248, 52, 1, 1)[FLOAT]], [encoder6.2.se.conv_expand.bias -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 52, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_279 for ONNX node: Conv_279
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1080 for ONNX tensor: 1080
[03/27/2022-19:09:38] [V] [TRT] Conv_279 [Conv] outputs: [1080 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_280 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1080
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_280 [Sigmoid] inputs: [1080 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_280 for ONNX node: Sigmoid_280
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1081 for ONNX tensor: 1081
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_280 [Sigmoid] outputs: [1081 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_281 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1075
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1081
[03/27/2022-19:09:38] [V] [TRT] Mul_281 [Mul] inputs: [1075 -> (4, 1248, 16, 16)[FLOAT]], [1081 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_281 for ONNX node: Mul_281
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1082 for ONNX tensor: 1082
[03/27/2022-19:09:38] [V] [TRT] Mul_281 [Mul] outputs: [1082 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_282 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1082
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1522
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1523
[03/27/2022-19:09:38] [V] [TRT] Conv_282 [Conv] inputs: [1082 -> (4, 1248, 16, 16)[FLOAT]], [1522 -> (208, 1248, 1, 1)[FLOAT]], [1523 -> (208)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_282 for ONNX node: Conv_282
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 208
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 208, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1521 for ONNX tensor: 1521
[03/27/2022-19:09:38] [V] [TRT] Conv_282 [Conv] outputs: [1521 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_283 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1521
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1067
[03/27/2022-19:09:38] [V] [TRT] Add_283 [Add] inputs: [1521 -> (4, 208, 16, 16)[FLOAT]], [1067 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_283 for ONNX node: Add_283
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1085 for ONNX tensor: 1085
[03/27/2022-19:09:38] [V] [TRT] Add_283 [Add] outputs: [1085 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_284 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1085
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1525
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1526
[03/27/2022-19:09:38] [V] [TRT] Conv_284 [Conv] inputs: [1085 -> (4, 208, 16, 16)[FLOAT]], [1525 -> (1248, 208, 1, 1)[FLOAT]], [1526 -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 208, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_284 for ONNX node: Conv_284
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1524 for ONNX tensor: 1524
[03/27/2022-19:09:38] [V] [TRT] Conv_284 [Conv] outputs: [1524 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_285 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1524
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_285 [Sigmoid] inputs: [1524 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_285 for ONNX node: Sigmoid_285
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1088 for ONNX tensor: 1088
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_285 [Sigmoid] outputs: [1088 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_286 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1524
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1088
[03/27/2022-19:09:38] [V] [TRT] Mul_286 [Mul] inputs: [1524 -> (4, 1248, 16, 16)[FLOAT]], [1088 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_286 for ONNX node: Mul_286
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1089 for ONNX tensor: 1089
[03/27/2022-19:09:38] [V] [TRT] Mul_286 [Mul] outputs: [1089 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_287 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1089
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1528
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1529
[03/27/2022-19:09:38] [V] [TRT] Conv_287 [Conv] inputs: [1089 -> (4, 1248, 16, 16)[FLOAT]], [1528 -> (1248, 1, 5, 5)[FLOAT]], [1529 -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_287 for ONNX node: Conv_287
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1527 for ONNX tensor: 1527
[03/27/2022-19:09:38] [V] [TRT] Conv_287 [Conv] outputs: [1527 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_288 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1527
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_288 [Sigmoid] inputs: [1527 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_288 for ONNX node: Sigmoid_288
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1092 for ONNX tensor: 1092
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_288 [Sigmoid] outputs: [1092 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_289 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1527
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1092
[03/27/2022-19:09:38] [V] [TRT] Mul_289 [Mul] inputs: [1527 -> (4, 1248, 16, 16)[FLOAT]], [1092 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_289 for ONNX node: Mul_289
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1093 for ONNX tensor: 1093
[03/27/2022-19:09:38] [V] [TRT] Mul_289 [Mul] outputs: [1093 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_290 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1093
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_290 [ReduceMean] inputs: [1093 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_290 for ONNX node: ReduceMean_290
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1094 for ONNX tensor: 1094
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_290 [ReduceMean] outputs: [1094 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_291 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1094
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.3.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.3.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_291 [Conv] inputs: [1094 -> (4, 1248, 1, 1)[FLOAT]], [encoder6.3.se.conv_reduce.weight -> (52, 1248, 1, 1)[FLOAT]], [encoder6.3.se.conv_reduce.bias -> (52)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_291 for ONNX node: Conv_291
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 52
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 52, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1095 for ONNX tensor: 1095
[03/27/2022-19:09:38] [V] [TRT] Conv_291 [Conv] outputs: [1095 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_292 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1095
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_292 [Sigmoid] inputs: [1095 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_292 for ONNX node: Sigmoid_292
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1096 for ONNX tensor: 1096
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_292 [Sigmoid] outputs: [1096 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_293 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1095
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1096
[03/27/2022-19:09:38] [V] [TRT] Mul_293 [Mul] inputs: [1095 -> (4, 52, 1, 1)[FLOAT]], [1096 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_293 for ONNX node: Mul_293
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1097 for ONNX tensor: 1097
[03/27/2022-19:09:38] [V] [TRT] Mul_293 [Mul] outputs: [1097 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_294 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1097
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.3.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.3.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_294 [Conv] inputs: [1097 -> (4, 52, 1, 1)[FLOAT]], [encoder6.3.se.conv_expand.weight -> (1248, 52, 1, 1)[FLOAT]], [encoder6.3.se.conv_expand.bias -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 52, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_294 for ONNX node: Conv_294
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1098 for ONNX tensor: 1098
[03/27/2022-19:09:38] [V] [TRT] Conv_294 [Conv] outputs: [1098 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_295 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1098
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_295 [Sigmoid] inputs: [1098 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_295 for ONNX node: Sigmoid_295
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1099 for ONNX tensor: 1099
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_295 [Sigmoid] outputs: [1099 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_296 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1093
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1099
[03/27/2022-19:09:38] [V] [TRT] Mul_296 [Mul] inputs: [1093 -> (4, 1248, 16, 16)[FLOAT]], [1099 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_296 for ONNX node: Mul_296
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1100 for ONNX tensor: 1100
[03/27/2022-19:09:38] [V] [TRT] Mul_296 [Mul] outputs: [1100 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_297 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1100
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1531
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1532
[03/27/2022-19:09:38] [V] [TRT] Conv_297 [Conv] inputs: [1100 -> (4, 1248, 16, 16)[FLOAT]], [1531 -> (208, 1248, 1, 1)[FLOAT]], [1532 -> (208)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_297 for ONNX node: Conv_297
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 208
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 208, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1530 for ONNX tensor: 1530
[03/27/2022-19:09:38] [V] [TRT] Conv_297 [Conv] outputs: [1530 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_298 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1530
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1085
[03/27/2022-19:09:38] [V] [TRT] Add_298 [Add] inputs: [1530 -> (4, 208, 16, 16)[FLOAT]], [1085 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_298 for ONNX node: Add_298
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1103 for ONNX tensor: 1103
[03/27/2022-19:09:38] [V] [TRT] Add_298 [Add] outputs: [1103 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_299 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1103
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1534
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1535
[03/27/2022-19:09:38] [V] [TRT] Conv_299 [Conv] inputs: [1103 -> (4, 208, 16, 16)[FLOAT]], [1534 -> (1248, 208, 1, 1)[FLOAT]], [1535 -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 208, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_299 for ONNX node: Conv_299
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1533 for ONNX tensor: 1533
[03/27/2022-19:09:38] [V] [TRT] Conv_299 [Conv] outputs: [1533 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_300 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1533
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_300 [Sigmoid] inputs: [1533 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_300 for ONNX node: Sigmoid_300
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1106 for ONNX tensor: 1106
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_300 [Sigmoid] outputs: [1106 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_301 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1533
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1106
[03/27/2022-19:09:38] [V] [TRT] Mul_301 [Mul] inputs: [1533 -> (4, 1248, 16, 16)[FLOAT]], [1106 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_301 for ONNX node: Mul_301
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1107 for ONNX tensor: 1107
[03/27/2022-19:09:38] [V] [TRT] Mul_301 [Mul] outputs: [1107 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_302 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1107
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1537
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1538
[03/27/2022-19:09:38] [V] [TRT] Conv_302 [Conv] inputs: [1107 -> (4, 1248, 16, 16)[FLOAT]], [1537 -> (1248, 1, 5, 5)[FLOAT]], [1538 -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_302 for ONNX node: Conv_302
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 5), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1536 for ONNX tensor: 1536
[03/27/2022-19:09:38] [V] [TRT] Conv_302 [Conv] outputs: [1536 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_303 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1536
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_303 [Sigmoid] inputs: [1536 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_303 for ONNX node: Sigmoid_303
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1110 for ONNX tensor: 1110
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_303 [Sigmoid] outputs: [1110 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_304 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1536
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1110
[03/27/2022-19:09:38] [V] [TRT] Mul_304 [Mul] inputs: [1536 -> (4, 1248, 16, 16)[FLOAT]], [1110 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_304 for ONNX node: Mul_304
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1111 for ONNX tensor: 1111
[03/27/2022-19:09:38] [V] [TRT] Mul_304 [Mul] outputs: [1111 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_305 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1111
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_305 [ReduceMean] inputs: [1111 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_305 for ONNX node: ReduceMean_305
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1112 for ONNX tensor: 1112
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_305 [ReduceMean] outputs: [1112 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_306 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1112
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.4.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.4.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_306 [Conv] inputs: [1112 -> (4, 1248, 1, 1)[FLOAT]], [encoder6.4.se.conv_reduce.weight -> (52, 1248, 1, 1)[FLOAT]], [encoder6.4.se.conv_reduce.bias -> (52)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_306 for ONNX node: Conv_306
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 52
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 52, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1113 for ONNX tensor: 1113
[03/27/2022-19:09:38] [V] [TRT] Conv_306 [Conv] outputs: [1113 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_307 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1113
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_307 [Sigmoid] inputs: [1113 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_307 for ONNX node: Sigmoid_307
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1114 for ONNX tensor: 1114
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_307 [Sigmoid] outputs: [1114 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_308 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1113
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1114
[03/27/2022-19:09:38] [V] [TRT] Mul_308 [Mul] inputs: [1113 -> (4, 52, 1, 1)[FLOAT]], [1114 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_308 for ONNX node: Mul_308
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1115 for ONNX tensor: 1115
[03/27/2022-19:09:38] [V] [TRT] Mul_308 [Mul] outputs: [1115 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_309 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1115
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.4.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder6.4.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_309 [Conv] inputs: [1115 -> (4, 52, 1, 1)[FLOAT]], [encoder6.4.se.conv_expand.weight -> (1248, 52, 1, 1)[FLOAT]], [encoder6.4.se.conv_expand.bias -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 52, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_309 for ONNX node: Conv_309
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1116 for ONNX tensor: 1116
[03/27/2022-19:09:38] [V] [TRT] Conv_309 [Conv] outputs: [1116 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_310 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1116
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_310 [Sigmoid] inputs: [1116 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_310 for ONNX node: Sigmoid_310
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1117 for ONNX tensor: 1117
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_310 [Sigmoid] outputs: [1117 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_311 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1111
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1117
[03/27/2022-19:09:38] [V] [TRT] Mul_311 [Mul] inputs: [1111 -> (4, 1248, 16, 16)[FLOAT]], [1117 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_311 for ONNX node: Mul_311
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1118 for ONNX tensor: 1118
[03/27/2022-19:09:38] [V] [TRT] Mul_311 [Mul] outputs: [1118 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_312 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1118
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1540
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1541
[03/27/2022-19:09:38] [V] [TRT] Conv_312 [Conv] inputs: [1118 -> (4, 1248, 16, 16)[FLOAT]], [1540 -> (208, 1248, 1, 1)[FLOAT]], [1541 -> (208)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_312 for ONNX node: Conv_312
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 208
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 208, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1539 for ONNX tensor: 1539
[03/27/2022-19:09:38] [V] [TRT] Conv_312 [Conv] outputs: [1539 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_313 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1539
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1103
[03/27/2022-19:09:38] [V] [TRT] Add_313 [Add] inputs: [1539 -> (4, 208, 16, 16)[FLOAT]], [1103 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_313 for ONNX node: Add_313
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1121 for ONNX tensor: 1121
[03/27/2022-19:09:38] [V] [TRT] Add_313 [Add] outputs: [1121 -> (4, 208, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_314 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1121
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1543
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1544
[03/27/2022-19:09:38] [V] [TRT] Conv_314 [Conv] inputs: [1121 -> (4, 208, 16, 16)[FLOAT]], [1543 -> (1248, 208, 1, 1)[FLOAT]], [1544 -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 208, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_314 for ONNX node: Conv_314
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1542 for ONNX tensor: 1542
[03/27/2022-19:09:38] [V] [TRT] Conv_314 [Conv] outputs: [1542 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_315 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1542
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_315 [Sigmoid] inputs: [1542 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_315 for ONNX node: Sigmoid_315
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1124 for ONNX tensor: 1124
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_315 [Sigmoid] outputs: [1124 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_316 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1542
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1124
[03/27/2022-19:09:38] [V] [TRT] Mul_316 [Mul] inputs: [1542 -> (4, 1248, 16, 16)[FLOAT]], [1124 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_316 for ONNX node: Mul_316
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1125 for ONNX tensor: 1125
[03/27/2022-19:09:38] [V] [TRT] Mul_316 [Mul] outputs: [1125 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_317 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1125
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1546
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1547
[03/27/2022-19:09:38] [V] [TRT] Conv_317 [Conv] inputs: [1125 -> (4, 1248, 16, 16)[FLOAT]], [1546 -> (1248, 1, 3, 3)[FLOAT]], [1547 -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_317 for ONNX node: Conv_317
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1545 for ONNX tensor: 1545
[03/27/2022-19:09:38] [V] [TRT] Conv_317 [Conv] outputs: [1545 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_318 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1545
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_318 [Sigmoid] inputs: [1545 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_318 for ONNX node: Sigmoid_318
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1128 for ONNX tensor: 1128
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_318 [Sigmoid] outputs: [1128 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_319 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1545
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1128
[03/27/2022-19:09:38] [V] [TRT] Mul_319 [Mul] inputs: [1545 -> (4, 1248, 16, 16)[FLOAT]], [1128 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_319 for ONNX node: Mul_319
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1129 for ONNX tensor: 1129
[03/27/2022-19:09:38] [V] [TRT] Mul_319 [Mul] outputs: [1129 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_320 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1129
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_320 [ReduceMean] inputs: [1129 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_320 for ONNX node: ReduceMean_320
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1130 for ONNX tensor: 1130
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_320 [ReduceMean] outputs: [1130 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_321 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1130
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder7.0.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder7.0.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_321 [Conv] inputs: [1130 -> (4, 1248, 1, 1)[FLOAT]], [encoder7.0.se.conv_reduce.weight -> (52, 1248, 1, 1)[FLOAT]], [encoder7.0.se.conv_reduce.bias -> (52)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_321 for ONNX node: Conv_321
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 52
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 52, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1131 for ONNX tensor: 1131
[03/27/2022-19:09:38] [V] [TRT] Conv_321 [Conv] outputs: [1131 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_322 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1131
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_322 [Sigmoid] inputs: [1131 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_322 for ONNX node: Sigmoid_322
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1132 for ONNX tensor: 1132
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_322 [Sigmoid] outputs: [1132 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_323 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1131
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1132
[03/27/2022-19:09:38] [V] [TRT] Mul_323 [Mul] inputs: [1131 -> (4, 52, 1, 1)[FLOAT]], [1132 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_323 for ONNX node: Mul_323
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1133 for ONNX tensor: 1133
[03/27/2022-19:09:38] [V] [TRT] Mul_323 [Mul] outputs: [1133 -> (4, 52, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_324 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1133
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder7.0.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder7.0.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_324 [Conv] inputs: [1133 -> (4, 52, 1, 1)[FLOAT]], [encoder7.0.se.conv_expand.weight -> (1248, 52, 1, 1)[FLOAT]], [encoder7.0.se.conv_expand.bias -> (1248)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 52, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_324 for ONNX node: Conv_324
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1248
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1248, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1134 for ONNX tensor: 1134
[03/27/2022-19:09:38] [V] [TRT] Conv_324 [Conv] outputs: [1134 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_325 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1134
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_325 [Sigmoid] inputs: [1134 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_325 for ONNX node: Sigmoid_325
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1135 for ONNX tensor: 1135
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_325 [Sigmoid] outputs: [1135 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_326 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1129
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1135
[03/27/2022-19:09:38] [V] [TRT] Mul_326 [Mul] inputs: [1129 -> (4, 1248, 16, 16)[FLOAT]], [1135 -> (4, 1248, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_326 for ONNX node: Mul_326
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1136 for ONNX tensor: 1136
[03/27/2022-19:09:38] [V] [TRT] Mul_326 [Mul] outputs: [1136 -> (4, 1248, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_327 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1136
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1549
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1550
[03/27/2022-19:09:38] [V] [TRT] Conv_327 [Conv] inputs: [1136 -> (4, 1248, 16, 16)[FLOAT]], [1549 -> (352, 1248, 1, 1)[FLOAT]], [1550 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1248, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_327 for ONNX node: Conv_327
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1548 for ONNX tensor: 1548
[03/27/2022-19:09:38] [V] [TRT] Conv_327 [Conv] outputs: [1548 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_328 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1548
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1552
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1553
[03/27/2022-19:09:38] [V] [TRT] Conv_328 [Conv] inputs: [1548 -> (4, 352, 16, 16)[FLOAT]], [1552 -> (2112, 352, 1, 1)[FLOAT]], [1553 -> (2112)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_328 for ONNX node: Conv_328
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 2112
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 2112, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1551 for ONNX tensor: 1551
[03/27/2022-19:09:38] [V] [TRT] Conv_328 [Conv] outputs: [1551 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_329 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1551
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_329 [Sigmoid] inputs: [1551 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_329 for ONNX node: Sigmoid_329
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1141 for ONNX tensor: 1141
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_329 [Sigmoid] outputs: [1141 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_330 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1551
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1141
[03/27/2022-19:09:38] [V] [TRT] Mul_330 [Mul] inputs: [1551 -> (4, 2112, 16, 16)[FLOAT]], [1141 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_330 for ONNX node: Mul_330
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1142 for ONNX tensor: 1142
[03/27/2022-19:09:38] [V] [TRT] Mul_330 [Mul] outputs: [1142 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_331 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1142
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1555
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1556
[03/27/2022-19:09:38] [V] [TRT] Conv_331 [Conv] inputs: [1142 -> (4, 2112, 16, 16)[FLOAT]], [1555 -> (2112, 1, 3, 3)[FLOAT]], [1556 -> (2112)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 2112, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_331 for ONNX node: Conv_331
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2112
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 2112, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1554 for ONNX tensor: 1554
[03/27/2022-19:09:38] [V] [TRT] Conv_331 [Conv] outputs: [1554 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_332 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1554
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_332 [Sigmoid] inputs: [1554 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_332 for ONNX node: Sigmoid_332
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1145 for ONNX tensor: 1145
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_332 [Sigmoid] outputs: [1145 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_333 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1554
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1145
[03/27/2022-19:09:38] [V] [TRT] Mul_333 [Mul] inputs: [1554 -> (4, 2112, 16, 16)[FLOAT]], [1145 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_333 for ONNX node: Mul_333
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1146 for ONNX tensor: 1146
[03/27/2022-19:09:38] [V] [TRT] Mul_333 [Mul] outputs: [1146 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ReduceMean_334 [ReduceMean]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1146
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_334 [ReduceMean] inputs: [1146 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ReduceMean_334 for ONNX node: ReduceMean_334
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1147 for ONNX tensor: 1147
[03/27/2022-19:09:38] [V] [TRT] ReduceMean_334 [ReduceMean] outputs: [1147 -> (4, 2112, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_335 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1147
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder7.1.se.conv_reduce.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder7.1.se.conv_reduce.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_335 [Conv] inputs: [1147 -> (4, 2112, 1, 1)[FLOAT]], [encoder7.1.se.conv_reduce.weight -> (88, 2112, 1, 1)[FLOAT]], [encoder7.1.se.conv_reduce.bias -> (88)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 2112, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_335 for ONNX node: Conv_335
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 88
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 88, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1148 for ONNX tensor: 1148
[03/27/2022-19:09:38] [V] [TRT] Conv_335 [Conv] outputs: [1148 -> (4, 88, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_336 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1148
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_336 [Sigmoid] inputs: [1148 -> (4, 88, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_336 for ONNX node: Sigmoid_336
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1149 for ONNX tensor: 1149
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_336 [Sigmoid] outputs: [1149 -> (4, 88, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_337 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1148
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1149
[03/27/2022-19:09:38] [V] [TRT] Mul_337 [Mul] inputs: [1148 -> (4, 88, 1, 1)[FLOAT]], [1149 -> (4, 88, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_337 for ONNX node: Mul_337
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1150 for ONNX tensor: 1150
[03/27/2022-19:09:38] [V] [TRT] Mul_337 [Mul] outputs: [1150 -> (4, 88, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_338 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1150
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder7.1.se.conv_expand.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: encoder7.1.se.conv_expand.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_338 [Conv] inputs: [1150 -> (4, 88, 1, 1)[FLOAT]], [encoder7.1.se.conv_expand.weight -> (2112, 88, 1, 1)[FLOAT]], [encoder7.1.se.conv_expand.bias -> (2112)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 88, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_338 for ONNX node: Conv_338
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 2112
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 2112, 1, 1)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1151 for ONNX tensor: 1151
[03/27/2022-19:09:38] [V] [TRT] Conv_338 [Conv] outputs: [1151 -> (4, 2112, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_339 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1151
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_339 [Sigmoid] inputs: [1151 -> (4, 2112, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_339 for ONNX node: Sigmoid_339
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1152 for ONNX tensor: 1152
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_339 [Sigmoid] outputs: [1152 -> (4, 2112, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_340 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1146
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1152
[03/27/2022-19:09:38] [V] [TRT] Mul_340 [Mul] inputs: [1146 -> (4, 2112, 16, 16)[FLOAT]], [1152 -> (4, 2112, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_340 for ONNX node: Mul_340
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1153 for ONNX tensor: 1153
[03/27/2022-19:09:38] [V] [TRT] Mul_340 [Mul] outputs: [1153 -> (4, 2112, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_341 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1153
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1558
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1559
[03/27/2022-19:09:38] [V] [TRT] Conv_341 [Conv] inputs: [1153 -> (4, 2112, 16, 16)[FLOAT]], [1558 -> (352, 2112, 1, 1)[FLOAT]], [1559 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 2112, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_341 for ONNX node: Conv_341
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1557 for ONNX tensor: 1557
[03/27/2022-19:09:38] [V] [TRT] Conv_341 [Conv] outputs: [1557 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_342 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1557
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1548
[03/27/2022-19:09:38] [V] [TRT] Add_342 [Add] inputs: [1557 -> (4, 352, 16, 16)[FLOAT]], [1548 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_342 for ONNX node: Add_342
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1156 for ONNX tensor: 1156
[03/27/2022-19:09:38] [V] [TRT] Add_342 [Add] outputs: [1156 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_343 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1156
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1561
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1562
[03/27/2022-19:09:38] [V] [TRT] Conv_343 [Conv] inputs: [1156 -> (4, 352, 16, 16)[FLOAT]], [1561 -> (352, 352, 1, 1)[FLOAT]], [1562 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_343 for ONNX node: Conv_343
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1560 for ONNX tensor: 1560
[03/27/2022-19:09:38] [V] [TRT] Conv_343 [Conv] outputs: [1560 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_344 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1156
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1564
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1565
[03/27/2022-19:09:38] [V] [TRT] Conv_344 [Conv] inputs: [1156 -> (4, 352, 16, 16)[FLOAT]], [1564 -> (352, 352, 1, 1)[FLOAT]], [1565 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_344 for ONNX node: Conv_344
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1563 for ONNX tensor: 1563
[03/27/2022-19:09:38] [V] [TRT] Conv_344 [Conv] outputs: [1563 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_345 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1563
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1567
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1568
[03/27/2022-19:09:38] [V] [TRT] Conv_345 [Conv] inputs: [1563 -> (4, 352, 16, 16)[FLOAT]], [1567 -> (352, 352, 1, 3)[FLOAT]], [1568 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_345 for ONNX node: Conv_345
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 3), strides: (1, 1), prepadding: (0, 1), postpadding: (0, 1), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1566 for ONNX tensor: 1566
[03/27/2022-19:09:38] [V] [TRT] Conv_345 [Conv] outputs: [1566 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_346 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1566
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1570
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1571
[03/27/2022-19:09:38] [V] [TRT] Conv_346 [Conv] inputs: [1566 -> (4, 352, 16, 16)[FLOAT]], [1570 -> (352, 352, 3, 1)[FLOAT]], [1571 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_346 for ONNX node: Conv_346
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 1), strides: (1, 1), prepadding: (1, 0), postpadding: (1, 0), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1569 for ONNX tensor: 1569
[03/27/2022-19:09:38] [V] [TRT] Conv_346 [Conv] outputs: [1569 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_347 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1569
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1573
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1574
[03/27/2022-19:09:38] [V] [TRT] Conv_347 [Conv] inputs: [1569 -> (4, 352, 16, 16)[FLOAT]], [1573 -> (352, 352, 3, 3)[FLOAT]], [1574 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_347 for ONNX node: Conv_347
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (3, 3), postpadding: (3, 3), dilations: (3, 3), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1572 for ONNX tensor: 1572
[03/27/2022-19:09:38] [V] [TRT] Conv_347 [Conv] outputs: [1572 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_348 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1156
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1576
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1577
[03/27/2022-19:09:38] [V] [TRT] Conv_348 [Conv] inputs: [1156 -> (4, 352, 16, 16)[FLOAT]], [1576 -> (352, 352, 1, 1)[FLOAT]], [1577 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_348 for ONNX node: Conv_348
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1575 for ONNX tensor: 1575
[03/27/2022-19:09:38] [V] [TRT] Conv_348 [Conv] outputs: [1575 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_349 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1575
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1579
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1580
[03/27/2022-19:09:38] [V] [TRT] Conv_349 [Conv] inputs: [1575 -> (4, 352, 16, 16)[FLOAT]], [1579 -> (352, 352, 1, 5)[FLOAT]], [1580 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_349 for ONNX node: Conv_349
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 5), strides: (1, 1), prepadding: (0, 2), postpadding: (0, 2), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1578 for ONNX tensor: 1578
[03/27/2022-19:09:38] [V] [TRT] Conv_349 [Conv] outputs: [1578 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_350 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1578
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1582
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1583
[03/27/2022-19:09:38] [V] [TRT] Conv_350 [Conv] inputs: [1578 -> (4, 352, 16, 16)[FLOAT]], [1582 -> (352, 352, 5, 1)[FLOAT]], [1583 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_350 for ONNX node: Conv_350
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (5, 1), strides: (1, 1), prepadding: (2, 0), postpadding: (2, 0), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1581 for ONNX tensor: 1581
[03/27/2022-19:09:38] [V] [TRT] Conv_350 [Conv] outputs: [1581 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_351 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1581
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1585
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1586
[03/27/2022-19:09:38] [V] [TRT] Conv_351 [Conv] inputs: [1581 -> (4, 352, 16, 16)[FLOAT]], [1585 -> (352, 352, 3, 3)[FLOAT]], [1586 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_351 for ONNX node: Conv_351
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (5, 5), postpadding: (5, 5), dilations: (5, 5), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1584 for ONNX tensor: 1584
[03/27/2022-19:09:38] [V] [TRT] Conv_351 [Conv] outputs: [1584 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_352 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1156
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1588
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1589
[03/27/2022-19:09:38] [V] [TRT] Conv_352 [Conv] inputs: [1156 -> (4, 352, 16, 16)[FLOAT]], [1588 -> (352, 352, 1, 1)[FLOAT]], [1589 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_352 for ONNX node: Conv_352
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1587 for ONNX tensor: 1587
[03/27/2022-19:09:38] [V] [TRT] Conv_352 [Conv] outputs: [1587 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_353 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1587
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1591
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1592
[03/27/2022-19:09:38] [V] [TRT] Conv_353 [Conv] inputs: [1587 -> (4, 352, 16, 16)[FLOAT]], [1591 -> (352, 352, 1, 7)[FLOAT]], [1592 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_353 for ONNX node: Conv_353
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 7), strides: (1, 1), prepadding: (0, 3), postpadding: (0, 3), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1590 for ONNX tensor: 1590
[03/27/2022-19:09:38] [V] [TRT] Conv_353 [Conv] outputs: [1590 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_354 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1590
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1594
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1595
[03/27/2022-19:09:38] [V] [TRT] Conv_354 [Conv] inputs: [1590 -> (4, 352, 16, 16)[FLOAT]], [1594 -> (352, 352, 7, 1)[FLOAT]], [1595 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_354 for ONNX node: Conv_354
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (7, 1), strides: (1, 1), prepadding: (3, 0), postpadding: (3, 0), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1593 for ONNX tensor: 1593
[03/27/2022-19:09:38] [V] [TRT] Conv_354 [Conv] outputs: [1593 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_355 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1593
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1597
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1598
[03/27/2022-19:09:38] [V] [TRT] Conv_355 [Conv] inputs: [1593 -> (4, 352, 16, 16)[FLOAT]], [1597 -> (352, 352, 3, 3)[FLOAT]], [1598 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_355 for ONNX node: Conv_355
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (7, 7), postpadding: (7, 7), dilations: (7, 7), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1596 for ONNX tensor: 1596
[03/27/2022-19:09:38] [V] [TRT] Conv_355 [Conv] outputs: [1596 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_356 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1560
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1572
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1584
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1596
[03/27/2022-19:09:38] [V] [TRT] Concat_356 [Concat] inputs: [1560 -> (4, 352, 16, 16)[FLOAT]], [1572 -> (4, 352, 16, 16)[FLOAT]], [1584 -> (4, 352, 16, 16)[FLOAT]], [1596 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_356 for ONNX node: Concat_356
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1183 for ONNX tensor: 1183
[03/27/2022-19:09:38] [V] [TRT] Concat_356 [Concat] outputs: [1183 -> (4, 1408, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_357 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1183
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1600
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1601
[03/27/2022-19:09:38] [V] [TRT] Conv_357 [Conv] inputs: [1183 -> (4, 1408, 16, 16)[FLOAT]], [1600 -> (352, 1408, 3, 3)[FLOAT]], [1601 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 1408, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_357 for ONNX node: Conv_357
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1599 for ONNX tensor: 1599
[03/27/2022-19:09:38] [V] [TRT] Conv_357 [Conv] outputs: [1599 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_358 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1156
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1603
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1604
[03/27/2022-19:09:38] [V] [TRT] Conv_358 [Conv] inputs: [1156 -> (4, 352, 16, 16)[FLOAT]], [1603 -> (352, 352, 1, 1)[FLOAT]], [1604 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_358 for ONNX node: Conv_358
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1602 for ONNX tensor: 1602
[03/27/2022-19:09:38] [V] [TRT] Conv_358 [Conv] outputs: [1602 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_359 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1599
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1602
[03/27/2022-19:09:38] [V] [TRT] Add_359 [Add] inputs: [1599 -> (4, 352, 16, 16)[FLOAT]], [1602 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_359 for ONNX node: Add_359
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1188 for ONNX tensor: 1188
[03/27/2022-19:09:38] [V] [TRT] Add_359 [Add] outputs: [1188 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_360 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1188
[03/27/2022-19:09:38] [V] [TRT] Relu_360 [Relu] inputs: [1188 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_360 for ONNX node: Relu_360
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1189 for ONNX tensor: 1189
[03/27/2022-19:09:38] [V] [TRT] Relu_360 [Relu] outputs: [1189 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_361 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1189
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1606
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1607
[03/27/2022-19:09:38] [V] [TRT] Conv_361 [Conv] inputs: [1189 -> (4, 352, 16, 16)[FLOAT]], [1606 -> (352, 352, 3, 3)[FLOAT]], [1607 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_361 for ONNX node: Conv_361
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (2, 2), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1605 for ONNX tensor: 1605
[03/27/2022-19:09:38] [V] [TRT] Conv_361 [Conv] outputs: [1605 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_362 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1605
[03/27/2022-19:09:38] [V] [TRT] Relu_362 [Relu] inputs: [1605 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_362 for ONNX node: Relu_362
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1192 for ONNX tensor: 1192
[03/27/2022-19:09:38] [V] [TRT] Relu_362 [Relu] outputs: [1192 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_363 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1192
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1609
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1610
[03/27/2022-19:09:38] [V] [TRT] Conv_363 [Conv] inputs: [1192 -> (4, 352, 16, 16)[FLOAT]], [1609 -> (352, 352, 3, 3)[FLOAT]], [1610 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_363 for ONNX node: Conv_363
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (2, 2), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1608 for ONNX tensor: 1608
[03/27/2022-19:09:38] [V] [TRT] Conv_363 [Conv] outputs: [1608 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_364 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1608
[03/27/2022-19:09:38] [V] [TRT] Relu_364 [Relu] inputs: [1608 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_364 for ONNX node: Relu_364
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1195 for ONNX tensor: 1195
[03/27/2022-19:09:38] [V] [TRT] Relu_364 [Relu] outputs: [1195 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_365 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1195
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1612
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1613
[03/27/2022-19:09:38] [V] [TRT] Conv_365 [Conv] inputs: [1195 -> (4, 352, 16, 16)[FLOAT]], [1612 -> (352, 352, 3, 3)[FLOAT]], [1613 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_365 for ONNX node: Conv_365
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (2, 2), postpadding: (2, 2), dilations: (2, 2), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1611 for ONNX tensor: 1611
[03/27/2022-19:09:38] [V] [TRT] Conv_365 [Conv] outputs: [1611 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_366 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1611
[03/27/2022-19:09:38] [V] [TRT] Relu_366 [Relu] inputs: [1611 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_366 for ONNX node: Relu_366
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1198 for ONNX tensor: 1198
[03/27/2022-19:09:38] [V] [TRT] Relu_366 [Relu] outputs: [1198 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_367 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1198
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1156
[03/27/2022-19:09:38] [V] [TRT] Concat_367 [Concat] inputs: [1198 -> (4, 352, 16, 16)[FLOAT]], [1156 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_367 for ONNX node: Concat_367
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1199 for ONNX tensor: 1199
[03/27/2022-19:09:38] [V] [TRT] Concat_367 [Concat] outputs: [1199 -> (4, 704, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_368 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1199
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1615
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1616
[03/27/2022-19:09:38] [V] [TRT] Conv_368 [Conv] inputs: [1199 -> (4, 704, 16, 16)[FLOAT]], [1615 -> (352, 704, 3, 3)[FLOAT]], [1616 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 704, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_368 for ONNX node: Conv_368
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1614 for ONNX tensor: 1614
[03/27/2022-19:09:38] [V] [TRT] Conv_368 [Conv] outputs: [1614 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_369 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1614
[03/27/2022-19:09:38] [V] [TRT] Relu_369 [Relu] inputs: [1614 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_369 for ONNX node: Relu_369
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1202 for ONNX tensor: 1202
[03/27/2022-19:09:38] [V] [TRT] Relu_369 [Relu] outputs: [1202 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_370 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1202
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1618
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1619
[03/27/2022-19:09:38] [V] [TRT] Conv_370 [Conv] inputs: [1202 -> (4, 352, 16, 16)[FLOAT]], [1618 -> (352, 352, 3, 3)[FLOAT]], [1619 -> (352)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_370 for ONNX node: Conv_370
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 352
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1617 for ONNX tensor: 1617
[03/27/2022-19:09:38] [V] [TRT] Conv_370 [Conv] outputs: [1617 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_371 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1617
[03/27/2022-19:09:38] [V] [TRT] Relu_371 [Relu] inputs: [1617 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_371 for ONNX node: Relu_371
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1205 for ONNX tensor: 1205
[03/27/2022-19:09:38] [V] [TRT] Relu_371 [Relu] outputs: [1205 -> (4, 352, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_372 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1205
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1621
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1622
[03/27/2022-19:09:38] [V] [TRT] Conv_372 [Conv] inputs: [1205 -> (4, 352, 16, 16)[FLOAT]], [1621 -> (120, 352, 3, 3)[FLOAT]], [1622 -> (120)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 352, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_372 for ONNX node: Conv_372
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 120
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 120, 16, 16)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1620 for ONNX tensor: 1620
[03/27/2022-19:09:38] [V] [TRT] Conv_372 [Conv] outputs: [1620 -> (4, 120, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_373 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1620
[03/27/2022-19:09:38] [V] [TRT] Relu_373 [Relu] inputs: [1620 -> (4, 120, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_373 for ONNX node: Relu_373
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1208 for ONNX tensor: 1208
[03/27/2022-19:09:38] [V] [TRT] Relu_373 [Relu] outputs: [1208 -> (4, 120, 16, 16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_374 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_374 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_374 [Constant] outputs: [1212 -> ()[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Resize_375 [Resize]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1208
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1212
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1666
[03/27/2022-19:09:38] [V] [TRT] Resize_375 [Resize] inputs: [1208 -> (4, 120, 16, 16)[FLOAT]], [1212 -> ()[FLOAT]], [1666 -> (4)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Resize_375 for ONNX node: Resize_375
[03/27/2022-19:09:38] [V] [TRT] Running resize layer with: 
Transformation mode: pytorch_half_pixel
Resize mode: linear

[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1213 for ONNX tensor: 1213
[03/27/2022-19:09:38] [V] [TRT] Resize_375 [Resize] outputs: [1213 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_376 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1213
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1032
[03/27/2022-19:09:38] [V] [TRT] Concat_376 [Concat] inputs: [1213 -> (4, 120, 32, 32)[FLOAT]], [1032 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_376 for ONNX node: Concat_376
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1214 for ONNX tensor: 1214
[03/27/2022-19:09:38] [V] [TRT] Concat_376 [Concat] outputs: [1214 -> (4, 240, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_377 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1214
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1624
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1625
[03/27/2022-19:09:38] [V] [TRT] Conv_377 [Conv] inputs: [1214 -> (4, 240, 32, 32)[FLOAT]], [1624 -> (120, 240, 3, 3)[FLOAT]], [1625 -> (120)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 240, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_377 for ONNX node: Conv_377
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 120
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1623 for ONNX tensor: 1623
[03/27/2022-19:09:38] [V] [TRT] Conv_377 [Conv] outputs: [1623 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_378 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1623
[03/27/2022-19:09:38] [V] [TRT] Relu_378 [Relu] inputs: [1623 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_378 for ONNX node: Relu_378
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1217 for ONNX tensor: 1217
[03/27/2022-19:09:38] [V] [TRT] Relu_378 [Relu] outputs: [1217 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_379 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1217
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1627
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1628
[03/27/2022-19:09:38] [V] [TRT] Conv_379 [Conv] inputs: [1217 -> (4, 120, 32, 32)[FLOAT]], [1627 -> (120, 120, 3, 3)[FLOAT]], [1628 -> (120)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_379 for ONNX node: Conv_379
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 120
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1626 for ONNX tensor: 1626
[03/27/2022-19:09:38] [V] [TRT] Conv_379 [Conv] outputs: [1626 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_380 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1626
[03/27/2022-19:09:38] [V] [TRT] Relu_380 [Relu] inputs: [1626 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_380 for ONNX node: Relu_380
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1220 for ONNX tensor: 1220
[03/27/2022-19:09:38] [V] [TRT] Relu_380 [Relu] outputs: [1220 -> (4, 120, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_381 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1220
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1630
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1631
[03/27/2022-19:09:38] [V] [TRT] Conv_381 [Conv] inputs: [1220 -> (4, 120, 32, 32)[FLOAT]], [1630 -> (48, 120, 3, 3)[FLOAT]], [1631 -> (48)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 120, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_381 for ONNX node: Conv_381
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 48
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 48, 32, 32)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1629 for ONNX tensor: 1629
[03/27/2022-19:09:38] [V] [TRT] Conv_381 [Conv] outputs: [1629 -> (4, 48, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_382 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1629
[03/27/2022-19:09:38] [V] [TRT] Relu_382 [Relu] inputs: [1629 -> (4, 48, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_382 for ONNX node: Relu_382
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1223 for ONNX tensor: 1223
[03/27/2022-19:09:38] [V] [TRT] Relu_382 [Relu] outputs: [1223 -> (4, 48, 32, 32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_383 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_383 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_383 [Constant] outputs: [1227 -> ()[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Resize_384 [Resize]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1223
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1227
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1667
[03/27/2022-19:09:38] [V] [TRT] Resize_384 [Resize] inputs: [1223 -> (4, 48, 32, 32)[FLOAT]], [1227 -> ()[FLOAT]], [1667 -> (4)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Resize_384 for ONNX node: Resize_384
[03/27/2022-19:09:38] [V] [TRT] Running resize layer with: 
Transformation mode: pytorch_half_pixel
Resize mode: linear

[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1228 for ONNX tensor: 1228
[03/27/2022-19:09:38] [V] [TRT] Resize_384 [Resize] outputs: [1228 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_385 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1228
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 890
[03/27/2022-19:09:38] [V] [TRT] Concat_385 [Concat] inputs: [1228 -> (4, 48, 64, 64)[FLOAT]], [890 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_385 for ONNX node: Concat_385
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1229 for ONNX tensor: 1229
[03/27/2022-19:09:38] [V] [TRT] Concat_385 [Concat] outputs: [1229 -> (4, 96, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_386 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1229
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1633
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1634
[03/27/2022-19:09:38] [V] [TRT] Conv_386 [Conv] inputs: [1229 -> (4, 96, 64, 64)[FLOAT]], [1633 -> (48, 96, 3, 3)[FLOAT]], [1634 -> (48)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 96, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_386 for ONNX node: Conv_386
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 48
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 48, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1632 for ONNX tensor: 1632
[03/27/2022-19:09:38] [V] [TRT] Conv_386 [Conv] outputs: [1632 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_387 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1632
[03/27/2022-19:09:38] [V] [TRT] Relu_387 [Relu] inputs: [1632 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_387 for ONNX node: Relu_387
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1232 for ONNX tensor: 1232
[03/27/2022-19:09:38] [V] [TRT] Relu_387 [Relu] outputs: [1232 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_388 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1232
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1636
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1637
[03/27/2022-19:09:38] [V] [TRT] Conv_388 [Conv] inputs: [1232 -> (4, 48, 64, 64)[FLOAT]], [1636 -> (48, 48, 3, 3)[FLOAT]], [1637 -> (48)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 48, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_388 for ONNX node: Conv_388
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 48
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 48, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1635 for ONNX tensor: 1635
[03/27/2022-19:09:38] [V] [TRT] Conv_388 [Conv] outputs: [1635 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_389 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1635
[03/27/2022-19:09:38] [V] [TRT] Relu_389 [Relu] inputs: [1635 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_389 for ONNX node: Relu_389
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1235 for ONNX tensor: 1235
[03/27/2022-19:09:38] [V] [TRT] Relu_389 [Relu] outputs: [1235 -> (4, 48, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_390 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1235
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1639
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1640
[03/27/2022-19:09:38] [V] [TRT] Conv_390 [Conv] inputs: [1235 -> (4, 48, 64, 64)[FLOAT]], [1639 -> (24, 48, 3, 3)[FLOAT]], [1640 -> (24)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 48, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_390 for ONNX node: Conv_390
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 24
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 24, 64, 64)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1638 for ONNX tensor: 1638
[03/27/2022-19:09:38] [V] [TRT] Conv_390 [Conv] outputs: [1638 -> (4, 24, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_391 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1638
[03/27/2022-19:09:38] [V] [TRT] Relu_391 [Relu] inputs: [1638 -> (4, 24, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_391 for ONNX node: Relu_391
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1238 for ONNX tensor: 1238
[03/27/2022-19:09:38] [V] [TRT] Relu_391 [Relu] outputs: [1238 -> (4, 24, 64, 64)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_392 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_392 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_392 [Constant] outputs: [1242 -> ()[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Resize_393 [Resize]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1238
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1242
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1668
[03/27/2022-19:09:38] [V] [TRT] Resize_393 [Resize] inputs: [1238 -> (4, 24, 64, 64)[FLOAT]], [1242 -> ()[FLOAT]], [1668 -> (4)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Resize_393 for ONNX node: Resize_393
[03/27/2022-19:09:38] [V] [TRT] Running resize layer with: 
Transformation mode: pytorch_half_pixel
Resize mode: linear

[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1243 for ONNX tensor: 1243
[03/27/2022-19:09:38] [V] [TRT] Resize_393 [Resize] outputs: [1243 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_394 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1243
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 837
[03/27/2022-19:09:38] [V] [TRT] Concat_394 [Concat] inputs: [1243 -> (4, 24, 128, 128)[FLOAT]], [837 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_394 for ONNX node: Concat_394
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1244 for ONNX tensor: 1244
[03/27/2022-19:09:38] [V] [TRT] Concat_394 [Concat] outputs: [1244 -> (4, 48, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_395 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1244
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1642
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1643
[03/27/2022-19:09:38] [V] [TRT] Conv_395 [Conv] inputs: [1244 -> (4, 48, 128, 128)[FLOAT]], [1642 -> (24, 48, 3, 3)[FLOAT]], [1643 -> (24)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 48, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_395 for ONNX node: Conv_395
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 24
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 24, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1641 for ONNX tensor: 1641
[03/27/2022-19:09:38] [V] [TRT] Conv_395 [Conv] outputs: [1641 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_396 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1641
[03/27/2022-19:09:38] [V] [TRT] Relu_396 [Relu] inputs: [1641 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_396 for ONNX node: Relu_396
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1247 for ONNX tensor: 1247
[03/27/2022-19:09:38] [V] [TRT] Relu_396 [Relu] outputs: [1247 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_397 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1247
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1645
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1646
[03/27/2022-19:09:38] [V] [TRT] Conv_397 [Conv] inputs: [1247 -> (4, 24, 128, 128)[FLOAT]], [1645 -> (24, 24, 3, 3)[FLOAT]], [1646 -> (24)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 24, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_397 for ONNX node: Conv_397
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 24
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 24, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1644 for ONNX tensor: 1644
[03/27/2022-19:09:38] [V] [TRT] Conv_397 [Conv] outputs: [1644 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_398 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1644
[03/27/2022-19:09:38] [V] [TRT] Relu_398 [Relu] inputs: [1644 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_398 for ONNX node: Relu_398
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1250 for ONNX tensor: 1250
[03/27/2022-19:09:38] [V] [TRT] Relu_398 [Relu] outputs: [1250 -> (4, 24, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_399 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1250
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1648
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1649
[03/27/2022-19:09:38] [V] [TRT] Conv_399 [Conv] inputs: [1250 -> (4, 24, 128, 128)[FLOAT]], [1648 -> (16, 24, 3, 3)[FLOAT]], [1649 -> (16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 24, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_399 for ONNX node: Conv_399
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 16
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 16, 128, 128)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1647 for ONNX tensor: 1647
[03/27/2022-19:09:38] [V] [TRT] Conv_399 [Conv] outputs: [1647 -> (4, 16, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_400 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1647
[03/27/2022-19:09:38] [V] [TRT] Relu_400 [Relu] inputs: [1647 -> (4, 16, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_400 for ONNX node: Relu_400
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1253 for ONNX tensor: 1253
[03/27/2022-19:09:38] [V] [TRT] Relu_400 [Relu] outputs: [1253 -> (4, 16, 128, 128)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_401 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_401 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_401 [Constant] outputs: [1257 -> ()[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Resize_402 [Resize]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1253
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1257
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1669
[03/27/2022-19:09:38] [V] [TRT] Resize_402 [Resize] inputs: [1253 -> (4, 16, 128, 128)[FLOAT]], [1257 -> ()[FLOAT]], [1669 -> (4)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Resize_402 for ONNX node: Resize_402
[03/27/2022-19:09:38] [V] [TRT] Running resize layer with: 
Transformation mode: pytorch_half_pixel
Resize mode: linear

[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1258 for ONNX tensor: 1258
[03/27/2022-19:09:38] [V] [TRT] Resize_402 [Resize] outputs: [1258 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_403 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1258
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 784
[03/27/2022-19:09:38] [V] [TRT] Concat_403 [Concat] inputs: [1258 -> (4, 16, 256, 256)[FLOAT]], [784 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_403 for ONNX node: Concat_403
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1259 for ONNX tensor: 1259
[03/27/2022-19:09:38] [V] [TRT] Concat_403 [Concat] outputs: [1259 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_404 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1259
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1651
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1652
[03/27/2022-19:09:38] [V] [TRT] Conv_404 [Conv] inputs: [1259 -> (4, 32, 256, 256)[FLOAT]], [1651 -> (16, 32, 3, 3)[FLOAT]], [1652 -> (16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 32, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_404 for ONNX node: Conv_404
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 16
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1650 for ONNX tensor: 1650
[03/27/2022-19:09:38] [V] [TRT] Conv_404 [Conv] outputs: [1650 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_405 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1650
[03/27/2022-19:09:38] [V] [TRT] Relu_405 [Relu] inputs: [1650 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_405 for ONNX node: Relu_405
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1262 for ONNX tensor: 1262
[03/27/2022-19:09:38] [V] [TRT] Relu_405 [Relu] outputs: [1262 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_406 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1262
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1654
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1655
[03/27/2022-19:09:38] [V] [TRT] Conv_406 [Conv] inputs: [1262 -> (4, 16, 256, 256)[FLOAT]], [1654 -> (16, 16, 3, 3)[FLOAT]], [1655 -> (16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_406 for ONNX node: Conv_406
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 16
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1653 for ONNX tensor: 1653
[03/27/2022-19:09:38] [V] [TRT] Conv_406 [Conv] outputs: [1653 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_407 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1653
[03/27/2022-19:09:38] [V] [TRT] Relu_407 [Relu] inputs: [1653 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_407 for ONNX node: Relu_407
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1265 for ONNX tensor: 1265
[03/27/2022-19:09:38] [V] [TRT] Relu_407 [Relu] outputs: [1265 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_408 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1265
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1657
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1658
[03/27/2022-19:09:38] [V] [TRT] Conv_408 [Conv] inputs: [1265 -> (4, 16, 256, 256)[FLOAT]], [1657 -> (16, 16, 3, 3)[FLOAT]], [1658 -> (16)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_408 for ONNX node: Conv_408
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 16
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1656 for ONNX tensor: 1656
[03/27/2022-19:09:38] [V] [TRT] Conv_408 [Conv] outputs: [1656 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_409 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1656
[03/27/2022-19:09:38] [V] [TRT] Relu_409 [Relu] inputs: [1656 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_409 for ONNX node: Relu_409
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1268 for ONNX tensor: 1268
[03/27/2022-19:09:38] [V] [TRT] Relu_409 [Relu] outputs: [1268 -> (4, 16, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_410 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1268
[03/27/2022-19:09:38] [V] [TRT] Searching for input: outconv1.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: outconv1.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_410 [Conv] inputs: [1268 -> (4, 16, 256, 256)[FLOAT]], [outconv1.weight -> (1, 16, 3, 3)[FLOAT]], [outconv1.bias -> (1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 16, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_410 for ONNX node: Conv_410
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1269 for ONNX tensor: 1269
[03/27/2022-19:09:38] [V] [TRT] Conv_410 [Conv] outputs: [1269 -> (4, 1, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_411 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_411 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_411 [Constant] outputs: [1270 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_412 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_412 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_412 [Constant] outputs: [1271 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_413 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_413 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_413 [Constant] outputs: [1272 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_414 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_414 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_414 [Constant] outputs: [1273 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Slice_415 [Slice]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 754
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1271
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1272
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1270
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1273
[03/27/2022-19:09:38] [V] [TRT] Slice_415 [Slice] inputs: [754 -> (4, 3, 256, 256)[FLOAT]], [1271 -> (1)[INT32]], [1272 -> (1)[INT32]], [1270 -> (1)[INT32]], [1273 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Slice_415 for ONNX node: Slice_415
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1274 for ONNX tensor: 1274
[03/27/2022-19:09:38] [V] [TRT] Slice_415 [Slice] outputs: [1274 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_416 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_416 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_416 [Constant] outputs: [1275 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_417 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_417 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_417 [Constant] outputs: [1276 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_418 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_418 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_418 [Constant] outputs: [1277 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_419 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_419 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_419 [Constant] outputs: [1278 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Slice_420 [Slice]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1269
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1276
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1277
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1275
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1278
[03/27/2022-19:09:38] [V] [TRT] Slice_420 [Slice] inputs: [1269 -> (4, 1, 256, 256)[FLOAT]], [1276 -> (1)[INT32]], [1277 -> (1)[INT32]], [1275 -> (1)[INT32]], [1278 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Slice_420 for ONNX node: Slice_420
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1279 for ONNX tensor: 1279
[03/27/2022-19:09:38] [V] [TRT] Slice_420 [Slice] outputs: [1279 -> (4, 1, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_421 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_421 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_421 [Constant] outputs: [1280 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_422 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_422 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_422 [Constant] outputs: [1281 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_423 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_423 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_423 [Constant] outputs: [1282 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_424 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_424 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_424 [Constant] outputs: [1283 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Slice_425 [Slice]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: x_orig
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1281
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1282
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1280
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1283
[03/27/2022-19:09:38] [V] [TRT] Slice_425 [Slice] inputs: [x_orig -> (4, 3, 1280, 720)[FLOAT]], [1281 -> (1)[INT32]], [1282 -> (1)[INT32]], [1280 -> (1)[INT32]], [1283 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Slice_425 for ONNX node: Slice_425
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1284 for ONNX tensor: 1284
[03/27/2022-19:09:38] [V] [TRT] Slice_425 [Slice] outputs: [1284 -> (4, 3, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_426 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1279
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1279
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1279
[03/27/2022-19:09:38] [V] [TRT] Concat_426 [Concat] inputs: [1279 -> (4, 1, 256, 256)[FLOAT]], [1279 -> (4, 1, 256, 256)[FLOAT]], [1279 -> (4, 1, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_426 for ONNX node: Concat_426
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1285 for ONNX tensor: 1285
[03/27/2022-19:09:38] [V] [TRT] Concat_426 [Concat] outputs: [1285 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Shape_427 [Shape]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1274
[03/27/2022-19:09:38] [V] [TRT] Shape_427 [Shape] inputs: [1274 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Shape_427 for ONNX node: Shape_427
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1286 for ONNX tensor: 1286
[03/27/2022-19:09:38] [V] [TRT] Shape_427 [Shape] outputs: [1286 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_428 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_428 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_428 [Constant] outputs: [1287 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Gather_429 [Gather]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1286
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1287
[03/27/2022-19:09:38] [V] [TRT] Gather_429 [Gather] inputs: [1286 -> (4)[INT32]], [1287 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: 1287 for ONNX node: 1287
[03/27/2022-19:09:38] [V] [TRT] Using Gather axis: 0
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Gather_429 for ONNX node: Gather_429
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1288 for ONNX tensor: 1288
[03/27/2022-19:09:38] [V] [TRT] Gather_429 [Gather] outputs: [1288 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Shape_430 [Shape]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1274
[03/27/2022-19:09:38] [V] [TRT] Shape_430 [Shape] inputs: [1274 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Shape_430 for ONNX node: Shape_430
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1289 for ONNX tensor: 1289
[03/27/2022-19:09:38] [V] [TRT] Shape_430 [Shape] outputs: [1289 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_431 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_431 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_431 [Constant] outputs: [1290 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Gather_432 [Gather]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1289
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1290
[03/27/2022-19:09:38] [V] [TRT] Gather_432 [Gather] inputs: [1289 -> (4)[INT32]], [1290 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: 1290 for ONNX node: 1290
[03/27/2022-19:09:38] [V] [TRT] Using Gather axis: 0
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Gather_432 for ONNX node: Gather_432
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1291 for ONNX tensor: 1291
[03/27/2022-19:09:38] [V] [TRT] Gather_432 [Gather] outputs: [1291 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Shape_433 [Shape]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1274
[03/27/2022-19:09:38] [V] [TRT] Shape_433 [Shape] inputs: [1274 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Shape_433 for ONNX node: Shape_433
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1292 for ONNX tensor: 1292
[03/27/2022-19:09:38] [V] [TRT] Shape_433 [Shape] outputs: [1292 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_434 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_434 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_434 [Constant] outputs: [1293 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Gather_435 [Gather]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1292
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1293
[03/27/2022-19:09:38] [V] [TRT] Gather_435 [Gather] inputs: [1292 -> (4)[INT32]], [1293 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: 1293 for ONNX node: 1293
[03/27/2022-19:09:38] [V] [TRT] Using Gather axis: 0
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Gather_435 for ONNX node: Gather_435
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1294 for ONNX tensor: 1294
[03/27/2022-19:09:38] [V] [TRT] Gather_435 [Gather] outputs: [1294 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Shape_436 [Shape]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1274
[03/27/2022-19:09:38] [V] [TRT] Shape_436 [Shape] inputs: [1274 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Shape_436 for ONNX node: Shape_436
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1295 for ONNX tensor: 1295
[03/27/2022-19:09:38] [V] [TRT] Shape_436 [Shape] outputs: [1295 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_437 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_437 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_437 [Constant] outputs: [1296 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Gather_438 [Gather]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1295
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1296
[03/27/2022-19:09:38] [V] [TRT] Gather_438 [Gather] inputs: [1295 -> (4)[INT32]], [1296 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: 1296 for ONNX node: 1296
[03/27/2022-19:09:38] [V] [TRT] Using Gather axis: 0
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Gather_438 for ONNX node: Gather_438
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1297 for ONNX tensor: 1297
[03/27/2022-19:09:38] [V] [TRT] Gather_438 [Gather] outputs: [1297 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Unsqueeze_439 [Unsqueeze]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1288
[03/27/2022-19:09:38] [V] [TRT] Unsqueeze_439 [Unsqueeze] inputs: [1288 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Unsqueeze_439 for ONNX node: Unsqueeze_439
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1298 for ONNX tensor: 1298
[03/27/2022-19:09:38] [V] [TRT] Unsqueeze_439 [Unsqueeze] outputs: [1298 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Unsqueeze_440 [Unsqueeze]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1291
[03/27/2022-19:09:38] [V] [TRT] Unsqueeze_440 [Unsqueeze] inputs: [1291 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Unsqueeze_440 for ONNX node: Unsqueeze_440
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1299 for ONNX tensor: 1299
[03/27/2022-19:09:38] [V] [TRT] Unsqueeze_440 [Unsqueeze] outputs: [1299 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Unsqueeze_441 [Unsqueeze]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1294
[03/27/2022-19:09:38] [V] [TRT] Unsqueeze_441 [Unsqueeze] inputs: [1294 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Unsqueeze_441 for ONNX node: Unsqueeze_441
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1300 for ONNX tensor: 1300
[03/27/2022-19:09:38] [V] [TRT] Unsqueeze_441 [Unsqueeze] outputs: [1300 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Unsqueeze_442 [Unsqueeze]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1297
[03/27/2022-19:09:38] [V] [TRT] Unsqueeze_442 [Unsqueeze] inputs: [1297 -> ()[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Original shape: (), unsqueezing to: (1,)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Unsqueeze_442 for ONNX node: Unsqueeze_442
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1301 for ONNX tensor: 1301
[03/27/2022-19:09:38] [V] [TRT] Unsqueeze_442 [Unsqueeze] outputs: [1301 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_443 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1298
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1299
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1300
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1301
[03/27/2022-19:09:38] [V] [TRT] Concat_443 [Concat] inputs: [1298 -> (1)[INT32]], [1299 -> (1)[INT32]], [1300 -> (1)[INT32]], [1301 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_443 for ONNX node: Concat_443
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1302 for ONNX tensor: 1302
[03/27/2022-19:09:38] [V] [TRT] Concat_443 [Concat] outputs: [1302 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: ConstantOfShape_444 [ConstantOfShape]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1302
[03/27/2022-19:09:38] [V] [TRT] ConstantOfShape_444 [ConstantOfShape] inputs: [1302 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: ConstantOfShape_444 for ONNX node: ConstantOfShape_444
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1303 for ONNX tensor: 1303
[03/27/2022-19:09:38] [V] [TRT] ConstantOfShape_444 [ConstantOfShape] outputs: [1303 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_445 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1303
[03/27/2022-19:09:38] [V] [TRT] Searching for input: convfilter.box_filter.weight
[03/27/2022-19:09:38] [V] [TRT] Conv_445 [Conv] inputs: [1303 -> (4, 3, 256, 256)[FLOAT]], [convfilter.box_filter.weight -> (3, 3, 3, 3)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_445 for ONNX node: Conv_445
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1304 for ONNX tensor: 1304
[03/27/2022-19:09:38] [V] [TRT] Conv_445 [Conv] outputs: [1304 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_446 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1274
[03/27/2022-19:09:38] [V] [TRT] Searching for input: convfilter.box_filter.weight
[03/27/2022-19:09:38] [V] [TRT] Conv_446 [Conv] inputs: [1274 -> (4, 3, 256, 256)[FLOAT]], [convfilter.box_filter.weight -> (3, 3, 3, 3)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_446 for ONNX node: Conv_446
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1305 for ONNX tensor: 1305
[03/27/2022-19:09:38] [V] [TRT] Conv_446 [Conv] outputs: [1305 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Div_447 [Div]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1305
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1304
[03/27/2022-19:09:38] [V] [TRT] Div_447 [Div] inputs: [1305 -> (4, 3, 256, 256)[FLOAT]], [1304 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Div_447 for ONNX node: Div_447
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1306 for ONNX tensor: 1306
[03/27/2022-19:09:38] [V] [TRT] Div_447 [Div] outputs: [1306 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_448 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1285
[03/27/2022-19:09:38] [V] [TRT] Searching for input: convfilter.box_filter.weight
[03/27/2022-19:09:38] [V] [TRT] Conv_448 [Conv] inputs: [1285 -> (4, 3, 256, 256)[FLOAT]], [convfilter.box_filter.weight -> (3, 3, 3, 3)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_448 for ONNX node: Conv_448
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1307 for ONNX tensor: 1307
[03/27/2022-19:09:38] [V] [TRT] Conv_448 [Conv] outputs: [1307 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Div_449 [Div]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1307
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1304
[03/27/2022-19:09:38] [V] [TRT] Div_449 [Div] inputs: [1307 -> (4, 3, 256, 256)[FLOAT]], [1304 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Div_449 for ONNX node: Div_449
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1308 for ONNX tensor: 1308
[03/27/2022-19:09:38] [V] [TRT] Div_449 [Div] outputs: [1308 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_450 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1274
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1285
[03/27/2022-19:09:38] [V] [TRT] Mul_450 [Mul] inputs: [1274 -> (4, 3, 256, 256)[FLOAT]], [1285 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_450 for ONNX node: Mul_450
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1309 for ONNX tensor: 1309
[03/27/2022-19:09:38] [V] [TRT] Mul_450 [Mul] outputs: [1309 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_451 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1309
[03/27/2022-19:09:38] [V] [TRT] Searching for input: convfilter.box_filter.weight
[03/27/2022-19:09:38] [V] [TRT] Conv_451 [Conv] inputs: [1309 -> (4, 3, 256, 256)[FLOAT]], [convfilter.box_filter.weight -> (3, 3, 3, 3)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_451 for ONNX node: Conv_451
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1310 for ONNX tensor: 1310
[03/27/2022-19:09:38] [V] [TRT] Conv_451 [Conv] outputs: [1310 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Div_452 [Div]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1310
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1304
[03/27/2022-19:09:38] [V] [TRT] Div_452 [Div] inputs: [1310 -> (4, 3, 256, 256)[FLOAT]], [1304 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Div_452 for ONNX node: Div_452
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1311 for ONNX tensor: 1311
[03/27/2022-19:09:38] [V] [TRT] Div_452 [Div] outputs: [1311 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_453 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1306
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1308
[03/27/2022-19:09:38] [V] [TRT] Mul_453 [Mul] inputs: [1306 -> (4, 3, 256, 256)[FLOAT]], [1308 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_453 for ONNX node: Mul_453
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1312 for ONNX tensor: 1312
[03/27/2022-19:09:38] [V] [TRT] Mul_453 [Mul] outputs: [1312 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sub_454 [Sub]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1311
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1312
[03/27/2022-19:09:38] [V] [TRT] Sub_454 [Sub] inputs: [1311 -> (4, 3, 256, 256)[FLOAT]], [1312 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sub_454 for ONNX node: Sub_454
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1313 for ONNX tensor: 1313
[03/27/2022-19:09:38] [V] [TRT] Sub_454 [Sub] outputs: [1313 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_455 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1274
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1274
[03/27/2022-19:09:38] [V] [TRT] Mul_455 [Mul] inputs: [1274 -> (4, 3, 256, 256)[FLOAT]], [1274 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_455 for ONNX node: Mul_455
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1314 for ONNX tensor: 1314
[03/27/2022-19:09:38] [V] [TRT] Mul_455 [Mul] outputs: [1314 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_456 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1314
[03/27/2022-19:09:38] [V] [TRT] Searching for input: convfilter.box_filter.weight
[03/27/2022-19:09:38] [V] [TRT] Conv_456 [Conv] inputs: [1314 -> (4, 3, 256, 256)[FLOAT]], [convfilter.box_filter.weight -> (3, 3, 3, 3)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_456 for ONNX node: Conv_456
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1315 for ONNX tensor: 1315
[03/27/2022-19:09:38] [V] [TRT] Conv_456 [Conv] outputs: [1315 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Div_457 [Div]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1315
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1304
[03/27/2022-19:09:38] [V] [TRT] Div_457 [Div] inputs: [1315 -> (4, 3, 256, 256)[FLOAT]], [1304 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Div_457 for ONNX node: Div_457
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1316 for ONNX tensor: 1316
[03/27/2022-19:09:38] [V] [TRT] Div_457 [Div] outputs: [1316 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_458 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1306
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1306
[03/27/2022-19:09:38] [V] [TRT] Mul_458 [Mul] inputs: [1306 -> (4, 3, 256, 256)[FLOAT]], [1306 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_458 for ONNX node: Mul_458
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1317 for ONNX tensor: 1317
[03/27/2022-19:09:38] [V] [TRT] Mul_458 [Mul] outputs: [1317 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sub_459 [Sub]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1316
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1317
[03/27/2022-19:09:38] [V] [TRT] Sub_459 [Sub] inputs: [1316 -> (4, 3, 256, 256)[FLOAT]], [1317 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sub_459 for ONNX node: Sub_459
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1318 for ONNX tensor: 1318
[03/27/2022-19:09:38] [V] [TRT] Sub_459 [Sub] outputs: [1318 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_460 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1313
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1318
[03/27/2022-19:09:38] [V] [TRT] Concat_460 [Concat] inputs: [1313 -> (4, 3, 256, 256)[FLOAT]], [1318 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_460 for ONNX node: Concat_460
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1319 for ONNX tensor: 1319
[03/27/2022-19:09:38] [V] [TRT] Concat_460 [Concat] outputs: [1319 -> (4, 6, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_461 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1319
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1660
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1661
[03/27/2022-19:09:38] [V] [TRT] Conv_461 [Conv] inputs: [1319 -> (4, 6, 256, 256)[FLOAT]], [1660 -> (32, 6, 1, 1)[FLOAT]], [1661 -> (32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 6, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_461 for ONNX node: Conv_461
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 32
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 32, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1659 for ONNX tensor: 1659
[03/27/2022-19:09:38] [V] [TRT] Conv_461 [Conv] outputs: [1659 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_462 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1659
[03/27/2022-19:09:38] [V] [TRT] Relu_462 [Relu] inputs: [1659 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_462 for ONNX node: Relu_462
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1322 for ONNX tensor: 1322
[03/27/2022-19:09:38] [V] [TRT] Relu_462 [Relu] outputs: [1322 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_463 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1322
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1663
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1664
[03/27/2022-19:09:38] [V] [TRT] Conv_463 [Conv] inputs: [1322 -> (4, 32, 256, 256)[FLOAT]], [1663 -> (32, 32, 1, 1)[FLOAT]], [1664 -> (32)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 32, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_463 for ONNX node: Conv_463
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 32
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 32, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1662 for ONNX tensor: 1662
[03/27/2022-19:09:38] [V] [TRT] Conv_463 [Conv] outputs: [1662 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Relu_464 [Relu]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1662
[03/27/2022-19:09:38] [V] [TRT] Relu_464 [Relu] inputs: [1662 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Relu_464 for ONNX node: Relu_464
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1325 for ONNX tensor: 1325
[03/27/2022-19:09:38] [V] [TRT] Relu_464 [Relu] outputs: [1325 -> (4, 32, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_465 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1325
[03/27/2022-19:09:38] [V] [TRT] Searching for input: convfilter.conv_a.6.weight
[03/27/2022-19:09:38] [V] [TRT] Conv_465 [Conv] inputs: [1325 -> (4, 32, 256, 256)[FLOAT]], [convfilter.conv_a.6.weight -> (3, 32, 1, 1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 32, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_465 for ONNX node: Conv_465
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 3
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 3, 256, 256)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1326 for ONNX tensor: 1326
[03/27/2022-19:09:38] [V] [TRT] Conv_465 [Conv] outputs: [1326 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_466 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1326
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1306
[03/27/2022-19:09:38] [V] [TRT] Mul_466 [Mul] inputs: [1326 -> (4, 3, 256, 256)[FLOAT]], [1306 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_466 for ONNX node: Mul_466
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1327 for ONNX tensor: 1327
[03/27/2022-19:09:38] [V] [TRT] Mul_466 [Mul] outputs: [1327 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sub_467 [Sub]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1308
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1327
[03/27/2022-19:09:38] [V] [TRT] Sub_467 [Sub] inputs: [1308 -> (4, 3, 256, 256)[FLOAT]], [1327 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sub_467 for ONNX node: Sub_467
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1328 for ONNX tensor: 1328
[03/27/2022-19:09:38] [V] [TRT] Sub_467 [Sub] outputs: [1328 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Shape_468 [Shape]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1326
[03/27/2022-19:09:38] [V] [TRT] Shape_468 [Shape] inputs: [1326 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Shape_468 for ONNX node: Shape_468
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1330 for ONNX tensor: 1330
[03/27/2022-19:09:38] [V] [TRT] Shape_468 [Shape] outputs: [1330 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_469 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_469 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_469 [Constant] outputs: [1331 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_470 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_470 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_470 [Constant] outputs: [1332 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_471 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_471 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_471 [Constant] outputs: [1333 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Slice_472 [Slice]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1330
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1332
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1333
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1331
[03/27/2022-19:09:38] [V] [TRT] Slice_472 [Slice] inputs: [1330 -> (4)[INT32]], [1332 -> (1)[INT32]], [1333 -> (1)[INT32]], [1331 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Slice_472 for ONNX node: Slice_472
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1334 for ONNX tensor: 1334
[03/27/2022-19:09:38] [V] [TRT] Slice_472 [Slice] outputs: [1334 -> (2)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_473 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1334
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1670
[03/27/2022-19:09:38] [V] [TRT] Concat_473 [Concat] inputs: [1334 -> (2)[INT32]], [1670 -> (2)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: 1670 for ONNX node: 1670
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_473 for ONNX node: Concat_473
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1336 for ONNX tensor: 1336
[03/27/2022-19:09:38] [V] [TRT] Concat_473 [Concat] outputs: [1336 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_474 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_474 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_474 [Constant] outputs: [1337 -> ()[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_475 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_475 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_475 [Constant] outputs: [1338 -> ()[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Resize_476 [Resize]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1326
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1337
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1338
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1336
[03/27/2022-19:09:38] [V] [TRT] Resize_476 [Resize] inputs: [1326 -> (4, 3, 256, 256)[FLOAT]], [1337 -> ()[FLOAT]], [1338 -> ()[FLOAT]], [1336 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Resize_476 for ONNX node: Resize_476
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1339 for ONNX tensor: 1339
[03/27/2022-19:09:38] [V] [TRT] Resize_476 [Resize] outputs: [1339 -> (4, 3, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Shape_477 [Shape]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1328
[03/27/2022-19:09:38] [V] [TRT] Shape_477 [Shape] inputs: [1328 -> (4, 3, 256, 256)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Shape_477 for ONNX node: Shape_477
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1341 for ONNX tensor: 1341
[03/27/2022-19:09:38] [V] [TRT] Shape_477 [Shape] outputs: [1341 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_478 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_478 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_478 [Constant] outputs: [1342 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_479 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_479 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_479 [Constant] outputs: [1343 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_480 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_480 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_480 [Constant] outputs: [1344 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Slice_481 [Slice]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1341
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1343
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1344
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1342
[03/27/2022-19:09:38] [V] [TRT] Slice_481 [Slice] inputs: [1341 -> (4)[INT32]], [1343 -> (1)[INT32]], [1344 -> (1)[INT32]], [1342 -> (1)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Slice_481 for ONNX node: Slice_481
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1345 for ONNX tensor: 1345
[03/27/2022-19:09:38] [V] [TRT] Slice_481 [Slice] outputs: [1345 -> (2)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_482 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1345
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1671
[03/27/2022-19:09:38] [V] [TRT] Concat_482 [Concat] inputs: [1345 -> (2)[INT32]], [1671 -> (2)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: 1671 for ONNX node: 1671
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_482 for ONNX node: Concat_482
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1347 for ONNX tensor: 1347
[03/27/2022-19:09:38] [V] [TRT] Concat_482 [Concat] outputs: [1347 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_483 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_483 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_483 [Constant] outputs: [1348 -> ()[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Constant_484 [Constant]
[03/27/2022-19:09:38] [V] [TRT] Constant_484 [Constant] inputs: 
[03/27/2022-19:09:38] [V] [TRT] Constant_484 [Constant] outputs: [1349 -> ()[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Resize_485 [Resize]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1328
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1348
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1349
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1347
[03/27/2022-19:09:38] [V] [TRT] Resize_485 [Resize] inputs: [1328 -> (4, 3, 256, 256)[FLOAT]], [1348 -> ()[FLOAT]], [1349 -> ()[FLOAT]], [1347 -> (4)[INT32]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Resize_485 for ONNX node: Resize_485
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1350 for ONNX tensor: 1350
[03/27/2022-19:09:38] [V] [TRT] Resize_485 [Resize] outputs: [1350 -> (4, 3, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Mul_486 [Mul]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1339
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1284
[03/27/2022-19:09:38] [V] [TRT] Mul_486 [Mul] inputs: [1339 -> (4, 3, 1280, 720)[FLOAT]], [1284 -> (4, 3, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Mul_486 for ONNX node: Mul_486
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1351 for ONNX tensor: 1351
[03/27/2022-19:09:38] [V] [TRT] Mul_486 [Mul] outputs: [1351 -> (4, 3, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Add_487 [Add]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1351
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1350
[03/27/2022-19:09:38] [V] [TRT] Add_487 [Add] inputs: [1351 -> (4, 3, 1280, 720)[FLOAT]], [1350 -> (4, 3, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Add_487 for ONNX node: Add_487
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1352 for ONNX tensor: 1352
[03/27/2022-19:09:38] [V] [TRT] Add_487 [Add] outputs: [1352 -> (4, 3, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Conv_488 [Conv]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1352
[03/27/2022-19:09:38] [V] [TRT] Searching for input: convfilter.compress.weight
[03/27/2022-19:09:38] [V] [TRT] Searching for input: convfilter.compress.bias
[03/27/2022-19:09:38] [V] [TRT] Conv_488 [Conv] inputs: [1352 -> (4, 3, 1280, 720)[FLOAT]], [convfilter.compress.weight -> (1, 3, 1, 1)[FLOAT]], [convfilter.compress.bias -> (1)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Convolution input dimensions: (4, 3, 1280, 720)
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Conv_488 for ONNX node: Conv_488
[03/27/2022-19:09:38] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1
[03/27/2022-19:09:38] [V] [TRT] Convolution output dimensions: (4, 1, 1280, 720)
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1353 for ONNX tensor: 1353
[03/27/2022-19:09:38] [V] [TRT] Conv_488 [Conv] outputs: [1353 -> (4, 1, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Concat_489 [Concat]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1353
[03/27/2022-19:09:38] [V] [TRT] Concat_489 [Concat] inputs: [1353 -> (4, 1, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Concat_489 for ONNX node: Concat_489
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1354 for ONNX tensor: 1354
[03/27/2022-19:09:38] [V] [TRT] Concat_489 [Concat] outputs: [1354 -> (4, 1, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Parsing node: Sigmoid_490 [Sigmoid]
[03/27/2022-19:09:38] [V] [TRT] Searching for input: 1354
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_490 [Sigmoid] inputs: [1354 -> (4, 1, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Registering layer: Sigmoid_490 for ONNX node: Sigmoid_490
[03/27/2022-19:09:38] [V] [TRT] Registering tensor: 1355_29 for ONNX tensor: 1355
[03/27/2022-19:09:38] [V] [TRT] Sigmoid_490 [Sigmoid] outputs: [1355 -> (4, 1, 1280, 720)[FLOAT]], 
[03/27/2022-19:09:38] [V] [TRT] Marking 1355_29 as output: 1355
[03/27/2022-19:09:38] [I] Finish parsing network model
[03/27/2022-19:09:38] [V] [TRT] Applying generic optimizations to the graph for inference.
[03/27/2022-19:09:38] [V] [TRT] Original: 436 layers
[03/27/2022-19:09:38] [V] [TRT] After dead-layer removal: 436 layers
[03/27/2022-19:09:38] [V] [TRT] Running: ConstShuffleFusion
[03/27/2022-19:09:38] [V] [TRT] ConstShuffleFusion: Fusing (Unnamed Layer* 424) [Constant] with (Unnamed Layer* 425) [Shuffle]
[03/27/2022-19:09:38] [V] [TRT] After Myelin optimization: 435 layers
[03/27/2022-19:09:38] [V] [TRT] Applying ScaleNodes fusions.
[03/27/2022-19:09:38] [V] [TRT] After scale fusion: 435 layers
[03/27/2022-19:09:38] [V] [TRT] Running: SliceErasure
[03/27/2022-19:09:38] [V] [TRT] Removing Slice_425
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_9 with Relu_10
[03/27/2022-19:09:38] [V] [TRT] Running: SliceErasure
[03/27/2022-19:09:38] [V] [TRT] Removing Slice_415
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_14 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_25 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_32 with Add_33
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_40 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_54 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_61 with Add_62
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_69 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_76 with Add_77
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_84 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_98 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_105 with Add_106
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_113 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_120 with Add_121
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_128 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_142 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_149 with Add_150
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_157 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_164 with Add_165
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_172 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_179 with Add_180
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_187 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_201 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_208 with Add_209
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_216 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_223 with Add_224
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_231 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_238 with Add_239
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_246 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_260 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_267 with Add_268
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_275 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_282 with Add_283
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_290 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_297 with Add_298
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_305 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_312 with Add_313
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_320 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ReduceToPoolingFusion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of ReduceMean_334 from REDUCE to POOLING
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_341 with Add_342
[03/27/2022-19:09:38] [V] [TRT] Running: ConvEltwiseSumFusion
[03/27/2022-19:09:38] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_358 with Add_359
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_358 + Add_359 with Relu_360
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_361 with Relu_362
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_363 with Relu_364
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_365 with Relu_366
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_368 with Relu_369
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_370 with Relu_371
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_372 with Relu_373
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_377 with Relu_378
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_379 with Relu_380
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_381 with Relu_382
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_386 with Relu_387
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_388 with Relu_389
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_390 with Relu_391
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_395 with Relu_396
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_397 with Relu_398
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_399 with Relu_400
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_404 with Relu_405
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_406 with Relu_407
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_408 with Relu_409
[03/27/2022-19:09:38] [V] [TRT] Running: SliceErasure
[03/27/2022-19:09:38] [V] [TRT] Removing Slice_420
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_461 with Relu_462
[03/27/2022-19:09:38] [V] [TRT] Running: ConvReluFusion
[03/27/2022-19:09:38] [V] [TRT] ConvReluFusion: Fusing Conv_463 with Relu_464
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_12 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_16 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_19 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_23 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_27 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_30 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_35 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_38 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_42 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_45 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_49 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_52 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_56 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_59 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_64 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_67 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_71 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_74 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_79 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_82 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_86 from ACTIVATION to POINTWISE
[03/27/2022-19:09:38] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:38] [V] [TRT] Swap the layer type of Sigmoid_89 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_93 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_96 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_100 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_103 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_108 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_111 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_115 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_118 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_123 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_126 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_130 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_133 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_137 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_140 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_144 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_147 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_152 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_155 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_159 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_162 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_167 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_170 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_174 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_177 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_182 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_185 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_189 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_192 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_196 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_199 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_203 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_206 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_211 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_214 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_218 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_221 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_226 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_229 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_233 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_236 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_241 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_244 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_248 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_251 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_255 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_258 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_262 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_265 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_270 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_273 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_277 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_280 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_285 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_288 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_292 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_295 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_300 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_303 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_307 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_310 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_315 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_318 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_322 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_325 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_329 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_332 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_336 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_339 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: ActivationToPointwiseConversion
[03/27/2022-19:09:39] [V] [TRT] Swap the layer type of Sigmoid_490 from ACTIVATION to POINTWISE
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_12) with Mul_13
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_16) with Mul_17
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing Div_457 with Sub_459
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing Mul_458 with PWN(Div_457, Sub_459)
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_19) with Mul_20
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_23) with Mul_24
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_27) with Mul_28
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_30) with Mul_31
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_35) with Mul_36
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_38) with Mul_39
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_42) with Mul_43
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_45) with Mul_46
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_49) with Mul_50
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_52) with Mul_53
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_56) with Mul_57
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_59) with Mul_60
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_64) with Mul_65
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_67) with Mul_68
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_71) with Mul_72
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_74) with Mul_75
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_79) with Mul_80
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_82) with Mul_83
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_86) with Mul_87
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_89) with Mul_90
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_93) with Mul_94
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_96) with Mul_97
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_100) with Mul_101
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_103) with Mul_104
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_108) with Mul_109
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_111) with Mul_112
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_115) with Mul_116
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_118) with Mul_119
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_123) with Mul_124
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_126) with Mul_127
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_130) with Mul_131
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_133) with Mul_134
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_137) with Mul_138
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_140) with Mul_141
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_144) with Mul_145
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_147) with Mul_148
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_152) with Mul_153
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_155) with Mul_156
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_159) with Mul_160
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_162) with Mul_163
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_167) with Mul_168
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_170) with Mul_171
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_174) with Mul_175
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_177) with Mul_178
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_182) with Mul_183
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_185) with Mul_186
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_189) with Mul_190
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_192) with Mul_193
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_196) with Mul_197
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_199) with Mul_200
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_203) with Mul_204
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_206) with Mul_207
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_211) with Mul_212
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_214) with Mul_215
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_218) with Mul_219
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_221) with Mul_222
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_226) with Mul_227
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_229) with Mul_230
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_233) with Mul_234
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_236) with Mul_237
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_241) with Mul_242
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_244) with Mul_245
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_248) with Mul_249
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_251) with Mul_252
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_255) with Mul_256
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_258) with Mul_259
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_262) with Mul_263
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_265) with Mul_266
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_270) with Mul_271
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_273) with Mul_274
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_277) with Mul_278
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_280) with Mul_281
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_285) with Mul_286
[03/27/2022-19:09:39] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:39] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_288) with Mul_289
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_292) with Mul_293
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_295) with Mul_296
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_300) with Mul_301
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_303) with Mul_304
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_307) with Mul_308
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_310) with Mul_311
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_315) with Mul_316
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_318) with Mul_319
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_322) with Mul_323
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_325) with Mul_326
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_329) with Mul_330
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_332) with Mul_333
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_336) with Mul_337
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing PWN(Sigmoid_339) with Mul_340
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing Mul_453 with Sub_454
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing Div_452 with PWN(Mul_453, Sub_454)
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing Mul_466 with Sub_467
[03/27/2022-19:09:40] [V] [TRT] Running: PointWiseFusion
[03/27/2022-19:09:40] [V] [TRT] PointWiseFusion: Fusing Mul_486 with Add_487
[03/27/2022-19:09:40] [V] [TRT] After vertical fusions: 297 layers
[03/27/2022-19:09:40] [V] [TRT] After dupe layer removal: 297 layers
[03/27/2022-19:09:40] [V] [TRT] After final dead-layer removal: 297 layers
[03/27/2022-19:09:41] [V] [TRT] Merging layers: Conv_343 || Conv_344 || Conv_348 || Conv_352
[03/27/2022-19:09:41] [V] [TRT] After tensor merging: 294 layers
[03/27/2022-19:09:41] [V] [TRT] After slice removal: 294 layers
[03/27/2022-19:09:41] [V] [TRT] Eliminating concatenation Concat_489
[03/27/2022-19:09:41] [V] [TRT] Retargeting 1353 to 1354
[03/27/2022-19:09:41] [V] [TRT] Eliminating concatenation Concat_460
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 1313 to 1319 because of stomping hazard.
[03/27/2022-19:09:41] [V] [TRT] Retargeting 1318 to 1319
[03/27/2022-19:09:41] [V] [TRT] Eliminating concatenation Concat_426
[03/27/2022-19:09:41] [V] [TRT] Retargeting 1269 to 1285
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 1285 to 1285 because input is not movable.
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 1285 to 1285 because input is not movable.
[03/27/2022-19:09:41] [V] [TRT] Eliminating concatenation Concat_403
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 1258 to 1259 because input does not support striding.
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 784 to 1259 because input does not support striding.
[03/27/2022-19:09:41] [V] [TRT] Eliminating concatenation Concat_394
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 1243 to 1244 because input does not support striding.
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 837 to 1244 because input does not support striding.
[03/27/2022-19:09:41] [V] [TRT] Eliminating concatenation Concat_385
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 1228 to 1229 because input does not support striding.
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 890 to 1229 because input does not support striding.
[03/27/2022-19:09:41] [V] [TRT] Eliminating concatenation Concat_376
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 1213 to 1214 because input does not support striding.
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 1032 to 1214 because input does not support striding.
[03/27/2022-19:09:41] [V] [TRT] Eliminating concatenation Concat_367
[03/27/2022-19:09:41] [V] [TRT] Retargeting 1198 to 1199
[03/27/2022-19:09:41] [V] [TRT] Generating copy for 1156 to 1199 because input does not support striding.
[03/27/2022-19:09:41] [V] [TRT] Eliminating concatenation Concat_356
[03/27/2022-19:09:41] [V] [TRT] Generating copy for Conv_343 || Conv_344 || Conv_348 || Conv_352 to 1183 because input is not movable.
[03/27/2022-19:09:41] [V] [TRT] Retargeting 1572 to 1183
[03/27/2022-19:09:41] [V] [TRT] Retargeting 1584 to 1183
[03/27/2022-19:09:41] [V] [TRT] Retargeting 1596 to 1183
[03/27/2022-19:09:41] [V] [TRT] After concat removal: 298 layers
[03/27/2022-19:09:41] [V] [TRT] Graph construction and optimization completed in 2.6849 seconds.
[03/27/2022-19:09:43] [V] [TRT] Using cublas as a tactic source
[03/27/2022-19:09:43] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +258, GPU +108, now: CPU 596, GPU 740 (MiB)
[03/27/2022-19:09:43] [V] [TRT] Using cuDNN as a tactic source
[03/27/2022-19:09:43] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +111, GPU +46, now: CPU 707, GPU 786 (MiB)
[03/27/2022-19:09:43] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[03/27/2022-19:09:43] [V] [TRT] Constructing optimization profile number 0 [1/1].
[03/27/2022-19:09:43] [V] [TRT] Reserving memory for activation tensors. Host: 0 bytes Device: 58982400 bytes
[03/27/2022-19:09:43] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:43] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:43] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:43] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 754) (Reformat)
[03/27/2022-19:09:43] [V] [TRT] Tactic: 1002 Time: 0.045948
[03/27/2022-19:09:43] [V] [TRT] Tactic: 0 Time: 0.03276
[03/27/2022-19:09:43] [V] [TRT] Fastest Tactic: 0 Time: 0.03276
[03/27/2022-19:09:43] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 754) (Reformat)
[03/27/2022-19:09:43] [V] [TRT] Tactic: 1002 Time: 0.519296
[03/27/2022-19:09:43] [V] [TRT] Tactic: 0 Time: 2.20019
[03/27/2022-19:09:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.519296
[03/27/2022-19:09:43] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:43] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(754 -> <out>) (Reformat)
[03/27/2022-19:09:43] [V] [TRT] Tactic: 1002 Time: 0.04608
[03/27/2022-19:09:43] [V] [TRT] Tactic: 0 Time: 0.032764
[03/27/2022-19:09:43] [V] [TRT] Fastest Tactic: 0 Time: 0.032764
[03/27/2022-19:09:43] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(754 -> <out>) (Reformat)
[03/27/2022-19:09:43] [V] [TRT] Tactic: 1002 Time: 0.5111
[03/27/2022-19:09:43] [V] [TRT] Tactic: 0 Time: 0.033152
[03/27/2022-19:09:43] [V] [TRT] Fastest Tactic: 0 Time: 0.033152
[03/27/2022-19:09:43] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(754 -> <out>) (Reformat)
[03/27/2022-19:09:43] [V] [TRT] Tactic: 1002 Time: 0.512
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 0.078336
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 0 Time: 0.078336
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(754 -> <out>) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.4832
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 0.037504
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 0 Time: 0.037504
[03/27/2022-19:09:44] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:44] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(754 -> <out>) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.519936
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 2.26816
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.519936
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(754 -> <out>) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.492924
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 2.18509
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.492924
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(2097152,65536,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(757 -> <out>) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.60096
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 0.36096
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 0 Time: 0.36096
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(757 -> <out>) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.508908
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 0.752896
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.508908
[03/27/2022-19:09:44] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:44] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(2097152,65536,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(2097152,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1359 -> <out>) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.597888
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 2.30975
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.597888
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1359 -> <out>) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.513408
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 3.45651
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.513408
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1359 -> <out>) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.47744
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 0.755328
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.47744
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1359 -> <out>) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.512256
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 0.243828
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 0 Time: 0.243828
[03/27/2022-19:09:44] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(2097152,65536,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 761) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.560384
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 0.34688
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 0 Time: 0.34688
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(2097152,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 761) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.562048
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 2.32179
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.562048
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 761) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.475008
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 0.756728
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.475008
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 761) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.51136
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 3.34976
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.51136
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 761) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.471296
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 0.757504
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.471296
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 761) (Reformat)
[03/27/2022-19:09:44] [V] [TRT] Tactic: 1002 Time: 0.511744
[03/27/2022-19:09:44] [V] [TRT] Tactic: 0 Time: 0.243968
[03/27/2022-19:09:44] [V] [TRT] Fastest Tactic: 0 Time: 0.243968
[03/27/2022-19:09:44] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:44] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:44] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:44] [V] [TRT] *************** Autotuning Reformat: Float(32,1,1,1) -> Float(32,1,32,32) ***************
[03/27/2022-19:09:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(762 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.016256
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.00512
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(32,1,32,32) -> Float(32,1,1,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(762 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.016384
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.004992
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.004992
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1304) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.384768
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.027632
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.027632
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1304) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.372984
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 2.24627
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.372984
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1306) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.386944
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.076544
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.076544
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1306) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.363904
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.034556
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.034556
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(8,1,1,1) -> Float(8,1,8,8) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(763 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.016384
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.005376
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.005376
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(8,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(763 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.016768
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.005248
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.005248
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(8,1,8,8) -> Float(8,1,1,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(763 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.016508
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.005632
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.005632
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(8,1,8,8) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(763 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.016512
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.005632
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.005632
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(8,1,1,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(763 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.025252
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.005632
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.005632
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(8,1,8,8) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(763 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.016768
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.0055
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.0055
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(8,1,1,1) -> Float(8,1,8,8) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(8,1,8,8) -> Float(8,1,1,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(8,1,1,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(8,1,8,8) ***************
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(393216,65536,256,1) -> Float(393216,1,1536,6) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1318) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.044292
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.043136
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.043136
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(393216,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1318) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.39872
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 1.98029
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.39872
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,1536,6) -> Float(393216,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1318) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.385148
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.02752
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.02752
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,1536,6) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1318) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.376436
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 1.98003
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.376436
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(393216,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1318) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.385408
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.075904
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.075904
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(393216,1,1536,6) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1318) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.364028
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.057216
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.057216
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1318) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.431872
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 1.97414
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.431872
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(32,1,1,1) -> Float(32,1,32,32) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(32,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(766 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.016256
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.005368
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.005368
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(32,1,32,32) -> Float(32,1,1,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(32,1,32,32) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(766 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.016512
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.005116
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.005116
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(32,1,1,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(766 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.0179
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.006644
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.006644
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(32,1,32,32) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(766 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.016636
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.004984
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.004984
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(2097152,65536,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(2097152,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(2097152,65536,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1362) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.11968
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.118784
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.118784
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1362) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.411008
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.346496
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.346496
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1362 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.10982
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.118892
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.10982
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1362 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.396544
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 0.346368
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 0 Time: 0.346368
[03/27/2022-19:09:45] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1365 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.412672
[03/27/2022-19:09:45] [V] [TRT] Tactic: 0 Time: 2.22719
[03/27/2022-19:09:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.412672
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1365 -> <out>) (Reformat)
[03/27/2022-19:09:45] [V] [TRT] Tactic: 1002 Time: 0.380672
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 2.5047
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.380672
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1365 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.397692
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.381184
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.381184
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1365 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.380288
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.126204
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.126204
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 774) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.551808
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 2.24397
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.551808
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 774) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.380544
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 2.48525
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.380544
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 774) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.398208
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.380672
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.380672
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 774) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.380288
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.125944
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.125944
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(16,1,1,1) -> Float(16,1,16,16) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(775 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.016384
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.0055
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.0055
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(16,1,16,16) -> Float(16,1,1,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(775 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.016512
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.005248
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005248
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(4,1,1,1) -> Float(4,1,4,4) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(776 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.016752
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(4,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(776 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.016512
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(4,1,4,4) -> Float(4,1,1,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(776 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.016768
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.005248
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005248
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(4,1,4,4) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(776 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.016256
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(4,1,1,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(776 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.01676
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.00512
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(4,1,4,4) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(776 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.016376
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.005496
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005496
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(4,1,1,1) -> Float(4,1,4,4) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(4,1,4,4) -> Float(4,1,1,1) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(4,1,1,1) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(4,1,4,4) ***************
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(16,1,1,1) -> Float(16,1,16,16) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(16,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(779 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.017144
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.005376
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005376
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(16,1,16,16) -> Float(16,1,1,1) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(16,1,16,16) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(779 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.016384
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.005116
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005116
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(16,1,1,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(779 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.01664
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.005492
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005492
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(16,1,16,16) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(779 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 0.016512
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 0.0055
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 0.0055
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(6291456,65536,256,1) -> Float(6291456,1,24576,96) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1371 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 1.44973
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 1.06765
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 0 Time: 1.06765
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(6291456,65536,256,1) -> Float(196608,65536:32,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1371 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 1.44256
[03/27/2022-19:09:46] [V] [TRT] Tactic: 0 Time: 6.97434
[03/27/2022-19:09:46] [V] [TRT] Fastest Tactic: 1002 Time: 1.44256
[03/27/2022-19:09:46] [V] [TRT] *************** Autotuning Reformat: Float(6291456,1,24576,96) -> Float(6291456,65536,256,1) ***************
[03/27/2022-19:09:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1371 -> <out>) (Reformat)
[03/27/2022-19:09:46] [V] [TRT] Tactic: 1002 Time: 1.38202
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 4.45952
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 1002 Time: 1.38202
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(6291456,1,24576,96) -> Float(196608,65536:32,256,1) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1371 -> <out>) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 1.22675
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 14.6894
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 1002 Time: 1.22675
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536:32,256,1) -> Float(6291456,65536,256,1) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1371 -> <out>) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 1.26707
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 2.25702
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 1002 Time: 1.26707
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536:32,256,1) -> Float(6291456,1,24576,96) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1371 -> <out>) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 1.20894
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.717952
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.717952
[03/27/2022-19:09:47] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(6291456,65536,256,1) -> Float(6291456,1,24576,96) ***************
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(6291456,1,24576,96) -> Float(6291456,65536,256,1) ***************
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536:32,256,1) -> Float(6291456,65536,256,1) ***************
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536:32,256,1) -> Float(6291456,1,24576,96) ***************
[03/27/2022-19:09:47] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(1572864,16384,128,1) -> Float(1572864,1,12288,96) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1374 -> <out>) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.366076
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.2286
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.2286
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(1572864,16384,128,1) -> Float(49152,16384:32,128,1) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1374 -> <out>) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.367356
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.35072
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.35072
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(1572864,1,12288,96) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1374 -> <out>) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.362112
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.284032
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.284032
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(1572864,1,12288,96) -> Float(49152,16384:32,128,1) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1374 -> <out>) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.30592
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 1.30035
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.30592
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384:32,128,1) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1374 -> <out>) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.34304
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.215936
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.215936
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384:32,128,1) -> Float(1572864,1,12288,96) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1374 -> <out>) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.302208
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.184576
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.184576
[03/27/2022-19:09:47] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(1572864,16384,128,1) -> Float(1572864,1,12288,96) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 792) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.367616
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.22848
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.22848
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(1572864,16384,128,1) -> Float(49152,16384:32,128,1) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 792) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.3712
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.351096
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.351096
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(1572864,1,12288,96) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 792) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.361984
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.28326
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.28326
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(1572864,1,12288,96) -> Float(49152,16384:32,128,1) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 792) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.323968
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 1.30188
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.323968
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384:32,128,1) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 792) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.343296
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.216824
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.216824
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384:32,128,1) -> Float(1572864,1,12288,96) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 792) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.304252
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.185088
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.185088
[03/27/2022-19:09:47] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(1572864,1,12288,96) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384:32,128,1) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:09:47] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(96,1,1,1) -> Float(96,1,96,96) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(793 -> <out>) (Reformat)
[03/27/2022-19:09:47] [V] [TRT] Tactic: 1002 Time: 0.028032
[03/27/2022-19:09:47] [V] [TRT] Tactic: 0 Time: 0.005376
[03/27/2022-19:09:47] [V] [TRT] Fastest Tactic: 0 Time: 0.005376
[03/27/2022-19:09:47] [V] [TRT] *************** Autotuning Reformat: Float(96,1,96,96) -> Float(96,1,1,1) ***************
[03/27/2022-19:09:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(793 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.097732
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.004988
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.004988
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(4,1,1,1) -> Float(4,1,4,4) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(4,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(4,1,4,4) -> Float(4,1,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(4,1,4,4) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(4,1,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(4,1,4,4) ***************
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(4,1,1,1) -> Float(4,1,4,4) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(4,1,4,4) -> Float(4,1,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(4,1,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(4,1,4,4) ***************
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(96,1,1,1) -> Float(96,1,96,96) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(96,1,1,1) -> Float(3,1:32,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(797 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.01664
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(96,1,96,96) -> Float(96,1,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(96,1,96,96) -> Float(3,1:32,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(797 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.045152
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.005736
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.005736
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(3,1:32,1,1) -> Float(96,1,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(797 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.017252
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(3,1:32,1,1) -> Float(96,1,96,96) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(797 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.016896
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.005376
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.005376
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1572864,16384,128,1) -> Float(1572864,1,12288,96) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1572864,16384,128,1) -> Float(49152,16384:32,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1572864,1,12288,96) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1572864,1,12288,96) -> Float(49152,16384:32,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384:32,128,1) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384:32,128,1) -> Float(1572864,1,12288,96) ***************
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1572864,16384,128,1) -> Float(1572864,1,12288,96) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1572864,1,12288,96) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384:32,128,1) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384:32,128,1) -> Float(1572864,1,12288,96) ***************
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1377) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.114812
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.057984
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.057984
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1377) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.108408
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.059648
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.059648
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1377 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.11456
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.057856
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.057856
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1377 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.107904
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.059904
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.059904
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1380 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.547456
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.335616
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.335616
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1380 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.558716
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.604416
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.558716
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1380 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.55168
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.476544
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.476544
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1380 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.466176
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 2.1783
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.466176
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1380 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.514176
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.321664
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.321664
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1380 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.448512
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.273772
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.273772
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 809) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.56192
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.335612
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.335612
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 809) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.558464
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.604288
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.558464
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 809) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.550396
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.47552
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.47552
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 809) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.466672
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 2.17663
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.466672
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 809) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.514432
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.321536
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.321536
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 809) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.448512
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.27406
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.27406
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(144,1,1,1) -> Float(144,1,144,144) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(810 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.01664
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.00512
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(144,1,144,144) -> Float(144,1,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(810 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.016384
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.004992
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.004992
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(6,1,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(811 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.016896
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.005376
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.005376
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(6,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(811 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.016896
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.005248
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.005248
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(6,1,6,6) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(811 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.073456
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.010576
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.010576
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(6,1,6,6) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(811 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.087936
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.005376
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.005376
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(811 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.016512
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.00512
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(811 -> <out>) (Reformat)
[03/27/2022-19:09:48] [V] [TRT] Tactic: 1002 Time: 0.01626
[03/27/2022-19:09:48] [V] [TRT] Tactic: 0 Time: 0.00512
[03/27/2022-19:09:48] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(6,1,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(6,1,6,6) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:48] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(144,1,1,1) -> Float(144,1,144,144) ***************
[03/27/2022-19:09:48] [V] [TRT] *************** Autotuning Reformat: Float(144,1,1,1) -> Float(5,1:32,1,1) ***************
[03/27/2022-19:09:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(814 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.016768
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.004992
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.004992
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,144,144) -> Float(144,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,144,144) -> Float(5,1:32,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(814 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.016512
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.0055
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.0055
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(5,1:32,1,1) -> Float(144,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(814 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.188164
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.04902
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.04902
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(5,1:32,1,1) -> Float(144,1,144,144) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(814 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.016256
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.005116
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.005116
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,1,1) -> Float(144,1,144,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,144,144) -> Float(144,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,6,6) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,6,6) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,6,6) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,1,1) -> Float(144,1,144,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,1,1) -> Float(5,1:32,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,144,144) -> Float(144,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,144,144) -> Float(5,1:32,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(5,1:32,1,1) -> Float(144,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(5,1:32,1,1) -> Float(144,1,144,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,16384,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(2359296,1,18432,144) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(81920,16384:32,128,1) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,4096,64,1) -> Float(589824,1,9216,144) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1401 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.149248
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.088704
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.088704
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,4096,64,1) -> Float(20480,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1401 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.151552
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.134008
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.134008
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,1,9216,144) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1401 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.150272
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.085888
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.085888
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,1,9216,144) -> Float(20480,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1401 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.124928
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.183288
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.124928
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(20480,4096:32,64,1) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1401 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.14848
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.080252
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.080252
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(20480,4096:32,64,1) -> Float(589824,1,9216,144) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1401 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.146432
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.076672
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.076672
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,4096,64,1) -> Float(589824,1,9216,144) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 845) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.171264
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.088704
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.088704
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,4096,64,1) -> Float(20480,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 845) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.151296
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.133888
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.133888
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,1,9216,144) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 845) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.150912
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.08614
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.08614
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,1,9216,144) -> Float(20480,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 845) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.124928
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.182528
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.124928
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(20480,4096:32,64,1) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 845) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.14784
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.075904
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.075904
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(20480,4096:32,64,1) -> Float(589824,1,9216,144) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 845) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.120056
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.073604
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.073604
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,1,9216,144) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(20480,4096:32,64,1) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,1,1) -> Float(144,1,144,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,144,144) -> Float(144,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,6,6) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,6,6) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(6,1,6,6) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(6,1,6,6) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,1,1) -> Float(144,1,144,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,1,1) -> Float(5,1:32,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,144,144) -> Float(144,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(144,1,144,144) -> Float(5,1:32,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(5,1:32,1,1) -> Float(144,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(5,1:32,1,1) -> Float(144,1,144,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,4096,64,1) -> Float(589824,1,9216,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,4096,64,1) -> Float(20480,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,1,9216,144) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,1,9216,144) -> Float(20480,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(20480,4096:32,64,1) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(20480,4096:32,64,1) -> Float(589824,1,9216,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,4096,64,1) -> Float(589824,1,9216,144) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(589824,1,9216,144) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(20480,4096:32,64,1) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(20480,4096:32,64,1) -> Float(589824,1,9216,144) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1404) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.0576
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.0343
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.0343
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1404) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.051712
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.029424
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.029424
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1404 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.057728
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.034176
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.034176
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1404 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.052096
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.02944
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.02944
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1407 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.25356
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.16384
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.16384
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1407 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.253836
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.23616
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.23616
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1407 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.24768
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.209024
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.209024
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1407 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.234112
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.347264
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.234112
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1407 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.242684
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.143996
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.143996
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1407 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.20736
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.140668
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.140668
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 862) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.25536
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.164352
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.164352
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 862) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.338944
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.236416
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.236416
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 862) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.246784
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.2094
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.2094
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 862) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.212864
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.34752
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.212864
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 862) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.242048
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.143872
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.143872
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 862) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.204288
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.140544
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.140544
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(288,1,1,1) -> Float(288,1,288,288) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(863 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.006144
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(288,1,288,288) -> Float(288,1,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(863 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.0064
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.005248
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.005248
[03/27/2022-19:09:49] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(12,1,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(864 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.01664
[03/27/2022-19:09:49] [V] [TRT] Tactic: 0 Time: 0.005632
[03/27/2022-19:09:49] [V] [TRT] Fastest Tactic: 0 Time: 0.005632
[03/27/2022-19:09:49] [V] [TRT] *************** Autotuning Reformat: Float(12,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(864 -> <out>) (Reformat)
[03/27/2022-19:09:49] [V] [TRT] Tactic: 1002 Time: 0.01664
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.005632
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005632
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,12,12) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(864 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.047716
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.005632
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005632
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,12,12) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(864 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.01664
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.005864
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005864
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(864 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.031612
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.014976
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.014976
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(864 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.016512
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,12,12) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,1,1) -> Float(288,1,288,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,1,1) -> Float(9,1:32,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(867 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.041192
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.010624
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.010624
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,288,288) -> Float(288,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,288,288) -> Float(9,1:32,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(867 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.125424
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.005632
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005632
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9,1:32,1,1) -> Float(288,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(867 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.202496
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.006144
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.006144
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9,1:32,1,1) -> Float(288,1,288,288) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(867 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.143744
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.005248
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005248
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,1,1) -> Float(288,1,288,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,288,288) -> Float(288,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,12,12) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,12,12) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,12,12) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,1,1) -> Float(288,1,288,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,1,1) -> Float(9,1:32,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,288,288) -> Float(288,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,288,288) -> Float(9,1:32,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9,1:32,1,1) -> Float(288,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9,1:32,1,1) -> Float(288,1,288,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,4096,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1179648,1,18432,288) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(36864,4096:32,64,1) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1024,32,1) -> Float(294912,1,9216,288) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1428 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.076544
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.045184
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.045184
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1024,32,1) -> Float(9216,1024:32,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1428 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.076416
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.06528
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.06528
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1,9216,288) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1428 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.07372
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.045184
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.045184
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1,9216,288) -> Float(9216,1024:32,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1428 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.060544
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.090624
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.060544
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9216,1024:32,32,1) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1428 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.074368
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.039424
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.039424
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9216,1024:32,32,1) -> Float(294912,1,9216,288) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1428 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.0608
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.03968
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.03968
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1024,32,1) -> Float(294912,1,9216,288) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 898) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.076032
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.045184
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.045184
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1024,32,1) -> Float(9216,1024:32,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 898) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.07654
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.065664
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.065664
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1,9216,288) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 898) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.074496
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.04544
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.04544
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1,9216,288) -> Float(9216,1024:32,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 898) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.060544
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.090496
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.060544
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9216,1024:32,32,1) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 898) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.084224
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.039168
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.039168
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9216,1024:32,32,1) -> Float(294912,1,9216,288) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 898) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.061568
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.03968
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.03968
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1,9216,288) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9216,1024:32,32,1) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,1,1) -> Float(288,1,288,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,288,288) -> Float(288,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,12,12) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,12,12) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(12,1,12,12) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(12,1,12,12) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,1,1) -> Float(288,1,288,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,1,1) -> Float(9,1:32,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,288,288) -> Float(288,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(288,1,288,288) -> Float(9,1:32,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9,1:32,1,1) -> Float(288,1,1,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9,1:32,1,1) -> Float(288,1,288,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1024,32,1) -> Float(294912,1,9216,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1024,32,1) -> Float(9216,1024:32,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1,9216,288) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1,9216,288) -> Float(9216,1024:32,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9216,1024:32,32,1) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9216,1024:32,32,1) -> Float(294912,1,9216,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1024,32,1) -> Float(294912,1,9216,288) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(294912,1,9216,288) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9216,1024:32,32,1) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(9216,1024:32,32,1) -> Float(294912,1,9216,288) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(90112,1024,32,1) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1431) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.022912
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.01664
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.01664
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,2816,88) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1431) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.0224
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.014968
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.014968
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(90112,1024,32,1) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1431 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.023168
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.016384
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.016384
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,2816,88) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1431 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.023552
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.014976
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.014976
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1434 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.116736
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.078848
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.078848
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1434 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.117504
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.117752
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.117504
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1434 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.115072
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.082424
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.082424
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1434 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.095616
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.17062
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.095616
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1434 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.116352
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.067456
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.067456
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1434 -> <out>) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.094848
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.068096
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.068096
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:50] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 915) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.116608
[03/27/2022-19:09:50] [V] [TRT] Tactic: 0 Time: 0.080128
[03/27/2022-19:09:50] [V] [TRT] Fastest Tactic: 0 Time: 0.080128
[03/27/2022-19:09:50] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 915) (Reformat)
[03/27/2022-19:09:50] [V] [TRT] Tactic: 1002 Time: 0.18624
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.118272
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.118272
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 915) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.124408
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.085376
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.085376
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 915) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.096124
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.170368
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.096124
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 915) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.132852
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.077184
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.077184
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 915) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.144128
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.067712
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.067712
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(916 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.006272
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.00512
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(916 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.006272
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.005248
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005248
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(917 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.01688
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.005376
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005376
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(917 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.016512
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(917 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.016888
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.005248
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005248
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(917 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.016756
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.005628
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005628
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(917 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.016896
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.004992
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.004992
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(917 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.016256
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.005248
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005248
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(17,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(920 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.017152
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(17,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(920 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.017404
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.005888
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005888
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17,1:32,1,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(920 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.034304
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.006388
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.006388
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17,1:32,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(920 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.021376
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.072516
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.021376
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1024,32,1) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,2816,88) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1024,32,1) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,2816,88) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1024,32,1) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,2816,88) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(17,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(17,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17,1:32,1,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17,1:32,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1024,32,1) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,2816,88) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1024,32,1) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,2816,88) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1024,32,1) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,2816,88) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(17,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(17,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17,1:32,1,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17,1:32,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1024,32,1) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,2816,88) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1024,32,1) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,2816,88) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(22,1,22,22) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(22,1,22,22) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,1,1) -> Float(17,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(528,1,528,528) -> Float(17,1:32,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17,1:32,1,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17,1:32,1,1) -> Float(528,1,528,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1024,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,16896,528) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(17408,1024:32,32,1) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1467) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.075776
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.036096
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.036096
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1467) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.10688
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.051456
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.051456
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1467 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.061952
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.041728
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.041728
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1467 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.039676
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.025472
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.025472
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1470 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.193792
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.128128
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.128128
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1470 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.195196
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.20838
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.195196
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1470 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.189816
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.143488
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.143488
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1470 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.255356
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.29414
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.255356
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1470 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.187008
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.11546
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.11546
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1470 -> <out>) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.149376
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.119424
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.119424
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:51] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 986) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.194176
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.129664
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.129664
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 986) (Reformat)
[03/27/2022-19:09:51] [V] [TRT] Tactic: 1002 Time: 0.3392
[03/27/2022-19:09:51] [V] [TRT] Tactic: 0 Time: 0.323968
[03/27/2022-19:09:51] [V] [TRT] Fastest Tactic: 0 Time: 0.323968
[03/27/2022-19:09:51] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 986) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.190848
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.142592
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.142592
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 986) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.168444
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.293504
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.168444
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 986) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.188284
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.114944
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.114944
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 986) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.148604
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.119552
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.119552
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(987 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.007804
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.006396
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.006396
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(987 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.007552
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.006144
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.006144
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(988 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.020992
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.006148
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.006148
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(988 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.020992
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.005888
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005888
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(988 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.02112
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.005884
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005884
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(988 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.020864
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.00614
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.00614
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(988 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.020848
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.005888
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005888
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(988 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.021108
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.006148
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.006148
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(23,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(991 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.021504
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.006272
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.006272
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(23,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(991 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.020732
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.00614
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.00614
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23,1:32,1,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(991 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.020868
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.00576
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.00576
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23,1:32,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(991 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.020608
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.006008
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.006008
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(23,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(23,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23,1:32,1,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23,1:32,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(23,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(23,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23,1:32,1,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23,1:32,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1024,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(737280,1,23040,720) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23552,1024:32,32,1) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,256,16,1) -> Float(184320,1,11520,720) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1500 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.058368
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.036864
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.036864
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,256,16,1) -> Float(5888,256:32,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1500 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.058116
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.056704
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.056704
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,1,11520,720) -> Float(184320,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1500 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.059648
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.039168
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.039168
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,1,11520,720) -> Float(5888,256:32,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1500 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.043648
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.078976
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.043648
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(5888,256:32,16,1) -> Float(184320,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1500 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.059388
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.034816
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.034816
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(5888,256:32,16,1) -> Float(184320,1,11520,720) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1500 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.068868
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.035072
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.035072
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,256,16,1) -> Float(184320,1,11520,720) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1040) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.058624
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.03712
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.03712
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,256,16,1) -> Float(5888,256:32,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1040) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.06848
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.056832
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.056832
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,1,11520,720) -> Float(184320,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1040) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.059904
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.039424
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.039424
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,1,11520,720) -> Float(5888,256:32,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1040) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.04288
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.079104
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.04288
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(5888,256:32,16,1) -> Float(184320,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1040) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.060032
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.034688
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.034688
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(5888,256:32,16,1) -> Float(184320,1,11520,720) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1040) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.044292
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.035072
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.035072
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,1,11520,720) -> Float(184320,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(5888,256:32,16,1) -> Float(184320,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(30,1,30,30) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(1,1:32,1,1) -> Float(30,1,30,30) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,1,1) -> Float(23,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(720,1,720,720) -> Float(23,1:32,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23,1:32,1,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(23,1:32,1,1) -> Float(720,1,720,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,256,16,1) -> Float(184320,1,11520,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,256,16,1) -> Float(5888,256:32,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,1,11520,720) -> Float(184320,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,1,11520,720) -> Float(5888,256:32,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(5888,256:32,16,1) -> Float(184320,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(5888,256:32,16,1) -> Float(184320,1,11520,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,256,16,1) -> Float(184320,1,11520,720) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(184320,1,11520,720) -> Float(184320,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(5888,256:32,16,1) -> Float(184320,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(5888,256:32,16,1) -> Float(184320,1,11520,720) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1503) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.024704
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.014332
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.014332
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1503) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.023424
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.014464
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.014464
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1503 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.014204
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.014204
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1503 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.023812
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.01408
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.01408
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1506 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.093568
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.057984
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.057984
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1506 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.092672
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.090496
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.090496
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1506 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.092544
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.060672
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.060672
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1506 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.069248
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.127744
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.069248
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1506 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.092416
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.054912
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.054912
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1506 -> <out>) (Reformat)
[03/27/2022-19:09:52] [V] [TRT] Tactic: 1002 Time: 0.068096
[03/27/2022-19:09:52] [V] [TRT] Tactic: 0 Time: 0.055936
[03/27/2022-19:09:52] [V] [TRT] Fastest Tactic: 0 Time: 0.055936
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:52] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:52] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1057) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.093824
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.058368
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.058368
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1057) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.092792
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.090752
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.090752
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1057) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.092284
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.060676
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.060676
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1057) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.069364
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.127736
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.069364
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1057) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.091516
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.05542
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.05542
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1057) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.080004
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.05568
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.05568
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1058 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.00742
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.00752
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.00742
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1058 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.09534
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.0064
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.0064
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1059 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.022904
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.00576
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.00576
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1059 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.020992
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.00614
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.00614
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1059 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.021244
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.006136
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.006136
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1059 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.020736
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.006524
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.006524
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1059 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.02112
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.006024
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.006024
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1059 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.020352
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.005892
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.005892
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(39,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1062 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.021116
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.006272
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.006272
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(39,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1062 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.020736
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.00702
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.00702
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(39,1:32,1,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1062 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.020608
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.006144
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.006144
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(39,1:32,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1062 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.020348
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.006148
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.006148
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(39,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(39,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(39,1:32,1,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(39,1:32,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(39,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(39,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(39,1:32,1,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(39,1:32,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(39,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(39,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(39,1:32,1,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(39,1:32,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,256,16,1) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(53248,1,3328,208) -> Float(53248,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(52,1,52,52) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(2,1:32,1,1) -> Float(52,1,52,52) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1,1) -> Float(39,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(1248,1,1248,1248) -> Float(39,1:32,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(39,1:32,1,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(39,1:32,1,1) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,256,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(319488,1,19968,1248) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(9984,256:32,16,1) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1548) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.02816
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.019588
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.019588
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1548) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.02688
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.019968
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.019968
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1548 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.028288
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.019712
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.019712
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1548 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.056456
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.019712
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.019712
[03/27/2022-19:09:53] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(540672,256,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1551 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.135936
[03/27/2022-19:09:53] [V] [TRT] Tactic: 0 Time: 0.093952
[03/27/2022-19:09:53] [V] [TRT] Fastest Tactic: 0 Time: 0.093952
[03/27/2022-19:09:53] [V] [TRT] *************** Autotuning Reformat: Float(540672,256,16,1) -> Float(16896,256:32,16,1) ***************
[03/27/2022-19:09:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1551 -> <out>) (Reformat)
[03/27/2022-19:09:53] [V] [TRT] Tactic: 1002 Time: 0.135172
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.147712
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.135172
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,33792,2112) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1551 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.155392
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.1184
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.1184
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,33792,2112) -> Float(16896,256:32,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1551 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.102912
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.228352
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.102912
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1551 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.134784
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.087424
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.087424
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1551 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.102396
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.089472
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.089472
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,256,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,33792,2112) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,256,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,256,16,1) -> Float(16896,256:32,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,33792,2112) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,33792,2112) -> Float(16896,256:32,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,256,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1146) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.13644
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.094208
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.094208
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,256,16,1) -> Float(16896,256:32,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1146) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.13542
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.1472
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.13542
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,33792,2112) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1146) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.134652
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.1184
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.1184
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,33792,2112) -> Float(16896,256:32,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1146) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.102272
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.22874
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.102272
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1146) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.134016
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.087416
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.087416
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1146) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.102276
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.089728
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.089728
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,33792,2112) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(2112,1,1,1) -> Float(2112,1,2112,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1147 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.007552
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.006144
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.006144
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(2112,1,2112,2112) -> Float(2112,1,1,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1147 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.00704
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.006144
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.006144
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(88,1,1,1) -> Float(88,1,88,88) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1148 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.020992
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.006276
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.006276
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(88,1,1,1) -> Float(3,1:32,1,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1148 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.021124
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.006012
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.006012
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(88,1,88,88) -> Float(88,1,1,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1148 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.021248
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.006144
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.006144
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(88,1,88,88) -> Float(3,1:32,1,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1148 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.02112
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.006144
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.006144
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(3,1:32,1,1) -> Float(88,1,1,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1148 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.020864
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.006016
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.006016
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(3,1:32,1,1) -> Float(88,1,88,88) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1148 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.020608
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.006012
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.006012
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(88,1,1,1) -> Float(88,1,88,88) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(88,1,88,88) -> Float(88,1,1,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(3,1:32,1,1) -> Float(88,1,1,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(3,1:32,1,1) -> Float(88,1,88,88) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(2112,1,1,1) -> Float(2112,1,2112,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(2112,1,1,1) -> Float(66,1:32,1,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1151 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.021888
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.0064
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.0064
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(2112,1,2112,2112) -> Float(2112,1,1,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(2112,1,2112,2112) -> Float(66,1:32,1,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1151 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.021632
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.006004
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.006004
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(66,1:32,1,1) -> Float(2112,1,1,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1151 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.021888
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.006012
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.006012
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(66,1:32,1,1) -> Float(2112,1,2112,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1151 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.020608
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.006268
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.006268
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,256,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,256,16,1) -> Float(16896,256:32,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,33792,2112) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,33792,2112) -> Float(16896,256:32,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,256,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(540672,1,33792,2112) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(16896,256:32,16,1) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,256,16,1) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_343 || Conv_344 || Conv_348 || Conv_352) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.094848
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.064128
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.064128
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,1,22528,1408) -> Float(360448,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_343 || Conv_344 || Conv_348 || Conv_352) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.097404
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.068736
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.068736
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,256,16,1) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1563 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.027636
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.019452
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.019452
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,1,22528,1408) -> Float(360448,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1563 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.035072
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.034176
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.034176
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,256,16,1) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,1,22528,1408) -> Float(360448,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,256,16,1) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,1,22528,1408) -> Float(360448,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,256,16,1) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1572) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.03046
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.01984
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.01984
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,1,22528,1408) -> Float(360448,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1572) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.027392
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.019588
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.019588
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,256,16,1) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,1,22528,1408) -> Float(360448,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,256,16,1) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,1,22528,1408) -> Float(360448,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,256,16,1) -> Float(360448,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: 1560 copy (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.02048
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.010756
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.010756
[03/27/2022-19:09:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,256,16,1) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: 1560 copy (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.028928
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.019844
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.019844
[03/27/2022-19:09:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,1,22528,1408) -> Float(360448,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: 1560 copy (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.030592
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.021504
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.021504
[03/27/2022-19:09:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,1,22528,1408) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: 1560 copy (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.02342
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.018428
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.018428
[03/27/2022-19:09:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,256,16,1) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1183 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.096256
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.064384
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.064384
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(360448,1,22528,1408) -> Float(360448,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1183 -> <out>) (Reformat)
[03/27/2022-19:09:54] [V] [TRT] Tactic: 1002 Time: 0.09792
[03/27/2022-19:09:54] [V] [TRT] Tactic: 0 Time: 0.06848
[03/27/2022-19:09:54] [V] [TRT] Fastest Tactic: 0 Time: 0.06848
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:54] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:54] [V] [TRT] *************** Autotuning Reformat: Float(180224,256,16,1) -> Float(180224,1,11264,704) ***************
[03/27/2022-19:09:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1198) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.030976
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.019456
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.019456
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(180224,1,11264,704) -> Float(180224,256,16,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1198) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.027636
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.019712
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.019712
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(180224,256,16,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1156 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.020736
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.011008
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.011008
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(180224,1,11264,704) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1156 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.030332
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.019836
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.019836
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(180224,256,16,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1156 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.03264
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.020604
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.020604
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(180224,1,11264,704) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1156 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.023296
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.01792
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.01792
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(180224,256,16,1) -> Float(180224,1,11264,704) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1199 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.058744
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.035712
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.035712
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(180224,1,11264,704) -> Float(180224,256,16,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1199 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.057984
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.040444
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.040444
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(90112,256,16,1) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(90112,1,5632,352) -> Float(90112,256,16,1) ***************
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(30720,1,1920,120) -> Float(30720,256,16,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1208 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.022908
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.011016
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.011016
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(245760,1024,32,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1213 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.025344
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.014332
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.014332
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(245760,1,7680,240) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1213 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.038528
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.029312
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.029312
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(245760,1024,32,1) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(245760,1,7680,240) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(245760,1024,32,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1032 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.039928
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.025984
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.025984
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(245760,1,7680,240) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1032 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.032004
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.022784
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.022784
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(245760,1024,32,1) -> Float(245760,1,7680,240) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1214 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.070016
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.04864
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.04864
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(245760,1,7680,240) -> Float(245760,1024,32,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1214 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.070656
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.045692
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.045692
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(122880,1024,32,1) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(122880,1,3840,120) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(49152,1,1536,48) -> Float(49152,1024,32,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1223 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.02496
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.01344
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.01344
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(393216,4096,64,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1228 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.035072
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.02048
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.02048
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(393216,1,6144,96) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1228 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.073088
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.043904
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.043904
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(393216,4096,64,1) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(393216,1,6144,96) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(393216,4096,64,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 890 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.06272
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.037376
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.037376
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(393216,1,6144,96) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 890 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.062336
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.032388
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.032388
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,4096,64,1) -> Float(393216,1,6144,96) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1229 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.116592
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.077188
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.077188
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,6144,96) -> Float(393216,4096,64,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1229 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.117632
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.070276
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.070276
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(196608,4096,64,1) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,3072,48) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(98304,1,1536,24) -> Float(98304,4096,64,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1238 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.044932
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.019456
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.019456
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(786432,16384,128,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1243 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.060676
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.03482
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.03482
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(786432,1,6144,48) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1243 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.244868
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.146432
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.146432
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(786432,16384,128,1) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(786432,1,6144,48) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(786432,16384,128,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 837 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.173952
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.072192
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.072192
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(786432,1,6144,48) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 837 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.150652
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.140544
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.140544
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(786432,16384,128,1) -> Float(786432,1,6144,48) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1244 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.378236
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.156032
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.156032
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(786432,1,6144,48) -> Float(786432,16384,128,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1244 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.224764
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.152832
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.152832
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,16384,128,1) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,3072,24) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(262144,1,2048,16) -> Float(262144,16384,128,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1253 -> <out>) (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.141184
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.045824
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.045824
[03/27/2022-19:09:55] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1258 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.144128
[03/27/2022-19:09:55] [V] [TRT] Tactic: 0 Time: 0.083072
[03/27/2022-19:09:55] [V] [TRT] Fastest Tactic: 0 Time: 0.083072
[03/27/2022-19:09:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:55] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:55] [V] [TRT] --------------- Timing Runner: 1258 copy (Reformat)
[03/27/2022-19:09:55] [V] [TRT] Tactic: 1002 Time: 0.14464
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.141696
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.141696
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 784 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.522496
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.347648
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.347648
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 784 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.54528
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.140928
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.140928
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(2097152,65536,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,65536,256,1) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,4096,16) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1269) (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.044928
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.020608
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.020608
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1269) (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.076032
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.077184
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.076032
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1269) (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.017148
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.007808
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.007808
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1269) (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.48064
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.07552
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.07552
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1269 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.017276
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.008832
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.008832
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1269 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.478464
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.015872
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.015872
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1269 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.479744
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.106624
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.106624
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1269 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.017024
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.008832
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.008832
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1269 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.478592
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.016112
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.016112
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1269 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.479104
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.10496
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.10496
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1269 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.017284
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.008828
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.008828
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1269 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.478592
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.01598
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.01598
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1269 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.481152
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.104828
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.104828
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(393216,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1313 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.034828
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.02022
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.02022
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(393216,1,1536,6) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1313 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.04928
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.04672
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.04672
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1313 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.109184
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.219772
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.109184
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(393216,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1313 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.51072
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.033156
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.033156
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(393216,1,1536,6) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1313 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.480384
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.043908
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.043908
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1313 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.495744
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.229248
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.229248
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(393216,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1313 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.539136
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.07808
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.07808
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(393216,1,1536,6) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1313 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.536064
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.061056
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.061056
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: 1313 copy (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.530048
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.335104
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.335104
[03/27/2022-19:09:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(393216,65536,256,1) -> Float(393216,1,1536,6) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1319 -> <out>) (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.203264
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.058368
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.058368
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(393216,1,1536,6) -> Float(393216,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1319 -> <out>) (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.512256
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.066048
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.066048
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(393216,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1319 -> <out>) (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.513028
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.1472
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.1472
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(393216,1,1536,6) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1319 -> <out>) (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.493436
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.067328
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.067328
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(2097152,65536,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(2097152,65536,256,1) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(2097152,1,8192,32) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,65536,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,1,768,3) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(196608,1,768,3) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(65536,65536:32,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:09:56] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(2764800,921600,720,1) -> Float(2764800,1,2160,3) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1339 -> <out>) (Reformat)
[03/27/2022-19:09:56] [V] [TRT] Tactic: 1002 Time: 0.53184
[03/27/2022-19:09:56] [V] [TRT] Tactic: 0 Time: 0.35776
[03/27/2022-19:09:56] [V] [TRT] Fastest Tactic: 0 Time: 0.35776
[03/27/2022-19:09:56] [V] [TRT] *************** Autotuning Reformat: Float(2764800,921600,720,1) -> Float(921600,921600:32,720,1) ***************
[03/27/2022-19:09:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1339 -> <out>) (Reformat)
[03/27/2022-19:09:57] [V] [TRT] Tactic: 1002 Time: 6.22221
[03/27/2022-19:09:57] [V] [TRT] Tactic: 0 Time: 32.4361
[03/27/2022-19:09:57] [V] [TRT] Fastest Tactic: 1002 Time: 6.22221
[03/27/2022-19:09:57] [V] [TRT] *************** Autotuning Reformat: Float(2764800,1,2160,3) -> Float(2764800,921600,720,1) ***************
[03/27/2022-19:09:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1339 -> <out>) (Reformat)
[03/27/2022-19:09:57] [V] [TRT] Tactic: 1002 Time: 5.25952
[03/27/2022-19:09:57] [V] [TRT] Tactic: 0 Time: 0.432252
[03/27/2022-19:09:57] [V] [TRT] Fastest Tactic: 0 Time: 0.432252
[03/27/2022-19:09:57] [V] [TRT] *************** Autotuning Reformat: Float(2764800,1,2160,3) -> Float(921600,921600:32,720,1) ***************
[03/27/2022-19:09:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1339 -> <out>) (Reformat)
[03/27/2022-19:09:57] [V] [TRT] Tactic: 1002 Time: 5.08006
[03/27/2022-19:09:58] [V] [TRT] Tactic: 0 Time: 32.9015
[03/27/2022-19:09:58] [V] [TRT] Fastest Tactic: 1002 Time: 5.08006
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(921600,921600:32,720,1) -> Float(2764800,921600,720,1) ***************
[03/27/2022-19:09:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1339 -> <out>) (Reformat)
[03/27/2022-19:09:58] [V] [TRT] Tactic: 1002 Time: 5.2576
[03/27/2022-19:09:58] [V] [TRT] Tactic: 0 Time: 0.99712
[03/27/2022-19:09:58] [V] [TRT] Fastest Tactic: 0 Time: 0.99712
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(921600,921600:32,720,1) -> Float(2764800,1,2160,3) ***************
[03/27/2022-19:09:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1339 -> <out>) (Reformat)
[03/27/2022-19:09:58] [V] [TRT] Tactic: 1002 Time: 4.96332
[03/27/2022-19:09:58] [V] [TRT] Tactic: 0 Time: 0.40448
[03/27/2022-19:09:58] [V] [TRT] Fastest Tactic: 0 Time: 0.40448
[03/27/2022-19:09:58] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(2764800,921600,720,1) -> Float(2764800,1,2160,3) ***************
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(2764800,921600,720,1) -> Float(921600,921600:32,720,1) ***************
[03/27/2022-19:09:58] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(2764800,921600,720,1) -> Float(2764800,1,2160,3) ***************
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(2764800,921600,720,1) -> Float(921600,921600:32,720,1) ***************
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(2764800,1,2160,3) -> Float(2764800,921600,720,1) ***************
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(2764800,1,2160,3) -> Float(921600,921600:32,720,1) ***************
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(921600,921600:32,720,1) -> Float(2764800,921600,720,1) ***************
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(921600,921600:32,720,1) -> Float(2764800,1,2160,3) ***************
[03/27/2022-19:09:58] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(2764800,921600,720,1) -> Float(2764800,1,2160,3) ***************
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(2764800,1,2160,3) -> Float(2764800,921600,720,1) ***************
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(921600,921600:32,720,1) -> Float(2764800,921600,720,1) ***************
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(921600,921600:32,720,1) -> Float(2764800,1,2160,3) ***************
[03/27/2022-19:09:58] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(921600,921600,720,1) -> Float(921600,1,720,1) ***************
[03/27/2022-19:09:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1354 -> <out>) (Reformat)
[03/27/2022-19:09:58] [V] [TRT] Tactic: 1002 Time: 0.097276
[03/27/2022-19:09:58] [V] [TRT] Tactic: 0 Time: 0.095232
[03/27/2022-19:09:58] [V] [TRT] Fastest Tactic: 0 Time: 0.095232
[03/27/2022-19:09:58] [V] [TRT] *************** Autotuning Reformat: Float(921600,921600,720,1) -> Float(921600,921600:32,720,1) ***************
[03/27/2022-19:09:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1354 -> <out>) (Reformat)
[03/27/2022-19:09:58] [V] [TRT] Tactic: 1002 Time: 5.34515
[03/27/2022-19:09:59] [V] [TRT] Tactic: 0 Time: 32.5082
[03/27/2022-19:09:59] [V] [TRT] Fastest Tactic: 1002 Time: 5.34515
[03/27/2022-19:09:59] [V] [TRT] *************** Autotuning Reformat: Float(921600,1,720,1) -> Float(921600,921600,720,1) ***************
[03/27/2022-19:09:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1354 -> <out>) (Reformat)
[03/27/2022-19:09:59] [V] [TRT] Tactic: 1002 Time: 0.09728
[03/27/2022-19:09:59] [V] [TRT] Tactic: 0 Time: 0.074752
[03/27/2022-19:09:59] [V] [TRT] Fastest Tactic: 0 Time: 0.074752
[03/27/2022-19:09:59] [V] [TRT] *************** Autotuning Reformat: Float(921600,1,720,1) -> Float(921600,921600:32,720,1) ***************
[03/27/2022-19:09:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1354 -> <out>) (Reformat)
[03/27/2022-19:09:59] [V] [TRT] Tactic: 1002 Time: 5.15968
[03/27/2022-19:09:59] [V] [TRT] Tactic: 0 Time: 32.5623
[03/27/2022-19:09:59] [V] [TRT] Fastest Tactic: 1002 Time: 5.15968
[03/27/2022-19:09:59] [V] [TRT] *************** Autotuning Reformat: Float(921600,921600:32,720,1) -> Float(921600,921600,720,1) ***************
[03/27/2022-19:09:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1354 -> <out>) (Reformat)
[03/27/2022-19:09:59] [V] [TRT] Tactic: 1002 Time: 5.24966
[03/27/2022-19:10:00] [V] [TRT] Tactic: 0 Time: 0.336128
[03/27/2022-19:10:00] [V] [TRT] Fastest Tactic: 0 Time: 0.336128
[03/27/2022-19:10:00] [V] [TRT] *************** Autotuning Reformat: Float(921600,921600:32,720,1) -> Float(921600,1,720,1) ***************
[03/27/2022-19:10:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(1354 -> <out>) (Reformat)
[03/27/2022-19:10:00] [V] [TRT] Tactic: 1002 Time: 5.28384
[03/27/2022-19:10:00] [V] [TRT] Tactic: 0 Time: 0.336
[03/27/2022-19:10:00] [V] [TRT] Fastest Tactic: 0 Time: 0.336
[03/27/2022-19:10:00] [V] [TRT] =============== Computing reformatting costs
[03/27/2022-19:10:00] [V] [TRT] *************** Autotuning Reformat: Float(921600,1,720,1) -> Float(921600,921600,720,1) ***************
[03/27/2022-19:10:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1355) (Reformat)
[03/27/2022-19:10:00] [V] [TRT] Tactic: 1002 Time: 0.09728
[03/27/2022-19:10:00] [V] [TRT] Tactic: 0 Time: 0.075252
[03/27/2022-19:10:00] [V] [TRT] Fastest Tactic: 0 Time: 0.075252
[03/27/2022-19:10:00] [V] [TRT] *************** Autotuning Reformat: Float(921600,921600:32,720,1) -> Float(921600,921600,720,1) ***************
[03/27/2022-19:10:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 1355) (Reformat)
[03/27/2022-19:10:00] [V] [TRT] Tactic: 1002 Time: 5.27194
[03/27/2022-19:10:00] [V] [TRT] Tactic: 0 Time: 0.335484
[03/27/2022-19:10:00] [V] [TRT] Fastest Tactic: 0 Time: 0.335484
[03/27/2022-19:10:00] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:00] [V] [TRT] *************** Autotuning format combination:  -> Float(1,1,1,1) ***************
[03/27/2022-19:10:00] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:00] [V] [TRT] *************** Autotuning format combination: Float(2764800,921600,720,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:10:00] [V] [TRT] --------------- Timing Runner: Resize_8 (Resize)
[03/27/2022-19:10:00] [V] [TRT] Tactic: 1 Time: 0.061952
[03/27/2022-19:10:00] [V] [TRT] Fastest Tactic: 1 Time: 0.061952
[03/27/2022-19:10:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 1
[03/27/2022-19:10:00] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:00] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:10:00] [V] [TRT] --------------- Timing Runner: Conv_9 + Relu_10 (CudaDepthwiseConvolution)
[03/27/2022-19:10:00] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:00] [V] [TRT] --------------- Timing Runner: Conv_9 + Relu_10 (FusedConvActConvolution)
[03/27/2022-19:10:00] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:00] [V] [TRT] --------------- Timing Runner: Conv_9 + Relu_10 (CudnnConvolution)
[03/27/2022-19:10:01] [V] [TRT] Tactic: 0 Time: 0.530048
[03/27/2022-19:10:01] [V] [TRT] Tactic: 1 Time: 0.481664
[03/27/2022-19:10:01] [V] [TRT] Tactic: 2 Time: 0.621824
[03/27/2022-19:10:01] [V] [TRT] Tactic: 5 Time: 2.33779
[03/27/2022-19:10:01] [V] [TRT] Tactic: 6 Time: 0.618472
[03/27/2022-19:10:01] [V] [TRT] Fastest Tactic: 1 Time: 0.481664
[03/27/2022-19:10:01] [V] [TRT] --------------- Timing Runner: Conv_9 + Relu_10 (CaskConvolution)
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:01] [V] [TRT] Tactic: 1062367460111450758 Time: 0.131324
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:10:01] [V] [TRT] Tactic: 1754984623894446479 Time: 0.1504
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:10:01] [V] [TRT] Tactic: 3611739942397549984 Time: 0.396544
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:10:01] [V] [TRT] Tactic: 3827454225649558724 Time: 0.299512
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:10:01] [V] [TRT] Tactic: 4337000649858996379 Time: 0.200824
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:01] [V] [TRT] Tactic: 4501471010995462441 Time: 0.37632
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:01] [V] [TRT] Tactic: 5137655947464784826 Time: 0.195064
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:01] [V] [TRT] Tactic: 5288347012147084929 Time: 0.392576
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:10:01] [V] [TRT] Tactic: 5921334924264294896 Time: 0.274176
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:01] [V] [TRT] Tactic: 6645123197870846056 Time: 0.199296
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:01] [V] [TRT] Tactic: 7144526460361122478 Time: 0.149888
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:10:01] [V] [TRT] Tactic: 7852627285308570038 Time: 0.272512
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:10:01] [V] [TRT] Tactic: -9137461792520977713 Time: 0.37888
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:10:01] [V] [TRT] Tactic: -8776506421218919509 Time: 0.304768
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:01] [V] [TRT] Tactic: -8262349710178828730 Time: 0.396672
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:10:01] [V] [TRT] Tactic: -8133971918129952780 Time: 0.201712
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:10:01] [V] [TRT] Tactic: -6092040395344634144 Time: 0.131456
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:01] [V] [TRT] Tactic: -4787320710726427159 Time: 0.150396
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:01] [V] [TRT] Tactic: -3456450830548107839 Time: 0.129516
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:10:01] [V] [TRT] Tactic: -2318106587342035239 Time: 0.27098
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:10:01] [V] [TRT] Tactic: -1343271414618805657 Time: 0.271616
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:01] [V] [TRT] Tactic: -1218658103698133241 Time: 0.20134
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:01] [V] [TRT] Tactic: -836875257600482091 Time: 0.198912
[03/27/2022-19:10:01] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:01] [V] [TRT] Tactic: -410470605513481746 Time: 0.370688
[03/27/2022-19:10:01] [V] [TRT] Fastest Tactic: -3456450830548107839 Time: 0.129516
[03/27/2022-19:10:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3456450830548107839
[03/27/2022-19:10:01] [V] [TRT] *************** Autotuning format combination: Float(196608,1,768,3) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:10:01] [V] [TRT] --------------- Timing Runner: Conv_9 + Relu_10 (CaskConvolution)
[03/27/2022-19:10:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:01] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:01] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:10:01] [V] [TRT] --------------- Timing Runner: Conv_446 (CudaDepthwiseConvolution)
[03/27/2022-19:10:01] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:01] [V] [TRT] --------------- Timing Runner: Conv_446 (FusedConvActConvolution)
[03/27/2022-19:10:01] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:01] [V] [TRT] --------------- Timing Runner: Conv_446 (CudnnConvolution)
[03/27/2022-19:10:01] [V] [TRT] Tactic: 0 Time: 0.398208
[03/27/2022-19:10:01] [V] [TRT] Tactic: 1 Time: 0.397312
[03/27/2022-19:10:01] [V] [TRT] Tactic: 2 Time: 0.39808
[03/27/2022-19:10:01] [V] [TRT] Tactic: 5 Time: 1.75642
[03/27/2022-19:10:01] [V] [TRT] Tactic: 6 Time: 0.191868
[03/27/2022-19:10:01] [V] [TRT] Fastest Tactic: 6 Time: 0.191868
[03/27/2022-19:10:01] [V] [TRT] --------------- Timing Runner: Conv_446 (CaskConvolution)
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:01] [V] [TRT] Tactic: 1062367460111450758 Time: 0.113152
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:10:01] [V] [TRT] Tactic: 1754984623894446479 Time: 0.11904
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:10:01] [V] [TRT] Tactic: 3611739942397549984 Time: 0.387456
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:10:01] [V] [TRT] Tactic: 3827454225649558724 Time: 0.174844
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:10:01] [V] [TRT] Tactic: 4337000649858996379 Time: 0.19684
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:01] [V] [TRT] Tactic: 4501471010995462441 Time: 0.367872
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:01] [V] [TRT] Tactic: 5137655947464784826 Time: 0.189696
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:01] [V] [TRT] Tactic: 5288347012147084929 Time: 0.383876
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:10:01] [V] [TRT] Tactic: 5921334924264294896 Time: 0.1792
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:01] [V] [TRT] Tactic: 6645123197870846056 Time: 0.194936
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:01] [V] [TRT] Tactic: 7144526460361122478 Time: 0.115324
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:10:01] [V] [TRT] Tactic: 7852627285308570038 Time: 0.189312
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:10:01] [V] [TRT] Tactic: -9137461792520977713 Time: 0.371832
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:10:01] [V] [TRT] Tactic: -8776506421218919509 Time: 0.170736
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:01] [V] [TRT] Tactic: -8262349710178828730 Time: 0.388212
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:10:01] [V] [TRT] Tactic: -8133971918129952780 Time: 0.193396
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:10:01] [V] [TRT] Tactic: -6092040395344634144 Time: 0.116096
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:01] [V] [TRT] Tactic: -4787320710726427159 Time: 0.118144
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:01] [V] [TRT] Tactic: -3456450830548107839 Time: 0.10944
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:10:01] [V] [TRT] Tactic: -2318106587342035239 Time: 0.181248
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:10:01] [V] [TRT] Tactic: -1343271414618805657 Time: 0.172292
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:01] [V] [TRT] Tactic: -1218658103698133241 Time: 0.192896
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:01] [V] [TRT] Tactic: -836875257600482091 Time: 0.19008
[03/27/2022-19:10:01] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:01] [V] [TRT] Tactic: -410470605513481746 Time: 0.362744
[03/27/2022-19:10:01] [V] [TRT] Fastest Tactic: -3456450830548107839 Time: 0.10944
[03/27/2022-19:10:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3456450830548107839
[03/27/2022-19:10:01] [V] [TRT] *************** Autotuning format combination: Float(196608,1,768,3) -> Float(196608,1,768,3) ***************
[03/27/2022-19:10:01] [V] [TRT] --------------- Timing Runner: Conv_446 (CaskConvolution)
[03/27/2022-19:10:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:01] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:01] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1), Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:10:01] [V] [TRT] --------------- Timing Runner: Mul_455 (ElementWise)
[03/27/2022-19:10:01] [V] [TRT] Tactic: 1 Time: 0.019068
[03/27/2022-19:10:01] [V] [TRT] Fastest Tactic: 1 Time: 0.019068
[03/27/2022-19:10:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1
[03/27/2022-19:10:01] [V] [TRT] *************** Autotuning format combination: Float(65536,65536:32,256,1), Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:10:01] [V] [TRT] --------------- Timing Runner: Mul_455 (ElementWise)
[03/27/2022-19:10:01] [V] [TRT] Tactic: 1 Time: 0.158848
[03/27/2022-19:10:01] [V] [TRT] Fastest Tactic: 1 Time: 0.158848
[03/27/2022-19:10:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1
[03/27/2022-19:10:01] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:01] [V] [TRT] *************** Autotuning format combination: Float(2097152,65536,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:10:01] [V] [TRT] --------------- Timing Runner: Conv_11 (CudaDepthwiseConvolution)
[03/27/2022-19:10:01] [V] [TRT] Tactic: -1 Time: 0.299136
[03/27/2022-19:10:01] [V] [TRT] Fastest Tactic: -1 Time: 0.299136
[03/27/2022-19:10:01] [V] [TRT] --------------- Timing Runner: Conv_11 (CudnnConvolution)
[03/27/2022-19:10:01] [V] [TRT] Tactic: 0 Time: 0.57152
[03/27/2022-19:10:01] [V] [TRT] Tactic: 1 Time: 0.57216
[03/27/2022-19:10:02] [V] [TRT] Tactic: 2 Time: 1.73465
[03/27/2022-19:10:03] [V] [TRT] Tactic: 5 Time: 74.5375
[03/27/2022-19:10:03] [V] [TRT] Tactic: 6 Time: 18.5272
[03/27/2022-19:10:03] [V] [TRT] Fastest Tactic: 0 Time: 0.57152
[03/27/2022-19:10:03] [V] [TRT] --------------- Timing Runner: Conv_11 (CaskConvolution)
[03/27/2022-19:10:03] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:03] [V] [TRT] Tactic: 1062367460111450758 Time: 2.58982
[03/27/2022-19:10:03] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:10:03] [V] [TRT] Tactic: 1754984623894446479 Time: 2.62387
[03/27/2022-19:10:03] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:10:03] [V] [TRT] Tactic: 3611739942397549984 Time: 9.50554
[03/27/2022-19:10:03] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:10:03] [V] [TRT] Tactic: 3827454225649558724 Time: 5.37293
[03/27/2022-19:10:03] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:10:04] [V] [TRT] Tactic: 4337000649858996379 Time: 4.64333
[03/27/2022-19:10:04] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:04] [V] [TRT] Tactic: 4501471010995462441 Time: 8.88499
[03/27/2022-19:10:04] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:04] [V] [TRT] Tactic: 5137655947464784826 Time: 4.50304
[03/27/2022-19:10:04] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:04] [V] [TRT] Tactic: 5288347012147084929 Time: 9.91373
[03/27/2022-19:10:04] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:10:04] [V] [TRT] Tactic: 5921334924264294896 Time: 5.58464
[03/27/2022-19:10:04] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:04] [V] [TRT] Tactic: 6645123197870846056 Time: 4.66509
[03/27/2022-19:10:04] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:04] [V] [TRT] Tactic: 7144526460361122478 Time: 2.60403
[03/27/2022-19:10:04] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:10:04] [V] [TRT] Tactic: 7852627285308570038 Time: 5.8871
[03/27/2022-19:10:04] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:10:05] [V] [TRT] Tactic: -9137461792520977713 Time: 9.0729
[03/27/2022-19:10:05] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:10:05] [V] [TRT] Tactic: -8776506421218919509 Time: 5.28269
[03/27/2022-19:10:05] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:05] [V] [TRT] Tactic: -8262349710178828730 Time: 9.68128
[03/27/2022-19:10:05] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:10:05] [V] [TRT] Tactic: -8133971918129952780 Time: 4.39219
[03/27/2022-19:10:05] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:10:05] [V] [TRT] Tactic: -6092040395344634144 Time: 2.75456
[03/27/2022-19:10:05] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:05] [V] [TRT] Tactic: -4787320710726427159 Time: 2.66534
[03/27/2022-19:10:05] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:05] [V] [TRT] Tactic: -3456450830548107839 Time: 2.49754
[03/27/2022-19:10:05] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:10:05] [V] [TRT] Tactic: -2318106587342035239 Time: 5.57466
[03/27/2022-19:10:05] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:10:05] [V] [TRT] Tactic: -1343271414618805657 Time: 5.40595
[03/27/2022-19:10:05] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:05] [V] [TRT] Tactic: -1218658103698133241 Time: 4.41214
[03/27/2022-19:10:05] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:06] [V] [TRT] Tactic: -836875257600482091 Time: 4.37786
[03/27/2022-19:10:06] [V] [TRT] Conv_11 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:06] [V] [TRT] Tactic: -410470605513481746 Time: 8.81869
[03/27/2022-19:10:06] [V] [TRT] Fastest Tactic: -3456450830548107839 Time: 2.49754
[03/27/2022-19:10:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:10:06] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,8192,32) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:10:06] [V] [TRT] --------------- Timing Runner: Conv_11 (CaskConvolution)
[03/27/2022-19:10:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:06] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:06] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:10:06] [V] [TRT] *************** Autotuning format combination: Float(196608,1,768,3) -> Float(196608,1,768,3) ***************
[03/27/2022-19:10:06] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:06] [V] [TRT] *************** Autotuning format combination: Float(2097152,65536,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:10:06] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_12), Mul_13) (PointWiseV2)
[03/27/2022-19:10:06] [V] [TRT] Tactic: 0 Time: 0.160512
[03/27/2022-19:10:06] [V] [TRT] Tactic: 1 Time: 0.16038
[03/27/2022-19:10:07] [V] [TRT] Tactic: 2 Time: 0.159092
[03/27/2022-19:10:08] [V] [TRT] Tactic: 3 Time: 0.16038
[03/27/2022-19:10:08] [V] [TRT] Tactic: 4 Time: 0.160896
[03/27/2022-19:10:09] [V] [TRT] Tactic: 5 Time: 0.160636
[03/27/2022-19:10:09] [V] [TRT] Tactic: 6 Time: 0.165888
[03/27/2022-19:10:10] [V] [TRT] Tactic: 7 Time: 0.161024
[03/27/2022-19:10:11] [V] [TRT] Tactic: 8 Time: 0.16038
[03/27/2022-19:10:11] [V] [TRT] Tactic: 9 Time: 0.16064
[03/27/2022-19:10:12] [V] [TRT] Tactic: 28 Time: 0.192004
[03/27/2022-19:10:12] [V] [TRT] Fastest Tactic: 2 Time: 0.159092
[03/27/2022-19:10:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_12), Mul_13) (PointWise)
[03/27/2022-19:10:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:10:12] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,8192,32) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:10:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_12), Mul_13) (PointWiseV2)
[03/27/2022-19:10:12] [V] [TRT] Tactic: 0 Time: 0.192504
[03/27/2022-19:10:12] [V] [TRT] Tactic: 1 Time: 0.162688
[03/27/2022-19:10:12] [V] [TRT] Tactic: 2 Time: 0.160512
[03/27/2022-19:10:12] [V] [TRT] Tactic: 3 Time: 0.162048
[03/27/2022-19:10:12] [V] [TRT] Tactic: 4 Time: 0.160772
[03/27/2022-19:10:12] [V] [TRT] Tactic: 5 Time: 0.159752
[03/27/2022-19:10:12] [V] [TRT] Tactic: 6 Time: 0.166272
[03/27/2022-19:10:12] [V] [TRT] Tactic: 7 Time: 0.161284
[03/27/2022-19:10:12] [V] [TRT] Tactic: 8 Time: 0.160376
[03/27/2022-19:10:12] [V] [TRT] Tactic: 9 Time: 0.160636
[03/27/2022-19:10:12] [V] [TRT] Tactic: 28 Time: 0.190592
[03/27/2022-19:10:12] [V] [TRT] Fastest Tactic: 5 Time: 0.159752
[03/27/2022-19:10:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_12), Mul_13) (PointWise)
[03/27/2022-19:10:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:10:12] [V] [TRT] *************** Autotuning format combination: Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:10:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_12), Mul_13) (PointWiseV2)
[03/27/2022-19:10:12] [V] [TRT] Tactic: 24 Time: 0.160768
[03/27/2022-19:10:13] [V] [TRT] Tactic: 25 Time: 0.160252
[03/27/2022-19:10:14] [V] [TRT] Tactic: 26 Time: 0.161796
[03/27/2022-19:10:15] [V] [TRT] Tactic: 27 Time: 0.163072
[03/27/2022-19:10:15] [V] [TRT] Tactic: 31 Time: 0.16026
[03/27/2022-19:10:15] [V] [TRT] Fastest Tactic: 25 Time: 0.160252
[03/27/2022-19:10:15] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_12), Mul_13) (PointWise)
[03/27/2022-19:10:15] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[03/27/2022-19:10:15] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:15] [V] [TRT] *************** Autotuning format combination: Float(2097152,65536,256,1) -> Float(32,1,1,1) ***************
[03/27/2022-19:10:15] [V] [TRT] --------------- Timing Runner: ReduceMean_14 (TiledPooling)
[03/27/2022-19:10:15] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:10:15] [V] [TRT] --------------- Timing Runner: ReduceMean_14 (CudnnPooling)
[03/27/2022-19:10:15] [V] [TRT] Tactic: -1 Time: 0.12352
[03/27/2022-19:10:15] [V] [TRT] Fastest Tactic: -1 Time: 0.12352
[03/27/2022-19:10:15] [V] [TRT] --------------- Timing Runner: ReduceMean_14 (CaskPooling)
[03/27/2022-19:10:15] [V] [TRT] ReduceMean_14 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:10:15] [V] [TRT] Tactic: 6119644359078410246 Time: 0.117252
[03/27/2022-19:10:15] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.117252
[03/27/2022-19:10:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 6119644359078410246
[03/27/2022-19:10:15] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:15] [V] [TRT] *************** Autotuning format combination: Float(1,1,1,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:10:15] [V] [TRT] --------------- Timing Runner: ConstantOfShape_444 (Slice)
[03/27/2022-19:10:15] [V] [TRT] Tactic: 0 Time: 0.02688
[03/27/2022-19:10:15] [V] [TRT] Fastest Tactic: 0 Time: 0.02688
[03/27/2022-19:10:15] [V] [TRT] --------------- Timing Runner: ConstantOfShape_444 (Padding)
[03/27/2022-19:10:15] [V] [TRT] Padding has no valid tactics for this config, skipping
[03/27/2022-19:10:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Slice Tactic: 0
[03/27/2022-19:10:15] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:15] [V] [TRT] *************** Autotuning format combination: Float(32,1,1,1) -> Float(8,1,1,1) ***************
[03/27/2022-19:10:15] [V] [TRT] --------------- Timing Runner: Conv_15 (CudaDepthwiseConvolution)
[03/27/2022-19:10:15] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:15] [V] [TRT] --------------- Timing Runner: Conv_15 (FusedConvActConvolution)
[03/27/2022-19:10:15] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:15] [V] [TRT] --------------- Timing Runner: Conv_15 (CudnnConvolution)
[03/27/2022-19:10:15] [V] [TRT] Tactic: 0 Time: 0.01318
[03/27/2022-19:10:15] [V] [TRT] Tactic: 1 Time: 0.009344
[03/27/2022-19:10:15] [V] [TRT] Tactic: 2 Time: 0.025984
[03/27/2022-19:10:15] [V] [TRT] Tactic: 4 Time: 0.03648
[03/27/2022-19:10:15] [V] [TRT] Tactic: 5 Time: 0.387292
[03/27/2022-19:10:15] [V] [TRT] Fastest Tactic: 1 Time: 0.009344
[03/27/2022-19:10:15] [V] [TRT] --------------- Timing Runner: Conv_15 (CublasConvolution)
[03/27/2022-19:10:16] [V] [TRT] Tactic: 0 Time: 0.00896
[03/27/2022-19:10:16] [V] [TRT] Tactic: 1 Time: 0.008576
[03/27/2022-19:10:16] [V] [TRT] Fastest Tactic: 1 Time: 0.008576
[03/27/2022-19:10:16] [V] [TRT] --------------- Timing Runner: Conv_15 (CaskConvolution)
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:16] [V] [TRT] Tactic: 1062367460111450758 Time: 0.015112
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:10:16] [V] [TRT] Tactic: 1698681053543049347 Time: 0.011264
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:16] [V] [TRT] Tactic: 4501471010995462441 Time: 0.015488
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:16] [V] [TRT] Tactic: 5137655947464784826 Time: 0.014336
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:16] [V] [TRT] Tactic: 5288347012147084929 Time: 0.01536
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:10:16] [V] [TRT] Tactic: 5326823351883942011 Time: 0.015104
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:10:16] [V] [TRT] Tactic: 5500448035057547314 Time: 0.014204
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:16] [V] [TRT] Tactic: 6645123197870846056 Time: 0.014464
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:16] [V] [TRT] Tactic: 7144526460361122478 Time: 0.01152
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:16] [V] [TRT] Tactic: -8262349710178828730 Time: 0.015488
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:10:16] [V] [TRT] Tactic: -6576203419454146580 Time: 0.014464
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:16] [V] [TRT] Tactic: -4787320710726427159 Time: 0.011904
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:16] [V] [TRT] Tactic: -3456450830548107839 Time: 0.014724
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:16] [V] [TRT] Tactic: -1218658103698133241 Time: 0.014592
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:16] [V] [TRT] Tactic: -836875257600482091 Time: 0.01446
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:16] [V] [TRT] Tactic: -410470605513481746 Time: 0.014848
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:10:16] [V] [TRT] Tactic: -377491875521947884 Time: 0.015488
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:10:16] [V] [TRT] Tactic: -37215280111360163 Time: 0.014076
[03/27/2022-19:10:16] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.011264
[03/27/2022-19:10:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1
[03/27/2022-19:10:16] [V] [TRT] *************** Autotuning format combination: Float(32,1,32,32) -> Float(8,1,8,8) ***************
[03/27/2022-19:10:16] [V] [TRT] --------------- Timing Runner: Conv_15 (CublasConvolution)
[03/27/2022-19:10:16] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:16] [V] [TRT] --------------- Timing Runner: Conv_15 (CaskConvolution)
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:10:16] [V] [TRT] Tactic: 3886731678879822788 Time: 0.012288
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:10:16] [V] [TRT] Tactic: 6629944304117643200 Time: 0.011648
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:10:16] [V] [TRT] Tactic: -9153228964338181824 Time: 0.011648
[03/27/2022-19:10:16] [V] [TRT] Conv_15 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:10:16] [V] [TRT] Tactic: -7394439838318485025 Time: 0.012416
[03/27/2022-19:10:16] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.011648
[03/27/2022-19:10:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:10:16] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:16] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:10:16] [V] [TRT] *************** Autotuning format combination: Float(196608,1,768,3) -> Float(196608,1,768,3) ***************
[03/27/2022-19:10:16] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:16] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1), Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:10:16] [V] [TRT] --------------- Timing Runner: Div_447 (ElementWise)
[03/27/2022-19:10:16] [V] [TRT] Tactic: 1 Time: 0.0288
[03/27/2022-19:10:16] [V] [TRT] Fastest Tactic: 1 Time: 0.0288
[03/27/2022-19:10:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1
[03/27/2022-19:10:16] [V] [TRT] *************** Autotuning format combination: Float(65536,65536:32,256,1), Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:10:16] [V] [TRT] --------------- Timing Runner: Div_447 (ElementWise)
[03/27/2022-19:10:16] [V] [TRT] Tactic: 1 Time: 0.237184
[03/27/2022-19:10:16] [V] [TRT] Fastest Tactic: 1 Time: 0.237184
[03/27/2022-19:10:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1
[03/27/2022-19:10:16] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:16] [V] [TRT] *************** Autotuning format combination: Float(8,1,1,1) -> Float(8,1,1,1) ***************
[03/27/2022-19:10:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_16), Mul_17) (PointWiseV2)
[03/27/2022-19:10:17] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:10:17] [V] [TRT] Tactic: 1 Time: 0.005892
[03/27/2022-19:10:17] [V] [TRT] Tactic: 2 Time: 0.00576
[03/27/2022-19:10:17] [V] [TRT] Tactic: 3 Time: 0.005628
[03/27/2022-19:10:17] [V] [TRT] Tactic: 4 Time: 0.0055
[03/27/2022-19:10:17] [V] [TRT] Tactic: 5 Time: 0.00576
[03/27/2022-19:10:17] [V] [TRT] Tactic: 6 Time: 0.006268
[03/27/2022-19:10:17] [V] [TRT] Tactic: 7 Time: 0.00602
[03/27/2022-19:10:17] [V] [TRT] Tactic: 8 Time: 0.00576
[03/27/2022-19:10:17] [V] [TRT] Tactic: 9 Time: 0.006272
[03/27/2022-19:10:17] [V] [TRT] Tactic: 28 Time: 0.005632
[03/27/2022-19:10:17] [V] [TRT] Fastest Tactic: 4 Time: 0.0055
[03/27/2022-19:10:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_16), Mul_17) (PointWise)
[03/27/2022-19:10:17] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 4
[03/27/2022-19:10:17] [V] [TRT] *************** Autotuning format combination: Float(8,1,8,8) -> Float(8,1,8,8) ***************
[03/27/2022-19:10:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_16), Mul_17) (PointWiseV2)
[03/27/2022-19:10:17] [V] [TRT] Tactic: 0 Time: 0.005508
[03/27/2022-19:10:17] [V] [TRT] Tactic: 1 Time: 0.005632
[03/27/2022-19:10:17] [V] [TRT] Tactic: 2 Time: 0.005888
[03/27/2022-19:10:17] [V] [TRT] Tactic: 3 Time: 0.005888
[03/27/2022-19:10:17] [V] [TRT] Tactic: 4 Time: 0.006016
[03/27/2022-19:10:17] [V] [TRT] Tactic: 5 Time: 0.00576
[03/27/2022-19:10:17] [V] [TRT] Tactic: 6 Time: 0.006268
[03/27/2022-19:10:17] [V] [TRT] Tactic: 7 Time: 0.089856
[03/27/2022-19:10:17] [V] [TRT] Tactic: 8 Time: 0.005632
[03/27/2022-19:10:17] [V] [TRT] Tactic: 9 Time: 0.005632
[03/27/2022-19:10:17] [V] [TRT] Tactic: 28 Time: 0.005628
[03/27/2022-19:10:17] [V] [TRT] Fastest Tactic: 0 Time: 0.005508
[03/27/2022-19:10:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_16), Mul_17) (PointWise)
[03/27/2022-19:10:17] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0
[03/27/2022-19:10:17] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:10:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_16), Mul_17) (PointWiseV2)
[03/27/2022-19:10:18] [V] [TRT] Tactic: 24 Time: 0.006528
[03/27/2022-19:10:19] [V] [TRT] Tactic: 25 Time: 0.00666
[03/27/2022-19:10:19] [V] [TRT] Tactic: 26 Time: 0.007044
[03/27/2022-19:10:20] [V] [TRT] Tactic: 27 Time: 0.007168
[03/27/2022-19:10:20] [V] [TRT] Tactic: 31 Time: 0.006404
[03/27/2022-19:10:20] [V] [TRT] Fastest Tactic: 31 Time: 0.006404
[03/27/2022-19:10:20] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_16), Mul_17) (PointWise)
[03/27/2022-19:10:20] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:10:20] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:20] [V] [TRT] *************** Autotuning format combination: Float(8,1,1,1) -> Float(32,1,1,1) ***************
[03/27/2022-19:10:20] [V] [TRT] --------------- Timing Runner: Conv_18 (CudaDepthwiseConvolution)
[03/27/2022-19:10:20] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:20] [V] [TRT] --------------- Timing Runner: Conv_18 (FusedConvActConvolution)
[03/27/2022-19:10:20] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:20] [V] [TRT] --------------- Timing Runner: Conv_18 (CudnnConvolution)
[03/27/2022-19:10:20] [V] [TRT] Tactic: 0 Time: 0.012404
[03/27/2022-19:10:20] [V] [TRT] Tactic: 1 Time: 0.164216
[03/27/2022-19:10:20] [V] [TRT] Tactic: 2 Time: 0.188908
[03/27/2022-19:10:20] [V] [TRT] Tactic: 4 Time: 0.255744
[03/27/2022-19:10:20] [V] [TRT] Tactic: 5 Time: 0.301316
[03/27/2022-19:10:20] [V] [TRT] Fastest Tactic: 0 Time: 0.012404
[03/27/2022-19:10:20] [V] [TRT] --------------- Timing Runner: Conv_18 (CublasConvolution)
[03/27/2022-19:10:20] [V] [TRT] Tactic: 0 Time: 0.008832
[03/27/2022-19:10:20] [V] [TRT] Tactic: 1 Time: 0.009344
[03/27/2022-19:10:20] [V] [TRT] Fastest Tactic: 0 Time: 0.008832
[03/27/2022-19:10:20] [V] [TRT] --------------- Timing Runner: Conv_18 (CaskConvolution)
[03/27/2022-19:10:20] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:20] [V] [TRT] Tactic: 1062367460111450758 Time: 0.013184
[03/27/2022-19:10:20] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:10:20] [V] [TRT] Tactic: 1698681053543049347 Time: 0.009856
[03/27/2022-19:10:20] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:20] [V] [TRT] Tactic: 4501471010995462441 Time: 0.01254
[03/27/2022-19:10:20] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:20] [V] [TRT] Tactic: 5137655947464784826 Time: 0.013696
[03/27/2022-19:10:20] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:20] [V] [TRT] Tactic: 5288347012147084929 Time: 0.014204
[03/27/2022-19:10:20] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:10:20] [V] [TRT] Tactic: 5326823351883942011 Time: 0.10458
[03/27/2022-19:10:20] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:10:20] [V] [TRT] Tactic: 5500448035057547314 Time: 0.046464
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:21] [V] [TRT] Tactic: 6645123197870846056 Time: 0.013056
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:21] [V] [TRT] Tactic: 7144526460361122478 Time: 0.009984
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:21] [V] [TRT] Tactic: -8262349710178828730 Time: 0.013184
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:10:21] [V] [TRT] Tactic: -6576203419454146580 Time: 0.0128
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:21] [V] [TRT] Tactic: -4787320710726427159 Time: 0.00998
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:21] [V] [TRT] Tactic: -3456450830548107839 Time: 0.013056
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:21] [V] [TRT] Tactic: -1218658103698133241 Time: 0.013568
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:21] [V] [TRT] Tactic: -836875257600482091 Time: 0.012036
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:21] [V] [TRT] Tactic: -410470605513481746 Time: 0.01306
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:10:21] [V] [TRT] Tactic: -377491875521947884 Time: 0.012928
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:10:21] [V] [TRT] Tactic: -37215280111360163 Time: 0.01254
[03/27/2022-19:10:21] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.009856
[03/27/2022-19:10:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0
[03/27/2022-19:10:21] [V] [TRT] *************** Autotuning format combination: Float(8,1,8,8) -> Float(32,1,32,32) ***************
[03/27/2022-19:10:21] [V] [TRT] --------------- Timing Runner: Conv_18 (CublasConvolution)
[03/27/2022-19:10:21] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:21] [V] [TRT] --------------- Timing Runner: Conv_18 (CaskConvolution)
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:10:21] [V] [TRT] Tactic: 3886731678879822788 Time: 0.011392
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:10:21] [V] [TRT] Tactic: 6629944304117643200 Time: 0.011532
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:10:21] [V] [TRT] Tactic: -9153228964338181824 Time: 0.01164
[03/27/2022-19:10:21] [V] [TRT] Conv_18 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:10:21] [V] [TRT] Tactic: -7394439838318485025 Time: 0.01152
[03/27/2022-19:10:21] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.011392
[03/27/2022-19:10:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:10:21] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:21] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1), Float(196608,65536,256,1), Float(196608,65536,256,1) -> Float(393216,65536,256,1) ***************
[03/27/2022-19:10:21] [V] [TRT] --------------- Timing Runner: PWN(Mul_458, PWN(Div_457, Sub_459)) (PointWiseV2)
[03/27/2022-19:10:22] [V] [TRT] Tactic: 0 Time: 0.038016
[03/27/2022-19:10:22] [V] [TRT] Tactic: 1 Time: 0.036224
[03/27/2022-19:10:23] [V] [TRT] Tactic: 2 Time: 0.03584
[03/27/2022-19:10:23] [V] [TRT] Tactic: 3 Time: 0.036352
[03/27/2022-19:10:24] [V] [TRT] Tactic: 4 Time: 0.036096
[03/27/2022-19:10:24] [V] [TRT] Tactic: 5 Time: 0.036356
[03/27/2022-19:10:25] [V] [TRT] Tactic: 6 Time: 0.036352
[03/27/2022-19:10:26] [V] [TRT] Tactic: 7 Time: 0.036224
[03/27/2022-19:10:26] [V] [TRT] Tactic: 8 Time: 0.03622
[03/27/2022-19:10:26] [V] [TRT] Tactic: 9 Time: 0.038144
[03/27/2022-19:10:27] [V] [TRT] Tactic: 28 Time: 0.037228
[03/27/2022-19:10:27] [V] [TRT] Fastest Tactic: 2 Time: 0.03584
[03/27/2022-19:10:27] [V] [TRT] --------------- Timing Runner: PWN(Mul_458, PWN(Div_457, Sub_459)) (PointWise)
[03/27/2022-19:10:27] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:10:27] [V] [TRT] *************** Autotuning format combination: Float(196608,1,768,3), Float(196608,1,768,3), Float(196608,1,768,3) -> Float(393216,1,1536,6) ***************
[03/27/2022-19:10:27] [V] [TRT] --------------- Timing Runner: PWN(Mul_458, PWN(Div_457, Sub_459)) (PointWiseV2)
[03/27/2022-19:10:27] [V] [TRT] Tactic: 0 Time: 0.3168
[03/27/2022-19:10:27] [V] [TRT] Tactic: 1 Time: 0.396284
[03/27/2022-19:10:27] [V] [TRT] Tactic: 2 Time: 0.33024
[03/27/2022-19:10:27] [V] [TRT] Tactic: 3 Time: 0.460416
[03/27/2022-19:10:27] [V] [TRT] Tactic: 4 Time: 0.513408
[03/27/2022-19:10:27] [V] [TRT] Tactic: 5 Time: 0.340736
[03/27/2022-19:10:27] [V] [TRT] Tactic: 6 Time: 0.59162
[03/27/2022-19:10:27] [V] [TRT] Tactic: 7 Time: 0.667264
[03/27/2022-19:10:27] [V] [TRT] Tactic: 8 Time: 0.653568
[03/27/2022-19:10:27] [V] [TRT] Tactic: 9 Time: 0.387584
[03/27/2022-19:10:27] [V] [TRT] Tactic: 28 Time: 0.058752
[03/27/2022-19:10:27] [V] [TRT] Fastest Tactic: 28 Time: 0.058752
[03/27/2022-19:10:27] [V] [TRT] --------------- Timing Runner: PWN(Mul_458, PWN(Div_457, Sub_459)) (PointWise)
[03/27/2022-19:10:27] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:10:27] [V] [TRT] *************** Autotuning format combination: Float(65536,65536:32,256,1), Float(65536,65536:32,256,1), Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:10:27] [V] [TRT] --------------- Timing Runner: PWN(Mul_458, PWN(Div_457, Sub_459)) (PointWiseV2)
[03/27/2022-19:10:27] [V] [TRT] Tactic: 24 Time: 0.310144
[03/27/2022-19:10:28] [V] [TRT] Tactic: 25 Time: 0.310528
[03/27/2022-19:10:28] [V] [TRT] Tactic: 26 Time: 0.312832
[03/27/2022-19:10:29] [V] [TRT] Tactic: 27 Time: 0.315392
[03/27/2022-19:10:29] [V] [TRT] Tactic: 31 Time: 0.310656
[03/27/2022-19:10:29] [V] [TRT] Fastest Tactic: 24 Time: 0.310144
[03/27/2022-19:10:29] [V] [TRT] --------------- Timing Runner: PWN(Mul_458, PWN(Div_457, Sub_459)) (PointWise)
[03/27/2022-19:10:29] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[03/27/2022-19:10:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:29] [V] [TRT] *************** Autotuning format combination: Float(32,1,1,1), Float(2097152,65536,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:10:29] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_19), Mul_20) (PointWiseV2)
[03/27/2022-19:10:30] [V] [TRT] Tactic: 0 Time: 0.326268
[03/27/2022-19:10:30] [V] [TRT] Tactic: 1 Time: 0.255744
[03/27/2022-19:10:30] [V] [TRT] Tactic: 2 Time: 0.255616
[03/27/2022-19:10:31] [V] [TRT] Tactic: 3 Time: 0.253184
[03/27/2022-19:10:31] [V] [TRT] Tactic: 4 Time: 0.252928
[03/27/2022-19:10:31] [V] [TRT] Tactic: 5 Time: 0.254464
[03/27/2022-19:10:32] [V] [TRT] Tactic: 6 Time: 0.249216
[03/27/2022-19:10:32] [V] [TRT] Tactic: 7 Time: 0.24934
[03/27/2022-19:10:32] [V] [TRT] Tactic: 8 Time: 0.25216
[03/27/2022-19:10:33] [V] [TRT] Tactic: 9 Time: 0.253952
[03/27/2022-19:10:33] [V] [TRT] Tactic: 28 Time: 0.310016
[03/27/2022-19:10:33] [V] [TRT] Fastest Tactic: 6 Time: 0.249216
[03/27/2022-19:10:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_19), Mul_20) (PointWise)
[03/27/2022-19:10:33] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 6
[03/27/2022-19:10:33] [V] [TRT] *************** Autotuning format combination: Float(32,1,32,32), Float(2097152,1,8192,32) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:10:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_19), Mul_20) (PointWiseV2)
[03/27/2022-19:10:33] [V] [TRT] Tactic: 0 Time: 0.822912
[03/27/2022-19:10:34] [V] [TRT] Tactic: 1 Time: 0.824192
[03/27/2022-19:10:34] [V] [TRT] Tactic: 2 Time: 0.82432
[03/27/2022-19:10:34] [V] [TRT] Tactic: 3 Time: 0.82624
[03/27/2022-19:10:34] [V] [TRT] Tactic: 4 Time: 0.826628
[03/27/2022-19:10:35] [V] [TRT] Tactic: 5 Time: 0.825604
[03/27/2022-19:10:35] [V] [TRT] Tactic: 6 Time: 0.827648
[03/27/2022-19:10:35] [V] [TRT] Tactic: 7 Time: 0.918404
[03/27/2022-19:10:36] [V] [TRT] Tactic: 8 Time: 0.828288
[03/27/2022-19:10:36] [V] [TRT] Tactic: 9 Time: 0.82624
[03/27/2022-19:10:36] [V] [TRT] Tactic: 28 Time: 0.8224
[03/27/2022-19:10:36] [V] [TRT] Fastest Tactic: 28 Time: 0.8224
[03/27/2022-19:10:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_19), Mul_20) (PointWise)
[03/27/2022-19:10:36] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:10:36] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1), Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:10:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_19), Mul_20) (PointWiseV2)
[03/27/2022-19:10:37] [V] [TRT] Tactic: 24 Time: 0.240264
[03/27/2022-19:10:37] [V] [TRT] Tactic: 25 Time: 0.239104
[03/27/2022-19:10:37] [V] [TRT] Tactic: 26 Time: 0.235776
[03/27/2022-19:10:38] [V] [TRT] Tactic: 27 Time: 0.233072
[03/27/2022-19:10:38] [V] [TRT] Tactic: 31 Time: 0.240512
[03/27/2022-19:10:38] [V] [TRT] Fastest Tactic: 27 Time: 0.233072
[03/27/2022-19:10:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_19), Mul_20) (PointWise)
[03/27/2022-19:10:38] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[03/27/2022-19:10:38] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:38] [V] [TRT] *************** Autotuning format combination: Float(2097152,65536,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:10:38] [V] [TRT] --------------- Timing Runner: Conv_21 (CudaDepthwiseConvolution)
[03/27/2022-19:10:38] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:38] [V] [TRT] --------------- Timing Runner: Conv_21 (FusedConvActConvolution)
[03/27/2022-19:10:38] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:38] [V] [TRT] --------------- Timing Runner: Conv_21 (CudnnConvolution)
[03/27/2022-19:10:38] [V] [TRT] Tactic: 0 Time: 0.33536
[03/27/2022-19:10:38] [V] [TRT] Tactic: 1 Time: 0.291196
[03/27/2022-19:10:38] [V] [TRT] Tactic: 2 Time: 0.489088
[03/27/2022-19:10:38] [V] [TRT] Tactic: 4 Time: 4.24614
[03/27/2022-19:10:38] [V] [TRT] Tactic: 5 Time: 0.795392
[03/27/2022-19:10:38] [V] [TRT] Fastest Tactic: 1 Time: 0.291196
[03/27/2022-19:10:38] [V] [TRT] --------------- Timing Runner: Conv_21 (CublasConvolution)
[03/27/2022-19:10:38] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:38] [V] [TRT] --------------- Timing Runner: Conv_21 (CaskConvolution)
[03/27/2022-19:10:38] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:38] [V] [TRT] Tactic: 1062367460111450758 Time: 0.16512
[03/27/2022-19:10:38] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:10:38] [V] [TRT] Tactic: 1698681053543049347 Time: 0.164988
[03/27/2022-19:10:38] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:38] [V] [TRT] Tactic: 4501471010995462441 Time: 0.487424
[03/27/2022-19:10:38] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:39] [V] [TRT] Tactic: 5137655947464784826 Time: 0.253824
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:39] [V] [TRT] Tactic: 5288347012147084929 Time: 0.500348
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:10:39] [V] [TRT] Tactic: 5326823351883942011 Time: 0.475396
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:10:39] [V] [TRT] Tactic: 5500448035057547314 Time: 0.268416
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:39] [V] [TRT] Tactic: 6645123197870846056 Time: 0.259584
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:39] [V] [TRT] Tactic: 7144526460361122478 Time: 0.181124
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:39] [V] [TRT] Tactic: -8262349710178828730 Time: 0.505216
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:10:39] [V] [TRT] Tactic: -6576203419454146580 Time: 0.157568
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:39] [V] [TRT] Tactic: -4787320710726427159 Time: 0.182144
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:39] [V] [TRT] Tactic: -3456450830548107839 Time: 0.16064
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:39] [V] [TRT] Tactic: -1218658103698133241 Time: 0.278784
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:39] [V] [TRT] Tactic: -836875257600482091 Time: 0.2752
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:39] [V] [TRT] Tactic: -410470605513481746 Time: 0.480768
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:10:39] [V] [TRT] Tactic: -377491875521947884 Time: 0.491004
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:10:39] [V] [TRT] Tactic: -37215280111360163 Time: 0.252032
[03/27/2022-19:10:39] [V] [TRT] Fastest Tactic: -6576203419454146580 Time: 0.157568
[03/27/2022-19:10:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6576203419454146580
[03/27/2022-19:10:39] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,8192,32) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:10:39] [V] [TRT] --------------- Timing Runner: Conv_21 (CublasConvolution)
[03/27/2022-19:10:39] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:39] [V] [TRT] --------------- Timing Runner: Conv_21 (CaskConvolution)
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:10:39] [V] [TRT] Tactic: 3886731678879822788 Time: 0.31206
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:10:39] [V] [TRT] Tactic: 6629944304117643200 Time: 0.263928
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:10:39] [V] [TRT] Tactic: -9153228964338181824 Time: 0.267776
[03/27/2022-19:10:39] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:10:39] [V] [TRT] Tactic: -7394439838318485025 Time: 0.31232
[03/27/2022-19:10:39] [V] [TRT] Fastest Tactic: 6629944304117643200 Time: 0.263928
[03/27/2022-19:10:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200
[03/27/2022-19:10:39] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:39] [V] [TRT] *************** Autotuning format combination: Float(1048576,65536,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:10:39] [V] [TRT] --------------- Timing Runner: Conv_22 (CudaDepthwiseConvolution)
[03/27/2022-19:10:39] [V] [TRT] Tactic: -1 Time: 0.195584
[03/27/2022-19:10:39] [V] [TRT] Fastest Tactic: -1 Time: 0.195584
[03/27/2022-19:10:39] [V] [TRT] --------------- Timing Runner: Conv_22 (CudnnConvolution)
[03/27/2022-19:10:39] [V] [TRT] Tactic: 0 Time: 0.363388
[03/27/2022-19:10:39] [V] [TRT] Tactic: 1 Time: 0.362496
[03/27/2022-19:10:39] [V] [TRT] Tactic: 2 Time: 1.16454
[03/27/2022-19:10:40] [V] [TRT] Tactic: 5 Time: 47.4321
[03/27/2022-19:10:40] [V] [TRT] Tactic: 6 Time: 10.1422
[03/27/2022-19:10:40] [V] [TRT] Fastest Tactic: 1 Time: 0.362496
[03/27/2022-19:10:40] [V] [TRT] --------------- Timing Runner: Conv_22 (CaskConvolution)
[03/27/2022-19:10:40] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:40] [V] [TRT] Tactic: 1062367460111450758 Time: 1.71085
[03/27/2022-19:10:40] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:10:40] [V] [TRT] Tactic: 1754984623894446479 Time: 1.72314
[03/27/2022-19:10:40] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:10:40] [V] [TRT] Tactic: 3611739942397549984 Time: 6.24179
[03/27/2022-19:10:40] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:10:40] [V] [TRT] Tactic: 3827454225649558724 Time: 3.49965
[03/27/2022-19:10:40] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:10:40] [V] [TRT] Tactic: 4337000649858996379 Time: 3.056
[03/27/2022-19:10:40] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:40] [V] [TRT] Tactic: 4501471010995462441 Time: 5.86278
[03/27/2022-19:10:40] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:40] [V] [TRT] Tactic: 5137655947464784826 Time: 2.94669
[03/27/2022-19:10:40] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:41] [V] [TRT] Tactic: 5288347012147084929 Time: 6.20761
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:10:41] [V] [TRT] Tactic: 5921334924264294896 Time: 3.6297
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:41] [V] [TRT] Tactic: 6645123197870846056 Time: 2.89036
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:41] [V] [TRT] Tactic: 7144526460361122478 Time: 1.58272
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:10:41] [V] [TRT] Tactic: 7852627285308570038 Time: 3.64429
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:10:41] [V] [TRT] Tactic: -9137461792520977713 Time: 5.78419
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:10:41] [V] [TRT] Tactic: -8776506421218919509 Time: 3.38508
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:41] [V] [TRT] Tactic: -8262349710178828730 Time: 6.25101
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:10:41] [V] [TRT] Tactic: -8133971918129952780 Time: 2.85133
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:10:41] [V] [TRT] Tactic: -6092040395344634144 Time: 1.73542
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:41] [V] [TRT] Tactic: -4787320710726427159 Time: 1.71596
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:41] [V] [TRT] Tactic: -3456450830548107839 Time: 1.64748
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:10:41] [V] [TRT] Tactic: -2318106587342035239 Time: 3.64224
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:10:41] [V] [TRT] Tactic: -1343271414618805657 Time: 3.53152
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:41] [V] [TRT] Tactic: -1218658103698133241 Time: 2.84467
[03/27/2022-19:10:41] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:42] [V] [TRT] Tactic: -836875257600482091 Time: 2.82227
[03/27/2022-19:10:42] [V] [TRT] Conv_22 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:42] [V] [TRT] Tactic: -410470605513481746 Time: 5.80378
[03/27/2022-19:10:42] [V] [TRT] Fastest Tactic: 7144526460361122478 Time: 1.58272
[03/27/2022-19:10:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:10:42] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,4096,16) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: Conv_22 (CaskConvolution)
[03/27/2022-19:10:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:42] [V] [TRT] *************** Autotuning format combination: Float(1048576,65536,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_23), Mul_24) (PointWiseV2)
[03/27/2022-19:10:42] [V] [TRT] Tactic: 0 Time: 0.100736
[03/27/2022-19:10:42] [V] [TRT] Tactic: 1 Time: 0.086012
[03/27/2022-19:10:42] [V] [TRT] Tactic: 2 Time: 0.084356
[03/27/2022-19:10:42] [V] [TRT] Tactic: 3 Time: 0.085888
[03/27/2022-19:10:42] [V] [TRT] Tactic: 4 Time: 0.084608
[03/27/2022-19:10:42] [V] [TRT] Tactic: 5 Time: 0.084096
[03/27/2022-19:10:42] [V] [TRT] Tactic: 6 Time: 0.087556
[03/27/2022-19:10:42] [V] [TRT] Tactic: 7 Time: 0.08474
[03/27/2022-19:10:42] [V] [TRT] Tactic: 8 Time: 0.083712
[03/27/2022-19:10:42] [V] [TRT] Tactic: 9 Time: 0.083712
[03/27/2022-19:10:42] [V] [TRT] Tactic: 28 Time: 0.099712
[03/27/2022-19:10:42] [V] [TRT] Fastest Tactic: 8 Time: 0.083712
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_23), Mul_24) (PointWise)
[03/27/2022-19:10:42] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:10:42] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,4096,16) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_23), Mul_24) (PointWiseV2)
[03/27/2022-19:10:42] [V] [TRT] Tactic: 0 Time: 0.101244
[03/27/2022-19:10:42] [V] [TRT] Tactic: 1 Time: 0.085888
[03/27/2022-19:10:42] [V] [TRT] Tactic: 2 Time: 0.084228
[03/27/2022-19:10:42] [V] [TRT] Tactic: 3 Time: 0.085504
[03/27/2022-19:10:42] [V] [TRT] Tactic: 4 Time: 0.084608
[03/27/2022-19:10:42] [V] [TRT] Tactic: 5 Time: 0.08384
[03/27/2022-19:10:42] [V] [TRT] Tactic: 6 Time: 0.08768
[03/27/2022-19:10:42] [V] [TRT] Tactic: 7 Time: 0.084608
[03/27/2022-19:10:42] [V] [TRT] Tactic: 8 Time: 0.083968
[03/27/2022-19:10:42] [V] [TRT] Tactic: 9 Time: 0.084224
[03/27/2022-19:10:42] [V] [TRT] Tactic: 28 Time: 0.099588
[03/27/2022-19:10:42] [V] [TRT] Fastest Tactic: 5 Time: 0.08384
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_23), Mul_24) (PointWise)
[03/27/2022-19:10:42] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:10:42] [V] [TRT] *************** Autotuning format combination: Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_23), Mul_24) (PointWiseV2)
[03/27/2022-19:10:42] [V] [TRT] Tactic: 24 Time: 0.161408
[03/27/2022-19:10:42] [V] [TRT] Tactic: 25 Time: 0.161664
[03/27/2022-19:10:42] [V] [TRT] Tactic: 26 Time: 0.162304
[03/27/2022-19:10:42] [V] [TRT] Tactic: 27 Time: 0.163328
[03/27/2022-19:10:42] [V] [TRT] Tactic: 31 Time: 0.161792
[03/27/2022-19:10:42] [V] [TRT] Fastest Tactic: 24 Time: 0.161408
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_23), Mul_24) (PointWise)
[03/27/2022-19:10:42] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[03/27/2022-19:10:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:42] [V] [TRT] *************** Autotuning format combination: Float(1048576,65536,256,1) -> Float(16,1,1,1) ***************
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: ReduceMean_25 (TiledPooling)
[03/27/2022-19:10:42] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: ReduceMean_25 (CudnnPooling)
[03/27/2022-19:10:42] [V] [TRT] Tactic: -1 Time: 0.09818
[03/27/2022-19:10:42] [V] [TRT] Fastest Tactic: -1 Time: 0.09818
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: ReduceMean_25 (CaskPooling)
[03/27/2022-19:10:42] [V] [TRT] ReduceMean_25 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:10:42] [V] [TRT] Tactic: 6119644359078410246 Time: 0.100992
[03/27/2022-19:10:42] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.100992
[03/27/2022-19:10:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[03/27/2022-19:10:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:42] [V] [TRT] *************** Autotuning format combination: Float(16,1,1,1) -> Float(4,1,1,1) ***************
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: Conv_26 (CudaDepthwiseConvolution)
[03/27/2022-19:10:42] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: Conv_26 (FusedConvActConvolution)
[03/27/2022-19:10:42] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: Conv_26 (CudnnConvolution)
[03/27/2022-19:10:42] [V] [TRT] Tactic: 0 Time: 0.012156
[03/27/2022-19:10:42] [V] [TRT] Tactic: 1 Time: 0.008964
[03/27/2022-19:10:42] [V] [TRT] Tactic: 2 Time: 0.019444
[03/27/2022-19:10:42] [V] [TRT] Tactic: 4 Time: 0.031488
[03/27/2022-19:10:42] [V] [TRT] Tactic: 5 Time: 0.044032
[03/27/2022-19:10:42] [V] [TRT] Fastest Tactic: 1 Time: 0.008964
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: Conv_26 (CublasConvolution)
[03/27/2022-19:10:42] [V] [TRT] Tactic: 0 Time: 0.008704
[03/27/2022-19:10:42] [V] [TRT] Tactic: 1 Time: 0.008576
[03/27/2022-19:10:42] [V] [TRT] Fastest Tactic: 1 Time: 0.008576
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: Conv_26 (CaskConvolution)
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:42] [V] [TRT] Tactic: 1062367460111450758 Time: 0.01382
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:10:42] [V] [TRT] Tactic: 1698681053543049347 Time: 0.010496
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:42] [V] [TRT] Tactic: 4501471010995462441 Time: 0.013696
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:42] [V] [TRT] Tactic: 5137655947464784826 Time: 0.013056
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:42] [V] [TRT] Tactic: 5288347012147084929 Time: 0.01382
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:10:42] [V] [TRT] Tactic: 5326823351883942011 Time: 0.01344
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:10:42] [V] [TRT] Tactic: 5500448035057547314 Time: 0.012416
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:42] [V] [TRT] Tactic: 6645123197870846056 Time: 0.012928
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:42] [V] [TRT] Tactic: 7144526460361122478 Time: 0.010496
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:42] [V] [TRT] Tactic: -8262349710178828730 Time: 0.013692
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:10:42] [V] [TRT] Tactic: -6576203419454146580 Time: 0.01344
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:42] [V] [TRT] Tactic: -4787320710726427159 Time: 0.010368
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:42] [V] [TRT] Tactic: -3456450830548107839 Time: 0.01344
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:42] [V] [TRT] Tactic: -1218658103698133241 Time: 0.012548
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:42] [V] [TRT] Tactic: -836875257600482091 Time: 0.012672
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:42] [V] [TRT] Tactic: -410470605513481746 Time: 0.013568
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:10:42] [V] [TRT] Tactic: -377491875521947884 Time: 0.01382
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:10:42] [V] [TRT] Tactic: -37215280111360163 Time: 0.012672
[03/27/2022-19:10:42] [V] [TRT] Fastest Tactic: -4787320710726427159 Time: 0.010368
[03/27/2022-19:10:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1
[03/27/2022-19:10:42] [V] [TRT] *************** Autotuning format combination: Float(16,1,16,16) -> Float(4,1,4,4) ***************
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: Conv_26 (CublasConvolution)
[03/27/2022-19:10:42] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: Conv_26 (CaskConvolution)
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:10:42] [V] [TRT] Tactic: 3886731678879822788 Time: 0.011264
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:10:42] [V] [TRT] Tactic: 6629944304117643200 Time: 0.01152
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:10:42] [V] [TRT] Tactic: -9153228964338181824 Time: 0.01152
[03/27/2022-19:10:42] [V] [TRT] Conv_26 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:10:42] [V] [TRT] Tactic: -7394439838318485025 Time: 0.01152
[03/27/2022-19:10:42] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.011264
[03/27/2022-19:10:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:10:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:42] [V] [TRT] *************** Autotuning format combination: Float(4,1,1,1) -> Float(4,1,1,1) ***************
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_27), Mul_28) (PointWiseV2)
[03/27/2022-19:10:42] [V] [TRT] Tactic: 0 Time: 0.00576
[03/27/2022-19:10:42] [V] [TRT] Tactic: 1 Time: 0.005508
[03/27/2022-19:10:42] [V] [TRT] Tactic: 2 Time: 0.005628
[03/27/2022-19:10:42] [V] [TRT] Tactic: 3 Time: 0.005888
[03/27/2022-19:10:42] [V] [TRT] Tactic: 4 Time: 0.005888
[03/27/2022-19:10:42] [V] [TRT] Tactic: 5 Time: 0.005764
[03/27/2022-19:10:42] [V] [TRT] Tactic: 6 Time: 0.006016
[03/27/2022-19:10:42] [V] [TRT] Tactic: 7 Time: 0.00614
[03/27/2022-19:10:42] [V] [TRT] Tactic: 8 Time: 0.006144
[03/27/2022-19:10:42] [V] [TRT] Tactic: 9 Time: 0.005504
[03/27/2022-19:10:42] [V] [TRT] Tactic: 28 Time: 0.005764
[03/27/2022-19:10:42] [V] [TRT] Fastest Tactic: 9 Time: 0.005504
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_27), Mul_28) (PointWise)
[03/27/2022-19:10:42] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[03/27/2022-19:10:42] [V] [TRT] *************** Autotuning format combination: Float(4,1,4,4) -> Float(4,1,4,4) ***************
[03/27/2022-19:10:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_27), Mul_28) (PointWiseV2)
[03/27/2022-19:10:42] [V] [TRT] Tactic: 0 Time: 0.00576
[03/27/2022-19:10:42] [V] [TRT] Tactic: 1 Time: 0.005756
[03/27/2022-19:10:42] [V] [TRT] Tactic: 2 Time: 0.006016
[03/27/2022-19:10:42] [V] [TRT] Tactic: 3 Time: 0.005632
[03/27/2022-19:10:43] [V] [TRT] Tactic: 4 Time: 0.005892
[03/27/2022-19:10:43] [V] [TRT] Tactic: 5 Time: 0.005504
[03/27/2022-19:10:43] [V] [TRT] Tactic: 6 Time: 0.006144
[03/27/2022-19:10:43] [V] [TRT] Tactic: 7 Time: 0.006016
[03/27/2022-19:10:43] [V] [TRT] Tactic: 8 Time: 0.005764
[03/27/2022-19:10:43] [V] [TRT] Tactic: 9 Time: 0.005884
[03/27/2022-19:10:43] [V] [TRT] Tactic: 28 Time: 0.005624
[03/27/2022-19:10:43] [V] [TRT] Fastest Tactic: 5 Time: 0.005504
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_27), Mul_28) (PointWise)
[03/27/2022-19:10:43] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:10:43] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_27), Mul_28) (PointWiseV2)
[03/27/2022-19:10:43] [V] [TRT] Tactic: 24 Time: 0.006524
[03/27/2022-19:10:43] [V] [TRT] Tactic: 25 Time: 0.006656
[03/27/2022-19:10:43] [V] [TRT] Tactic: 26 Time: 0.006656
[03/27/2022-19:10:43] [V] [TRT] Tactic: 27 Time: 0.007168
[03/27/2022-19:10:43] [V] [TRT] Tactic: 31 Time: 0.00614
[03/27/2022-19:10:43] [V] [TRT] Fastest Tactic: 31 Time: 0.00614
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_27), Mul_28) (PointWise)
[03/27/2022-19:10:43] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:10:43] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:43] [V] [TRT] *************** Autotuning format combination: Float(4,1,1,1) -> Float(16,1,1,1) ***************
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: Conv_29 (CudaDepthwiseConvolution)
[03/27/2022-19:10:43] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: Conv_29 (FusedConvActConvolution)
[03/27/2022-19:10:43] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: Conv_29 (CudnnConvolution)
[03/27/2022-19:10:43] [V] [TRT] Tactic: 0 Time: 0.010624
[03/27/2022-19:10:43] [V] [TRT] Tactic: 1 Time: 0.009084
[03/27/2022-19:10:43] [V] [TRT] Tactic: 2 Time: 0.014592
[03/27/2022-19:10:43] [V] [TRT] Tactic: 4 Time: 0.03072
[03/27/2022-19:10:43] [V] [TRT] Tactic: 5 Time: 0.044444
[03/27/2022-19:10:43] [V] [TRT] Fastest Tactic: 1 Time: 0.009084
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: Conv_29 (CublasConvolution)
[03/27/2022-19:10:43] [V] [TRT] Tactic: 0 Time: 0.008448
[03/27/2022-19:10:43] [V] [TRT] Tactic: 1 Time: 0.008196
[03/27/2022-19:10:43] [V] [TRT] Fastest Tactic: 1 Time: 0.008196
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: Conv_29 (CaskConvolution)
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:43] [V] [TRT] Tactic: 1062367460111450758 Time: 0.012928
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:10:43] [V] [TRT] Tactic: 1698681053543049347 Time: 0.009856
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:43] [V] [TRT] Tactic: 4501471010995462441 Time: 0.012804
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:43] [V] [TRT] Tactic: 5137655947464784826 Time: 0.012288
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:43] [V] [TRT] Tactic: 5288347012147084929 Time: 0.013056
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:10:43] [V] [TRT] Tactic: 5326823351883942011 Time: 0.012544
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:10:43] [V] [TRT] Tactic: 5500448035057547314 Time: 0.01152
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:43] [V] [TRT] Tactic: 6645123197870846056 Time: 0.012668
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:43] [V] [TRT] Tactic: 7144526460361122478 Time: 0.010112
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:43] [V] [TRT] Tactic: -8262349710178828730 Time: 0.013056
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:10:43] [V] [TRT] Tactic: -6576203419454146580 Time: 0.012928
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:43] [V] [TRT] Tactic: -4787320710726427159 Time: 0.009976
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:43] [V] [TRT] Tactic: -3456450830548107839 Time: 0.012544
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:43] [V] [TRT] Tactic: -1218658103698133241 Time: 0.0119
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:43] [V] [TRT] Tactic: -836875257600482091 Time: 0.011648
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:43] [V] [TRT] Tactic: -410470605513481746 Time: 0.012416
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:10:43] [V] [TRT] Tactic: -377491875521947884 Time: 0.01242
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:10:43] [V] [TRT] Tactic: -37215280111360163 Time: 0.012416
[03/27/2022-19:10:43] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.009856
[03/27/2022-19:10:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1
[03/27/2022-19:10:43] [V] [TRT] *************** Autotuning format combination: Float(4,1,4,4) -> Float(16,1,16,16) ***************
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: Conv_29 (CublasConvolution)
[03/27/2022-19:10:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: Conv_29 (CaskConvolution)
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:10:43] [V] [TRT] Tactic: 3886731678879822788 Time: 0.011132
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:10:43] [V] [TRT] Tactic: 6629944304117643200 Time: 0.011392
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:10:43] [V] [TRT] Tactic: -9153228964338181824 Time: 0.01216
[03/27/2022-19:10:43] [V] [TRT] Conv_29 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:10:43] [V] [TRT] Tactic: -7394439838318485025 Time: 0.01152
[03/27/2022-19:10:43] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.011132
[03/27/2022-19:10:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:10:43] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:43] [V] [TRT] *************** Autotuning format combination: Float(16,1,1,1), Float(1048576,65536,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_30), Mul_31) (PointWiseV2)
[03/27/2022-19:10:43] [V] [TRT] Tactic: 0 Time: 0.167168
[03/27/2022-19:10:43] [V] [TRT] Tactic: 1 Time: 0.132724
[03/27/2022-19:10:43] [V] [TRT] Tactic: 2 Time: 0.132608
[03/27/2022-19:10:43] [V] [TRT] Tactic: 3 Time: 0.13184
[03/27/2022-19:10:43] [V] [TRT] Tactic: 4 Time: 0.131584
[03/27/2022-19:10:43] [V] [TRT] Tactic: 5 Time: 0.131968
[03/27/2022-19:10:43] [V] [TRT] Tactic: 6 Time: 0.131328
[03/27/2022-19:10:43] [V] [TRT] Tactic: 7 Time: 0.131456
[03/27/2022-19:10:43] [V] [TRT] Tactic: 8 Time: 0.1312
[03/27/2022-19:10:43] [V] [TRT] Tactic: 9 Time: 0.1344
[03/27/2022-19:10:43] [V] [TRT] Tactic: 28 Time: 0.159616
[03/27/2022-19:10:43] [V] [TRT] Fastest Tactic: 8 Time: 0.1312
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_30), Mul_31) (PointWise)
[03/27/2022-19:10:43] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:10:43] [V] [TRT] *************** Autotuning format combination: Float(16,1,16,16), Float(1048576,1,4096,16) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_30), Mul_31) (PointWiseV2)
[03/27/2022-19:10:43] [V] [TRT] Tactic: 0 Time: 0.428672
[03/27/2022-19:10:43] [V] [TRT] Tactic: 1 Time: 0.463616
[03/27/2022-19:10:43] [V] [TRT] Tactic: 2 Time: 0.4288
[03/27/2022-19:10:43] [V] [TRT] Tactic: 3 Time: 0.513916
[03/27/2022-19:10:43] [V] [TRT] Tactic: 4 Time: 0.546304
[03/27/2022-19:10:43] [V] [TRT] Tactic: 5 Time: 0.473984
[03/27/2022-19:10:43] [V] [TRT] Tactic: 6 Time: 0.627072
[03/27/2022-19:10:43] [V] [TRT] Tactic: 7 Time: 0.67174
[03/27/2022-19:10:43] [V] [TRT] Tactic: 8 Time: 0.6688
[03/27/2022-19:10:43] [V] [TRT] Tactic: 9 Time: 0.563584
[03/27/2022-19:10:43] [V] [TRT] Tactic: 28 Time: 0.22656
[03/27/2022-19:10:43] [V] [TRT] Fastest Tactic: 28 Time: 0.22656
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_30), Mul_31) (PointWise)
[03/27/2022-19:10:43] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:10:43] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1), Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:10:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_30), Mul_31) (PointWiseV2)
[03/27/2022-19:10:44] [V] [TRT] Tactic: 24 Time: 0.241536
[03/27/2022-19:10:44] [V] [TRT] Tactic: 25 Time: 0.24
[03/27/2022-19:10:45] [V] [TRT] Tactic: 26 Time: 0.2368
[03/27/2022-19:10:46] [V] [TRT] Tactic: 27 Time: 0.23398
[03/27/2022-19:10:46] [V] [TRT] Tactic: 31 Time: 0.241528
[03/27/2022-19:10:46] [V] [TRT] Fastest Tactic: 27 Time: 0.23398
[03/27/2022-19:10:46] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_30), Mul_31) (PointWise)
[03/27/2022-19:10:46] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[03/27/2022-19:10:46] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:46] [V] [TRT] *************** Autotuning format combination: Float(1048576,65536,256,1), Float(1048576,65536,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:10:46] [V] [TRT] --------------- Timing Runner: Conv_32 + Add_33 (CudaDepthwiseConvolution)
[03/27/2022-19:10:46] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:46] [V] [TRT] --------------- Timing Runner: Conv_32 + Add_33 (FusedConvActConvolution)
[03/27/2022-19:10:46] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:46] [V] [TRT] --------------- Timing Runner: Conv_32 + Add_33 (CudnnConvolution)
[03/27/2022-19:10:46] [V] [TRT] Tactic: 0 Time: 0.38694
[03/27/2022-19:10:46] [V] [TRT] Tactic: 1 Time: 0.369408
[03/27/2022-19:10:46] [V] [TRT] Tactic: 2 Time: 0.474368
[03/27/2022-19:10:46] [V] [TRT] Tactic: 4 Time: 2.87411
[03/27/2022-19:10:46] [V] [TRT] Tactic: 5 Time: 0.77952
[03/27/2022-19:10:46] [V] [TRT] Fastest Tactic: 1 Time: 0.369408
[03/27/2022-19:10:46] [V] [TRT] --------------- Timing Runner: Conv_32 + Add_33 (CublasConvolution)
[03/27/2022-19:10:46] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:46] [V] [TRT] --------------- Timing Runner: Conv_32 + Add_33 (CaskConvolution)
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:46] [V] [TRT] Tactic: 1062367460111450758 Time: 0.144384
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:10:46] [V] [TRT] Tactic: 1698681053543049347 Time: 0.139392
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:46] [V] [TRT] Tactic: 4501471010995462441 Time: 0.418688
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:46] [V] [TRT] Tactic: 5137655947464784826 Time: 0.217988
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:46] [V] [TRT] Tactic: 5288347012147084929 Time: 0.43392
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:10:46] [V] [TRT] Tactic: 5326823351883942011 Time: 0.411008
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:10:46] [V] [TRT] Tactic: 5500448035057547314 Time: 0.227584
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:46] [V] [TRT] Tactic: 6645123197870846056 Time: 0.221312
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:46] [V] [TRT] Tactic: 7144526460361122478 Time: 0.152196
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:46] [V] [TRT] Tactic: -8262349710178828730 Time: 0.436228
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:10:46] [V] [TRT] Tactic: -6576203419454146580 Time: 0.140284
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:46] [V] [TRT] Tactic: -4787320710726427159 Time: 0.15296
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:46] [V] [TRT] Tactic: -3456450830548107839 Time: 0.142592
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:46] [V] [TRT] Tactic: -1218658103698133241 Time: 0.233728
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:46] [V] [TRT] Tactic: -836875257600482091 Time: 0.231808
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:46] [V] [TRT] Tactic: -410470605513481746 Time: 0.410748
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:10:46] [V] [TRT] Tactic: -377491875521947884 Time: 0.408192
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:10:46] [V] [TRT] Tactic: -37215280111360163 Time: 0.206972
[03/27/2022-19:10:46] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.139392
[03/27/2022-19:10:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 1698681053543049347
[03/27/2022-19:10:46] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,4096,16), Float(1048576,1,4096,16) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:10:46] [V] [TRT] --------------- Timing Runner: Conv_32 + Add_33 (CublasConvolution)
[03/27/2022-19:10:46] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:46] [V] [TRT] --------------- Timing Runner: Conv_32 + Add_33 (CaskConvolution)
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:10:46] [V] [TRT] Tactic: 3886731678879822788 Time: 0.331776
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:10:46] [V] [TRT] Tactic: 6629944304117643200 Time: 0.331648
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:10:46] [V] [TRT] Tactic: -9153228964338181824 Time: 0.335104
[03/27/2022-19:10:46] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:10:46] [V] [TRT] Tactic: -7394439838318485025 Time: 0.332032
[03/27/2022-19:10:46] [V] [TRT] Fastest Tactic: 6629944304117643200 Time: 0.331648
[03/27/2022-19:10:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200
[03/27/2022-19:10:46] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:46] [V] [TRT] *************** Autotuning format combination: Float(1048576,65536,256,1) -> Float(6291456,65536,256,1) ***************
[03/27/2022-19:10:46] [V] [TRT] --------------- Timing Runner: Conv_34 (CudaDepthwiseConvolution)
[03/27/2022-19:10:46] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:46] [V] [TRT] --------------- Timing Runner: Conv_34 (FusedConvActConvolution)
[03/27/2022-19:10:46] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:46] [V] [TRT] --------------- Timing Runner: Conv_34 (CudnnConvolution)
[03/27/2022-19:10:46] [V] [TRT] Tactic: 0 Time: 1.33427
[03/27/2022-19:10:46] [V] [TRT] Tactic: 1 Time: 1.12896
[03/27/2022-19:10:46] [V] [TRT] Tactic: 2 Time: 1.50822
[03/27/2022-19:10:47] [V] [TRT] Tactic: 4 Time: 11.5026
[03/27/2022-19:10:47] [V] [TRT] Tactic: 5 Time: 2.02509
[03/27/2022-19:10:47] [V] [TRT] Fastest Tactic: 1 Time: 1.12896
[03/27/2022-19:10:47] [V] [TRT] --------------- Timing Runner: Conv_34 (CublasConvolution)
[03/27/2022-19:10:47] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:47] [V] [TRT] --------------- Timing Runner: Conv_34 (CaskConvolution)
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:47] [V] [TRT] Tactic: 1062367460111450758 Time: 0.415996
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:10:47] [V] [TRT] Tactic: 1698681053543049347 Time: 0.426884
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:47] [V] [TRT] Tactic: 4501471010995462441 Time: 0.401152
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:47] [V] [TRT] Tactic: 5137655947464784826 Time: 0.413184
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:47] [V] [TRT] Tactic: 5288347012147084929 Time: 0.414976
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:10:47] [V] [TRT] Tactic: 5326823351883942011 Time: 0.406144
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:10:47] [V] [TRT] Tactic: 5500448035057547314 Time: 0.450048
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:47] [V] [TRT] Tactic: 6645123197870846056 Time: 0.4256
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:47] [V] [TRT] Tactic: 7144526460361122478 Time: 0.462596
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:47] [V] [TRT] Tactic: -8262349710178828730 Time: 0.445948
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:10:47] [V] [TRT] Tactic: -6576203419454146580 Time: 0.403836
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:47] [V] [TRT] Tactic: -4787320710726427159 Time: 0.466432
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:47] [V] [TRT] Tactic: -3456450830548107839 Time: 0.411392
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:47] [V] [TRT] Tactic: -1218658103698133241 Time: 0.459648
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:47] [V] [TRT] Tactic: -836875257600482091 Time: 0.460284
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:47] [V] [TRT] Tactic: -410470605513481746 Time: 0.424576
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:10:47] [V] [TRT] Tactic: -377491875521947884 Time: 0.433412
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:10:47] [V] [TRT] Tactic: -37215280111360163 Time: 0.417408
[03/27/2022-19:10:47] [V] [TRT] Fastest Tactic: 4501471010995462441 Time: 0.401152
[03/27/2022-19:10:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4501471010995462441
[03/27/2022-19:10:47] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,4096,16) -> Float(6291456,1,24576,96) ***************
[03/27/2022-19:10:47] [V] [TRT] --------------- Timing Runner: Conv_34 (CublasConvolution)
[03/27/2022-19:10:47] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:47] [V] [TRT] --------------- Timing Runner: Conv_34 (CaskConvolution)
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:10:47] [V] [TRT] Tactic: 3886731678879822788 Time: 0.52634
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:10:47] [V] [TRT] Tactic: 6629944304117643200 Time: 0.781828
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:10:47] [V] [TRT] Tactic: -9153228964338181824 Time: 0.773372
[03/27/2022-19:10:47] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:10:47] [V] [TRT] Tactic: -7394439838318485025 Time: 0.52684
[03/27/2022-19:10:47] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.52634
[03/27/2022-19:10:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:10:47] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:47] [V] [TRT] *************** Autotuning format combination: Float(6291456,65536,256,1) -> Float(6291456,65536,256,1) ***************
[03/27/2022-19:10:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_35), Mul_36) (PointWiseV2)
[03/27/2022-19:10:47] [V] [TRT] Tactic: 0 Time: 0.561796
[03/27/2022-19:10:47] [V] [TRT] Tactic: 1 Time: 0.47232
[03/27/2022-19:10:47] [V] [TRT] Tactic: 2 Time: 0.467452
[03/27/2022-19:10:47] [V] [TRT] Tactic: 3 Time: 0.471808
[03/27/2022-19:10:47] [V] [TRT] Tactic: 4 Time: 0.468984
[03/27/2022-19:10:47] [V] [TRT] Tactic: 5 Time: 0.467708
[03/27/2022-19:10:47] [V] [TRT] Tactic: 6 Time: 0.481924
[03/27/2022-19:10:47] [V] [TRT] Tactic: 7 Time: 0.47014
[03/27/2022-19:10:47] [V] [TRT] Tactic: 8 Time: 0.469376
[03/27/2022-19:10:47] [V] [TRT] Tactic: 9 Time: 0.468864
[03/27/2022-19:10:47] [V] [TRT] Tactic: 28 Time: 0.557936
[03/27/2022-19:10:47] [V] [TRT] Fastest Tactic: 2 Time: 0.467452
[03/27/2022-19:10:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_35), Mul_36) (PointWise)
[03/27/2022-19:10:47] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:10:47] [V] [TRT] *************** Autotuning format combination: Float(6291456,1,24576,96) -> Float(6291456,1,24576,96) ***************
[03/27/2022-19:10:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_35), Mul_36) (PointWiseV2)
[03/27/2022-19:10:47] [V] [TRT] Tactic: 0 Time: 0.56128
[03/27/2022-19:10:47] [V] [TRT] Tactic: 1 Time: 0.471808
[03/27/2022-19:10:48] [V] [TRT] Tactic: 2 Time: 0.466696
[03/27/2022-19:10:48] [V] [TRT] Tactic: 3 Time: 0.472576
[03/27/2022-19:10:48] [V] [TRT] Tactic: 4 Time: 0.468988
[03/27/2022-19:10:48] [V] [TRT] Tactic: 5 Time: 0.467576
[03/27/2022-19:10:48] [V] [TRT] Tactic: 6 Time: 0.481536
[03/27/2022-19:10:48] [V] [TRT] Tactic: 7 Time: 0.469888
[03/27/2022-19:10:48] [V] [TRT] Tactic: 8 Time: 0.468864
[03/27/2022-19:10:48] [V] [TRT] Tactic: 9 Time: 0.468352
[03/27/2022-19:10:48] [V] [TRT] Tactic: 28 Time: 0.557568
[03/27/2022-19:10:48] [V] [TRT] Fastest Tactic: 2 Time: 0.466696
[03/27/2022-19:10:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_35), Mul_36) (PointWise)
[03/27/2022-19:10:48] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:10:48] [V] [TRT] *************** Autotuning format combination: Float(196608,65536:32,256,1) -> Float(196608,65536:32,256,1) ***************
[03/27/2022-19:10:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_35), Mul_36) (PointWiseV2)
[03/27/2022-19:10:48] [V] [TRT] Tactic: 24 Time: 0.469636
[03/27/2022-19:10:48] [V] [TRT] Tactic: 25 Time: 0.469888
[03/27/2022-19:10:48] [V] [TRT] Tactic: 26 Time: 0.470912
[03/27/2022-19:10:48] [V] [TRT] Tactic: 27 Time: 0.47296
[03/27/2022-19:10:48] [V] [TRT] Tactic: 31 Time: 0.467584
[03/27/2022-19:10:48] [V] [TRT] Fastest Tactic: 31 Time: 0.467584
[03/27/2022-19:10:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_35), Mul_36) (PointWise)
[03/27/2022-19:10:48] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:10:48] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:48] [V] [TRT] *************** Autotuning format combination: Float(6291456,65536,256,1) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:10:48] [V] [TRT] --------------- Timing Runner: Conv_37 (CudaDepthwiseConvolution)
[03/27/2022-19:10:48] [V] [TRT] Tactic: -1 Time: 0.4558
[03/27/2022-19:10:48] [V] [TRT] Fastest Tactic: -1 Time: 0.4558
[03/27/2022-19:10:48] [V] [TRT] --------------- Timing Runner: Conv_37 (CudnnConvolution)
[03/27/2022-19:10:48] [V] [TRT] Tactic: 0 Time: 1.85907
[03/27/2022-19:10:48] [V] [TRT] Tactic: 1 Time: 1.85805
[03/27/2022-19:10:48] [V] [TRT] Tactic: 2 Time: 1.8592
[03/27/2022-19:10:53] [V] [TRT] Tactic: 5 Time: 295.173
[03/27/2022-19:10:53] [V] [TRT] Fastest Tactic: 1 Time: 1.85805
[03/27/2022-19:10:53] [V] [TRT] --------------- Timing Runner: Conv_37 (CaskConvolution)
[03/27/2022-19:10:53] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:54] [V] [TRT] Tactic: 1062367460111450758 Time: 3.64416
[03/27/2022-19:10:54] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:10:54] [V] [TRT] Tactic: 1754984623894446479 Time: 2.99366
[03/27/2022-19:10:54] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:10:54] [V] [TRT] Tactic: 3611739942397549984 Time: 9.9456
[03/27/2022-19:10:54] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:10:54] [V] [TRT] Tactic: 4337000649858996379 Time: 5.10234
[03/27/2022-19:10:54] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:54] [V] [TRT] Tactic: 4501471010995462441 Time: 9.35603
[03/27/2022-19:10:54] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:54] [V] [TRT] Tactic: 5137655947464784826 Time: 4.91942
[03/27/2022-19:10:54] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:54] [V] [TRT] Tactic: 5288347012147084929 Time: 9.92
[03/27/2022-19:10:54] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:54] [V] [TRT] Tactic: 6645123197870846056 Time: 5.01606
[03/27/2022-19:10:54] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:55] [V] [TRT] Tactic: 7144526460361122478 Time: 3.03642
[03/27/2022-19:10:55] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:10:55] [V] [TRT] Tactic: -9137461792520977713 Time: 9.47136
[03/27/2022-19:10:55] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:55] [V] [TRT] Tactic: -8262349710178828730 Time: 9.95878
[03/27/2022-19:10:55] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:10:55] [V] [TRT] Tactic: -8133971918129952780 Time: 4.85363
[03/27/2022-19:10:55] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:10:55] [V] [TRT] Tactic: -6092040395344634144 Time: 3.32941
[03/27/2022-19:10:55] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:55] [V] [TRT] Tactic: -4787320710726427159 Time: 2.99162
[03/27/2022-19:10:55] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:55] [V] [TRT] Tactic: -3456450830548107839 Time: 4.99763
[03/27/2022-19:10:55] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:56] [V] [TRT] Tactic: -1218658103698133241 Time: 4.68211
[03/27/2022-19:10:56] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:56] [V] [TRT] Tactic: -836875257600482091 Time: 4.77068
[03/27/2022-19:10:56] [V] [TRT] Conv_37 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:56] [V] [TRT] Tactic: -410470605513481746 Time: 9.28756
[03/27/2022-19:10:56] [V] [TRT] Fastest Tactic: -4787320710726427159 Time: 2.99162
[03/27/2022-19:10:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:10:56] [V] [TRT] *************** Autotuning format combination: Float(6291456,1,24576,96) -> Float(1572864,1,12288,96) ***************
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: Conv_37 (CaskConvolution)
[03/27/2022-19:10:56] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:56] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:56] [V] [TRT] *************** Autotuning format combination: Float(1572864,16384,128,1) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_38), Mul_39) (PointWiseV2)
[03/27/2022-19:10:56] [V] [TRT] Tactic: 0 Time: 0.146304
[03/27/2022-19:10:56] [V] [TRT] Tactic: 1 Time: 0.124288
[03/27/2022-19:10:56] [V] [TRT] Tactic: 2 Time: 0.120704
[03/27/2022-19:10:56] [V] [TRT] Tactic: 3 Time: 0.122104
[03/27/2022-19:10:56] [V] [TRT] Tactic: 4 Time: 0.1216
[03/27/2022-19:10:56] [V] [TRT] Tactic: 5 Time: 0.121064
[03/27/2022-19:10:56] [V] [TRT] Tactic: 6 Time: 0.124032
[03/27/2022-19:10:56] [V] [TRT] Tactic: 7 Time: 0.120964
[03/27/2022-19:10:56] [V] [TRT] Tactic: 8 Time: 0.12096
[03/27/2022-19:10:56] [V] [TRT] Tactic: 9 Time: 0.12224
[03/27/2022-19:10:56] [V] [TRT] Tactic: 28 Time: 0.14528
[03/27/2022-19:10:56] [V] [TRT] Fastest Tactic: 2 Time: 0.120704
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_38), Mul_39) (PointWise)
[03/27/2022-19:10:56] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:10:56] [V] [TRT] *************** Autotuning format combination: Float(1572864,1,12288,96) -> Float(1572864,1,12288,96) ***************
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_38), Mul_39) (PointWiseV2)
[03/27/2022-19:10:56] [V] [TRT] Tactic: 0 Time: 0.146304
[03/27/2022-19:10:56] [V] [TRT] Tactic: 1 Time: 0.12454
[03/27/2022-19:10:56] [V] [TRT] Tactic: 2 Time: 0.12288
[03/27/2022-19:10:56] [V] [TRT] Tactic: 3 Time: 0.123648
[03/27/2022-19:10:56] [V] [TRT] Tactic: 4 Time: 0.122624
[03/27/2022-19:10:56] [V] [TRT] Tactic: 5 Time: 0.122108
[03/27/2022-19:10:56] [V] [TRT] Tactic: 6 Time: 0.12646
[03/27/2022-19:10:56] [V] [TRT] Tactic: 7 Time: 0.123008
[03/27/2022-19:10:56] [V] [TRT] Tactic: 8 Time: 0.122236
[03/27/2022-19:10:56] [V] [TRT] Tactic: 9 Time: 0.122748
[03/27/2022-19:10:56] [V] [TRT] Tactic: 28 Time: 0.145536
[03/27/2022-19:10:56] [V] [TRT] Fastest Tactic: 5 Time: 0.122108
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_38), Mul_39) (PointWise)
[03/27/2022-19:10:56] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:10:56] [V] [TRT] *************** Autotuning format combination: Float(49152,16384:32,128,1) -> Float(49152,16384:32,128,1) ***************
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_38), Mul_39) (PointWiseV2)
[03/27/2022-19:10:56] [V] [TRT] Tactic: 24 Time: 0.121984
[03/27/2022-19:10:56] [V] [TRT] Tactic: 25 Time: 0.121984
[03/27/2022-19:10:56] [V] [TRT] Tactic: 26 Time: 0.123264
[03/27/2022-19:10:56] [V] [TRT] Tactic: 27 Time: 0.124416
[03/27/2022-19:10:56] [V] [TRT] Tactic: 31 Time: 0.121472
[03/27/2022-19:10:56] [V] [TRT] Fastest Tactic: 31 Time: 0.121472
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_38), Mul_39) (PointWise)
[03/27/2022-19:10:56] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:10:56] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:56] [V] [TRT] *************** Autotuning format combination: Float(1572864,16384,128,1) -> Float(96,1,1,1) ***************
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: ReduceMean_40 (TiledPooling)
[03/27/2022-19:10:56] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: ReduceMean_40 (CudnnPooling)
[03/27/2022-19:10:56] [V] [TRT] Tactic: -1 Time: 0.075644
[03/27/2022-19:10:56] [V] [TRT] Fastest Tactic: -1 Time: 0.075644
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: ReduceMean_40 (CaskPooling)
[03/27/2022-19:10:56] [V] [TRT] ReduceMean_40 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:10:56] [V] [TRT] Tactic: 6119644359078410246 Time: 0.077048
[03/27/2022-19:10:56] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.077048
[03/27/2022-19:10:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[03/27/2022-19:10:56] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:56] [V] [TRT] *************** Autotuning format combination: Float(96,1,1,1) -> Float(4,1,1,1) ***************
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: Conv_41 (CudaDepthwiseConvolution)
[03/27/2022-19:10:56] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: Conv_41 (FusedConvActConvolution)
[03/27/2022-19:10:56] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: Conv_41 (CudnnConvolution)
[03/27/2022-19:10:56] [V] [TRT] Tactic: 0 Time: 0.048624
[03/27/2022-19:10:56] [V] [TRT] Tactic: 1 Time: 0.009344
[03/27/2022-19:10:56] [V] [TRT] Tactic: 2 Time: 0.05184
[03/27/2022-19:10:56] [V] [TRT] Tactic: 4 Time: 0.044288
[03/27/2022-19:10:56] [V] [TRT] Tactic: 5 Time: 0.050056
[03/27/2022-19:10:56] [V] [TRT] Fastest Tactic: 1 Time: 0.009344
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: Conv_41 (CublasConvolution)
[03/27/2022-19:10:56] [V] [TRT] Tactic: 0 Time: 0.009472
[03/27/2022-19:10:56] [V] [TRT] Tactic: 1 Time: 0.009216
[03/27/2022-19:10:56] [V] [TRT] Fastest Tactic: 1 Time: 0.009216
[03/27/2022-19:10:56] [V] [TRT] --------------- Timing Runner: Conv_41 (CaskConvolution)
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:56] [V] [TRT] Tactic: 1062367460111450758 Time: 0.021116
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:10:56] [V] [TRT] Tactic: 1698681053543049347 Time: 0.016
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:56] [V] [TRT] Tactic: 4501471010995462441 Time: 0.022784
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:56] [V] [TRT] Tactic: 5137655947464784826 Time: 0.018688
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:56] [V] [TRT] Tactic: 5288347012147084929 Time: 0.022396
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:10:56] [V] [TRT] Tactic: 5326823351883942011 Time: 0.022016
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:10:56] [V] [TRT] Tactic: 5500448035057547314 Time: 0.020096
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:56] [V] [TRT] Tactic: 6645123197870846056 Time: 0.019712
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:56] [V] [TRT] Tactic: 7144526460361122478 Time: 0.016768
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:56] [V] [TRT] Tactic: -8262349710178828730 Time: 0.022528
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:10:56] [V] [TRT] Tactic: -6576203419454146580 Time: 0.019716
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:56] [V] [TRT] Tactic: -4787320710726427159 Time: 0.01728
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:56] [V] [TRT] Tactic: -3456450830548107839 Time: 0.01984
[03/27/2022-19:10:56] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:57] [V] [TRT] Tactic: -1218658103698133241 Time: 0.020992
[03/27/2022-19:10:57] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:57] [V] [TRT] Tactic: -836875257600482091 Time: 0.020608
[03/27/2022-19:10:57] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:57] [V] [TRT] Tactic: -410470605513481746 Time: 0.02202
[03/27/2022-19:10:57] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:10:57] [V] [TRT] Tactic: -377491875521947884 Time: 0.022144
[03/27/2022-19:10:57] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:10:57] [V] [TRT] Tactic: -37215280111360163 Time: 0.018304
[03/27/2022-19:10:57] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.016
[03/27/2022-19:10:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1
[03/27/2022-19:10:57] [V] [TRT] *************** Autotuning format combination: Float(96,1,96,96) -> Float(4,1,4,4) ***************
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: Conv_41 (CublasConvolution)
[03/27/2022-19:10:57] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: Conv_41 (CaskConvolution)
[03/27/2022-19:10:57] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:10:57] [V] [TRT] Tactic: 3886731678879822788 Time: 0.015616
[03/27/2022-19:10:57] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:10:57] [V] [TRT] Tactic: 6629944304117643200 Time: 0.013564
[03/27/2022-19:10:57] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:10:57] [V] [TRT] Tactic: -9153228964338181824 Time: 0.013316
[03/27/2022-19:10:57] [V] [TRT] Conv_41 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:10:57] [V] [TRT] Tactic: -7394439838318485025 Time: 0.016
[03/27/2022-19:10:57] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.013316
[03/27/2022-19:10:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:10:57] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:57] [V] [TRT] *************** Autotuning format combination: Float(4,1,1,1) -> Float(4,1,1,1) ***************
[03/27/2022-19:10:57] [V] [TRT] *************** Autotuning format combination: Float(4,1,4,4) -> Float(4,1,4,4) ***************
[03/27/2022-19:10:57] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:10:57] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:57] [V] [TRT] *************** Autotuning format combination: Float(4,1,1,1) -> Float(96,1,1,1) ***************
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: Conv_44 (CudaDepthwiseConvolution)
[03/27/2022-19:10:57] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: Conv_44 (FusedConvActConvolution)
[03/27/2022-19:10:57] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: Conv_44 (CudnnConvolution)
[03/27/2022-19:10:57] [V] [TRT] Tactic: 0 Time: 0.015872
[03/27/2022-19:10:57] [V] [TRT] Tactic: 1 Time: 0.0224
[03/27/2022-19:10:57] [V] [TRT] Tactic: 2 Time: 0.056832
[03/27/2022-19:10:57] [V] [TRT] Tactic: 4 Time: 0.134404
[03/27/2022-19:10:57] [V] [TRT] Tactic: 5 Time: 0.205828
[03/27/2022-19:10:57] [V] [TRT] Fastest Tactic: 0 Time: 0.015872
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: Conv_44 (CublasConvolution)
[03/27/2022-19:10:57] [V] [TRT] Tactic: 0 Time: 0.009088
[03/27/2022-19:10:57] [V] [TRT] Tactic: 1 Time: 0.204032
[03/27/2022-19:10:57] [V] [TRT] Fastest Tactic: 0 Time: 0.009088
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: Conv_44 (CaskConvolution)
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:57] [V] [TRT] Tactic: 1062367460111450758 Time: 0.060668
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:10:57] [V] [TRT] Tactic: 1698681053543049347 Time: 0.05056
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:57] [V] [TRT] Tactic: 4501471010995462441 Time: 0.026884
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:57] [V] [TRT] Tactic: 5137655947464784826 Time: 0.013436
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:57] [V] [TRT] Tactic: 5288347012147084929 Time: 0.012928
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:10:57] [V] [TRT] Tactic: 5326823351883942011 Time: 0.018552
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:10:57] [V] [TRT] Tactic: 5500448035057547314 Time: 0.013312
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:57] [V] [TRT] Tactic: 6645123197870846056 Time: 0.111364
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:57] [V] [TRT] Tactic: 7144526460361122478 Time: 0.03686
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:57] [V] [TRT] Tactic: -8262349710178828730 Time: 0.0407
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:10:57] [V] [TRT] Tactic: -6576203419454146580 Time: 0.023552
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:57] [V] [TRT] Tactic: -4787320710726427159 Time: 0.009596
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:57] [V] [TRT] Tactic: -3456450830548107839 Time: 0.013056
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:57] [V] [TRT] Tactic: -1218658103698133241 Time: 0.012924
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:57] [V] [TRT] Tactic: -836875257600482091 Time: 0.011396
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:57] [V] [TRT] Tactic: -410470605513481746 Time: 0.0128
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:10:57] [V] [TRT] Tactic: -377491875521947884 Time: 0.012672
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:10:57] [V] [TRT] Tactic: -37215280111360163 Time: 0.012416
[03/27/2022-19:10:57] [V] [TRT] Fastest Tactic: -4787320710726427159 Time: 0.009596
[03/27/2022-19:10:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0
[03/27/2022-19:10:57] [V] [TRT] *************** Autotuning format combination: Float(4,1,4,4) -> Float(96,1,96,96) ***************
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: Conv_44 (CublasConvolution)
[03/27/2022-19:10:57] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: Conv_44 (CaskConvolution)
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:10:57] [V] [TRT] Tactic: 3886731678879822788 Time: 0.011392
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:10:57] [V] [TRT] Tactic: 6629944304117643200 Time: 0.011652
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:10:57] [V] [TRT] Tactic: -9153228964338181824 Time: 0.011784
[03/27/2022-19:10:57] [V] [TRT] Conv_44 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:10:57] [V] [TRT] Tactic: -7394439838318485025 Time: 0.011396
[03/27/2022-19:10:57] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.011392
[03/27/2022-19:10:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:10:57] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:57] [V] [TRT] *************** Autotuning format combination: Float(96,1,1,1), Float(1572864,16384,128,1) -> Float(1572864,16384,128,1) ***************
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_45), Mul_46) (PointWiseV2)
[03/27/2022-19:10:57] [V] [TRT] Tactic: 0 Time: 0.246788
[03/27/2022-19:10:57] [V] [TRT] Tactic: 1 Time: 0.18944
[03/27/2022-19:10:57] [V] [TRT] Tactic: 2 Time: 0.189696
[03/27/2022-19:10:57] [V] [TRT] Tactic: 3 Time: 0.182144
[03/27/2022-19:10:57] [V] [TRT] Tactic: 4 Time: 0.181376
[03/27/2022-19:10:57] [V] [TRT] Tactic: 5 Time: 0.18406
[03/27/2022-19:10:57] [V] [TRT] Tactic: 6 Time: 0.18522
[03/27/2022-19:10:57] [V] [TRT] Tactic: 7 Time: 0.18752
[03/27/2022-19:10:57] [V] [TRT] Tactic: 8 Time: 0.191984
[03/27/2022-19:10:57] [V] [TRT] Tactic: 9 Time: 0.189952
[03/27/2022-19:10:57] [V] [TRT] Tactic: 28 Time: 0.23552
[03/27/2022-19:10:57] [V] [TRT] Fastest Tactic: 4 Time: 0.181376
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_45), Mul_46) (PointWise)
[03/27/2022-19:10:57] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 4
[03/27/2022-19:10:57] [V] [TRT] *************** Autotuning format combination: Float(96,1,96,96), Float(1572864,1,12288,96) -> Float(1572864,1,12288,96) ***************
[03/27/2022-19:10:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_45), Mul_46) (PointWiseV2)
[03/27/2022-19:10:57] [V] [TRT] Tactic: 0 Time: 0.4224
[03/27/2022-19:10:57] [V] [TRT] Tactic: 1 Time: 0.421504
[03/27/2022-19:10:57] [V] [TRT] Tactic: 2 Time: 0.421632
[03/27/2022-19:10:57] [V] [TRT] Tactic: 3 Time: 0.418688
[03/27/2022-19:10:57] [V] [TRT] Tactic: 4 Time: 0.4192
[03/27/2022-19:10:57] [V] [TRT] Tactic: 5 Time: 0.42074
[03/27/2022-19:10:57] [V] [TRT] Tactic: 6 Time: 0.420484
[03/27/2022-19:10:57] [V] [TRT] Tactic: 7 Time: 0.426112
[03/27/2022-19:10:57] [V] [TRT] Tactic: 8 Time: 0.423556
[03/27/2022-19:10:58] [V] [TRT] Tactic: 9 Time: 0.42304
[03/27/2022-19:10:58] [V] [TRT] Tactic: 28 Time: 0.422148
[03/27/2022-19:10:58] [V] [TRT] Fastest Tactic: 3 Time: 0.418688
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_45), Mul_46) (PointWise)
[03/27/2022-19:10:58] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 3
[03/27/2022-19:10:58] [V] [TRT] *************** Autotuning format combination: Float(3,1:32,1,1), Float(49152,16384:32,128,1) -> Float(49152,16384:32,128,1) ***************
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_45), Mul_46) (PointWiseV2)
[03/27/2022-19:10:58] [V] [TRT] Tactic: 24 Time: 0.174592
[03/27/2022-19:10:58] [V] [TRT] Tactic: 25 Time: 0.16896
[03/27/2022-19:10:58] [V] [TRT] Tactic: 26 Time: 0.159228
[03/27/2022-19:10:58] [V] [TRT] Tactic: 27 Time: 0.1376
[03/27/2022-19:10:58] [V] [TRT] Tactic: 31 Time: 0.174464
[03/27/2022-19:10:58] [V] [TRT] Fastest Tactic: 27 Time: 0.1376
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_45), Mul_46) (PointWise)
[03/27/2022-19:10:58] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[03/27/2022-19:10:58] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:58] [V] [TRT] *************** Autotuning format combination: Float(1572864,16384,128,1) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_47 (CudaDepthwiseConvolution)
[03/27/2022-19:10:58] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_47 (FusedConvActConvolution)
[03/27/2022-19:10:58] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_47 (CudnnConvolution)
[03/27/2022-19:10:58] [V] [TRT] Tactic: 0 Time: 0.182144
[03/27/2022-19:10:58] [V] [TRT] Tactic: 1 Time: 0.223488
[03/27/2022-19:10:58] [V] [TRT] Tactic: 2 Time: 0.324348
[03/27/2022-19:10:58] [V] [TRT] Tactic: 4 Time: 3.52064
[03/27/2022-19:10:58] [V] [TRT] Tactic: 5 Time: 0.424832
[03/27/2022-19:10:58] [V] [TRT] Fastest Tactic: 0 Time: 0.182144
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_47 (CublasConvolution)
[03/27/2022-19:10:58] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_47 (CaskConvolution)
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:58] [V] [TRT] Tactic: 1062367460111450758 Time: 0.106368
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:10:58] [V] [TRT] Tactic: 1698681053543049347 Time: 0.09728
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:58] [V] [TRT] Tactic: 4501471010995462441 Time: 0.252544
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:58] [V] [TRT] Tactic: 5137655947464784826 Time: 0.137344
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:58] [V] [TRT] Tactic: 5288347012147084929 Time: 0.253696
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:10:58] [V] [TRT] Tactic: 5326823351883942011 Time: 0.2455
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:10:58] [V] [TRT] Tactic: 5500448035057547314 Time: 0.148352
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:58] [V] [TRT] Tactic: 6645123197870846056 Time: 0.1408
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:58] [V] [TRT] Tactic: 7144526460361122478 Time: 0.108544
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:58] [V] [TRT] Tactic: -8262349710178828730 Time: 0.256896
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:10:58] [V] [TRT] Tactic: -6576203419454146580 Time: 0.102396
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:58] [V] [TRT] Tactic: -4787320710726427159 Time: 0.109944
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:58] [V] [TRT] Tactic: -3456450830548107839 Time: 0.104704
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:58] [V] [TRT] Tactic: -1218658103698133241 Time: 0.155008
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:58] [V] [TRT] Tactic: -836875257600482091 Time: 0.153344
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:58] [V] [TRT] Tactic: -410470605513481746 Time: 0.247424
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:10:58] [V] [TRT] Tactic: -377491875521947884 Time: 0.249088
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:10:58] [V] [TRT] Tactic: -37215280111360163 Time: 0.136064
[03/27/2022-19:10:58] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.09728
[03/27/2022-19:10:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 1698681053543049347
[03/27/2022-19:10:58] [V] [TRT] *************** Autotuning format combination: Float(1572864,1,12288,96) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_47 (CublasConvolution)
[03/27/2022-19:10:58] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_47 (CaskConvolution)
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:10:58] [V] [TRT] Tactic: 3886731678879822788 Time: 0.146812
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:10:58] [V] [TRT] Tactic: 6629944304117643200 Time: 0.11354
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:10:58] [V] [TRT] Tactic: -9153228964338181824 Time: 0.113792
[03/27/2022-19:10:58] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:10:58] [V] [TRT] Tactic: -7394439838318485025 Time: 0.146176
[03/27/2022-19:10:58] [V] [TRT] Fastest Tactic: 6629944304117643200 Time: 0.11354
[03/27/2022-19:10:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200
[03/27/2022-19:10:58] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:58] [V] [TRT] *************** Autotuning format combination: Float(393216,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_48 (CudaDepthwiseConvolution)
[03/27/2022-19:10:58] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_48 (FusedConvActConvolution)
[03/27/2022-19:10:58] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_48 (CudnnConvolution)
[03/27/2022-19:10:58] [V] [TRT] Tactic: 0 Time: 0.548736
[03/27/2022-19:10:58] [V] [TRT] Tactic: 1 Time: 0.5248
[03/27/2022-19:10:58] [V] [TRT] Tactic: 2 Time: 0.60096
[03/27/2022-19:10:58] [V] [TRT] Tactic: 4 Time: 5.6521
[03/27/2022-19:10:58] [V] [TRT] Tactic: 5 Time: 0.759684
[03/27/2022-19:10:58] [V] [TRT] Fastest Tactic: 1 Time: 0.5248
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_48 (CublasConvolution)
[03/27/2022-19:10:58] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_48 (CaskConvolution)
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:10:58] [V] [TRT] Tactic: 1062367460111450758 Time: 0.203648
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:10:58] [V] [TRT] Tactic: 1698681053543049347 Time: 0.205568
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:10:58] [V] [TRT] Tactic: 4501471010995462441 Time: 0.244868
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:10:58] [V] [TRT] Tactic: 5137655947464784826 Time: 0.197884
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:10:58] [V] [TRT] Tactic: 5288347012147084929 Time: 0.251648
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:10:58] [V] [TRT] Tactic: 5326823351883942011 Time: 0.23936
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:10:58] [V] [TRT] Tactic: 5500448035057547314 Time: 0.2048
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:10:58] [V] [TRT] Tactic: 6645123197870846056 Time: 0.198916
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:10:58] [V] [TRT] Tactic: 7144526460361122478 Time: 0.22208
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:10:58] [V] [TRT] Tactic: -8262349710178828730 Time: 0.255104
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:10:58] [V] [TRT] Tactic: -6576203419454146580 Time: 0.194176
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:10:58] [V] [TRT] Tactic: -4787320710726427159 Time: 0.215936
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:10:58] [V] [TRT] Tactic: -3456450830548107839 Time: 0.195456
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:10:58] [V] [TRT] Tactic: -1218658103698133241 Time: 0.203904
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:10:58] [V] [TRT] Tactic: -836875257600482091 Time: 0.202368
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:10:58] [V] [TRT] Tactic: -410470605513481746 Time: 0.234492
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:10:58] [V] [TRT] Tactic: -377491875521947884 Time: 0.241408
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:10:58] [V] [TRT] Tactic: -37215280111360163 Time: 0.189696
[03/27/2022-19:10:58] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.189696
[03/27/2022-19:10:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[03/27/2022-19:10:58] [V] [TRT] *************** Autotuning format combination: Float(393216,1,3072,24) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_48 (CublasConvolution)
[03/27/2022-19:10:58] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: Conv_48 (CaskConvolution)
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:10:58] [V] [TRT] Tactic: 3886731678879822788 Time: 0.238208
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:10:58] [V] [TRT] Tactic: 6629944304117643200 Time: 0.31872
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:10:58] [V] [TRT] Tactic: -9153228964338181824 Time: 0.32114
[03/27/2022-19:10:58] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:10:58] [V] [TRT] Tactic: -7394439838318485025 Time: 0.235644
[03/27/2022-19:10:58] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.235644
[03/27/2022-19:10:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[03/27/2022-19:10:58] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:58] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:10:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_49), Mul_50) (PointWiseV2)
[03/27/2022-19:10:58] [V] [TRT] Tactic: 0 Time: 0.207104
[03/27/2022-19:10:58] [V] [TRT] Tactic: 1 Time: 0.178816
[03/27/2022-19:10:58] [V] [TRT] Tactic: 2 Time: 0.177408
[03/27/2022-19:10:58] [V] [TRT] Tactic: 3 Time: 0.18176
[03/27/2022-19:10:59] [V] [TRT] Tactic: 4 Time: 0.180736
[03/27/2022-19:10:59] [V] [TRT] Tactic: 5 Time: 0.178812
[03/27/2022-19:10:59] [V] [TRT] Tactic: 6 Time: 0.1856
[03/27/2022-19:10:59] [V] [TRT] Tactic: 7 Time: 0.180352
[03/27/2022-19:10:59] [V] [TRT] Tactic: 8 Time: 0.179456
[03/27/2022-19:10:59] [V] [TRT] Tactic: 9 Time: 0.180096
[03/27/2022-19:10:59] [V] [TRT] Tactic: 28 Time: 0.213504
[03/27/2022-19:10:59] [V] [TRT] Fastest Tactic: 2 Time: 0.177408
[03/27/2022-19:10:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_49), Mul_50) (PointWise)
[03/27/2022-19:10:59] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:10:59] [V] [TRT] *************** Autotuning format combination: Float(2359296,1,18432,144) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:10:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_49), Mul_50) (PointWiseV2)
[03/27/2022-19:10:59] [V] [TRT] Tactic: 0 Time: 0.215288
[03/27/2022-19:10:59] [V] [TRT] Tactic: 1 Time: 0.182144
[03/27/2022-19:10:59] [V] [TRT] Tactic: 2 Time: 0.17984
[03/27/2022-19:10:59] [V] [TRT] Tactic: 3 Time: 0.182144
[03/27/2022-19:10:59] [V] [TRT] Tactic: 4 Time: 0.1801
[03/27/2022-19:10:59] [V] [TRT] Tactic: 5 Time: 0.179452
[03/27/2022-19:10:59] [V] [TRT] Tactic: 6 Time: 0.185984
[03/27/2022-19:10:59] [V] [TRT] Tactic: 7 Time: 0.180608
[03/27/2022-19:10:59] [V] [TRT] Tactic: 8 Time: 0.17946
[03/27/2022-19:10:59] [V] [TRT] Tactic: 9 Time: 0.179968
[03/27/2022-19:10:59] [V] [TRT] Tactic: 28 Time: 0.213492
[03/27/2022-19:10:59] [V] [TRT] Fastest Tactic: 5 Time: 0.179452
[03/27/2022-19:10:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_49), Mul_50) (PointWise)
[03/27/2022-19:10:59] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:10:59] [V] [TRT] *************** Autotuning format combination: Float(81920,16384:32,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:10:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_49), Mul_50) (PointWiseV2)
[03/27/2022-19:10:59] [V] [TRT] Tactic: 24 Time: 0.19968
[03/27/2022-19:10:59] [V] [TRT] Tactic: 25 Time: 0.199808
[03/27/2022-19:10:59] [V] [TRT] Tactic: 26 Time: 0.200708
[03/27/2022-19:10:59] [V] [TRT] Tactic: 27 Time: 0.202108
[03/27/2022-19:10:59] [V] [TRT] Tactic: 31 Time: 0.199936
[03/27/2022-19:10:59] [V] [TRT] Fastest Tactic: 24 Time: 0.19968
[03/27/2022-19:10:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_49), Mul_50) (PointWise)
[03/27/2022-19:10:59] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:10:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[03/27/2022-19:10:59] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:10:59] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:10:59] [V] [TRT] --------------- Timing Runner: Conv_51 (CudaDepthwiseConvolution)
[03/27/2022-19:10:59] [V] [TRT] Tactic: -1 Time: 0.28864
[03/27/2022-19:10:59] [V] [TRT] Fastest Tactic: -1 Time: 0.28864
[03/27/2022-19:10:59] [V] [TRT] --------------- Timing Runner: Conv_51 (CudnnConvolution)
[03/27/2022-19:10:59] [V] [TRT] Tactic: 0 Time: 0.627072
[03/27/2022-19:10:59] [V] [TRT] Tactic: 1 Time: 0.626816
[03/27/2022-19:10:59] [V] [TRT] Tactic: 2 Time: 2.47066
[03/27/2022-19:11:00] [V] [TRT] Tactic: 4 Time: 58.1106
[03/27/2022-19:11:03] [V] [TRT] Tactic: 5 Time: 165.21
[03/27/2022-19:11:03] [V] [TRT] Tactic: 6 Time: 22.5789
[03/27/2022-19:11:03] [V] [TRT] Fastest Tactic: 1 Time: 0.626816
[03/27/2022-19:11:03] [V] [TRT] --------------- Timing Runner: Conv_51 (CaskConvolution)
[03/27/2022-19:11:03] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:03] [V] [TRT] Tactic: 1062367460111450758 Time: 4.74996
[03/27/2022-19:11:03] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:11:04] [V] [TRT] Tactic: 1754984623894446479 Time: 4.41254
[03/27/2022-19:11:04] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:11:04] [V] [TRT] Tactic: 3611739942397549984 Time: 14.9536
[03/27/2022-19:11:04] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:11:04] [V] [TRT] Tactic: 3827454225649558724 Time: 8.45184
[03/27/2022-19:11:04] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:11:04] [V] [TRT] Tactic: 4337000649858996379 Time: 7.57184
[03/27/2022-19:11:04] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:04] [V] [TRT] Tactic: 4501471010995462441 Time: 14.0384
[03/27/2022-19:11:04] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:05] [V] [TRT] Tactic: 5137655947464784826 Time: 7.2759
[03/27/2022-19:11:05] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:05] [V] [TRT] Tactic: 5288347012147084929 Time: 14.8077
[03/27/2022-19:11:05] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:11:05] [V] [TRT] Tactic: 5921334924264294896 Time: 8.78477
[03/27/2022-19:11:05] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:05] [V] [TRT] Tactic: 6645123197870846056 Time: 7.49056
[03/27/2022-19:11:05] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:05] [V] [TRT] Tactic: 7144526460361122478 Time: 4.31603
[03/27/2022-19:11:05] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:11:06] [V] [TRT] Tactic: 7852627285308570038 Time: 9.20742
[03/27/2022-19:11:06] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:11:06] [V] [TRT] Tactic: -9137461792520977713 Time: 14.2467
[03/27/2022-19:11:06] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:11:06] [V] [TRT] Tactic: -8776506421218919509 Time: 7.90003
[03/27/2022-19:11:06] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:06] [V] [TRT] Tactic: -8262349710178828730 Time: 14.8948
[03/27/2022-19:11:06] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:11:06] [V] [TRT] Tactic: -8133971918129952780 Time: 7.17722
[03/27/2022-19:11:06] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:11:07] [V] [TRT] Tactic: -6092040395344634144 Time: 4.84979
[03/27/2022-19:11:07] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:07] [V] [TRT] Tactic: -4787320710726427159 Time: 4.40333
[03/27/2022-19:11:07] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:07] [V] [TRT] Tactic: -3456450830548107839 Time: 8.23885
[03/27/2022-19:11:07] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:11:07] [V] [TRT] Tactic: -2318106587342035239 Time: 8.549
[03/27/2022-19:11:07] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:11:07] [V] [TRT] Tactic: -1343271414618805657 Time: 8.48294
[03/27/2022-19:11:07] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:07] [V] [TRT] Tactic: -1218658103698133241 Time: 7.1296
[03/27/2022-19:11:07] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:07] [V] [TRT] Tactic: -836875257600482091 Time: 7.06394
[03/27/2022-19:11:07] [V] [TRT] Conv_51 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:08] [V] [TRT] Tactic: -410470605513481746 Time: 13.9026
[03/27/2022-19:11:08] [V] [TRT] Fastest Tactic: 7144526460361122478 Time: 4.31603
[03/27/2022-19:11:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:11:08] [V] [TRT] *************** Autotuning format combination: Float(2359296,1,18432,144) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: Conv_51 (CaskConvolution)
[03/27/2022-19:11:08] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:08] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:08] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:11:08] [V] [TRT] *************** Autotuning format combination: Float(2359296,1,18432,144) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:11:08] [V] [TRT] *************** Autotuning format combination: Float(81920,16384:32,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:11:08] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:08] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1) -> Float(144,1,1,1) ***************
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: ReduceMean_54 (TiledPooling)
[03/27/2022-19:11:08] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: ReduceMean_54 (CudnnPooling)
[03/27/2022-19:11:08] [V] [TRT] Tactic: -1 Time: 0.100864
[03/27/2022-19:11:08] [V] [TRT] Fastest Tactic: -1 Time: 0.100864
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: ReduceMean_54 (CaskPooling)
[03/27/2022-19:11:08] [V] [TRT] ReduceMean_54 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:11:08] [V] [TRT] Tactic: 6119644359078410246 Time: 0.101628
[03/27/2022-19:11:08] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.101628
[03/27/2022-19:11:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[03/27/2022-19:11:08] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:08] [V] [TRT] *************** Autotuning format combination: Float(144,1,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: Conv_55 (CudaDepthwiseConvolution)
[03/27/2022-19:11:08] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: Conv_55 (FusedConvActConvolution)
[03/27/2022-19:11:08] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: Conv_55 (CudnnConvolution)
[03/27/2022-19:11:08] [V] [TRT] Tactic: 0 Time: 0.021376
[03/27/2022-19:11:08] [V] [TRT] Tactic: 1 Time: 0.009596
[03/27/2022-19:11:08] [V] [TRT] Tactic: 2 Time: 0.14848
[03/27/2022-19:11:08] [V] [TRT] Tactic: 4 Time: 0.052864
[03/27/2022-19:11:08] [V] [TRT] Tactic: 5 Time: 0.205056
[03/27/2022-19:11:08] [V] [TRT] Fastest Tactic: 1 Time: 0.009596
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: Conv_55 (CublasConvolution)
[03/27/2022-19:11:08] [V] [TRT] Tactic: 0 Time: 0.009216
[03/27/2022-19:11:08] [V] [TRT] Tactic: 1 Time: 0.01024
[03/27/2022-19:11:08] [V] [TRT] Fastest Tactic: 0 Time: 0.009216
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: Conv_55 (CaskConvolution)
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:08] [V] [TRT] Tactic: 1062367460111450758 Time: 0.026368
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:08] [V] [TRT] Tactic: 1698681053543049347 Time: 0.019584
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:08] [V] [TRT] Tactic: 4501471010995462441 Time: 0.02752
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:08] [V] [TRT] Tactic: 5137655947464784826 Time: 0.022016
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:08] [V] [TRT] Tactic: 5288347012147084929 Time: 0.027396
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:08] [V] [TRT] Tactic: 5326823351883942011 Time: 0.027264
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:08] [V] [TRT] Tactic: 5500448035057547314 Time: 0.024452
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:08] [V] [TRT] Tactic: 6645123197870846056 Time: 0.02304
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:08] [V] [TRT] Tactic: 7144526460361122478 Time: 0.020104
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:08] [V] [TRT] Tactic: -8262349710178828730 Time: 0.028164
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:08] [V] [TRT] Tactic: -6576203419454146580 Time: 0.02304
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:08] [V] [TRT] Tactic: -4787320710726427159 Time: 0.02112
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:08] [V] [TRT] Tactic: -3456450830548107839 Time: 0.023804
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:08] [V] [TRT] Tactic: -1218658103698133241 Time: 0.02598
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:08] [V] [TRT] Tactic: -836875257600482091 Time: 0.024948
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:08] [V] [TRT] Tactic: -410470605513481746 Time: 0.027004
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:08] [V] [TRT] Tactic: -377491875521947884 Time: 0.027268
[03/27/2022-19:11:08] [V] [TRT] Conv_55 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:08] [V] [TRT] Tactic: -37215280111360163 Time: 0.021628
[03/27/2022-19:11:08] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.019584
[03/27/2022-19:11:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0
[03/27/2022-19:11:08] [V] [TRT] *************** Autotuning format combination: Float(144,1,144,144) -> Float(6,1,6,6) ***************
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: Conv_55 (CublasConvolution)
[03/27/2022-19:11:08] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: Conv_55 (CaskConvolution)
[03/27/2022-19:11:08] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:08] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:08] [V] [TRT] *************** Autotuning format combination: Float(6,1,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_56), Mul_57) (PointWiseV2)
[03/27/2022-19:11:08] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:11:08] [V] [TRT] Tactic: 1 Time: 0.005888
[03/27/2022-19:11:08] [V] [TRT] Tactic: 2 Time: 0.005888
[03/27/2022-19:11:08] [V] [TRT] Tactic: 3 Time: 0.00576
[03/27/2022-19:11:08] [V] [TRT] Tactic: 4 Time: 0.005888
[03/27/2022-19:11:08] [V] [TRT] Tactic: 5 Time: 0.005504
[03/27/2022-19:11:08] [V] [TRT] Tactic: 6 Time: 0.005888
[03/27/2022-19:11:08] [V] [TRT] Tactic: 7 Time: 0.006396
[03/27/2022-19:11:08] [V] [TRT] Tactic: 8 Time: 0.00576
[03/27/2022-19:11:08] [V] [TRT] Tactic: 9 Time: 0.005888
[03/27/2022-19:11:08] [V] [TRT] Tactic: 28 Time: 0.00576
[03/27/2022-19:11:08] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_56), Mul_57) (PointWise)
[03/27/2022-19:11:08] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0
[03/27/2022-19:11:08] [V] [TRT] *************** Autotuning format combination: Float(6,1,6,6) -> Float(6,1,6,6) ***************
[03/27/2022-19:11:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_56), Mul_57) (PointWiseV2)
[03/27/2022-19:11:08] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:11:08] [V] [TRT] Tactic: 1 Time: 0.005888
[03/27/2022-19:11:08] [V] [TRT] Tactic: 2 Time: 0.005628
[03/27/2022-19:11:08] [V] [TRT] Tactic: 3 Time: 0.005888
[03/27/2022-19:11:08] [V] [TRT] Tactic: 4 Time: 0.005632
[03/27/2022-19:11:08] [V] [TRT] Tactic: 5 Time: 0.006636
[03/27/2022-19:11:08] [V] [TRT] Tactic: 6 Time: 0.006016
[03/27/2022-19:11:08] [V] [TRT] Tactic: 7 Time: 0.006144
[03/27/2022-19:11:09] [V] [TRT] Tactic: 8 Time: 0.005888
[03/27/2022-19:11:09] [V] [TRT] Tactic: 9 Time: 0.006272
[03/27/2022-19:11:09] [V] [TRT] Tactic: 28 Time: 0.005888
[03/27/2022-19:11:09] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_56), Mul_57) (PointWise)
[03/27/2022-19:11:09] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0
[03/27/2022-19:11:09] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_56), Mul_57) (PointWiseV2)
[03/27/2022-19:11:09] [V] [TRT] Tactic: 24 Time: 0.0064
[03/27/2022-19:11:09] [V] [TRT] Tactic: 25 Time: 0.006396
[03/27/2022-19:11:09] [V] [TRT] Tactic: 26 Time: 0.006656
[03/27/2022-19:11:09] [V] [TRT] Tactic: 27 Time: 0.007552
[03/27/2022-19:11:09] [V] [TRT] Tactic: 31 Time: 0.006268
[03/27/2022-19:11:09] [V] [TRT] Fastest Tactic: 31 Time: 0.006268
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_56), Mul_57) (PointWise)
[03/27/2022-19:11:09] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:11:09] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:09] [V] [TRT] *************** Autotuning format combination: Float(6,1,1,1) -> Float(144,1,1,1) ***************
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: Conv_58 (CudaDepthwiseConvolution)
[03/27/2022-19:11:09] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: Conv_58 (FusedConvActConvolution)
[03/27/2022-19:11:09] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: Conv_58 (CudnnConvolution)
[03/27/2022-19:11:09] [V] [TRT] Tactic: 0 Time: 0.02816
[03/27/2022-19:11:09] [V] [TRT] Tactic: 1 Time: 0.030824
[03/27/2022-19:11:09] [V] [TRT] Tactic: 2 Time: 0.016884
[03/27/2022-19:11:09] [V] [TRT] Tactic: 4 Time: 0.098684
[03/27/2022-19:11:09] [V] [TRT] Tactic: 5 Time: 0.044416
[03/27/2022-19:11:09] [V] [TRT] Fastest Tactic: 2 Time: 0.016884
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: Conv_58 (CublasConvolution)
[03/27/2022-19:11:09] [V] [TRT] Tactic: 0 Time: 0.009084
[03/27/2022-19:11:09] [V] [TRT] Tactic: 1 Time: 0.009476
[03/27/2022-19:11:09] [V] [TRT] Fastest Tactic: 0 Time: 0.009084
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: Conv_58 (CaskConvolution)
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:09] [V] [TRT] Tactic: 1062367460111450758 Time: 0.01344
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:09] [V] [TRT] Tactic: 1698681053543049347 Time: 0.010236
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:09] [V] [TRT] Tactic: 4501471010995462441 Time: 0.0128
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:09] [V] [TRT] Tactic: 5137655947464784826 Time: 0.012928
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:09] [V] [TRT] Tactic: 5288347012147084929 Time: 0.013312
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:09] [V] [TRT] Tactic: 5326823351883942011 Time: 0.014592
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:09] [V] [TRT] Tactic: 5500448035057547314 Time: 0.012416
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:09] [V] [TRT] Tactic: 6645123197870846056 Time: 0.012928
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:09] [V] [TRT] Tactic: 7144526460361122478 Time: 0.009984
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:09] [V] [TRT] Tactic: -8262349710178828730 Time: 0.013308
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:09] [V] [TRT] Tactic: -6576203419454146580 Time: 0.013568
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:09] [V] [TRT] Tactic: -4787320710726427159 Time: 0.01062
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:09] [V] [TRT] Tactic: -3456450830548107839 Time: 0.013564
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:09] [V] [TRT] Tactic: -1218658103698133241 Time: 0.012672
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:09] [V] [TRT] Tactic: -836875257600482091 Time: 0.012284
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:09] [V] [TRT] Tactic: -410470605513481746 Time: 0.01318
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:09] [V] [TRT] Tactic: -377491875521947884 Time: 0.012928
[03/27/2022-19:11:09] [V] [TRT] Conv_58 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:09] [V] [TRT] Tactic: -37215280111360163 Time: 0.012544
[03/27/2022-19:11:09] [V] [TRT] Fastest Tactic: 7144526460361122478 Time: 0.009984
[03/27/2022-19:11:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0
[03/27/2022-19:11:09] [V] [TRT] *************** Autotuning format combination: Float(6,1,6,6) -> Float(144,1,144,144) ***************
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: Conv_58 (CublasConvolution)
[03/27/2022-19:11:09] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: Conv_58 (CaskConvolution)
[03/27/2022-19:11:09] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:09] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:09] [V] [TRT] *************** Autotuning format combination: Float(144,1,1,1), Float(2359296,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_59), Mul_60) (PointWiseV2)
[03/27/2022-19:11:09] [V] [TRT] Tactic: 0 Time: 0.365952
[03/27/2022-19:11:09] [V] [TRT] Tactic: 1 Time: 0.279036
[03/27/2022-19:11:09] [V] [TRT] Tactic: 2 Time: 0.278144
[03/27/2022-19:11:09] [V] [TRT] Tactic: 3 Time: 0.268544
[03/27/2022-19:11:09] [V] [TRT] Tactic: 4 Time: 0.267136
[03/27/2022-19:11:09] [V] [TRT] Tactic: 5 Time: 0.271104
[03/27/2022-19:11:09] [V] [TRT] Tactic: 6 Time: 0.27252
[03/27/2022-19:11:09] [V] [TRT] Tactic: 7 Time: 0.275708
[03/27/2022-19:11:09] [V] [TRT] Tactic: 8 Time: 0.28288
[03/27/2022-19:11:09] [V] [TRT] Tactic: 9 Time: 0.279556
[03/27/2022-19:11:09] [V] [TRT] Tactic: 28 Time: 0.348292
[03/27/2022-19:11:09] [V] [TRT] Fastest Tactic: 4 Time: 0.267136
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_59), Mul_60) (PointWise)
[03/27/2022-19:11:09] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 4
[03/27/2022-19:11:09] [V] [TRT] *************** Autotuning format combination: Float(144,1,144,144), Float(2359296,1,18432,144) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:11:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_59), Mul_60) (PointWiseV2)
[03/27/2022-19:11:09] [V] [TRT] Tactic: 0 Time: 0.515588
[03/27/2022-19:11:10] [V] [TRT] Tactic: 1 Time: 0.4896
[03/27/2022-19:11:10] [V] [TRT] Tactic: 2 Time: 0.542976
[03/27/2022-19:11:10] [V] [TRT] Tactic: 3 Time: 0.496768
[03/27/2022-19:11:10] [V] [TRT] Tactic: 4 Time: 0.490104
[03/27/2022-19:11:10] [V] [TRT] Tactic: 5 Time: 0.489216
[03/27/2022-19:11:10] [V] [TRT] Tactic: 6 Time: 0.496
[03/27/2022-19:11:10] [V] [TRT] Tactic: 7 Time: 0.495232
[03/27/2022-19:11:10] [V] [TRT] Tactic: 8 Time: 0.488832
[03/27/2022-19:11:10] [V] [TRT] Tactic: 9 Time: 0.488572
[03/27/2022-19:11:10] [V] [TRT] Tactic: 28 Time: 0.489856
[03/27/2022-19:11:10] [V] [TRT] Fastest Tactic: 9 Time: 0.488572
[03/27/2022-19:11:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_59), Mul_60) (PointWise)
[03/27/2022-19:11:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[03/27/2022-19:11:10] [V] [TRT] *************** Autotuning format combination: Float(5,1:32,1,1), Float(81920,16384:32,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:11:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_59), Mul_60) (PointWiseV2)
[03/27/2022-19:11:10] [V] [TRT] Tactic: 24 Time: 0.284032
[03/27/2022-19:11:10] [V] [TRT] Tactic: 25 Time: 0.275588
[03/27/2022-19:11:10] [V] [TRT] Tactic: 26 Time: 0.257276
[03/27/2022-19:11:10] [V] [TRT] Tactic: 27 Time: 0.217728
[03/27/2022-19:11:10] [V] [TRT] Tactic: 31 Time: 0.284284
[03/27/2022-19:11:10] [V] [TRT] Fastest Tactic: 27 Time: 0.217728
[03/27/2022-19:11:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_59), Mul_60) (PointWise)
[03/27/2022-19:11:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[03/27/2022-19:11:10] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:10] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1), Float(393216,16384,128,1) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:11:10] [V] [TRT] --------------- Timing Runner: Conv_61 + Add_62 (CudaDepthwiseConvolution)
[03/27/2022-19:11:10] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:10] [V] [TRT] --------------- Timing Runner: Conv_61 + Add_62 (FusedConvActConvolution)
[03/27/2022-19:11:10] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:10] [V] [TRT] --------------- Timing Runner: Conv_61 + Add_62 (CudnnConvolution)
[03/27/2022-19:11:10] [V] [TRT] Tactic: 0 Time: 0.282496
[03/27/2022-19:11:10] [V] [TRT] Tactic: 1 Time: 0.392832
[03/27/2022-19:11:10] [V] [TRT] Tactic: 2 Time: 0.491136
[03/27/2022-19:11:10] [V] [TRT] Tactic: 4 Time: 5.19859
[03/27/2022-19:11:10] [V] [TRT] Tactic: 5 Time: 1.63059
[03/27/2022-19:11:10] [V] [TRT] Fastest Tactic: 0 Time: 0.282496
[03/27/2022-19:11:10] [V] [TRT] --------------- Timing Runner: Conv_61 + Add_62 (CublasConvolution)
[03/27/2022-19:11:10] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:10] [V] [TRT] --------------- Timing Runner: Conv_61 + Add_62 (CaskConvolution)
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:10] [V] [TRT] Tactic: 1062367460111450758 Time: 0.161024
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:10] [V] [TRT] Tactic: 1698681053543049347 Time: 0.134784
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:10] [V] [TRT] Tactic: 4501471010995462441 Time: 0.352256
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:10] [V] [TRT] Tactic: 5137655947464784826 Time: 0.190596
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:10] [V] [TRT] Tactic: 5288347012147084929 Time: 0.35136
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:10] [V] [TRT] Tactic: 5326823351883942011 Time: 0.343028
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:10] [V] [TRT] Tactic: 5500448035057547314 Time: 0.20608
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:10] [V] [TRT] Tactic: 6645123197870846056 Time: 0.194692
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:10] [V] [TRT] Tactic: 7144526460361122478 Time: 0.149376
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:10] [V] [TRT] Tactic: -8262349710178828730 Time: 0.356864
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:10] [V] [TRT] Tactic: -6576203419454146580 Time: 0.139392
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:10] [V] [TRT] Tactic: -4787320710726427159 Time: 0.149504
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:10] [V] [TRT] Tactic: -3456450830548107839 Time: 0.143232
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:10] [V] [TRT] Tactic: -1218658103698133241 Time: 0.215548
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:10] [V] [TRT] Tactic: -836875257600482091 Time: 0.211196
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:10] [V] [TRT] Tactic: -410470605513481746 Time: 0.347904
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:10] [V] [TRT] Tactic: -377491875521947884 Time: 0.346756
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:10] [V] [TRT] Tactic: -37215280111360163 Time: 0.187136
[03/27/2022-19:11:10] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.134784
[03/27/2022-19:11:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 1698681053543049347
[03/27/2022-19:11:10] [V] [TRT] *************** Autotuning format combination: Float(2359296,1,18432,144), Float(393216,1,3072,24) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:11:10] [V] [TRT] --------------- Timing Runner: Conv_61 + Add_62 (CublasConvolution)
[03/27/2022-19:11:10] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:10] [V] [TRT] --------------- Timing Runner: Conv_61 + Add_62 (CaskConvolution)
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:11:10] [V] [TRT] Tactic: 3886731678879822788 Time: 0.21056
[03/27/2022-19:11:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:11:10] [V] [TRT] Tactic: 6629944304117643200 Time: 0.182528
[03/27/2022-19:11:11] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:11:11] [V] [TRT] Tactic: -9153228964338181824 Time: 0.172924
[03/27/2022-19:11:11] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:11:11] [V] [TRT] Tactic: -7394439838318485025 Time: 0.208132
[03/27/2022-19:11:11] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.172924
[03/27/2022-19:11:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(393216,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(393216,1,3072,24) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,1,18432,144) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(81920,16384:32,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,1,18432,144) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,1,18432,144) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(81920,16384:32,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1) -> Float(144,1,1,1) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(144,1,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(144,1,144,144) -> Float(6,1,6,6) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(6,1,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(6,1,6,6) -> Float(6,1,6,6) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(6,1,1,1) -> Float(144,1,1,1) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(6,1,6,6) -> Float(144,1,144,144) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(144,1,1,1), Float(2359296,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(144,1,144,144), Float(2359296,1,18432,144) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(5,1:32,1,1), Float(81920,16384:32,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1), Float(393216,16384,128,1) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,1,18432,144), Float(393216,1,3072,24) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(393216,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(393216,1,3072,24) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1) -> Float(2359296,16384,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,1,18432,144) -> Float(2359296,1,18432,144) ***************
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(81920,16384:32,128,1) -> Float(81920,16384:32,128,1) ***************
[03/27/2022-19:11:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:11] [V] [TRT] *************** Autotuning format combination: Float(2359296,16384,128,1) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:11:11] [V] [TRT] --------------- Timing Runner: Conv_81 (CudaDepthwiseConvolution)
[03/27/2022-19:11:11] [V] [TRT] Tactic: -1 Time: 0.3456
[03/27/2022-19:11:11] [V] [TRT] Fastest Tactic: -1 Time: 0.3456
[03/27/2022-19:11:11] [V] [TRT] --------------- Timing Runner: Conv_81 (CudnnConvolution)
[03/27/2022-19:11:11] [V] [TRT] Tactic: 0 Time: 1.00211
[03/27/2022-19:11:11] [V] [TRT] Tactic: 1 Time: 1.00134
[03/27/2022-19:11:11] [V] [TRT] Tactic: 2 Time: 1.00161
[03/27/2022-19:11:13] [V] [TRT] Tactic: 5 Time: 129.728
[03/27/2022-19:11:13] [V] [TRT] Fastest Tactic: 1 Time: 1.00134
[03/27/2022-19:11:13] [V] [TRT] --------------- Timing Runner: Conv_81 (CaskConvolution)
[03/27/2022-19:11:13] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:14] [V] [TRT] Tactic: 1062367460111450758 Time: 2.3753
[03/27/2022-19:11:14] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:11:14] [V] [TRT] Tactic: 1754984623894446479 Time: 2.67444
[03/27/2022-19:11:14] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:11:14] [V] [TRT] Tactic: 3611739942397549984 Time: 5.9552
[03/27/2022-19:11:14] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:11:14] [V] [TRT] Tactic: 4337000649858996379 Time: 4.00857
[03/27/2022-19:11:14] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:14] [V] [TRT] Tactic: 4501471010995462441 Time: 5.6983
[03/27/2022-19:11:14] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:14] [V] [TRT] Tactic: 5137655947464784826 Time: 3.53075
[03/27/2022-19:11:14] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:14] [V] [TRT] Tactic: 5288347012147084929 Time: 5.87635
[03/27/2022-19:11:14] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:14] [V] [TRT] Tactic: 6645123197870846056 Time: 3.59654
[03/27/2022-19:11:14] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:14] [V] [TRT] Tactic: 7144526460361122478 Time: 1.91462
[03/27/2022-19:11:14] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:11:15] [V] [TRT] Tactic: -9137461792520977713 Time: 5.78035
[03/27/2022-19:11:15] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:15] [V] [TRT] Tactic: -8262349710178828730 Time: 6.2496
[03/27/2022-19:11:15] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:11:15] [V] [TRT] Tactic: -8133971918129952780 Time: 3.56672
[03/27/2022-19:11:15] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:11:15] [V] [TRT] Tactic: -6092040395344634144 Time: 2.43853
[03/27/2022-19:11:15] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:15] [V] [TRT] Tactic: -4787320710726427159 Time: 1.98592
[03/27/2022-19:11:15] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:15] [V] [TRT] Tactic: -3456450830548107839 Time: 3.20807
[03/27/2022-19:11:15] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:15] [V] [TRT] Tactic: -1218658103698133241 Time: 3.56454
[03/27/2022-19:11:15] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:15] [V] [TRT] Tactic: -836875257600482091 Time: 3.50771
[03/27/2022-19:11:15] [V] [TRT] Conv_81 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:15] [V] [TRT] Tactic: -410470605513481746 Time: 5.61817
[03/27/2022-19:11:15] [V] [TRT] Fastest Tactic: 7144526460361122478 Time: 1.91462
[03/27/2022-19:11:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:11:15] [V] [TRT] *************** Autotuning format combination: Float(2359296,1,18432,144) -> Float(589824,1,9216,144) ***************
[03/27/2022-19:11:15] [V] [TRT] --------------- Timing Runner: Conv_81 (CaskConvolution)
[03/27/2022-19:11:15] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:15] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:15] [V] [TRT] *************** Autotuning format combination: Float(589824,4096,64,1) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:11:15] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_82), Mul_83) (PointWiseV2)
[03/27/2022-19:11:15] [V] [TRT] Tactic: 0 Time: 0.059776
[03/27/2022-19:11:15] [V] [TRT] Tactic: 1 Time: 0.051584
[03/27/2022-19:11:15] [V] [TRT] Tactic: 2 Time: 0.050432
[03/27/2022-19:11:15] [V] [TRT] Tactic: 3 Time: 0.051712
[03/27/2022-19:11:15] [V] [TRT] Tactic: 4 Time: 0.05018
[03/27/2022-19:11:15] [V] [TRT] Tactic: 5 Time: 0.049792
[03/27/2022-19:11:15] [V] [TRT] Tactic: 6 Time: 0.052488
[03/27/2022-19:11:15] [V] [TRT] Tactic: 7 Time: 0.050432
[03/27/2022-19:11:15] [V] [TRT] Tactic: 8 Time: 0.049792
[03/27/2022-19:11:15] [V] [TRT] Tactic: 9 Time: 0.050048
[03/27/2022-19:11:15] [V] [TRT] Tactic: 28 Time: 0.059136
[03/27/2022-19:11:15] [V] [TRT] Fastest Tactic: 5 Time: 0.049792
[03/27/2022-19:11:15] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_82), Mul_83) (PointWise)
[03/27/2022-19:11:15] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:11:15] [V] [TRT] *************** Autotuning format combination: Float(589824,1,9216,144) -> Float(589824,1,9216,144) ***************
[03/27/2022-19:11:15] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_82), Mul_83) (PointWiseV2)
[03/27/2022-19:11:15] [V] [TRT] Tactic: 0 Time: 0.05978
[03/27/2022-19:11:15] [V] [TRT] Tactic: 1 Time: 0.051456
[03/27/2022-19:11:15] [V] [TRT] Tactic: 2 Time: 0.050304
[03/27/2022-19:11:15] [V] [TRT] Tactic: 3 Time: 0.051324
[03/27/2022-19:11:15] [V] [TRT] Tactic: 4 Time: 0.0503
[03/27/2022-19:11:16] [V] [TRT] Tactic: 5 Time: 0.050172
[03/27/2022-19:11:16] [V] [TRT] Tactic: 6 Time: 0.052604
[03/27/2022-19:11:16] [V] [TRT] Tactic: 7 Time: 0.050432
[03/27/2022-19:11:16] [V] [TRT] Tactic: 8 Time: 0.04992
[03/27/2022-19:11:16] [V] [TRT] Tactic: 9 Time: 0.050176
[03/27/2022-19:11:16] [V] [TRT] Tactic: 28 Time: 0.059264
[03/27/2022-19:11:16] [V] [TRT] Fastest Tactic: 8 Time: 0.04992
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_82), Mul_83) (PointWise)
[03/27/2022-19:11:16] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(20480,4096:32,64,1) -> Float(20480,4096:32,64,1) ***************
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_82), Mul_83) (PointWiseV2)
[03/27/2022-19:11:16] [V] [TRT] Tactic: 24 Time: 0.056192
[03/27/2022-19:11:16] [V] [TRT] Tactic: 25 Time: 0.064512
[03/27/2022-19:11:16] [V] [TRT] Tactic: 26 Time: 0.055812
[03/27/2022-19:11:16] [V] [TRT] Tactic: 27 Time: 0.056708
[03/27/2022-19:11:16] [V] [TRT] Tactic: 31 Time: 0.055168
[03/27/2022-19:11:16] [V] [TRT] Fastest Tactic: 31 Time: 0.055168
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_82), Mul_83) (PointWise)
[03/27/2022-19:11:16] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:11:16] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(589824,4096,64,1) -> Float(144,1,1,1) ***************
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: ReduceMean_84 (TiledPooling)
[03/27/2022-19:11:16] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: ReduceMean_84 (CudnnPooling)
[03/27/2022-19:11:16] [V] [TRT] Tactic: -1 Time: 0.036096
[03/27/2022-19:11:16] [V] [TRT] Fastest Tactic: -1 Time: 0.036096
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: ReduceMean_84 (CaskPooling)
[03/27/2022-19:11:16] [V] [TRT] ReduceMean_84 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:11:16] [V] [TRT] Tactic: 6119644359078410246 Time: 0.037112
[03/27/2022-19:11:16] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.037112
[03/27/2022-19:11:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[03/27/2022-19:11:16] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(144,1,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(144,1,144,144) -> Float(6,1,6,6) ***************
[03/27/2022-19:11:16] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(6,1,1,1) -> Float(6,1,1,1) ***************
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(6,1,6,6) -> Float(6,1,6,6) ***************
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:11:16] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(6,1,1,1) -> Float(144,1,1,1) ***************
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(6,1,6,6) -> Float(144,1,144,144) ***************
[03/27/2022-19:11:16] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(144,1,1,1), Float(589824,4096,64,1) -> Float(589824,4096,64,1) ***************
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_89), Mul_90) (PointWiseV2)
[03/27/2022-19:11:16] [V] [TRT] Tactic: 0 Time: 0.09792
[03/27/2022-19:11:16] [V] [TRT] Tactic: 1 Time: 0.073472
[03/27/2022-19:11:16] [V] [TRT] Tactic: 2 Time: 0.0704
[03/27/2022-19:11:16] [V] [TRT] Tactic: 3 Time: 0.076548
[03/27/2022-19:11:16] [V] [TRT] Tactic: 4 Time: 0.077056
[03/27/2022-19:11:16] [V] [TRT] Tactic: 5 Time: 0.075776
[03/27/2022-19:11:16] [V] [TRT] Tactic: 6 Time: 0.091648
[03/27/2022-19:11:16] [V] [TRT] Tactic: 7 Time: 0.095872
[03/27/2022-19:11:16] [V] [TRT] Tactic: 8 Time: 0.094072
[03/27/2022-19:11:16] [V] [TRT] Tactic: 9 Time: 0.082816
[03/27/2022-19:11:16] [V] [TRT] Tactic: 28 Time: 0.09318
[03/27/2022-19:11:16] [V] [TRT] Fastest Tactic: 2 Time: 0.0704
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_89), Mul_90) (PointWise)
[03/27/2022-19:11:16] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(144,1,144,144), Float(589824,1,9216,144) -> Float(589824,1,9216,144) ***************
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_89), Mul_90) (PointWiseV2)
[03/27/2022-19:11:16] [V] [TRT] Tactic: 0 Time: 0.134272
[03/27/2022-19:11:16] [V] [TRT] Tactic: 1 Time: 0.12608
[03/27/2022-19:11:16] [V] [TRT] Tactic: 2 Time: 0.125568
[03/27/2022-19:11:16] [V] [TRT] Tactic: 3 Time: 0.128
[03/27/2022-19:11:16] [V] [TRT] Tactic: 4 Time: 0.12672
[03/27/2022-19:11:16] [V] [TRT] Tactic: 5 Time: 0.125184
[03/27/2022-19:11:16] [V] [TRT] Tactic: 6 Time: 0.149504
[03/27/2022-19:11:16] [V] [TRT] Tactic: 7 Time: 0.134656
[03/27/2022-19:11:16] [V] [TRT] Tactic: 8 Time: 0.125184
[03/27/2022-19:11:16] [V] [TRT] Tactic: 9 Time: 0.125052
[03/27/2022-19:11:16] [V] [TRT] Tactic: 28 Time: 0.126976
[03/27/2022-19:11:16] [V] [TRT] Fastest Tactic: 9 Time: 0.125052
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_89), Mul_90) (PointWise)
[03/27/2022-19:11:16] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(5,1:32,1,1), Float(20480,4096:32,64,1) -> Float(20480,4096:32,64,1) ***************
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_89), Mul_90) (PointWiseV2)
[03/27/2022-19:11:16] [V] [TRT] Tactic: 24 Time: 0.06592
[03/27/2022-19:11:16] [V] [TRT] Tactic: 25 Time: 0.060276
[03/27/2022-19:11:16] [V] [TRT] Tactic: 26 Time: 0.059136
[03/27/2022-19:11:16] [V] [TRT] Tactic: 27 Time: 0.059136
[03/27/2022-19:11:16] [V] [TRT] Tactic: 31 Time: 0.065792
[03/27/2022-19:11:16] [V] [TRT] Fastest Tactic: 26 Time: 0.059136
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_89), Mul_90) (PointWise)
[03/27/2022-19:11:16] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[03/27/2022-19:11:16] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(589824,4096,64,1) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: Conv_91 (CudaDepthwiseConvolution)
[03/27/2022-19:11:16] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: Conv_91 (FusedConvActConvolution)
[03/27/2022-19:11:16] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: Conv_91 (CudnnConvolution)
[03/27/2022-19:11:16] [V] [TRT] Tactic: 0 Time: 0.129156
[03/27/2022-19:11:16] [V] [TRT] Tactic: 1 Time: 0.090112
[03/27/2022-19:11:16] [V] [TRT] Tactic: 2 Time: 0.211456
[03/27/2022-19:11:16] [V] [TRT] Tactic: 4 Time: 1.67847
[03/27/2022-19:11:16] [V] [TRT] Tactic: 5 Time: 0.219392
[03/27/2022-19:11:16] [V] [TRT] Fastest Tactic: 1 Time: 0.090112
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: Conv_91 (CublasConvolution)
[03/27/2022-19:11:16] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskConvolution)
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:16] [V] [TRT] Tactic: 1062367460111450758 Time: 0.0768
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:16] [V] [TRT] Tactic: 1698681053543049347 Time: 0.07232
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:16] [V] [TRT] Tactic: 4501471010995462441 Time: 0.10368
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:16] [V] [TRT] Tactic: 5137655947464784826 Time: 0.064768
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:16] [V] [TRT] Tactic: 5288347012147084929 Time: 0.103936
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:16] [V] [TRT] Tactic: 5326823351883942011 Time: 0.10138
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:16] [V] [TRT] Tactic: 5500448035057547314 Time: 0.07424
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:16] [V] [TRT] Tactic: 6645123197870846056 Time: 0.066176
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:16] [V] [TRT] Tactic: 7144526460361122478 Time: 0.077692
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:16] [V] [TRT] Tactic: -8262349710178828730 Time: 0.105472
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:16] [V] [TRT] Tactic: -6576203419454146580 Time: 0.070144
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:16] [V] [TRT] Tactic: -4787320710726427159 Time: 0.07872
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:16] [V] [TRT] Tactic: -3456450830548107839 Time: 0.07424
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:16] [V] [TRT] Tactic: -1218658103698133241 Time: 0.077952
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:16] [V] [TRT] Tactic: -836875257600482091 Time: 0.075648
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:16] [V] [TRT] Tactic: -410470605513481746 Time: 0.10176
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:16] [V] [TRT] Tactic: -377491875521947884 Time: 0.102396
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:16] [V] [TRT] Tactic: -37215280111360163 Time: 0.062712
[03/27/2022-19:11:16] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.062712
[03/27/2022-19:11:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(589824,1,9216,144) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: Conv_91 (CublasConvolution)
[03/27/2022-19:11:16] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskConvolution)
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:11:16] [V] [TRT] Tactic: 3886731678879822788 Time: 0.063872
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:11:16] [V] [TRT] Tactic: 6629944304117643200 Time: 0.073344
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:11:16] [V] [TRT] Tactic: -9153228964338181824 Time: 0.07552
[03/27/2022-19:11:16] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:11:16] [V] [TRT] Tactic: -7394439838318485025 Time: 0.0631
[03/27/2022-19:11:16] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.0631
[03/27/2022-19:11:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[03/27/2022-19:11:16] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:16] [V] [TRT] *************** Autotuning format combination: Float(196608,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: Conv_92 (CudaDepthwiseConvolution)
[03/27/2022-19:11:16] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: Conv_92 (FusedConvActConvolution)
[03/27/2022-19:11:16] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:16] [V] [TRT] --------------- Timing Runner: Conv_92 (CudnnConvolution)
[03/27/2022-19:11:16] [V] [TRT] Tactic: 0 Time: 0.447744
[03/27/2022-19:11:16] [V] [TRT] Tactic: 1 Time: 0.237696
[03/27/2022-19:11:17] [V] [TRT] Tactic: 2 Time: 0.347772
[03/27/2022-19:11:17] [V] [TRT] Tactic: 4 Time: 3.2169
[03/27/2022-19:11:17] [V] [TRT] Tactic: 5 Time: 0.58342
[03/27/2022-19:11:17] [V] [TRT] Fastest Tactic: 1 Time: 0.237696
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: Conv_92 (CublasConvolution)
[03/27/2022-19:11:17] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: Conv_92 (CaskConvolution)
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:17] [V] [TRT] Tactic: 1062367460111450758 Time: 0.125436
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:17] [V] [TRT] Tactic: 1698681053543049347 Time: 0.127616
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:17] [V] [TRT] Tactic: 4501471010995462441 Time: 0.14144
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:17] [V] [TRT] Tactic: 5137655947464784826 Time: 0.11904
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:17] [V] [TRT] Tactic: 5288347012147084929 Time: 0.138744
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:17] [V] [TRT] Tactic: 5326823351883942011 Time: 0.136828
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:17] [V] [TRT] Tactic: 5500448035057547314 Time: 0.12658
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:17] [V] [TRT] Tactic: 6645123197870846056 Time: 0.120696
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:17] [V] [TRT] Tactic: 7144526460361122478 Time: 0.138496
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:17] [V] [TRT] Tactic: -8262349710178828730 Time: 0.141048
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:17] [V] [TRT] Tactic: -6576203419454146580 Time: 0.119168
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:17] [V] [TRT] Tactic: -4787320710726427159 Time: 0.13952
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:17] [V] [TRT] Tactic: -3456450830548107839 Time: 0.123136
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:17] [V] [TRT] Tactic: -1218658103698133241 Time: 0.130944
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:17] [V] [TRT] Tactic: -836875257600482091 Time: 0.128896
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:17] [V] [TRT] Tactic: -410470605513481746 Time: 0.138368
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:17] [V] [TRT] Tactic: -377491875521947884 Time: 0.140028
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:17] [V] [TRT] Tactic: -37215280111360163 Time: 0.119044
[03/27/2022-19:11:17] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 0.11904
[03/27/2022-19:11:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[03/27/2022-19:11:17] [V] [TRT] *************** Autotuning format combination: Float(196608,1,3072,48) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: Conv_92 (CublasConvolution)
[03/27/2022-19:11:17] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: Conv_92 (CaskConvolution)
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:11:17] [V] [TRT] Tactic: 3886731678879822788 Time: 0.128256
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:11:17] [V] [TRT] Tactic: 6629944304117643200 Time: 0.188416
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:11:17] [V] [TRT] Tactic: -9153228964338181824 Time: 0.188928
[03/27/2022-19:11:17] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:11:17] [V] [TRT] Tactic: -7394439838318485025 Time: 0.128636
[03/27/2022-19:11:17] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.128256
[03/27/2022-19:11:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:11:17] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:17] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_93), Mul_94) (PointWiseV2)
[03/27/2022-19:11:17] [V] [TRT] Tactic: 0 Time: 0.111744
[03/27/2022-19:11:17] [V] [TRT] Tactic: 1 Time: 0.095104
[03/27/2022-19:11:17] [V] [TRT] Tactic: 2 Time: 0.093948
[03/27/2022-19:11:17] [V] [TRT] Tactic: 3 Time: 0.095232
[03/27/2022-19:11:17] [V] [TRT] Tactic: 4 Time: 0.094332
[03/27/2022-19:11:17] [V] [TRT] Tactic: 5 Time: 0.093696
[03/27/2022-19:11:17] [V] [TRT] Tactic: 6 Time: 0.09728
[03/27/2022-19:11:17] [V] [TRT] Tactic: 7 Time: 0.094076
[03/27/2022-19:11:17] [V] [TRT] Tactic: 8 Time: 0.093312
[03/27/2022-19:11:17] [V] [TRT] Tactic: 9 Time: 0.093696
[03/27/2022-19:11:17] [V] [TRT] Tactic: 28 Time: 0.110848
[03/27/2022-19:11:17] [V] [TRT] Fastest Tactic: 8 Time: 0.093312
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_93), Mul_94) (PointWise)
[03/27/2022-19:11:17] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:11:17] [V] [TRT] *************** Autotuning format combination: Float(1179648,1,18432,288) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_93), Mul_94) (PointWiseV2)
[03/27/2022-19:11:17] [V] [TRT] Tactic: 0 Time: 0.11136
[03/27/2022-19:11:17] [V] [TRT] Tactic: 1 Time: 0.095104
[03/27/2022-19:11:17] [V] [TRT] Tactic: 2 Time: 0.093692
[03/27/2022-19:11:17] [V] [TRT] Tactic: 3 Time: 0.094848
[03/27/2022-19:11:17] [V] [TRT] Tactic: 4 Time: 0.09408
[03/27/2022-19:11:17] [V] [TRT] Tactic: 5 Time: 0.093444
[03/27/2022-19:11:17] [V] [TRT] Tactic: 6 Time: 0.09728
[03/27/2022-19:11:17] [V] [TRT] Tactic: 7 Time: 0.094076
[03/27/2022-19:11:17] [V] [TRT] Tactic: 8 Time: 0.093056
[03/27/2022-19:11:17] [V] [TRT] Tactic: 9 Time: 0.093696
[03/27/2022-19:11:17] [V] [TRT] Tactic: 28 Time: 0.110972
[03/27/2022-19:11:17] [V] [TRT] Fastest Tactic: 8 Time: 0.093056
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_93), Mul_94) (PointWise)
[03/27/2022-19:11:17] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:11:17] [V] [TRT] *************** Autotuning format combination: Float(36864,4096:32,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_93), Mul_94) (PointWiseV2)
[03/27/2022-19:11:17] [V] [TRT] Tactic: 24 Time: 0.093312
[03/27/2022-19:11:17] [V] [TRT] Tactic: 25 Time: 0.093696
[03/27/2022-19:11:17] [V] [TRT] Tactic: 26 Time: 0.094592
[03/27/2022-19:11:17] [V] [TRT] Tactic: 27 Time: 0.094848
[03/27/2022-19:11:17] [V] [TRT] Tactic: 31 Time: 0.093184
[03/27/2022-19:11:17] [V] [TRT] Fastest Tactic: 31 Time: 0.093184
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_93), Mul_94) (PointWise)
[03/27/2022-19:11:17] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:11:17] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:17] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: Conv_95 (CudaDepthwiseConvolution)
[03/27/2022-19:11:17] [V] [TRT] Tactic: -1 Time: 0.462208
[03/27/2022-19:11:17] [V] [TRT] Fastest Tactic: -1 Time: 0.462208
[03/27/2022-19:11:17] [V] [TRT] --------------- Timing Runner: Conv_95 (CudnnConvolution)
[03/27/2022-19:11:17] [V] [TRT] Tactic: 0 Time: 1.49299
[03/27/2022-19:11:17] [V] [TRT] Tactic: 1 Time: 1.48979
[03/27/2022-19:11:17] [V] [TRT] Tactic: 2 Time: 1.49005
[03/27/2022-19:11:18] [V] [TRT] Tactic: 4 Time: 55.122
[03/27/2022-19:11:20] [V] [TRT] Tactic: 5 Time: 123.112
[03/27/2022-19:11:20] [V] [TRT] Fastest Tactic: 1 Time: 1.48979
[03/27/2022-19:11:20] [V] [TRT] --------------- Timing Runner: Conv_95 (CaskConvolution)
[03/27/2022-19:11:20] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:21] [V] [TRT] Tactic: 1062367460111450758 Time: 4.77952
[03/27/2022-19:11:21] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:11:21] [V] [TRT] Tactic: 1754984623894446479 Time: 4.86899
[03/27/2022-19:11:21] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:11:21] [V] [TRT] Tactic: 3611739942397549984 Time: 11.8755
[03/27/2022-19:11:21] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:11:21] [V] [TRT] Tactic: 4337000649858996379 Time: 7.26848
[03/27/2022-19:11:21] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:21] [V] [TRT] Tactic: 4501471010995462441 Time: 12.3483
[03/27/2022-19:11:21] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:22] [V] [TRT] Tactic: 5137655947464784826 Time: 8.50803
[03/27/2022-19:11:22] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:22] [V] [TRT] Tactic: 5288347012147084929 Time: 11.679
[03/27/2022-19:11:22] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:22] [V] [TRT] Tactic: 6645123197870846056 Time: 7.21958
[03/27/2022-19:11:22] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:22] [V] [TRT] Tactic: 7144526460361122478 Time: 3.74606
[03/27/2022-19:11:22] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:11:22] [V] [TRT] Tactic: -9137461792520977713 Time: 11.6374
[03/27/2022-19:11:23] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:23] [V] [TRT] Tactic: -8262349710178828730 Time: 12.8154
[03/27/2022-19:11:23] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:11:23] [V] [TRT] Tactic: -8133971918129952780 Time: 11.2151
[03/27/2022-19:11:23] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:11:23] [V] [TRT] Tactic: -6092040395344634144 Time: 4.83904
[03/27/2022-19:11:23] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:23] [V] [TRT] Tactic: -4787320710726427159 Time: 3.73018
[03/27/2022-19:11:23] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:24] [V] [TRT] Tactic: -3456450830548107839 Time: 4.20108
[03/27/2022-19:11:24] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:24] [V] [TRT] Tactic: -1218658103698133241 Time: 11.0336
[03/27/2022-19:11:24] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:24] [V] [TRT] Tactic: -836875257600482091 Time: 7.63456
[03/27/2022-19:11:24] [V] [TRT] Conv_95 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:24] [V] [TRT] Tactic: -410470605513481746 Time: 11.3724
[03/27/2022-19:11:24] [V] [TRT] Fastest Tactic: -4787320710726427159 Time: 3.73018
[03/27/2022-19:11:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:11:24] [V] [TRT] *************** Autotuning format combination: Float(1179648,1,18432,288) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:24] [V] [TRT] --------------- Timing Runner: Conv_95 (CaskConvolution)
[03/27/2022-19:11:24] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:24] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:24] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:24] [V] [TRT] *************** Autotuning format combination: Float(1179648,1,18432,288) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:24] [V] [TRT] *************** Autotuning format combination: Float(36864,4096:32,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:11:24] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:24] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1) -> Float(288,1,1,1) ***************
[03/27/2022-19:11:24] [V] [TRT] --------------- Timing Runner: ReduceMean_98 (TiledPooling)
[03/27/2022-19:11:24] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:11:24] [V] [TRT] --------------- Timing Runner: ReduceMean_98 (CudnnPooling)
[03/27/2022-19:11:24] [V] [TRT] Tactic: -1 Time: 0.054656
[03/27/2022-19:11:24] [V] [TRT] Fastest Tactic: -1 Time: 0.054656
[03/27/2022-19:11:24] [V] [TRT] --------------- Timing Runner: ReduceMean_98 (CaskPooling)
[03/27/2022-19:11:24] [V] [TRT] ReduceMean_98 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:11:24] [V] [TRT] Tactic: 6119644359078410246 Time: 0.05554
[03/27/2022-19:11:24] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.05554
[03/27/2022-19:11:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[03/27/2022-19:11:24] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:24] [V] [TRT] *************** Autotuning format combination: Float(288,1,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:11:24] [V] [TRT] --------------- Timing Runner: Conv_99 (CudaDepthwiseConvolution)
[03/27/2022-19:11:24] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:24] [V] [TRT] --------------- Timing Runner: Conv_99 (FusedConvActConvolution)
[03/27/2022-19:11:24] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:24] [V] [TRT] --------------- Timing Runner: Conv_99 (CudnnConvolution)
[03/27/2022-19:11:24] [V] [TRT] Tactic: 0 Time: 0.030976
[03/27/2022-19:11:24] [V] [TRT] Tactic: 1 Time: 0.009856
[03/27/2022-19:11:24] [V] [TRT] Tactic: 2 Time: 0.12158
[03/27/2022-19:11:24] [V] [TRT] Tactic: 4 Time: 0.097536
[03/27/2022-19:11:24] [V] [TRT] Tactic: 5 Time: 0.062464
[03/27/2022-19:11:24] [V] [TRT] Fastest Tactic: 1 Time: 0.009856
[03/27/2022-19:11:24] [V] [TRT] --------------- Timing Runner: Conv_99 (CublasConvolution)
[03/27/2022-19:11:24] [V] [TRT] Tactic: 0 Time: 0.084476
[03/27/2022-19:11:24] [V] [TRT] Tactic: 1 Time: 0.053376
[03/27/2022-19:11:24] [V] [TRT] Fastest Tactic: 1 Time: 0.053376
[03/27/2022-19:11:25] [V] [TRT] --------------- Timing Runner: Conv_99 (CaskConvolution)
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:25] [V] [TRT] Tactic: 1062367460111450758 Time: 0.037888
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:25] [V] [TRT] Tactic: 1698681053543049347 Time: 0.028416
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:25] [V] [TRT] Tactic: 4501471010995462441 Time: 0.041216
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:25] [V] [TRT] Tactic: 5137655947464784826 Time: 0.030336
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:25] [V] [TRT] Tactic: 5288347012147084929 Time: 0.039936
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:25] [V] [TRT] Tactic: 5326823351883942011 Time: 0.039804
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:25] [V] [TRT] Tactic: 5500448035057547314 Time: 0.035304
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:25] [V] [TRT] Tactic: 6645123197870846056 Time: 0.031996
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:25] [V] [TRT] Tactic: 7144526460361122478 Time: 0.028804
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:25] [V] [TRT] Tactic: -8262349710178828730 Time: 0.041084
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:25] [V] [TRT] Tactic: -6576203419454146580 Time: 0.03314
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:25] [V] [TRT] Tactic: -4787320710726427159 Time: 0.033408
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:25] [V] [TRT] Tactic: -3456450830548107839 Time: 0.035844
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:25] [V] [TRT] Tactic: -1218658103698133241 Time: 0.040704
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:25] [V] [TRT] Tactic: -836875257600482091 Time: 0.039168
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:25] [V] [TRT] Tactic: -410470605513481746 Time: 0.043008
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:25] [V] [TRT] Tactic: -377491875521947884 Time: 0.042624
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:25] [V] [TRT] Tactic: -37215280111360163 Time: 0.03904
[03/27/2022-19:11:25] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.028416
[03/27/2022-19:11:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/27/2022-19:11:25] [V] [TRT] *************** Autotuning format combination: Float(288,1,288,288) -> Float(12,1,12,12) ***************
[03/27/2022-19:11:25] [V] [TRT] --------------- Timing Runner: Conv_99 (CublasConvolution)
[03/27/2022-19:11:25] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:25] [V] [TRT] --------------- Timing Runner: Conv_99 (CaskConvolution)
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:11:25] [V] [TRT] Tactic: 3886731678879822788 Time: 0.026112
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:11:25] [V] [TRT] Tactic: 6629944304117643200 Time: 0.018816
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:11:25] [V] [TRT] Tactic: -9153228964338181824 Time: 0.033532
[03/27/2022-19:11:25] [V] [TRT] Conv_99 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:11:25] [V] [TRT] Tactic: -7394439838318485025 Time: 0.02688
[03/27/2022-19:11:25] [V] [TRT] Fastest Tactic: 6629944304117643200 Time: 0.018816
[03/27/2022-19:11:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200
[03/27/2022-19:11:25] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:25] [V] [TRT] *************** Autotuning format combination: Float(12,1,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:11:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_100), Mul_101) (PointWiseV2)
[03/27/2022-19:11:25] [V] [TRT] Tactic: 0 Time: 0.005376
[03/27/2022-19:11:25] [V] [TRT] Tactic: 1 Time: 0.00614
[03/27/2022-19:11:25] [V] [TRT] Tactic: 2 Time: 0.00576
[03/27/2022-19:11:25] [V] [TRT] Tactic: 3 Time: 0.006016
[03/27/2022-19:11:25] [V] [TRT] Tactic: 4 Time: 0.005888
[03/27/2022-19:11:25] [V] [TRT] Tactic: 5 Time: 0.00576
[03/27/2022-19:11:25] [V] [TRT] Tactic: 6 Time: 0.006144
[03/27/2022-19:11:25] [V] [TRT] Tactic: 7 Time: 0.0064
[03/27/2022-19:11:25] [V] [TRT] Tactic: 8 Time: 0.00576
[03/27/2022-19:11:25] [V] [TRT] Tactic: 9 Time: 0.006012
[03/27/2022-19:11:25] [V] [TRT] Tactic: 28 Time: 0.026064
[03/27/2022-19:11:25] [V] [TRT] Fastest Tactic: 0 Time: 0.005376
[03/27/2022-19:11:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_100), Mul_101) (PointWise)
[03/27/2022-19:11:25] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0
[03/27/2022-19:11:25] [V] [TRT] *************** Autotuning format combination: Float(12,1,12,12) -> Float(12,1,12,12) ***************
[03/27/2022-19:11:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_100), Mul_101) (PointWiseV2)
[03/27/2022-19:11:25] [V] [TRT] Tactic: 0 Time: 0.005632
[03/27/2022-19:11:25] [V] [TRT] Tactic: 1 Time: 0.006012
[03/27/2022-19:11:25] [V] [TRT] Tactic: 2 Time: 0.005884
[03/27/2022-19:11:25] [V] [TRT] Tactic: 3 Time: 0.006272
[03/27/2022-19:11:25] [V] [TRT] Tactic: 4 Time: 0.00588
[03/27/2022-19:11:25] [V] [TRT] Tactic: 5 Time: 0.005884
[03/27/2022-19:11:26] [V] [TRT] Tactic: 6 Time: 0.006648
[03/27/2022-19:11:26] [V] [TRT] Tactic: 7 Time: 0.006272
[03/27/2022-19:11:26] [V] [TRT] Tactic: 8 Time: 0.006008
[03/27/2022-19:11:26] [V] [TRT] Tactic: 9 Time: 0.006276
[03/27/2022-19:11:26] [V] [TRT] Tactic: 28 Time: 0.005632
[03/27/2022-19:11:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005632
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_100), Mul_101) (PointWise)
[03/27/2022-19:11:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0
[03/27/2022-19:11:26] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_100), Mul_101) (PointWiseV2)
[03/27/2022-19:11:26] [V] [TRT] Tactic: 24 Time: 0.006016
[03/27/2022-19:11:26] [V] [TRT] Tactic: 25 Time: 0.006528
[03/27/2022-19:11:26] [V] [TRT] Tactic: 26 Time: 0.006788
[03/27/2022-19:11:26] [V] [TRT] Tactic: 27 Time: 0.007424
[03/27/2022-19:11:26] [V] [TRT] Tactic: 31 Time: 0.0064
[03/27/2022-19:11:26] [V] [TRT] Fastest Tactic: 24 Time: 0.006016
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_100), Mul_101) (PointWise)
[03/27/2022-19:11:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[03/27/2022-19:11:26] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:26] [V] [TRT] *************** Autotuning format combination: Float(12,1,1,1) -> Float(288,1,1,1) ***************
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: Conv_102 (CudaDepthwiseConvolution)
[03/27/2022-19:11:26] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: Conv_102 (FusedConvActConvolution)
[03/27/2022-19:11:26] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: Conv_102 (CudnnConvolution)
[03/27/2022-19:11:26] [V] [TRT] Tactic: 0 Time: 0.011904
[03/27/2022-19:11:26] [V] [TRT] Tactic: 1 Time: 0.009472
[03/27/2022-19:11:26] [V] [TRT] Tactic: 2 Time: 0.018048
[03/27/2022-19:11:26] [V] [TRT] Tactic: 4 Time: 0.100604
[03/27/2022-19:11:26] [V] [TRT] Tactic: 5 Time: 0.046212
[03/27/2022-19:11:26] [V] [TRT] Fastest Tactic: 1 Time: 0.009472
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: Conv_102 (CublasConvolution)
[03/27/2022-19:11:26] [V] [TRT] Tactic: 0 Time: 0.014712
[03/27/2022-19:11:26] [V] [TRT] Tactic: 1 Time: 0.00998
[03/27/2022-19:11:26] [V] [TRT] Fastest Tactic: 1 Time: 0.00998
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: Conv_102 (CaskConvolution)
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:26] [V] [TRT] Tactic: 1062367460111450758 Time: 0.014336
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:26] [V] [TRT] Tactic: 1698681053543049347 Time: 0.01024
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:26] [V] [TRT] Tactic: 4501471010995462441 Time: 0.013952
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:26] [V] [TRT] Tactic: 5137655947464784826 Time: 0.013184
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:26] [V] [TRT] Tactic: 5288347012147084929 Time: 0.014332
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:26] [V] [TRT] Tactic: 5326823351883942011 Time: 0.013952
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:26] [V] [TRT] Tactic: 5500448035057547314 Time: 0.012544
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:26] [V] [TRT] Tactic: 6645123197870846056 Time: 0.014076
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:26] [V] [TRT] Tactic: 7144526460361122478 Time: 0.010752
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:26] [V] [TRT] Tactic: -8262349710178828730 Time: 0.014592
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:26] [V] [TRT] Tactic: -6576203419454146580 Time: 0.014204
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:26] [V] [TRT] Tactic: -4787320710726427159 Time: 0.010496
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:26] [V] [TRT] Tactic: -3456450830548107839 Time: 0.01574
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:26] [V] [TRT] Tactic: -1218658103698133241 Time: 0.012928
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:26] [V] [TRT] Tactic: -836875257600482091 Time: 0.01728
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:26] [V] [TRT] Tactic: -410470605513481746 Time: 0.014204
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:26] [V] [TRT] Tactic: -377491875521947884 Time: 0.014588
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:26] [V] [TRT] Tactic: -37215280111360163 Time: 0.013568
[03/27/2022-19:11:26] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.01024
[03/27/2022-19:11:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/27/2022-19:11:26] [V] [TRT] *************** Autotuning format combination: Float(12,1,12,12) -> Float(288,1,288,288) ***************
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: Conv_102 (CublasConvolution)
[03/27/2022-19:11:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: Conv_102 (CaskConvolution)
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:11:26] [V] [TRT] Tactic: 3886731678879822788 Time: 0.011648
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:11:26] [V] [TRT] Tactic: 6629944304117643200 Time: 0.011904
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:11:26] [V] [TRT] Tactic: -9153228964338181824 Time: 0.011776
[03/27/2022-19:11:26] [V] [TRT] Conv_102 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:11:26] [V] [TRT] Tactic: -7394439838318485025 Time: 0.011772
[03/27/2022-19:11:26] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.011648
[03/27/2022-19:11:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:11:26] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:26] [V] [TRT] *************** Autotuning format combination: Float(288,1,1,1), Float(1179648,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_103), Mul_104) (PointWiseV2)
[03/27/2022-19:11:26] [V] [TRT] Tactic: 0 Time: 0.187264
[03/27/2022-19:11:26] [V] [TRT] Tactic: 1 Time: 0.132604
[03/27/2022-19:11:26] [V] [TRT] Tactic: 2 Time: 0.132224
[03/27/2022-19:11:26] [V] [TRT] Tactic: 3 Time: 0.144
[03/27/2022-19:11:26] [V] [TRT] Tactic: 4 Time: 0.14592
[03/27/2022-19:11:26] [V] [TRT] Tactic: 5 Time: 0.14208
[03/27/2022-19:11:26] [V] [TRT] Tactic: 6 Time: 0.174848
[03/27/2022-19:11:26] [V] [TRT] Tactic: 7 Time: 0.182528
[03/27/2022-19:11:26] [V] [TRT] Tactic: 8 Time: 0.178428
[03/27/2022-19:11:26] [V] [TRT] Tactic: 9 Time: 0.15616
[03/27/2022-19:11:26] [V] [TRT] Tactic: 28 Time: 0.178432
[03/27/2022-19:11:26] [V] [TRT] Fastest Tactic: 2 Time: 0.132224
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_103), Mul_104) (PointWise)
[03/27/2022-19:11:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:11:26] [V] [TRT] *************** Autotuning format combination: Float(288,1,288,288), Float(1179648,1,18432,288) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_103), Mul_104) (PointWiseV2)
[03/27/2022-19:11:26] [V] [TRT] Tactic: 0 Time: 0.226944
[03/27/2022-19:11:26] [V] [TRT] Tactic: 1 Time: 0.208896
[03/27/2022-19:11:26] [V] [TRT] Tactic: 2 Time: 0.2089
[03/27/2022-19:11:26] [V] [TRT] Tactic: 3 Time: 0.208892
[03/27/2022-19:11:26] [V] [TRT] Tactic: 4 Time: 0.208512
[03/27/2022-19:11:26] [V] [TRT] Tactic: 5 Time: 0.208252
[03/27/2022-19:11:26] [V] [TRT] Tactic: 6 Time: 0.206972
[03/27/2022-19:11:26] [V] [TRT] Tactic: 7 Time: 0.205184
[03/27/2022-19:11:26] [V] [TRT] Tactic: 8 Time: 0.206592
[03/27/2022-19:11:26] [V] [TRT] Tactic: 9 Time: 0.208
[03/27/2022-19:11:26] [V] [TRT] Tactic: 28 Time: 0.222468
[03/27/2022-19:11:26] [V] [TRT] Fastest Tactic: 7 Time: 0.205184
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_103), Mul_104) (PointWise)
[03/27/2022-19:11:26] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[03/27/2022-19:11:26] [V] [TRT] *************** Autotuning format combination: Float(9,1:32,1,1), Float(36864,4096:32,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:11:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_103), Mul_104) (PointWiseV2)
[03/27/2022-19:11:27] [V] [TRT] Tactic: 24 Time: 0.10688
[03/27/2022-19:11:27] [V] [TRT] Tactic: 25 Time: 0.098176
[03/27/2022-19:11:27] [V] [TRT] Tactic: 26 Time: 0.09792
[03/27/2022-19:11:27] [V] [TRT] Tactic: 27 Time: 0.097792
[03/27/2022-19:11:27] [V] [TRT] Tactic: 31 Time: 0.106624
[03/27/2022-19:11:27] [V] [TRT] Fastest Tactic: 27 Time: 0.097792
[03/27/2022-19:11:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_103), Mul_104) (PointWise)
[03/27/2022-19:11:27] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1), Float(196608,4096,64,1) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] --------------- Timing Runner: Conv_105 + Add_106 (CudaDepthwiseConvolution)
[03/27/2022-19:11:27] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:27] [V] [TRT] --------------- Timing Runner: Conv_105 + Add_106 (FusedConvActConvolution)
[03/27/2022-19:11:27] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:27] [V] [TRT] --------------- Timing Runner: Conv_105 + Add_106 (CudnnConvolution)
[03/27/2022-19:11:27] [V] [TRT] Tactic: 0 Time: 0.408832
[03/27/2022-19:11:27] [V] [TRT] Tactic: 1 Time: 0.329984
[03/27/2022-19:11:27] [V] [TRT] Tactic: 2 Time: 0.617472
[03/27/2022-19:11:27] [V] [TRT] Tactic: 4 Time: 3.52909
[03/27/2022-19:11:27] [V] [TRT] Tactic: 5 Time: 1.38316
[03/27/2022-19:11:27] [V] [TRT] Fastest Tactic: 1 Time: 0.329984
[03/27/2022-19:11:27] [V] [TRT] --------------- Timing Runner: Conv_105 + Add_106 (CublasConvolution)
[03/27/2022-19:11:27] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:27] [V] [TRT] --------------- Timing Runner: Conv_105 + Add_106 (CaskConvolution)
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:27] [V] [TRT] Tactic: 1062367460111450758 Time: 0.13606
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:27] [V] [TRT] Tactic: 1698681053543049347 Time: 0.152064
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:27] [V] [TRT] Tactic: 4501471010995462441 Time: 0.199168
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:27] [V] [TRT] Tactic: 5137655947464784826 Time: 0.114044
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:27] [V] [TRT] Tactic: 5288347012147084929 Time: 0.207616
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:27] [V] [TRT] Tactic: 5326823351883942011 Time: 0.262272
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:27] [V] [TRT] Tactic: 5500448035057547314 Time: 0.130944
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:27] [V] [TRT] Tactic: 6645123197870846056 Time: 0.113024
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:27] [V] [TRT] Tactic: 7144526460361122478 Time: 0.135296
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:27] [V] [TRT] Tactic: -8262349710178828730 Time: 0.185336
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:27] [V] [TRT] Tactic: -6576203419454146580 Time: 0.124288
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:27] [V] [TRT] Tactic: -4787320710726427159 Time: 0.137344
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:27] [V] [TRT] Tactic: -3456450830548107839 Time: 0.129408
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:27] [V] [TRT] Tactic: -1218658103698133241 Time: 0.137088
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:27] [V] [TRT] Tactic: -836875257600482091 Time: 0.13376
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:27] [V] [TRT] Tactic: -410470605513481746 Time: 0.180228
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:27] [V] [TRT] Tactic: -377491875521947884 Time: 0.180224
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:27] [V] [TRT] Tactic: -37215280111360163 Time: 0.113152
[03/27/2022-19:11:27] [V] [TRT] Fastest Tactic: 6645123197870846056 Time: 0.113024
[03/27/2022-19:11:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6645123197870846056
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,1,18432,288), Float(196608,1,3072,48) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:11:27] [V] [TRT] --------------- Timing Runner: Conv_105 + Add_106 (CublasConvolution)
[03/27/2022-19:11:27] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:27] [V] [TRT] --------------- Timing Runner: Conv_105 + Add_106 (CaskConvolution)
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:11:27] [V] [TRT] Tactic: 3886731678879822788 Time: 0.139264
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:11:27] [V] [TRT] Tactic: 6629944304117643200 Time: 0.131204
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:11:27] [V] [TRT] Tactic: -9153228964338181824 Time: 0.116352
[03/27/2022-19:11:27] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:11:27] [V] [TRT] Tactic: -7394439838318485025 Time: 0.138372
[03/27/2022-19:11:27] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.116352
[03/27/2022-19:11:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(196608,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(196608,1,3072,48) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,1,18432,288) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(36864,4096:32,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,1,18432,288) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,1,18432,288) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(36864,4096:32,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1) -> Float(288,1,1,1) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(288,1,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(288,1,288,288) -> Float(12,1,12,12) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(12,1,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(12,1,12,12) -> Float(12,1,12,12) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(12,1,1,1) -> Float(288,1,1,1) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(12,1,12,12) -> Float(288,1,288,288) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(288,1,1,1), Float(1179648,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(288,1,288,288), Float(1179648,1,18432,288) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(9,1:32,1,1), Float(36864,4096:32,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1), Float(196608,4096,64,1) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,1,18432,288), Float(196608,1,3072,48) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(196608,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(196608,1,3072,48) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1) -> Float(1179648,4096,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,1,18432,288) -> Float(1179648,1,18432,288) ***************
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(36864,4096:32,64,1) -> Float(36864,4096:32,64,1) ***************
[03/27/2022-19:11:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:27] [V] [TRT] *************** Autotuning format combination: Float(1179648,4096,64,1) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:11:27] [V] [TRT] --------------- Timing Runner: Conv_125 (CudaDepthwiseConvolution)
[03/27/2022-19:11:27] [V] [TRT] Tactic: -1 Time: 0.105984
[03/27/2022-19:11:27] [V] [TRT] Fastest Tactic: -1 Time: 0.105984
[03/27/2022-19:11:27] [V] [TRT] --------------- Timing Runner: Conv_125 (CudnnConvolution)
[03/27/2022-19:11:28] [V] [TRT] Tactic: 0 Time: 0.211584
[03/27/2022-19:11:28] [V] [TRT] Tactic: 1 Time: 0.211328
[03/27/2022-19:11:28] [V] [TRT] Tactic: 2 Time: 0.211584
[03/27/2022-19:11:31] [V] [TRT] Tactic: 5 Time: 130.095
[03/27/2022-19:11:31] [V] [TRT] Fastest Tactic: 1 Time: 0.211328
[03/27/2022-19:11:31] [V] [TRT] --------------- Timing Runner: Conv_125 (CaskConvolution)
[03/27/2022-19:11:31] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:31] [V] [TRT] Tactic: 1062367460111450758 Time: 3.80646
[03/27/2022-19:11:31] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:11:31] [V] [TRT] Tactic: 1754984623894446479 Time: 2.23437
[03/27/2022-19:11:31] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:11:31] [V] [TRT] Tactic: 3611739942397549984 Time: 4.04326
[03/27/2022-19:11:31] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:11:31] [V] [TRT] Tactic: 4337000649858996379 Time: 2.98586
[03/27/2022-19:11:31] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:31] [V] [TRT] Tactic: 4501471010995462441 Time: 3.8775
[03/27/2022-19:11:31] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:31] [V] [TRT] Tactic: 5137655947464784826 Time: 3.65836
[03/27/2022-19:11:31] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:31] [V] [TRT] Tactic: 5288347012147084929 Time: 3.91104
[03/27/2022-19:11:31] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:31] [V] [TRT] Tactic: 6645123197870846056 Time: 6.60608
[03/27/2022-19:11:32] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:32] [V] [TRT] Tactic: 7144526460361122478 Time: 10.3016
[03/27/2022-19:11:32] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:11:32] [V] [TRT] Tactic: -9137461792520977713 Time: 3.73146
[03/27/2022-19:11:32] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:32] [V] [TRT] Tactic: -8262349710178828730 Time: 3.92666
[03/27/2022-19:11:32] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:11:32] [V] [TRT] Tactic: -8133971918129952780 Time: 4.13581
[03/27/2022-19:11:32] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:11:32] [V] [TRT] Tactic: -6092040395344634144 Time: 3.21267
[03/27/2022-19:11:32] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:32] [V] [TRT] Tactic: -4787320710726427159 Time: 2.22374
[03/27/2022-19:11:32] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:32] [V] [TRT] Tactic: -3456450830548107839 Time: 2.99584
[03/27/2022-19:11:33] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:33] [V] [TRT] Tactic: -1218658103698133241 Time: 3.98158
[03/27/2022-19:11:33] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:33] [V] [TRT] Tactic: -836875257600482091 Time: 2.90892
[03/27/2022-19:11:33] [V] [TRT] Conv_125 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:33] [V] [TRT] Tactic: -410470605513481746 Time: 4.77543
[03/27/2022-19:11:33] [V] [TRT] Fastest Tactic: -4787320710726427159 Time: 2.22374
[03/27/2022-19:11:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(1179648,1,18432,288) -> Float(294912,1,9216,288) ***************
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: Conv_125 (CaskConvolution)
[03/27/2022-19:11:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:33] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(294912,1024,32,1) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_126), Mul_127) (PointWiseV2)
[03/27/2022-19:11:33] [V] [TRT] Tactic: 0 Time: 0.032768
[03/27/2022-19:11:33] [V] [TRT] Tactic: 1 Time: 0.0288
[03/27/2022-19:11:33] [V] [TRT] Tactic: 2 Time: 0.028416
[03/27/2022-19:11:33] [V] [TRT] Tactic: 3 Time: 0.028916
[03/27/2022-19:11:33] [V] [TRT] Tactic: 4 Time: 0.028292
[03/27/2022-19:11:33] [V] [TRT] Tactic: 5 Time: 0.028028
[03/27/2022-19:11:33] [V] [TRT] Tactic: 6 Time: 0.029952
[03/27/2022-19:11:33] [V] [TRT] Tactic: 7 Time: 0.028416
[03/27/2022-19:11:33] [V] [TRT] Tactic: 8 Time: 0.02816
[03/27/2022-19:11:33] [V] [TRT] Tactic: 9 Time: 0.028288
[03/27/2022-19:11:33] [V] [TRT] Tactic: 28 Time: 0.032512
[03/27/2022-19:11:33] [V] [TRT] Fastest Tactic: 5 Time: 0.028028
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_126), Mul_127) (PointWise)
[03/27/2022-19:11:33] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(294912,1,9216,288) -> Float(294912,1,9216,288) ***************
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_126), Mul_127) (PointWiseV2)
[03/27/2022-19:11:33] [V] [TRT] Tactic: 0 Time: 0.033024
[03/27/2022-19:11:33] [V] [TRT] Tactic: 1 Time: 0.029312
[03/27/2022-19:11:33] [V] [TRT] Tactic: 2 Time: 0.028412
[03/27/2022-19:11:33] [V] [TRT] Tactic: 3 Time: 0.028928
[03/27/2022-19:11:33] [V] [TRT] Tactic: 4 Time: 0.028668
[03/27/2022-19:11:33] [V] [TRT] Tactic: 5 Time: 0.028032
[03/27/2022-19:11:33] [V] [TRT] Tactic: 6 Time: 0.03008
[03/27/2022-19:11:33] [V] [TRT] Tactic: 7 Time: 0.028288
[03/27/2022-19:11:33] [V] [TRT] Tactic: 8 Time: 0.027648
[03/27/2022-19:11:33] [V] [TRT] Tactic: 9 Time: 0.02816
[03/27/2022-19:11:33] [V] [TRT] Tactic: 28 Time: 0.03264
[03/27/2022-19:11:33] [V] [TRT] Fastest Tactic: 8 Time: 0.027648
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_126), Mul_127) (PointWise)
[03/27/2022-19:11:33] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(9216,1024:32,32,1) -> Float(9216,1024:32,32,1) ***************
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_126), Mul_127) (PointWiseV2)
[03/27/2022-19:11:33] [V] [TRT] Tactic: 24 Time: 0.027656
[03/27/2022-19:11:33] [V] [TRT] Tactic: 25 Time: 0.02752
[03/27/2022-19:11:33] [V] [TRT] Tactic: 26 Time: 0.028928
[03/27/2022-19:11:33] [V] [TRT] Tactic: 27 Time: 0.029188
[03/27/2022-19:11:33] [V] [TRT] Tactic: 31 Time: 0.027392
[03/27/2022-19:11:33] [V] [TRT] Fastest Tactic: 31 Time: 0.027392
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_126), Mul_127) (PointWise)
[03/27/2022-19:11:33] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:11:33] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(294912,1024,32,1) -> Float(288,1,1,1) ***************
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: ReduceMean_128 (TiledPooling)
[03/27/2022-19:11:33] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: ReduceMean_128 (CudnnPooling)
[03/27/2022-19:11:33] [V] [TRT] Tactic: -1 Time: 0.021888
[03/27/2022-19:11:33] [V] [TRT] Fastest Tactic: -1 Time: 0.021888
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: ReduceMean_128 (CaskPooling)
[03/27/2022-19:11:33] [V] [TRT] ReduceMean_128 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:11:33] [V] [TRT] Tactic: 6119644359078410246 Time: 0.023808
[03/27/2022-19:11:33] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.023808
[03/27/2022-19:11:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[03/27/2022-19:11:33] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(288,1,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(288,1,288,288) -> Float(12,1,12,12) ***************
[03/27/2022-19:11:33] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(12,1,1,1) -> Float(12,1,1,1) ***************
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(12,1,12,12) -> Float(12,1,12,12) ***************
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:11:33] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(12,1,1,1) -> Float(288,1,1,1) ***************
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(12,1,12,12) -> Float(288,1,288,288) ***************
[03/27/2022-19:11:33] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(288,1,1,1), Float(294912,1024,32,1) -> Float(294912,1024,32,1) ***************
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_133), Mul_134) (PointWiseV2)
[03/27/2022-19:11:33] [V] [TRT] Tactic: 0 Time: 0.05248
[03/27/2022-19:11:33] [V] [TRT] Tactic: 1 Time: 0.06246
[03/27/2022-19:11:33] [V] [TRT] Tactic: 2 Time: 0.056956
[03/27/2022-19:11:33] [V] [TRT] Tactic: 3 Time: 0.070528
[03/27/2022-19:11:33] [V] [TRT] Tactic: 4 Time: 0.072832
[03/27/2022-19:11:33] [V] [TRT] Tactic: 5 Time: 0.064
[03/27/2022-19:11:33] [V] [TRT] Tactic: 6 Time: 0.08678
[03/27/2022-19:11:33] [V] [TRT] Tactic: 7 Time: 0.090752
[03/27/2022-19:11:33] [V] [TRT] Tactic: 8 Time: 0.088956
[03/27/2022-19:11:33] [V] [TRT] Tactic: 9 Time: 0.076544
[03/27/2022-19:11:33] [V] [TRT] Tactic: 28 Time: 0.050556
[03/27/2022-19:11:33] [V] [TRT] Fastest Tactic: 28 Time: 0.050556
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_133), Mul_134) (PointWise)
[03/27/2022-19:11:33] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(288,1,288,288), Float(294912,1,9216,288) -> Float(294912,1,9216,288) ***************
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_133), Mul_134) (PointWiseV2)
[03/27/2022-19:11:33] [V] [TRT] Tactic: 0 Time: 0.062976
[03/27/2022-19:11:33] [V] [TRT] Tactic: 1 Time: 0.054652
[03/27/2022-19:11:33] [V] [TRT] Tactic: 2 Time: 0.054268
[03/27/2022-19:11:33] [V] [TRT] Tactic: 3 Time: 0.055296
[03/27/2022-19:11:33] [V] [TRT] Tactic: 4 Time: 0.0544
[03/27/2022-19:11:33] [V] [TRT] Tactic: 5 Time: 0.053632
[03/27/2022-19:11:33] [V] [TRT] Tactic: 6 Time: 0.059264
[03/27/2022-19:11:33] [V] [TRT] Tactic: 7 Time: 0.053124
[03/27/2022-19:11:33] [V] [TRT] Tactic: 8 Time: 0.05222
[03/27/2022-19:11:33] [V] [TRT] Tactic: 9 Time: 0.055044
[03/27/2022-19:11:33] [V] [TRT] Tactic: 28 Time: 0.061184
[03/27/2022-19:11:33] [V] [TRT] Fastest Tactic: 8 Time: 0.05222
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_133), Mul_134) (PointWise)
[03/27/2022-19:11:33] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(9,1:32,1,1), Float(9216,1024:32,32,1) -> Float(9216,1024:32,32,1) ***************
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_133), Mul_134) (PointWiseV2)
[03/27/2022-19:11:33] [V] [TRT] Tactic: 24 Time: 0.029952
[03/27/2022-19:11:33] [V] [TRT] Tactic: 25 Time: 0.029564
[03/27/2022-19:11:33] [V] [TRT] Tactic: 26 Time: 0.029824
[03/27/2022-19:11:33] [V] [TRT] Tactic: 27 Time: 0.03046
[03/27/2022-19:11:33] [V] [TRT] Tactic: 31 Time: 0.030204
[03/27/2022-19:11:33] [V] [TRT] Fastest Tactic: 25 Time: 0.029564
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_133), Mul_134) (PointWise)
[03/27/2022-19:11:33] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[03/27/2022-19:11:33] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:33] [V] [TRT] *************** Autotuning format combination: Float(294912,1024,32,1) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: Conv_135 (CudaDepthwiseConvolution)
[03/27/2022-19:11:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: Conv_135 (FusedConvActConvolution)
[03/27/2022-19:11:33] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:33] [V] [TRT] --------------- Timing Runner: Conv_135 (CudnnConvolution)
[03/27/2022-19:11:34] [V] [TRT] Tactic: 0 Time: 0.09664
[03/27/2022-19:11:34] [V] [TRT] Tactic: 1 Time: 0.07168
[03/27/2022-19:11:34] [V] [TRT] Tactic: 2 Time: 0.207744
[03/27/2022-19:11:34] [V] [TRT] Tactic: 4 Time: 1.00608
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5 Time: 0.17882
[03/27/2022-19:11:34] [V] [TRT] Fastest Tactic: 1 Time: 0.07168
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_135 (CublasConvolution)
[03/27/2022-19:11:34] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_135 (CaskConvolution)
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:34] [V] [TRT] Tactic: 1062367460111450758 Time: 0.059264
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:34] [V] [TRT] Tactic: 1698681053543049347 Time: 0.05696
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:34] [V] [TRT] Tactic: 4501471010995462441 Time: 0.076032
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5137655947464784826 Time: 0.065408
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5288347012147084929 Time: 0.075904
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5326823351883942011 Time: 0.074112
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5500448035057547314 Time: 0.068864
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:34] [V] [TRT] Tactic: 6645123197870846056 Time: 0.067584
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:34] [V] [TRT] Tactic: 7144526460361122478 Time: 0.059268
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:34] [V] [TRT] Tactic: -8262349710178828730 Time: 0.077696
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:34] [V] [TRT] Tactic: -6576203419454146580 Time: 0.052736
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:34] [V] [TRT] Tactic: -4787320710726427159 Time: 0.060288
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:34] [V] [TRT] Tactic: -3456450830548107839 Time: 0.055168
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:34] [V] [TRT] Tactic: -1218658103698133241 Time: 0.072832
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:34] [V] [TRT] Tactic: -836875257600482091 Time: 0.070652
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:34] [V] [TRT] Tactic: -410470605513481746 Time: 0.07488
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:34] [V] [TRT] Tactic: -377491875521947884 Time: 0.07488
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:34] [V] [TRT] Tactic: -37215280111360163 Time: 0.064256
[03/27/2022-19:11:34] [V] [TRT] Fastest Tactic: -6576203419454146580 Time: 0.052736
[03/27/2022-19:11:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6576203419454146580
[03/27/2022-19:11:34] [V] [TRT] *************** Autotuning format combination: Float(294912,1,9216,288) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_135 (CublasConvolution)
[03/27/2022-19:11:34] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_135 (CaskConvolution)
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:11:34] [V] [TRT] Tactic: 3886731678879822788 Time: 0.062848
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:11:34] [V] [TRT] Tactic: 6629944304117643200 Time: 0.04928
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:11:34] [V] [TRT] Tactic: -9153228964338181824 Time: 0.049788
[03/27/2022-19:11:34] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:11:34] [V] [TRT] Tactic: -7394439838318485025 Time: 0.06374
[03/27/2022-19:11:34] [V] [TRT] Fastest Tactic: 6629944304117643200 Time: 0.04928
[03/27/2022-19:11:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200
[03/27/2022-19:11:34] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:34] [V] [TRT] *************** Autotuning format combination: Float(90112,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_136 (CudaDepthwiseConvolution)
[03/27/2022-19:11:34] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_136 (FusedConvActConvolution)
[03/27/2022-19:11:34] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_136 (CudnnConvolution)
[03/27/2022-19:11:34] [V] [TRT] Tactic: 0 Time: 0.218752
[03/27/2022-19:11:34] [V] [TRT] Tactic: 1 Time: 0.132484
[03/27/2022-19:11:34] [V] [TRT] Tactic: 2 Time: 0.22514
[03/27/2022-19:11:34] [V] [TRT] Tactic: 4 Time: 1.59475
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5 Time: 0.305152
[03/27/2022-19:11:34] [V] [TRT] Fastest Tactic: 1 Time: 0.132484
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_136 (CublasConvolution)
[03/27/2022-19:11:34] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskConvolution)
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:34] [V] [TRT] Tactic: 1062367460111450758 Time: 0.08896
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:34] [V] [TRT] Tactic: 1698681053543049347 Time: 0.0841
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:34] [V] [TRT] Tactic: 4501471010995462441 Time: 0.091008
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5137655947464784826 Time: 0.078592
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5288347012147084929 Time: 0.090752
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5326823351883942011 Time: 0.089472
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5500448035057547314 Time: 0.085252
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:34] [V] [TRT] Tactic: 6645123197870846056 Time: 0.080008
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:34] [V] [TRT] Tactic: 7144526460361122478 Time: 0.0896
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:34] [V] [TRT] Tactic: -8262349710178828730 Time: 0.091908
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:34] [V] [TRT] Tactic: -6576203419454146580 Time: 0.082816
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:34] [V] [TRT] Tactic: -4787320710726427159 Time: 0.091508
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:34] [V] [TRT] Tactic: -3456450830548107839 Time: 0.085632
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:34] [V] [TRT] Tactic: -1218658103698133241 Time: 0.089088
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:34] [V] [TRT] Tactic: -836875257600482091 Time: 0.088064
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:34] [V] [TRT] Tactic: -410470605513481746 Time: 0.089984
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:34] [V] [TRT] Tactic: -377491875521947884 Time: 0.090108
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:34] [V] [TRT] Tactic: -37215280111360163 Time: 0.078336
[03/27/2022-19:11:34] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.078336
[03/27/2022-19:11:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[03/27/2022-19:11:34] [V] [TRT] *************** Autotuning format combination: Float(90112,1,2816,88) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_136 (CublasConvolution)
[03/27/2022-19:11:34] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskConvolution)
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:11:34] [V] [TRT] Tactic: 3886731678879822788 Time: 0.085888
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:11:34] [V] [TRT] Tactic: 6629944304117643200 Time: 0.10802
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:11:34] [V] [TRT] Tactic: -9153228964338181824 Time: 0.109568
[03/27/2022-19:11:34] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:11:34] [V] [TRT] Tactic: -7394439838318485025 Time: 0.08614
[03/27/2022-19:11:34] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.085888
[03/27/2022-19:11:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:11:34] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:34] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_137), Mul_138) (PointWiseV2)
[03/27/2022-19:11:34] [V] [TRT] Tactic: 0 Time: 0.055168
[03/27/2022-19:11:34] [V] [TRT] Tactic: 1 Time: 0.04736
[03/27/2022-19:11:34] [V] [TRT] Tactic: 2 Time: 0.046592
[03/27/2022-19:11:34] [V] [TRT] Tactic: 3 Time: 0.047872
[03/27/2022-19:11:34] [V] [TRT] Tactic: 4 Time: 0.04672
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5 Time: 0.046324
[03/27/2022-19:11:34] [V] [TRT] Tactic: 6 Time: 0.049152
[03/27/2022-19:11:34] [V] [TRT] Tactic: 7 Time: 0.047356
[03/27/2022-19:11:34] [V] [TRT] Tactic: 8 Time: 0.046336
[03/27/2022-19:11:34] [V] [TRT] Tactic: 9 Time: 0.046208
[03/27/2022-19:11:34] [V] [TRT] Tactic: 28 Time: 0.054656
[03/27/2022-19:11:34] [V] [TRT] Fastest Tactic: 9 Time: 0.046208
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_137), Mul_138) (PointWise)
[03/27/2022-19:11:34] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[03/27/2022-19:11:34] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_137), Mul_138) (PointWiseV2)
[03/27/2022-19:11:34] [V] [TRT] Tactic: 0 Time: 0.054912
[03/27/2022-19:11:34] [V] [TRT] Tactic: 1 Time: 0.04762
[03/27/2022-19:11:34] [V] [TRT] Tactic: 2 Time: 0.046848
[03/27/2022-19:11:34] [V] [TRT] Tactic: 3 Time: 0.047872
[03/27/2022-19:11:34] [V] [TRT] Tactic: 4 Time: 0.047108
[03/27/2022-19:11:34] [V] [TRT] Tactic: 5 Time: 0.046076
[03/27/2022-19:11:34] [V] [TRT] Tactic: 6 Time: 0.048768
[03/27/2022-19:11:34] [V] [TRT] Tactic: 7 Time: 0.047108
[03/27/2022-19:11:34] [V] [TRT] Tactic: 8 Time: 0.046208
[03/27/2022-19:11:34] [V] [TRT] Tactic: 9 Time: 0.046464
[03/27/2022-19:11:34] [V] [TRT] Tactic: 28 Time: 0.054784
[03/27/2022-19:11:34] [V] [TRT] Fastest Tactic: 5 Time: 0.046076
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_137), Mul_138) (PointWise)
[03/27/2022-19:11:34] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:11:34] [V] [TRT] *************** Autotuning format combination: Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_137), Mul_138) (PointWiseV2)
[03/27/2022-19:11:34] [V] [TRT] Tactic: 24 Time: 0.048252
[03/27/2022-19:11:34] [V] [TRT] Tactic: 25 Time: 0.048128
[03/27/2022-19:11:34] [V] [TRT] Tactic: 26 Time: 0.049024
[03/27/2022-19:11:34] [V] [TRT] Tactic: 27 Time: 0.050052
[03/27/2022-19:11:34] [V] [TRT] Tactic: 31 Time: 0.047996
[03/27/2022-19:11:34] [V] [TRT] Fastest Tactic: 31 Time: 0.047996
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_137), Mul_138) (PointWise)
[03/27/2022-19:11:34] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:11:34] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:34] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_139 (CudaDepthwiseConvolution)
[03/27/2022-19:11:34] [V] [TRT] Tactic: -1 Time: 0.06656
[03/27/2022-19:11:34] [V] [TRT] Fastest Tactic: -1 Time: 0.06656
[03/27/2022-19:11:34] [V] [TRT] --------------- Timing Runner: Conv_139 (CudnnConvolution)
[03/27/2022-19:11:34] [V] [TRT] Tactic: 0 Time: 0.137728
[03/27/2022-19:11:34] [V] [TRT] Tactic: 1 Time: 0.137856
[03/27/2022-19:11:34] [V] [TRT] Tactic: 2 Time: 0.308736
[03/27/2022-19:11:35] [V] [TRT] Tactic: 4 Time: 50.9196
[03/27/2022-19:11:37] [V] [TRT] Tactic: 5 Time: 84.5951
[03/27/2022-19:11:38] [V] [TRT] Tactic: 6 Time: 16.998
[03/27/2022-19:11:38] [V] [TRT] Fastest Tactic: 0 Time: 0.137728
[03/27/2022-19:11:38] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskConvolution)
[03/27/2022-19:11:38] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:38] [V] [TRT] Tactic: 1062367460111450758 Time: 5.74733
[03/27/2022-19:11:38] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:11:38] [V] [TRT] Tactic: 1754984623894446479 Time: 4.19827
[03/27/2022-19:11:38] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:11:38] [V] [TRT] Tactic: 3611739942397549984 Time: 7.19078
[03/27/2022-19:11:38] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:11:38] [V] [TRT] Tactic: 3827454225649558724 Time: 5.29536
[03/27/2022-19:11:38] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:11:38] [V] [TRT] Tactic: 4337000649858996379 Time: 5.49709
[03/27/2022-19:11:38] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:39] [V] [TRT] Tactic: 4501471010995462441 Time: 6.81651
[03/27/2022-19:11:39] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:39] [V] [TRT] Tactic: 5137655947464784826 Time: 5.30764
[03/27/2022-19:11:39] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:39] [V] [TRT] Tactic: 5288347012147084929 Time: 9.49453
[03/27/2022-19:11:39] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:11:39] [V] [TRT] Tactic: 5921334924264294896 Time: 7.28307
[03/27/2022-19:11:39] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:40] [V] [TRT] Tactic: 6645123197870846056 Time: 10.6763
[03/27/2022-19:11:40] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:40] [V] [TRT] Tactic: 7144526460361122478 Time: 16.549
[03/27/2022-19:11:40] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:11:40] [V] [TRT] Tactic: 7852627285308570038 Time: 5.63776
[03/27/2022-19:11:40] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:11:40] [V] [TRT] Tactic: -9137461792520977713 Time: 10.3813
[03/27/2022-19:11:40] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:11:41] [V] [TRT] Tactic: -8776506421218919509 Time: 4.3104
[03/27/2022-19:11:41] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:41] [V] [TRT] Tactic: -8262349710178828730 Time: 7.6082
[03/27/2022-19:11:41] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:11:41] [V] [TRT] Tactic: -8133971918129952780 Time: 9.12512
[03/27/2022-19:11:41] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:11:41] [V] [TRT] Tactic: -6092040395344634144 Time: 8.79514
[03/27/2022-19:11:41] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:41] [V] [TRT] Tactic: -4787320710726427159 Time: 4.04378
[03/27/2022-19:11:42] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:42] [V] [TRT] Tactic: -3456450830548107839 Time: 6.38925
[03/27/2022-19:11:42] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:11:42] [V] [TRT] Tactic: -2318106587342035239 Time: 6.46157
[03/27/2022-19:11:42] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:11:42] [V] [TRT] Tactic: -1343271414618805657 Time: 11.8083
[03/27/2022-19:11:42] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:42] [V] [TRT] Tactic: -1218658103698133241 Time: 6.25331
[03/27/2022-19:11:43] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:43] [V] [TRT] Tactic: -836875257600482091 Time: 6.14387
[03/27/2022-19:11:43] [V] [TRT] Conv_139 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:43] [V] [TRT] Tactic: -410470605513481746 Time: 6.96358
[03/27/2022-19:11:43] [V] [TRT] Fastest Tactic: -4787320710726427159 Time: 4.04378
[03/27/2022-19:11:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:11:43] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskConvolution)
[03/27/2022-19:11:43] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:43] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:43] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:43] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:43] [V] [TRT] *************** Autotuning format combination: Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:43] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:43] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: ReduceMean_142 (TiledPooling)
[03/27/2022-19:11:43] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: ReduceMean_142 (CudnnPooling)
[03/27/2022-19:11:43] [V] [TRT] Tactic: -1 Time: 0.03008
[03/27/2022-19:11:43] [V] [TRT] Fastest Tactic: -1 Time: 0.03008
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: ReduceMean_142 (CaskPooling)
[03/27/2022-19:11:43] [V] [TRT] ReduceMean_142 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:11:43] [V] [TRT] Tactic: 6119644359078410246 Time: 0.031616
[03/27/2022-19:11:43] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.031616
[03/27/2022-19:11:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[03/27/2022-19:11:43] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:43] [V] [TRT] *************** Autotuning format combination: Float(528,1,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: Conv_143 (CudaDepthwiseConvolution)
[03/27/2022-19:11:43] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: Conv_143 (FusedConvActConvolution)
[03/27/2022-19:11:43] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: Conv_143 (CudnnConvolution)
[03/27/2022-19:11:43] [V] [TRT] Tactic: 0 Time: 0.048128
[03/27/2022-19:11:43] [V] [TRT] Tactic: 1 Time: 0.011132
[03/27/2022-19:11:43] [V] [TRT] Tactic: 2 Time: 0.218112
[03/27/2022-19:11:43] [V] [TRT] Tactic: 4 Time: 0.220288
[03/27/2022-19:11:43] [V] [TRT] Tactic: 5 Time: 0.080896
[03/27/2022-19:11:43] [V] [TRT] Fastest Tactic: 1 Time: 0.011132
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: Conv_143 (CublasConvolution)
[03/27/2022-19:11:43] [V] [TRT] Tactic: 0 Time: 0.013156
[03/27/2022-19:11:43] [V] [TRT] Tactic: 1 Time: 0.014076
[03/27/2022-19:11:43] [V] [TRT] Fastest Tactic: 0 Time: 0.013156
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: Conv_143 (CaskConvolution)
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:43] [V] [TRT] Tactic: 1062367460111450758 Time: 0.067968
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:43] [V] [TRT] Tactic: 1698681053543049347 Time: 0.049024
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:43] [V] [TRT] Tactic: 4501471010995462441 Time: 0.073216
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:43] [V] [TRT] Tactic: 5137655947464784826 Time: 0.049664
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:43] [V] [TRT] Tactic: 5288347012147084929 Time: 0.069504
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:43] [V] [TRT] Tactic: 5326823351883942011 Time: 0.068736
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:43] [V] [TRT] Tactic: 5500448035057547314 Time: 0.06144
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:43] [V] [TRT] Tactic: 6645123197870846056 Time: 0.053504
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:43] [V] [TRT] Tactic: 7144526460361122478 Time: 0.050176
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:43] [V] [TRT] Tactic: -8262349710178828730 Time: 0.070528
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:43] [V] [TRT] Tactic: -6576203419454146580 Time: 0.0544
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:43] [V] [TRT] Tactic: -4787320710726427159 Time: 0.054012
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:43] [V] [TRT] Tactic: -3456450830548107839 Time: 0.057724
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:43] [V] [TRT] Tactic: -1218658103698133241 Time: 0.066048
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:43] [V] [TRT] Tactic: -836875257600482091 Time: 0.063232
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:43] [V] [TRT] Tactic: -410470605513481746 Time: 0.068736
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:43] [V] [TRT] Tactic: -377491875521947884 Time: 0.068352
[03/27/2022-19:11:43] [V] [TRT] Conv_143 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:43] [V] [TRT] Tactic: -37215280111360163 Time: 0.049024
[03/27/2022-19:11:43] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.049024
[03/27/2022-19:11:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/27/2022-19:11:43] [V] [TRT] *************** Autotuning format combination: Float(528,1,528,528) -> Float(22,1,22,22) ***************
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: Conv_143 (CublasConvolution)
[03/27/2022-19:11:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: Conv_143 (CaskConvolution)
[03/27/2022-19:11:43] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:43] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:43] [V] [TRT] *************** Autotuning format combination: Float(22,1,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_144), Mul_145) (PointWiseV2)
[03/27/2022-19:11:43] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:11:43] [V] [TRT] Tactic: 1 Time: 0.006144
[03/27/2022-19:11:43] [V] [TRT] Tactic: 2 Time: 0.00576
[03/27/2022-19:11:43] [V] [TRT] Tactic: 3 Time: 0.006272
[03/27/2022-19:11:43] [V] [TRT] Tactic: 4 Time: 0.006264
[03/27/2022-19:11:43] [V] [TRT] Tactic: 5 Time: 0.006144
[03/27/2022-19:11:43] [V] [TRT] Tactic: 6 Time: 0.006656
[03/27/2022-19:11:43] [V] [TRT] Tactic: 7 Time: 0.006272
[03/27/2022-19:11:43] [V] [TRT] Tactic: 8 Time: 0.005632
[03/27/2022-19:11:43] [V] [TRT] Tactic: 9 Time: 0.005632
[03/27/2022-19:11:43] [V] [TRT] Tactic: 28 Time: 0.005376
[03/27/2022-19:11:43] [V] [TRT] Fastest Tactic: 28 Time: 0.005376
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_144), Mul_145) (PointWise)
[03/27/2022-19:11:43] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:11:43] [V] [TRT] *************** Autotuning format combination: Float(22,1,22,22) -> Float(22,1,22,22) ***************
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_144), Mul_145) (PointWiseV2)
[03/27/2022-19:11:43] [V] [TRT] Tactic: 0 Time: 0.005508
[03/27/2022-19:11:43] [V] [TRT] Tactic: 1 Time: 0.006016
[03/27/2022-19:11:43] [V] [TRT] Tactic: 2 Time: 0.006016
[03/27/2022-19:11:43] [V] [TRT] Tactic: 3 Time: 0.0064
[03/27/2022-19:11:43] [V] [TRT] Tactic: 4 Time: 0.005892
[03/27/2022-19:11:43] [V] [TRT] Tactic: 5 Time: 0.006144
[03/27/2022-19:11:43] [V] [TRT] Tactic: 6 Time: 0.006528
[03/27/2022-19:11:43] [V] [TRT] Tactic: 7 Time: 0.006144
[03/27/2022-19:11:43] [V] [TRT] Tactic: 8 Time: 0.005764
[03/27/2022-19:11:43] [V] [TRT] Tactic: 9 Time: 0.00602
[03/27/2022-19:11:43] [V] [TRT] Tactic: 28 Time: 0.005764
[03/27/2022-19:11:43] [V] [TRT] Fastest Tactic: 0 Time: 0.005508
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_144), Mul_145) (PointWise)
[03/27/2022-19:11:43] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0
[03/27/2022-19:11:43] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_144), Mul_145) (PointWiseV2)
[03/27/2022-19:11:43] [V] [TRT] Tactic: 24 Time: 0.006272
[03/27/2022-19:11:43] [V] [TRT] Tactic: 25 Time: 0.006396
[03/27/2022-19:11:43] [V] [TRT] Tactic: 26 Time: 0.007168
[03/27/2022-19:11:43] [V] [TRT] Tactic: 27 Time: 0.007424
[03/27/2022-19:11:43] [V] [TRT] Tactic: 31 Time: 0.0064
[03/27/2022-19:11:43] [V] [TRT] Fastest Tactic: 24 Time: 0.006272
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_144), Mul_145) (PointWise)
[03/27/2022-19:11:43] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[03/27/2022-19:11:43] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:43] [V] [TRT] *************** Autotuning format combination: Float(22,1,1,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: Conv_146 (CudaDepthwiseConvolution)
[03/27/2022-19:11:43] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: Conv_146 (FusedConvActConvolution)
[03/27/2022-19:11:43] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:43] [V] [TRT] --------------- Timing Runner: Conv_146 (CudnnConvolution)
[03/27/2022-19:11:44] [V] [TRT] Tactic: 0 Time: 0.0152
[03/27/2022-19:11:44] [V] [TRT] Tactic: 1 Time: 0.06846
[03/27/2022-19:11:44] [V] [TRT] Tactic: 2 Time: 0.162688
[03/27/2022-19:11:44] [V] [TRT] Tactic: 4 Time: 0.61568
[03/27/2022-19:11:44] [V] [TRT] Tactic: 5 Time: 0.062716
[03/27/2022-19:11:44] [V] [TRT] Fastest Tactic: 0 Time: 0.0152
[03/27/2022-19:11:44] [V] [TRT] --------------- Timing Runner: Conv_146 (CublasConvolution)
[03/27/2022-19:11:44] [V] [TRT] Tactic: 0 Time: 0.009984
[03/27/2022-19:11:44] [V] [TRT] Tactic: 1 Time: 0.010112
[03/27/2022-19:11:44] [V] [TRT] Fastest Tactic: 0 Time: 0.009984
[03/27/2022-19:11:44] [V] [TRT] --------------- Timing Runner: Conv_146 (CaskConvolution)
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:44] [V] [TRT] Tactic: 1062367460111450758 Time: 0.015356
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:44] [V] [TRT] Tactic: 1698681053543049347 Time: 0.011524
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:44] [V] [TRT] Tactic: 4501471010995462441 Time: 0.016892
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:44] [V] [TRT] Tactic: 5137655947464784826 Time: 0.01408
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:44] [V] [TRT] Tactic: 5288347012147084929 Time: 0.015228
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:44] [V] [TRT] Tactic: 5326823351883942011 Time: 0.014968
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:44] [V] [TRT] Tactic: 5500448035057547314 Time: 0.01382
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:44] [V] [TRT] Tactic: 6645123197870846056 Time: 0.01446
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:44] [V] [TRT] Tactic: 7144526460361122478 Time: 0.012032
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:44] [V] [TRT] Tactic: -8262349710178828730 Time: 0.015232
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:44] [V] [TRT] Tactic: -6576203419454146580 Time: 0.014708
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:44] [V] [TRT] Tactic: -4787320710726427159 Time: 0.01152
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:44] [V] [TRT] Tactic: -3456450830548107839 Time: 0.01498
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:44] [V] [TRT] Tactic: -1218658103698133241 Time: 0.014464
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:44] [V] [TRT] Tactic: -836875257600482091 Time: 0.01408
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:44] [V] [TRT] Tactic: -410470605513481746 Time: 0.014848
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:44] [V] [TRT] Tactic: -377491875521947884 Time: 0.01536
[03/27/2022-19:11:44] [V] [TRT] Conv_146 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:44] [V] [TRT] Tactic: -37215280111360163 Time: 0.014208
[03/27/2022-19:11:44] [V] [TRT] Fastest Tactic: -4787320710726427159 Time: 0.01152
[03/27/2022-19:11:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0
[03/27/2022-19:11:44] [V] [TRT] *************** Autotuning format combination: Float(22,1,22,22) -> Float(528,1,528,528) ***************
[03/27/2022-19:11:44] [V] [TRT] --------------- Timing Runner: Conv_146 (CublasConvolution)
[03/27/2022-19:11:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:44] [V] [TRT] --------------- Timing Runner: Conv_146 (CaskConvolution)
[03/27/2022-19:11:44] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:44] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:44] [V] [TRT] *************** Autotuning format combination: Float(528,1,1,1), Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_147), Mul_148) (PointWiseV2)
[03/27/2022-19:11:44] [V] [TRT] Tactic: 0 Time: 0.090748
[03/27/2022-19:11:44] [V] [TRT] Tactic: 1 Time: 0.107392
[03/27/2022-19:11:44] [V] [TRT] Tactic: 2 Time: 0.098812
[03/27/2022-19:11:44] [V] [TRT] Tactic: 3 Time: 0.121856
[03/27/2022-19:11:44] [V] [TRT] Tactic: 4 Time: 0.127488
[03/27/2022-19:11:44] [V] [TRT] Tactic: 5 Time: 0.111616
[03/27/2022-19:11:44] [V] [TRT] Tactic: 6 Time: 0.15232
[03/27/2022-19:11:44] [V] [TRT] Tactic: 7 Time: 0.160384
[03/27/2022-19:11:44] [V] [TRT] Tactic: 8 Time: 0.156028
[03/27/2022-19:11:44] [V] [TRT] Tactic: 9 Time: 0.13376
[03/27/2022-19:11:44] [V] [TRT] Tactic: 28 Time: 0.086396
[03/27/2022-19:11:44] [V] [TRT] Fastest Tactic: 28 Time: 0.086396
[03/27/2022-19:11:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_147), Mul_148) (PointWise)
[03/27/2022-19:11:44] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:11:44] [V] [TRT] *************** Autotuning format combination: Float(528,1,528,528), Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_147), Mul_148) (PointWiseV2)
[03/27/2022-19:11:44] [V] [TRT] Tactic: 0 Time: 0.111876
[03/27/2022-19:11:44] [V] [TRT] Tactic: 1 Time: 0.077952
[03/27/2022-19:11:44] [V] [TRT] Tactic: 2 Time: 0.072192
[03/27/2022-19:11:44] [V] [TRT] Tactic: 3 Time: 0.066304
[03/27/2022-19:11:44] [V] [TRT] Tactic: 4 Time: 0.064896
[03/27/2022-19:11:44] [V] [TRT] Tactic: 5 Time: 0.064644
[03/27/2022-19:11:44] [V] [TRT] Tactic: 6 Time: 0.064768
[03/27/2022-19:11:44] [V] [TRT] Tactic: 7 Time: 0.062848
[03/27/2022-19:11:44] [V] [TRT] Tactic: 8 Time: 0.063484
[03/27/2022-19:11:44] [V] [TRT] Tactic: 9 Time: 0.064512
[03/27/2022-19:11:44] [V] [TRT] Tactic: 28 Time: 0.105732
[03/27/2022-19:11:44] [V] [TRT] Fastest Tactic: 7 Time: 0.062848
[03/27/2022-19:11:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_147), Mul_148) (PointWise)
[03/27/2022-19:11:44] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[03/27/2022-19:11:44] [V] [TRT] *************** Autotuning format combination: Float(17,1:32,1,1), Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_147), Mul_148) (PointWiseV2)
[03/27/2022-19:11:44] [V] [TRT] Tactic: 24 Time: 0.054144
[03/27/2022-19:11:45] [V] [TRT] Tactic: 25 Time: 0.050176
[03/27/2022-19:11:45] [V] [TRT] Tactic: 26 Time: 0.050816
[03/27/2022-19:11:45] [V] [TRT] Tactic: 27 Time: 0.051716
[03/27/2022-19:11:45] [V] [TRT] Tactic: 31 Time: 0.053632
[03/27/2022-19:11:45] [V] [TRT] Fastest Tactic: 25 Time: 0.050176
[03/27/2022-19:11:45] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_147), Mul_148) (PointWise)
[03/27/2022-19:11:45] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1), Float(90112,1024,32,1) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] --------------- Timing Runner: Conv_149 + Add_150 (CudaDepthwiseConvolution)
[03/27/2022-19:11:45] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:45] [V] [TRT] --------------- Timing Runner: Conv_149 + Add_150 (FusedConvActConvolution)
[03/27/2022-19:11:45] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:45] [V] [TRT] --------------- Timing Runner: Conv_149 + Add_150 (CudnnConvolution)
[03/27/2022-19:11:45] [V] [TRT] Tactic: 0 Time: 0.176892
[03/27/2022-19:11:45] [V] [TRT] Tactic: 1 Time: 0.523008
[03/27/2022-19:11:45] [V] [TRT] Tactic: 2 Time: 0.68288
[03/27/2022-19:11:45] [V] [TRT] Tactic: 4 Time: 2.07155
[03/27/2022-19:11:45] [V] [TRT] Tactic: 5 Time: 0.282112
[03/27/2022-19:11:45] [V] [TRT] Fastest Tactic: 0 Time: 0.176892
[03/27/2022-19:11:45] [V] [TRT] --------------- Timing Runner: Conv_149 + Add_150 (CublasConvolution)
[03/27/2022-19:11:45] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:45] [V] [TRT] --------------- Timing Runner: Conv_149 + Add_150 (CaskConvolution)
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:45] [V] [TRT] Tactic: 1062367460111450758 Time: 0.096
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:45] [V] [TRT] Tactic: 1698681053543049347 Time: 0.092416
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:45] [V] [TRT] Tactic: 4501471010995462441 Time: 0.126464
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:45] [V] [TRT] Tactic: 5137655947464784826 Time: 0.107648
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:45] [V] [TRT] Tactic: 5288347012147084929 Time: 0.12544
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:45] [V] [TRT] Tactic: 5326823351883942011 Time: 0.12352
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:45] [V] [TRT] Tactic: 5500448035057547314 Time: 0.113792
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:45] [V] [TRT] Tactic: 6645123197870846056 Time: 0.109564
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:45] [V] [TRT] Tactic: 7144526460361122478 Time: 0.096124
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:45] [V] [TRT] Tactic: -8262349710178828730 Time: 0.127228
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:45] [V] [TRT] Tactic: -6576203419454146580 Time: 0.08602
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:45] [V] [TRT] Tactic: -4787320710726427159 Time: 0.104572
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:45] [V] [TRT] Tactic: -3456450830548107839 Time: 0.088964
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:45] [V] [TRT] Tactic: -1218658103698133241 Time: 0.11904
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:45] [V] [TRT] Tactic: -836875257600482091 Time: 0.116732
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:45] [V] [TRT] Tactic: -410470605513481746 Time: 0.124928
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:45] [V] [TRT] Tactic: -377491875521947884 Time: 0.12416
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:45] [V] [TRT] Tactic: -37215280111360163 Time: 0.104832
[03/27/2022-19:11:45] [V] [TRT] Fastest Tactic: -6576203419454146580 Time: 0.08602
[03/27/2022-19:11:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6576203419454146580
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528), Float(90112,1,2816,88) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:11:45] [V] [TRT] --------------- Timing Runner: Conv_149 + Add_150 (CublasConvolution)
[03/27/2022-19:11:45] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:45] [V] [TRT] --------------- Timing Runner: Conv_149 + Add_150 (CaskConvolution)
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:11:45] [V] [TRT] Tactic: 3886731678879822788 Time: 0.106624
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:11:45] [V] [TRT] Tactic: 6629944304117643200 Time: 0.081284
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:11:45] [V] [TRT] Tactic: -9153228964338181824 Time: 0.082176
[03/27/2022-19:11:45] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:11:45] [V] [TRT] Tactic: -7394439838318485025 Time: 0.106876
[03/27/2022-19:11:45] [V] [TRT] Fastest Tactic: 6629944304117643200 Time: 0.081284
[03/27/2022-19:11:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(90112,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(90112,1,2816,88) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(528,1,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(528,1,528,528) -> Float(22,1,22,22) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(22,1,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(22,1,22,22) -> Float(22,1,22,22) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(22,1,1,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(22,1,22,22) -> Float(528,1,528,528) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(528,1,1,1), Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(528,1,528,528), Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(17,1:32,1,1), Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1), Float(90112,1024,32,1) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528), Float(90112,1,2816,88) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(90112,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(90112,1,2816,88) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(528,1,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(528,1,528,528) -> Float(22,1,22,22) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(22,1,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(22,1,22,22) -> Float(22,1,22,22) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(22,1,1,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(22,1,22,22) -> Float(528,1,528,528) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(528,1,1,1), Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(528,1,528,528), Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(17,1:32,1,1), Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1), Float(90112,1024,32,1) -> Float(90112,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528), Float(90112,1,2816,88) -> Float(90112,1,2816,88) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(90112,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(90112,1,2816,88) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:45] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:45] [V] [TRT] --------------- Timing Runner: Conv_184 (CudaDepthwiseConvolution)
[03/27/2022-19:11:45] [V] [TRT] Tactic: -1 Time: 0.219516
[03/27/2022-19:11:45] [V] [TRT] Fastest Tactic: -1 Time: 0.219516
[03/27/2022-19:11:45] [V] [TRT] --------------- Timing Runner: Conv_184 (CudnnConvolution)
[03/27/2022-19:11:45] [V] [TRT] Tactic: 0 Time: 0.42906
[03/27/2022-19:11:45] [V] [TRT] Tactic: 1 Time: 0.4288
[03/27/2022-19:11:45] [V] [TRT] Tactic: 2 Time: 0.42944
[03/27/2022-19:11:46] [V] [TRT] Tactic: 4 Time: 47.0109
[03/27/2022-19:11:48] [V] [TRT] Tactic: 5 Time: 90.3208
[03/27/2022-19:11:48] [V] [TRT] Fastest Tactic: 1 Time: 0.4288
[03/27/2022-19:11:48] [V] [TRT] --------------- Timing Runner: Conv_184 (CaskConvolution)
[03/27/2022-19:11:48] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:48] [V] [TRT] Tactic: 1062367460111450758 Time: 9.22778
[03/27/2022-19:11:48] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:11:48] [V] [TRT] Tactic: 1754984623894446479 Time: 10.9993
[03/27/2022-19:11:48] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:11:49] [V] [TRT] Tactic: 3611739942397549984 Time: 9.38022
[03/27/2022-19:11:49] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:11:49] [V] [TRT] Tactic: 4337000649858996379 Time: 8.43469
[03/27/2022-19:11:49] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:49] [V] [TRT] Tactic: 4501471010995462441 Time: 11.61
[03/27/2022-19:11:49] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:49] [V] [TRT] Tactic: 5137655947464784826 Time: 6.77991
[03/27/2022-19:11:49] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:49] [V] [TRT] Tactic: 5288347012147084929 Time: 9.04179
[03/27/2022-19:11:49] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:50] [V] [TRT] Tactic: 6645123197870846056 Time: 7.36217
[03/27/2022-19:11:50] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:50] [V] [TRT] Tactic: 7144526460361122478 Time: 5.28294
[03/27/2022-19:11:50] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:11:50] [V] [TRT] Tactic: -9137461792520977713 Time: 8.97754
[03/27/2022-19:11:50] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:50] [V] [TRT] Tactic: -8262349710178828730 Time: 9.90272
[03/27/2022-19:11:50] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:11:50] [V] [TRT] Tactic: -8133971918129952780 Time: 6.87475
[03/27/2022-19:11:51] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:11:51] [V] [TRT] Tactic: -6092040395344634144 Time: 7.64134
[03/27/2022-19:11:51] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:51] [V] [TRT] Tactic: -4787320710726427159 Time: 9.73581
[03/27/2022-19:11:51] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:51] [V] [TRT] Tactic: -3456450830548107839 Time: 9.52333
[03/27/2022-19:11:51] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:51] [V] [TRT] Tactic: -1218658103698133241 Time: 8.40397
[03/27/2022-19:11:51] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:52] [V] [TRT] Tactic: -836875257600482091 Time: 10.2838
[03/27/2022-19:11:52] [V] [TRT] Conv_184 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:52] [V] [TRT] Tactic: -410470605513481746 Time: 8.49856
[03/27/2022-19:11:52] [V] [TRT] Fastest Tactic: 7144526460361122478 Time: 5.28294
[03/27/2022-19:11:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_184 (CaskConvolution)
[03/27/2022-19:11:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:52] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:52] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:11:52] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(528,1,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(528,1,528,528) -> Float(22,1,22,22) ***************
[03/27/2022-19:11:52] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(22,1,1,1) -> Float(22,1,1,1) ***************
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(22,1,22,22) -> Float(22,1,22,22) ***************
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:11:52] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(22,1,1,1) -> Float(528,1,1,1) ***************
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(22,1,22,22) -> Float(528,1,528,528) ***************
[03/27/2022-19:11:52] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(528,1,1,1), Float(540672,1024,32,1) -> Float(540672,1024,32,1) ***************
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(528,1,528,528), Float(540672,1,16896,528) -> Float(540672,1,16896,528) ***************
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(17,1:32,1,1), Float(17408,1024:32,32,1) -> Float(17408,1024:32,32,1) ***************
[03/27/2022-19:11:52] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(540672,1024,32,1) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_194 (CudaDepthwiseConvolution)
[03/27/2022-19:11:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_194 (FusedConvActConvolution)
[03/27/2022-19:11:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_194 (CudnnConvolution)
[03/27/2022-19:11:52] [V] [TRT] Tactic: 0 Time: 0.205824
[03/27/2022-19:11:52] [V] [TRT] Tactic: 1 Time: 0.12096
[03/27/2022-19:11:52] [V] [TRT] Tactic: 2 Time: 0.314368
[03/27/2022-19:11:52] [V] [TRT] Tactic: 4 Time: 2.70477
[03/27/2022-19:11:52] [V] [TRT] Tactic: 5 Time: 0.341376
[03/27/2022-19:11:52] [V] [TRT] Fastest Tactic: 1 Time: 0.12096
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_194 (CublasConvolution)
[03/27/2022-19:11:52] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_194 (CaskConvolution)
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:52] [V] [TRT] Tactic: 1062367460111450758 Time: 0.124928
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:52] [V] [TRT] Tactic: 1698681053543049347 Time: 0.099964
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:52] [V] [TRT] Tactic: 4501471010995462441 Time: 0.125568
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:52] [V] [TRT] Tactic: 5137655947464784826 Time: 0.105984
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:52] [V] [TRT] Tactic: 5288347012147084929 Time: 0.124672
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:52] [V] [TRT] Tactic: 5326823351883942011 Time: 0.12262
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:52] [V] [TRT] Tactic: 5500448035057547314 Time: 0.112128
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:52] [V] [TRT] Tactic: 6645123197870846056 Time: 0.109056
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:52] [V] [TRT] Tactic: 7144526460361122478 Time: 0.107136
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:52] [V] [TRT] Tactic: -8262349710178828730 Time: 0.126456
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:52] [V] [TRT] Tactic: -6576203419454146580 Time: 0.113796
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:52] [V] [TRT] Tactic: -4787320710726427159 Time: 0.111616
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:52] [V] [TRT] Tactic: -3456450830548107839 Time: 0.12032
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:52] [V] [TRT] Tactic: -1218658103698133241 Time: 0.118916
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:52] [V] [TRT] Tactic: -836875257600482091 Time: 0.116096
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:52] [V] [TRT] Tactic: -410470605513481746 Time: 0.123648
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:52] [V] [TRT] Tactic: -377491875521947884 Time: 0.123252
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:52] [V] [TRT] Tactic: -37215280111360163 Time: 0.103424
[03/27/2022-19:11:52] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.099964
[03/27/2022-19:11:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 1698681053543049347
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(540672,1,16896,528) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_194 (CublasConvolution)
[03/27/2022-19:11:52] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_194 (CaskConvolution)
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:11:52] [V] [TRT] Tactic: 3886731678879822788 Time: 0.103808
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:11:52] [V] [TRT] Tactic: 6629944304117643200 Time: 0.094972
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:11:52] [V] [TRT] Tactic: -9153228964338181824 Time: 0.095988
[03/27/2022-19:11:52] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:11:52] [V] [TRT] Tactic: -7394439838318485025 Time: 0.104064
[03/27/2022-19:11:52] [V] [TRT] Fastest Tactic: 6629944304117643200 Time: 0.094972
[03/27/2022-19:11:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200
[03/27/2022-19:11:52] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(122880,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_195 (CudaDepthwiseConvolution)
[03/27/2022-19:11:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_195 (FusedConvActConvolution)
[03/27/2022-19:11:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_195 (CudnnConvolution)
[03/27/2022-19:11:52] [V] [TRT] Tactic: 0 Time: 0.300288
[03/27/2022-19:11:52] [V] [TRT] Tactic: 1 Time: 0.212608
[03/27/2022-19:11:52] [V] [TRT] Tactic: 2 Time: 0.329856
[03/27/2022-19:11:52] [V] [TRT] Tactic: 4 Time: 2.90509
[03/27/2022-19:11:52] [V] [TRT] Tactic: 5 Time: 0.442236
[03/27/2022-19:11:52] [V] [TRT] Fastest Tactic: 1 Time: 0.212608
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_195 (CublasConvolution)
[03/27/2022-19:11:52] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_195 (CaskConvolution)
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:52] [V] [TRT] Tactic: 1062367460111450758 Time: 0.140548
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:11:52] [V] [TRT] Tactic: 1698681053543049347 Time: 0.13376
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:52] [V] [TRT] Tactic: 4501471010995462441 Time: 0.129536
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:52] [V] [TRT] Tactic: 5137655947464784826 Time: 0.126072
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:52] [V] [TRT] Tactic: 5288347012147084929 Time: 0.12928
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:11:52] [V] [TRT] Tactic: 5326823351883942011 Time: 0.125572
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:11:52] [V] [TRT] Tactic: 5500448035057547314 Time: 0.13504
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:52] [V] [TRT] Tactic: 6645123197870846056 Time: 0.126844
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:52] [V] [TRT] Tactic: 7144526460361122478 Time: 0.14208
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:11:52] [V] [TRT] Tactic: -8262349710178828730 Time: 0.128892
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:11:52] [V] [TRT] Tactic: -6576203419454146580 Time: 0.128644
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:11:52] [V] [TRT] Tactic: -4787320710726427159 Time: 0.15104
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:11:52] [V] [TRT] Tactic: -3456450830548107839 Time: 0.133888
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:11:52] [V] [TRT] Tactic: -1218658103698133241 Time: 0.14208
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:11:52] [V] [TRT] Tactic: -836875257600482091 Time: 0.13952
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:11:52] [V] [TRT] Tactic: -410470605513481746 Time: 0.126208
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:11:52] [V] [TRT] Tactic: -377491875521947884 Time: 0.125952
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:11:52] [V] [TRT] Tactic: -37215280111360163 Time: 0.124544
[03/27/2022-19:11:52] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.124544
[03/27/2022-19:11:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(122880,1,3840,120) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_195 (CublasConvolution)
[03/27/2022-19:11:52] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: Conv_195 (CaskConvolution)
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:11:52] [V] [TRT] Tactic: 3886731678879822788 Time: 0.132992
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:11:52] [V] [TRT] Tactic: 6629944304117643200 Time: 0.166404
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:11:52] [V] [TRT] Tactic: -9153228964338181824 Time: 0.168448
[03/27/2022-19:11:52] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:11:52] [V] [TRT] Tactic: -7394439838318485025 Time: 0.131584
[03/27/2022-19:11:52] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.131584
[03/27/2022-19:11:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[03/27/2022-19:11:52] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:52] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:11:52] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_196), Mul_197) (PointWiseV2)
[03/27/2022-19:11:52] [V] [TRT] Tactic: 0 Time: 0.07296
[03/27/2022-19:11:52] [V] [TRT] Tactic: 1 Time: 0.062848
[03/27/2022-19:11:52] [V] [TRT] Tactic: 2 Time: 0.061312
[03/27/2022-19:11:52] [V] [TRT] Tactic: 3 Time: 0.062336
[03/27/2022-19:11:52] [V] [TRT] Tactic: 4 Time: 0.061184
[03/27/2022-19:11:52] [V] [TRT] Tactic: 5 Time: 0.060928
[03/27/2022-19:11:53] [V] [TRT] Tactic: 6 Time: 0.064128
[03/27/2022-19:11:53] [V] [TRT] Tactic: 7 Time: 0.06208
[03/27/2022-19:11:53] [V] [TRT] Tactic: 8 Time: 0.0608
[03/27/2022-19:11:53] [V] [TRT] Tactic: 9 Time: 0.061312
[03/27/2022-19:11:53] [V] [TRT] Tactic: 28 Time: 0.072324
[03/27/2022-19:11:53] [V] [TRT] Fastest Tactic: 8 Time: 0.0608
[03/27/2022-19:11:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_196), Mul_197) (PointWise)
[03/27/2022-19:11:53] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:11:53] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:11:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_196), Mul_197) (PointWiseV2)
[03/27/2022-19:11:53] [V] [TRT] Tactic: 0 Time: 0.072828
[03/27/2022-19:11:53] [V] [TRT] Tactic: 1 Time: 0.062208
[03/27/2022-19:11:53] [V] [TRT] Tactic: 2 Time: 0.061688
[03/27/2022-19:11:53] [V] [TRT] Tactic: 3 Time: 0.062464
[03/27/2022-19:11:53] [V] [TRT] Tactic: 4 Time: 0.061692
[03/27/2022-19:11:53] [V] [TRT] Tactic: 5 Time: 0.060804
[03/27/2022-19:11:53] [V] [TRT] Tactic: 6 Time: 0.063864
[03/27/2022-19:11:53] [V] [TRT] Tactic: 7 Time: 0.061568
[03/27/2022-19:11:53] [V] [TRT] Tactic: 8 Time: 0.06106
[03/27/2022-19:11:53] [V] [TRT] Tactic: 9 Time: 0.061692
[03/27/2022-19:11:53] [V] [TRT] Tactic: 28 Time: 0.072192
[03/27/2022-19:11:53] [V] [TRT] Fastest Tactic: 5 Time: 0.060804
[03/27/2022-19:11:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_196), Mul_197) (PointWise)
[03/27/2022-19:11:53] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:11:53] [V] [TRT] *************** Autotuning format combination: Float(23552,1024:32,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:11:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_196), Mul_197) (PointWiseV2)
[03/27/2022-19:11:53] [V] [TRT] Tactic: 24 Time: 0.062976
[03/27/2022-19:11:53] [V] [TRT] Tactic: 25 Time: 0.062976
[03/27/2022-19:11:53] [V] [TRT] Tactic: 26 Time: 0.064256
[03/27/2022-19:11:53] [V] [TRT] Tactic: 27 Time: 0.06438
[03/27/2022-19:11:53] [V] [TRT] Tactic: 31 Time: 0.06272
[03/27/2022-19:11:53] [V] [TRT] Fastest Tactic: 31 Time: 0.06272
[03/27/2022-19:11:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_196), Mul_197) (PointWise)
[03/27/2022-19:11:53] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:11:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:11:53] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:11:53] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:11:53] [V] [TRT] --------------- Timing Runner: Conv_198 (CudaDepthwiseConvolution)
[03/27/2022-19:11:53] [V] [TRT] Tactic: -1 Time: 0.294016
[03/27/2022-19:11:53] [V] [TRT] Fastest Tactic: -1 Time: 0.294016
[03/27/2022-19:11:53] [V] [TRT] --------------- Timing Runner: Conv_198 (CudnnConvolution)
[03/27/2022-19:11:53] [V] [TRT] Tactic: 0 Time: 0.577792
[03/27/2022-19:11:53] [V] [TRT] Tactic: 1 Time: 0.576896
[03/27/2022-19:11:53] [V] [TRT] Tactic: 2 Time: 0.577664
[03/27/2022-19:11:54] [V] [TRT] Tactic: 4 Time: 64.5763
[03/27/2022-19:11:56] [V] [TRT] Tactic: 5 Time: 124.989
[03/27/2022-19:11:56] [V] [TRT] Fastest Tactic: 1 Time: 0.576896
[03/27/2022-19:11:56] [V] [TRT] --------------- Timing Runner: Conv_198 (CaskConvolution)
[03/27/2022-19:11:56] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:11:56] [V] [TRT] Tactic: 1062367460111450758 Time: 10.9156
[03/27/2022-19:11:57] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:11:57] [V] [TRT] Tactic: 1754984623894446479 Time: 11.264
[03/27/2022-19:11:57] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:11:57] [V] [TRT] Tactic: 3611739942397549984 Time: 13.815
[03/27/2022-19:11:57] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:11:57] [V] [TRT] Tactic: 4337000649858996379 Time: 9.55648
[03/27/2022-19:11:58] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:11:58] [V] [TRT] Tactic: 4501471010995462441 Time: 12.3798
[03/27/2022-19:11:58] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:11:58] [V] [TRT] Tactic: 5137655947464784826 Time: 8.90061
[03/27/2022-19:11:58] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:11:58] [V] [TRT] Tactic: 5288347012147084929 Time: 12.3539
[03/27/2022-19:11:58] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:11:59] [V] [TRT] Tactic: 6645123197870846056 Time: 12.0518
[03/27/2022-19:11:59] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:11:59] [V] [TRT] Tactic: 7144526460361122478 Time: 6.7817
[03/27/2022-19:11:59] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:11:59] [V] [TRT] Tactic: -9137461792520977713 Time: 13.4857
[03/27/2022-19:12:00] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:00] [V] [TRT] Tactic: -8262349710178828730 Time: 12.6915
[03/27/2022-19:12:00] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:12:00] [V] [TRT] Tactic: -8133971918129952780 Time: 12.3354
[03/27/2022-19:12:00] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:12:01] [V] [TRT] Tactic: -6092040395344634144 Time: 12.1416
[03/27/2022-19:12:01] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:01] [V] [TRT] Tactic: -4787320710726427159 Time: 9.95059
[03/27/2022-19:12:01] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:01] [V] [TRT] Tactic: -3456450830548107839 Time: 12.1779
[03/27/2022-19:12:02] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:02] [V] [TRT] Tactic: -1218658103698133241 Time: 10.565
[03/27/2022-19:12:02] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:02] [V] [TRT] Tactic: -836875257600482091 Time: 10.3905
[03/27/2022-19:12:02] [V] [TRT] Conv_198 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:02] [V] [TRT] Tactic: -410470605513481746 Time: 11.7358
[03/27/2022-19:12:02] [V] [TRT] Fastest Tactic: 7144526460361122478 Time: 6.7817
[03/27/2022-19:12:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:12:02] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:02] [V] [TRT] --------------- Timing Runner: Conv_198 (CaskConvolution)
[03/27/2022-19:12:02] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:02] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:02] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:02] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:02] [V] [TRT] *************** Autotuning format combination: Float(23552,1024:32,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:12:02] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:02] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:12:02] [V] [TRT] --------------- Timing Runner: ReduceMean_201 (TiledPooling)
[03/27/2022-19:12:02] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:12:02] [V] [TRT] --------------- Timing Runner: ReduceMean_201 (CudnnPooling)
[03/27/2022-19:12:02] [V] [TRT] Tactic: -1 Time: 0.036352
[03/27/2022-19:12:02] [V] [TRT] Fastest Tactic: -1 Time: 0.036352
[03/27/2022-19:12:02] [V] [TRT] --------------- Timing Runner: ReduceMean_201 (CaskPooling)
[03/27/2022-19:12:02] [V] [TRT] ReduceMean_201 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:12:02] [V] [TRT] Tactic: 6119644359078410246 Time: 0.038392
[03/27/2022-19:12:02] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.038392
[03/27/2022-19:12:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[03/27/2022-19:12:02] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:02] [V] [TRT] *************** Autotuning format combination: Float(720,1,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:12:02] [V] [TRT] --------------- Timing Runner: Conv_202 (CudaDepthwiseConvolution)
[03/27/2022-19:12:02] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:02] [V] [TRT] --------------- Timing Runner: Conv_202 (FusedConvActConvolution)
[03/27/2022-19:12:02] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:02] [V] [TRT] --------------- Timing Runner: Conv_202 (CudnnConvolution)
[03/27/2022-19:12:02] [V] [TRT] Tactic: 0 Time: 0.074348
[03/27/2022-19:12:02] [V] [TRT] Tactic: 1 Time: 0.239068
[03/27/2022-19:12:02] [V] [TRT] Tactic: 2 Time: 0.31488
[03/27/2022-19:12:02] [V] [TRT] Tactic: 4 Time: 0.373632
[03/27/2022-19:12:02] [V] [TRT] Tactic: 5 Time: 0.135424
[03/27/2022-19:12:02] [V] [TRT] Fastest Tactic: 0 Time: 0.074348
[03/27/2022-19:12:02] [V] [TRT] --------------- Timing Runner: Conv_202 (CublasConvolution)
[03/27/2022-19:12:02] [V] [TRT] Tactic: 0 Time: 0.012416
[03/27/2022-19:12:02] [V] [TRT] Tactic: 1 Time: 0.016
[03/27/2022-19:12:02] [V] [TRT] Fastest Tactic: 0 Time: 0.012416
[03/27/2022-19:12:02] [V] [TRT] --------------- Timing Runner: Conv_202 (CaskConvolution)
[03/27/2022-19:12:02] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:02] [V] [TRT] Tactic: 1062367460111450758 Time: 0.086144
[03/27/2022-19:12:02] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:12:02] [V] [TRT] Tactic: 1698681053543049347 Time: 0.063616
[03/27/2022-19:12:02] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:02] [V] [TRT] Tactic: 4501471010995462441 Time: 0.091392
[03/27/2022-19:12:02] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:02] [V] [TRT] Tactic: 5137655947464784826 Time: 0.063868
[03/27/2022-19:12:02] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:02] [V] [TRT] Tactic: 5288347012147084929 Time: 0.09024
[03/27/2022-19:12:02] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:12:02] [V] [TRT] Tactic: 5326823351883942011 Time: 0.089856
[03/27/2022-19:12:02] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:12:02] [V] [TRT] Tactic: 5500448035057547314 Time: 0.079872
[03/27/2022-19:12:02] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:02] [V] [TRT] Tactic: 6645123197870846056 Time: 0.070016
[03/27/2022-19:12:02] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:02] [V] [TRT] Tactic: 7144526460361122478 Time: 0.065536
[03/27/2022-19:12:02] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:02] [V] [TRT] Tactic: -8262349710178828730 Time: 0.092672
[03/27/2022-19:12:02] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:12:02] [V] [TRT] Tactic: -6576203419454146580 Time: 0.074624
[03/27/2022-19:12:03] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:03] [V] [TRT] Tactic: -4787320710726427159 Time: 0.078844
[03/27/2022-19:12:03] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:03] [V] [TRT] Tactic: -3456450830548107839 Time: 0.073472
[03/27/2022-19:12:03] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:03] [V] [TRT] Tactic: -1218658103698133241 Time: 0.093696
[03/27/2022-19:12:03] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:03] [V] [TRT] Tactic: -836875257600482091 Time: 0.08166
[03/27/2022-19:12:03] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:03] [V] [TRT] Tactic: -410470605513481746 Time: 0.095616
[03/27/2022-19:12:03] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:12:03] [V] [TRT] Tactic: -377491875521947884 Time: 0.088576
[03/27/2022-19:12:03] [V] [TRT] Conv_202 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:12:03] [V] [TRT] Tactic: -37215280111360163 Time: 0.061824
[03/27/2022-19:12:03] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.061824
[03/27/2022-19:12:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0
[03/27/2022-19:12:03] [V] [TRT] *************** Autotuning format combination: Float(720,1,720,720) -> Float(30,1,30,30) ***************
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_202 (CublasConvolution)
[03/27/2022-19:12:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_202 (CaskConvolution)
[03/27/2022-19:12:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:03] [V] [TRT] *************** Autotuning format combination: Float(30,1,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_203), Mul_204) (PointWiseV2)
[03/27/2022-19:12:03] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:12:03] [V] [TRT] Tactic: 1 Time: 0.006272
[03/27/2022-19:12:03] [V] [TRT] Tactic: 2 Time: 0.005632
[03/27/2022-19:12:03] [V] [TRT] Tactic: 3 Time: 0.006404
[03/27/2022-19:12:03] [V] [TRT] Tactic: 4 Time: 0.0064
[03/27/2022-19:12:03] [V] [TRT] Tactic: 5 Time: 0.006016
[03/27/2022-19:12:03] [V] [TRT] Tactic: 6 Time: 0.006912
[03/27/2022-19:12:03] [V] [TRT] Tactic: 7 Time: 0.006016
[03/27/2022-19:12:03] [V] [TRT] Tactic: 8 Time: 0.006016
[03/27/2022-19:12:03] [V] [TRT] Tactic: 9 Time: 0.006016
[03/27/2022-19:12:03] [V] [TRT] Tactic: 28 Time: 0.00576
[03/27/2022-19:12:03] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_203), Mul_204) (PointWise)
[03/27/2022-19:12:03] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0
[03/27/2022-19:12:03] [V] [TRT] *************** Autotuning format combination: Float(30,1,30,30) -> Float(30,1,30,30) ***************
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_203), Mul_204) (PointWiseV2)
[03/27/2022-19:12:03] [V] [TRT] Tactic: 0 Time: 0.005504
[03/27/2022-19:12:03] [V] [TRT] Tactic: 1 Time: 0.005888
[03/27/2022-19:12:03] [V] [TRT] Tactic: 2 Time: 0.005632
[03/27/2022-19:12:03] [V] [TRT] Tactic: 3 Time: 0.006528
[03/27/2022-19:12:03] [V] [TRT] Tactic: 4 Time: 0.006144
[03/27/2022-19:12:03] [V] [TRT] Tactic: 5 Time: 0.00576
[03/27/2022-19:12:03] [V] [TRT] Tactic: 6 Time: 0.006784
[03/27/2022-19:12:03] [V] [TRT] Tactic: 7 Time: 0.0064
[03/27/2022-19:12:03] [V] [TRT] Tactic: 8 Time: 0.006144
[03/27/2022-19:12:03] [V] [TRT] Tactic: 9 Time: 0.006144
[03/27/2022-19:12:03] [V] [TRT] Tactic: 28 Time: 0.00576
[03/27/2022-19:12:03] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_203), Mul_204) (PointWise)
[03/27/2022-19:12:03] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0
[03/27/2022-19:12:03] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_203), Mul_204) (PointWiseV2)
[03/27/2022-19:12:03] [V] [TRT] Tactic: 24 Time: 0.006144
[03/27/2022-19:12:03] [V] [TRT] Tactic: 25 Time: 0.006272
[03/27/2022-19:12:03] [V] [TRT] Tactic: 26 Time: 0.006656
[03/27/2022-19:12:03] [V] [TRT] Tactic: 27 Time: 0.007424
[03/27/2022-19:12:03] [V] [TRT] Tactic: 31 Time: 0.006272
[03/27/2022-19:12:03] [V] [TRT] Fastest Tactic: 24 Time: 0.006144
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_203), Mul_204) (PointWise)
[03/27/2022-19:12:03] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[03/27/2022-19:12:03] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:03] [V] [TRT] *************** Autotuning format combination: Float(30,1,1,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_205 (CudaDepthwiseConvolution)
[03/27/2022-19:12:03] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_205 (FusedConvActConvolution)
[03/27/2022-19:12:03] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_205 (CudnnConvolution)
[03/27/2022-19:12:03] [V] [TRT] Tactic: 0 Time: 0.013184
[03/27/2022-19:12:03] [V] [TRT] Tactic: 1 Time: 0.011772
[03/27/2022-19:12:03] [V] [TRT] Tactic: 2 Time: 0.025472
[03/27/2022-19:12:03] [V] [TRT] Tactic: 4 Time: 0.316796
[03/27/2022-19:12:03] [V] [TRT] Tactic: 5 Time: 0.093952
[03/27/2022-19:12:03] [V] [TRT] Fastest Tactic: 1 Time: 0.011772
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_205 (CublasConvolution)
[03/27/2022-19:12:03] [V] [TRT] Tactic: 0 Time: 0.0096
[03/27/2022-19:12:03] [V] [TRT] Tactic: 1 Time: 0.0096
[03/27/2022-19:12:03] [V] [TRT] Fastest Tactic: 0 Time: 0.0096
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_205 (CaskConvolution)
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:03] [V] [TRT] Tactic: 1062367460111450758 Time: 0.016128
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:12:03] [V] [TRT] Tactic: 1698681053543049347 Time: 0.012288
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:03] [V] [TRT] Tactic: 4501471010995462441 Time: 0.015864
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:03] [V] [TRT] Tactic: 5137655947464784826 Time: 0.01472
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:03] [V] [TRT] Tactic: 5288347012147084929 Time: 0.0165
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:12:03] [V] [TRT] Tactic: 5326823351883942011 Time: 0.015996
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:12:03] [V] [TRT] Tactic: 5500448035057547314 Time: 0.014848
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:03] [V] [TRT] Tactic: 6645123197870846056 Time: 0.01472
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:03] [V] [TRT] Tactic: 7144526460361122478 Time: 0.01242
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:03] [V] [TRT] Tactic: -8262349710178828730 Time: 0.016512
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:12:03] [V] [TRT] Tactic: -6576203419454146580 Time: 0.015612
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:03] [V] [TRT] Tactic: -4787320710726427159 Time: 0.012796
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:03] [V] [TRT] Tactic: -3456450830548107839 Time: 0.015488
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:03] [V] [TRT] Tactic: -1218658103698133241 Time: 0.015476
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:03] [V] [TRT] Tactic: -836875257600482091 Time: 0.015104
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:03] [V] [TRT] Tactic: -410470605513481746 Time: 0.015748
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:12:03] [V] [TRT] Tactic: -377491875521947884 Time: 0.016
[03/27/2022-19:12:03] [V] [TRT] Conv_205 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:12:03] [V] [TRT] Tactic: -37215280111360163 Time: 0.014208
[03/27/2022-19:12:03] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.012288
[03/27/2022-19:12:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0
[03/27/2022-19:12:03] [V] [TRT] *************** Autotuning format combination: Float(30,1,30,30) -> Float(720,1,720,720) ***************
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_205 (CublasConvolution)
[03/27/2022-19:12:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_205 (CaskConvolution)
[03/27/2022-19:12:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:03] [V] [TRT] *************** Autotuning format combination: Float(720,1,1,1), Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_206), Mul_207) (PointWiseV2)
[03/27/2022-19:12:03] [V] [TRT] Tactic: 0 Time: 0.12032
[03/27/2022-19:12:03] [V] [TRT] Tactic: 1 Time: 0.14336
[03/27/2022-19:12:03] [V] [TRT] Tactic: 2 Time: 0.131456
[03/27/2022-19:12:03] [V] [TRT] Tactic: 3 Time: 0.162816
[03/27/2022-19:12:03] [V] [TRT] Tactic: 4 Time: 0.170112
[03/27/2022-19:12:03] [V] [TRT] Tactic: 5 Time: 0.148476
[03/27/2022-19:12:03] [V] [TRT] Tactic: 6 Time: 0.204416
[03/27/2022-19:12:03] [V] [TRT] Tactic: 7 Time: 0.214912
[03/27/2022-19:12:03] [V] [TRT] Tactic: 8 Time: 0.209156
[03/27/2022-19:12:03] [V] [TRT] Tactic: 9 Time: 0.178816
[03/27/2022-19:12:03] [V] [TRT] Tactic: 28 Time: 0.114816
[03/27/2022-19:12:03] [V] [TRT] Fastest Tactic: 28 Time: 0.114816
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_206), Mul_207) (PointWise)
[03/27/2022-19:12:03] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:12:03] [V] [TRT] *************** Autotuning format combination: Float(720,1,720,720), Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_206), Mul_207) (PointWiseV2)
[03/27/2022-19:12:03] [V] [TRT] Tactic: 0 Time: 0.147712
[03/27/2022-19:12:03] [V] [TRT] Tactic: 1 Time: 0.100988
[03/27/2022-19:12:03] [V] [TRT] Tactic: 2 Time: 0.09408
[03/27/2022-19:12:03] [V] [TRT] Tactic: 3 Time: 0.071936
[03/27/2022-19:12:03] [V] [TRT] Tactic: 4 Time: 0.070528
[03/27/2022-19:12:03] [V] [TRT] Tactic: 5 Time: 0.069888
[03/27/2022-19:12:03] [V] [TRT] Tactic: 6 Time: 0.071296
[03/27/2022-19:12:03] [V] [TRT] Tactic: 7 Time: 0.068864
[03/27/2022-19:12:03] [V] [TRT] Tactic: 8 Time: 0.068992
[03/27/2022-19:12:03] [V] [TRT] Tactic: 9 Time: 0.069504
[03/27/2022-19:12:03] [V] [TRT] Tactic: 28 Time: 0.141056
[03/27/2022-19:12:03] [V] [TRT] Fastest Tactic: 7 Time: 0.068864
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_206), Mul_207) (PointWise)
[03/27/2022-19:12:03] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[03/27/2022-19:12:03] [V] [TRT] *************** Autotuning format combination: Float(23,1:32,1,1), Float(23552,1024:32,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_206), Mul_207) (PointWiseV2)
[03/27/2022-19:12:03] [V] [TRT] Tactic: 24 Time: 0.069892
[03/27/2022-19:12:03] [V] [TRT] Tactic: 25 Time: 0.064764
[03/27/2022-19:12:03] [V] [TRT] Tactic: 26 Time: 0.066048
[03/27/2022-19:12:03] [V] [TRT] Tactic: 27 Time: 0.069252
[03/27/2022-19:12:03] [V] [TRT] Tactic: 31 Time: 0.06976
[03/27/2022-19:12:03] [V] [TRT] Fastest Tactic: 25 Time: 0.064764
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_206), Mul_207) (PointWise)
[03/27/2022-19:12:03] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[03/27/2022-19:12:03] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:03] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1), Float(122880,1024,32,1) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_208 + Add_209 (CudaDepthwiseConvolution)
[03/27/2022-19:12:03] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_208 + Add_209 (FusedConvActConvolution)
[03/27/2022-19:12:03] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:03] [V] [TRT] --------------- Timing Runner: Conv_208 + Add_209 (CudnnConvolution)
[03/27/2022-19:12:03] [V] [TRT] Tactic: 0 Time: 0.281468
[03/27/2022-19:12:03] [V] [TRT] Tactic: 1 Time: 0.164864
[03/27/2022-19:12:03] [V] [TRT] Tactic: 2 Time: 0.384768
[03/27/2022-19:12:03] [V] [TRT] Tactic: 4 Time: 4.18752
[03/27/2022-19:12:04] [V] [TRT] Tactic: 5 Time: 0.818048
[03/27/2022-19:12:04] [V] [TRT] Fastest Tactic: 1 Time: 0.164864
[03/27/2022-19:12:04] [V] [TRT] --------------- Timing Runner: Conv_208 + Add_209 (CublasConvolution)
[03/27/2022-19:12:04] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:04] [V] [TRT] --------------- Timing Runner: Conv_208 + Add_209 (CaskConvolution)
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:04] [V] [TRT] Tactic: 1062367460111450758 Time: 0.164864
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:12:04] [V] [TRT] Tactic: 1698681053543049347 Time: 0.133124
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:04] [V] [TRT] Tactic: 4501471010995462441 Time: 0.16768
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:04] [V] [TRT] Tactic: 5137655947464784826 Time: 0.14042
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:04] [V] [TRT] Tactic: 5288347012147084929 Time: 0.166528
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:12:04] [V] [TRT] Tactic: 5326823351883942011 Time: 0.162944
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:12:04] [V] [TRT] Tactic: 5500448035057547314 Time: 0.148096
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:04] [V] [TRT] Tactic: 6645123197870846056 Time: 0.143104
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:04] [V] [TRT] Tactic: 7144526460361122478 Time: 0.142336
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:04] [V] [TRT] Tactic: -8262349710178828730 Time: 0.167808
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:12:04] [V] [TRT] Tactic: -6576203419454146580 Time: 0.147328
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:04] [V] [TRT] Tactic: -4787320710726427159 Time: 0.147456
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:04] [V] [TRT] Tactic: -3456450830548107839 Time: 0.159872
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:04] [V] [TRT] Tactic: -1218658103698133241 Time: 0.157436
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:04] [V] [TRT] Tactic: -836875257600482091 Time: 0.153984
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:04] [V] [TRT] Tactic: -410470605513481746 Time: 0.164988
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:12:04] [V] [TRT] Tactic: -377491875521947884 Time: 0.163964
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:12:04] [V] [TRT] Tactic: -37215280111360163 Time: 0.135288
[03/27/2022-19:12:04] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.133124
[03/27/2022-19:12:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 1698681053543049347
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720), Float(122880,1,3840,120) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:12:04] [V] [TRT] --------------- Timing Runner: Conv_208 + Add_209 (CublasConvolution)
[03/27/2022-19:12:04] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:04] [V] [TRT] --------------- Timing Runner: Conv_208 + Add_209 (CaskConvolution)
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:12:04] [V] [TRT] Tactic: 3886731678879822788 Time: 0.170752
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:12:04] [V] [TRT] Tactic: 6629944304117643200 Time: 0.125952
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:12:04] [V] [TRT] Tactic: -9153228964338181824 Time: 0.12544
[03/27/2022-19:12:04] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:12:04] [V] [TRT] Tactic: -7394439838318485025 Time: 0.170752
[03/27/2022-19:12:04] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.12544
[03/27/2022-19:12:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(122880,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(122880,1,3840,120) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(23552,1024:32,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(23552,1024:32,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(720,1,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(720,1,720,720) -> Float(30,1,30,30) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(30,1,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(30,1,30,30) -> Float(30,1,30,30) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(30,1,1,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(30,1,30,30) -> Float(720,1,720,720) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(720,1,1,1), Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(720,1,720,720), Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(23,1:32,1,1), Float(23552,1024:32,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1), Float(122880,1024,32,1) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720), Float(122880,1,3840,120) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(122880,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(122880,1,3840,120) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(23552,1024:32,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(23552,1024:32,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(720,1,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(720,1,720,720) -> Float(30,1,30,30) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(30,1,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(30,1,30,30) -> Float(30,1,30,30) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(30,1,1,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(30,1,30,30) -> Float(720,1,720,720) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(720,1,1,1), Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(720,1,720,720), Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(23,1:32,1,1), Float(23552,1024:32,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1), Float(122880,1024,32,1) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720), Float(122880,1,3840,120) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(122880,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(122880,1,3840,120) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(737280,1024,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720) -> Float(737280,1,23040,720) ***************
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(23552,1024:32,32,1) -> Float(23552,1024:32,32,1) ***************
[03/27/2022-19:12:04] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:04] [V] [TRT] *************** Autotuning format combination: Float(737280,1024,32,1) -> Float(184320,256,16,1) ***************
[03/27/2022-19:12:04] [V] [TRT] --------------- Timing Runner: Conv_243 (CudaDepthwiseConvolution)
[03/27/2022-19:12:04] [V] [TRT] Tactic: -1 Time: 0.101892
[03/27/2022-19:12:04] [V] [TRT] Fastest Tactic: -1 Time: 0.101892
[03/27/2022-19:12:04] [V] [TRT] --------------- Timing Runner: Conv_243 (CudnnConvolution)
[03/27/2022-19:12:04] [V] [TRT] Tactic: 0 Time: 0.200572
[03/27/2022-19:12:04] [V] [TRT] Tactic: 1 Time: 0.200448
[03/27/2022-19:12:04] [V] [TRT] Tactic: 2 Time: 0.200192
[03/27/2022-19:12:06] [V] [TRT] Tactic: 5 Time: 123.13
[03/27/2022-19:12:06] [V] [TRT] Fastest Tactic: 2 Time: 0.200192
[03/27/2022-19:12:06] [V] [TRT] --------------- Timing Runner: Conv_243 (CaskConvolution)
[03/27/2022-19:12:06] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:07] [V] [TRT] Tactic: 1062367460111450758 Time: 9.38624
[03/27/2022-19:12:07] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:12:07] [V] [TRT] Tactic: 1754984623894446479 Time: 6.69146
[03/27/2022-19:12:07] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:12:07] [V] [TRT] Tactic: 3611739942397549984 Time: 9.2727
[03/27/2022-19:12:07] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:12:07] [V] [TRT] Tactic: 4337000649858996379 Time: 8.29273
[03/27/2022-19:12:07] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:07] [V] [TRT] Tactic: 4501471010995462441 Time: 8.83226
[03/27/2022-19:12:07] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:07] [V] [TRT] Tactic: 5137655947464784826 Time: 7.81107
[03/27/2022-19:12:08] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:08] [V] [TRT] Tactic: 5288347012147084929 Time: 9.06598
[03/27/2022-19:12:08] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:08] [V] [TRT] Tactic: 6645123197870846056 Time: 8.18905
[03/27/2022-19:12:08] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:08] [V] [TRT] Tactic: 7144526460361122478 Time: 6.35827
[03/27/2022-19:12:08] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:12:08] [V] [TRT] Tactic: -9137461792520977713 Time: 9.00403
[03/27/2022-19:12:08] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:09] [V] [TRT] Tactic: -8262349710178828730 Time: 9.49402
[03/27/2022-19:12:09] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:12:09] [V] [TRT] Tactic: -8133971918129952780 Time: 8.41202
[03/27/2022-19:12:09] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:12:09] [V] [TRT] Tactic: -6092040395344634144 Time: 13.632
[03/27/2022-19:12:09] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:09] [V] [TRT] Tactic: -4787320710726427159 Time: 6.69991
[03/27/2022-19:12:09] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:10] [V] [TRT] Tactic: -3456450830548107839 Time: 13.8674
[03/27/2022-19:12:10] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:10] [V] [TRT] Tactic: -1218658103698133241 Time: 8.45709
[03/27/2022-19:12:10] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:10] [V] [TRT] Tactic: -836875257600482091 Time: 8.22566
[03/27/2022-19:12:10] [V] [TRT] Conv_243 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:10] [V] [TRT] Tactic: -410470605513481746 Time: 15.0144
[03/27/2022-19:12:10] [V] [TRT] Fastest Tactic: 7144526460361122478 Time: 6.35827
[03/27/2022-19:12:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:12:10] [V] [TRT] *************** Autotuning format combination: Float(737280,1,23040,720) -> Float(184320,1,11520,720) ***************
[03/27/2022-19:12:10] [V] [TRT] --------------- Timing Runner: Conv_243 (CaskConvolution)
[03/27/2022-19:12:10] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:10] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:10] [V] [TRT] *************** Autotuning format combination: Float(184320,256,16,1) -> Float(184320,256,16,1) ***************
[03/27/2022-19:12:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_244), Mul_245) (PointWiseV2)
[03/27/2022-19:12:10] [V] [TRT] Tactic: 0 Time: 0.022784
[03/27/2022-19:12:10] [V] [TRT] Tactic: 1 Time: 0.020612
[03/27/2022-19:12:10] [V] [TRT] Tactic: 2 Time: 0.019968
[03/27/2022-19:12:10] [V] [TRT] Tactic: 3 Time: 0.020864
[03/27/2022-19:12:10] [V] [TRT] Tactic: 4 Time: 0.020096
[03/27/2022-19:12:10] [V] [TRT] Tactic: 5 Time: 0.019456
[03/27/2022-19:12:10] [V] [TRT] Tactic: 6 Time: 0.021376
[03/27/2022-19:12:10] [V] [TRT] Tactic: 7 Time: 0.02022
[03/27/2022-19:12:10] [V] [TRT] Tactic: 8 Time: 0.019204
[03/27/2022-19:12:10] [V] [TRT] Tactic: 9 Time: 0.019712
[03/27/2022-19:12:10] [V] [TRT] Tactic: 28 Time: 0.022528
[03/27/2022-19:12:10] [V] [TRT] Fastest Tactic: 8 Time: 0.019204
[03/27/2022-19:12:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_244), Mul_245) (PointWise)
[03/27/2022-19:12:10] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:12:10] [V] [TRT] *************** Autotuning format combination: Float(184320,1,11520,720) -> Float(184320,1,11520,720) ***************
[03/27/2022-19:12:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_244), Mul_245) (PointWiseV2)
[03/27/2022-19:12:10] [V] [TRT] Tactic: 0 Time: 0.02304
[03/27/2022-19:12:10] [V] [TRT] Tactic: 1 Time: 0.02074
[03/27/2022-19:12:11] [V] [TRT] Tactic: 2 Time: 0.019968
[03/27/2022-19:12:11] [V] [TRT] Tactic: 3 Time: 0.020352
[03/27/2022-19:12:11] [V] [TRT] Tactic: 4 Time: 0.019968
[03/27/2022-19:12:11] [V] [TRT] Tactic: 5 Time: 0.019456
[03/27/2022-19:12:11] [V] [TRT] Tactic: 6 Time: 0.020992
[03/27/2022-19:12:11] [V] [TRT] Tactic: 7 Time: 0.020228
[03/27/2022-19:12:11] [V] [TRT] Tactic: 8 Time: 0.019328
[03/27/2022-19:12:11] [V] [TRT] Tactic: 9 Time: 0.019836
[03/27/2022-19:12:11] [V] [TRT] Tactic: 28 Time: 0.022912
[03/27/2022-19:12:11] [V] [TRT] Fastest Tactic: 8 Time: 0.019328
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_244), Mul_245) (PointWise)
[03/27/2022-19:12:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(5888,256:32,16,1) -> Float(5888,256:32,16,1) ***************
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_244), Mul_245) (PointWiseV2)
[03/27/2022-19:12:11] [V] [TRT] Tactic: 24 Time: 0.019952
[03/27/2022-19:12:11] [V] [TRT] Tactic: 25 Time: 0.020608
[03/27/2022-19:12:11] [V] [TRT] Tactic: 26 Time: 0.021124
[03/27/2022-19:12:11] [V] [TRT] Tactic: 27 Time: 0.021376
[03/27/2022-19:12:11] [V] [TRT] Tactic: 31 Time: 0.02048
[03/27/2022-19:12:11] [V] [TRT] Fastest Tactic: 24 Time: 0.019952
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_244), Mul_245) (PointWise)
[03/27/2022-19:12:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[03/27/2022-19:12:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(184320,256,16,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: ReduceMean_246 (TiledPooling)
[03/27/2022-19:12:11] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: ReduceMean_246 (CudnnPooling)
[03/27/2022-19:12:11] [V] [TRT] Tactic: -1 Time: 0.011776
[03/27/2022-19:12:11] [V] [TRT] Fastest Tactic: -1 Time: 0.011776
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: ReduceMean_246 (CaskPooling)
[03/27/2022-19:12:11] [V] [TRT] ReduceMean_246 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:12:11] [V] [TRT] Tactic: 6119644359078410246 Time: 0.013568
[03/27/2022-19:12:11] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.013568
[03/27/2022-19:12:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[03/27/2022-19:12:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(720,1,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(720,1,720,720) -> Float(30,1,30,30) ***************
[03/27/2022-19:12:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(30,1,1,1) -> Float(30,1,1,1) ***************
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(30,1,30,30) -> Float(30,1,30,30) ***************
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(1,1:32,1,1) -> Float(1,1:32,1,1) ***************
[03/27/2022-19:12:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(30,1,1,1) -> Float(720,1,1,1) ***************
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(30,1,30,30) -> Float(720,1,720,720) ***************
[03/27/2022-19:12:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(720,1,1,1), Float(184320,256,16,1) -> Float(184320,256,16,1) ***************
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_251), Mul_252) (PointWiseV2)
[03/27/2022-19:12:11] [V] [TRT] Tactic: 0 Time: 0.063616
[03/27/2022-19:12:11] [V] [TRT] Tactic: 1 Time: 0.075396
[03/27/2022-19:12:11] [V] [TRT] Tactic: 2 Time: 0.069632
[03/27/2022-19:12:11] [V] [TRT] Tactic: 3 Time: 0.08576
[03/27/2022-19:12:11] [V] [TRT] Tactic: 4 Time: 0.089212
[03/27/2022-19:12:11] [V] [TRT] Tactic: 5 Time: 0.077824
[03/27/2022-19:12:11] [V] [TRT] Tactic: 6 Time: 0.106492
[03/27/2022-19:12:11] [V] [TRT] Tactic: 7 Time: 0.111616
[03/27/2022-19:12:11] [V] [TRT] Tactic: 8 Time: 0.108544
[03/27/2022-19:12:11] [V] [TRT] Tactic: 9 Time: 0.093568
[03/27/2022-19:12:11] [V] [TRT] Tactic: 28 Time: 0.03392
[03/27/2022-19:12:11] [V] [TRT] Fastest Tactic: 28 Time: 0.03392
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_251), Mul_252) (PointWise)
[03/27/2022-19:12:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(720,1,720,720), Float(184320,1,11520,720) -> Float(184320,1,11520,720) ***************
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_251), Mul_252) (PointWiseV2)
[03/27/2022-19:12:11] [V] [TRT] Tactic: 0 Time: 0.042752
[03/27/2022-19:12:11] [V] [TRT] Tactic: 1 Time: 0.030592
[03/27/2022-19:12:11] [V] [TRT] Tactic: 2 Time: 0.0288
[03/27/2022-19:12:11] [V] [TRT] Tactic: 3 Time: 0.02368
[03/27/2022-19:12:11] [V] [TRT] Tactic: 4 Time: 0.022908
[03/27/2022-19:12:11] [V] [TRT] Tactic: 5 Time: 0.022784
[03/27/2022-19:12:11] [V] [TRT] Tactic: 6 Time: 0.02406
[03/27/2022-19:12:11] [V] [TRT] Tactic: 7 Time: 0.022656
[03/27/2022-19:12:11] [V] [TRT] Tactic: 8 Time: 0.022144
[03/27/2022-19:12:11] [V] [TRT] Tactic: 9 Time: 0.022784
[03/27/2022-19:12:11] [V] [TRT] Tactic: 28 Time: 0.040832
[03/27/2022-19:12:11] [V] [TRT] Fastest Tactic: 8 Time: 0.022144
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_251), Mul_252) (PointWise)
[03/27/2022-19:12:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(23,1:32,1,1), Float(5888,256:32,16,1) -> Float(5888,256:32,16,1) ***************
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_251), Mul_252) (PointWiseV2)
[03/27/2022-19:12:11] [V] [TRT] Tactic: 24 Time: 0.022656
[03/27/2022-19:12:11] [V] [TRT] Tactic: 25 Time: 0.02176
[03/27/2022-19:12:11] [V] [TRT] Tactic: 26 Time: 0.024068
[03/27/2022-19:12:11] [V] [TRT] Tactic: 27 Time: 0.025212
[03/27/2022-19:12:11] [V] [TRT] Tactic: 31 Time: 0.022528
[03/27/2022-19:12:11] [V] [TRT] Fastest Tactic: 25 Time: 0.02176
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_251), Mul_252) (PointWise)
[03/27/2022-19:12:11] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[03/27/2022-19:12:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(184320,256,16,1) -> Float(53248,256,16,1) ***************
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: Conv_253 (CudaDepthwiseConvolution)
[03/27/2022-19:12:11] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: Conv_253 (FusedConvActConvolution)
[03/27/2022-19:12:11] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: Conv_253 (CudnnConvolution)
[03/27/2022-19:12:11] [V] [TRT] Tactic: 0 Time: 0.128636
[03/27/2022-19:12:11] [V] [TRT] Tactic: 1 Time: 0.100736
[03/27/2022-19:12:11] [V] [TRT] Tactic: 2 Time: 0.223872
[03/27/2022-19:12:11] [V] [TRT] Tactic: 4 Time: 2.02394
[03/27/2022-19:12:11] [V] [TRT] Tactic: 5 Time: 0.357888
[03/27/2022-19:12:11] [V] [TRT] Fastest Tactic: 1 Time: 0.100736
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: Conv_253 (CublasConvolution)
[03/27/2022-19:12:11] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: Conv_253 (CaskConvolution)
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:11] [V] [TRT] Tactic: 1062367460111450758 Time: 0.104448
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:12:11] [V] [TRT] Tactic: 1698681053543049347 Time: 0.114812
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:11] [V] [TRT] Tactic: 4501471010995462441 Time: 0.096768
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:11] [V] [TRT] Tactic: 5137655947464784826 Time: 0.095488
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:11] [V] [TRT] Tactic: 5288347012147084929 Time: 0.097788
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:12:11] [V] [TRT] Tactic: 5326823351883942011 Time: 0.096644
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:12:11] [V] [TRT] Tactic: 5500448035057547314 Time: 0.11968
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:11] [V] [TRT] Tactic: 6645123197870846056 Time: 0.099588
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:11] [V] [TRT] Tactic: 7144526460361122478 Time: 0.114936
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:11] [V] [TRT] Tactic: -8262349710178828730 Time: 0.098436
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:12:11] [V] [TRT] Tactic: -6576203419454146580 Time: 0.090756
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:11] [V] [TRT] Tactic: -4787320710726427159 Time: 0.114048
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:11] [V] [TRT] Tactic: -3456450830548107839 Time: 0.097424
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:11] [V] [TRT] Tactic: -1218658103698133241 Time: 0.127232
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:11] [V] [TRT] Tactic: -836875257600482091 Time: 0.1248
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:11] [V] [TRT] Tactic: -410470605513481746 Time: 0.096516
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:12:11] [V] [TRT] Tactic: -377491875521947884 Time: 0.097536
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:12:11] [V] [TRT] Tactic: -37215280111360163 Time: 0.0928
[03/27/2022-19:12:11] [V] [TRT] Fastest Tactic: -6576203419454146580 Time: 0.090756
[03/27/2022-19:12:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6576203419454146580
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(184320,1,11520,720) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: Conv_253 (CublasConvolution)
[03/27/2022-19:12:11] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: Conv_253 (CaskConvolution)
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:12:11] [V] [TRT] Tactic: 3886731678879822788 Time: 0.085892
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:12:11] [V] [TRT] Tactic: 6629944304117643200 Time: 0.053376
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:12:11] [V] [TRT] Tactic: -9153228964338181824 Time: 0.053884
[03/27/2022-19:12:11] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:12:11] [V] [TRT] Tactic: -7394439838318485025 Time: 0.086912
[03/27/2022-19:12:11] [V] [TRT] Fastest Tactic: 6629944304117643200 Time: 0.053376
[03/27/2022-19:12:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200
[03/27/2022-19:12:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:11] [V] [TRT] *************** Autotuning format combination: Float(53248,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: Conv_254 (CudaDepthwiseConvolution)
[03/27/2022-19:12:11] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: Conv_254 (FusedConvActConvolution)
[03/27/2022-19:12:11] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:11] [V] [TRT] --------------- Timing Runner: Conv_254 (CudnnConvolution)
[03/27/2022-19:12:11] [V] [TRT] Tactic: 0 Time: 0.162432
[03/27/2022-19:12:11] [V] [TRT] Tactic: 1 Time: 0.145792
[03/27/2022-19:12:11] [V] [TRT] Tactic: 2 Time: 0.267264
[03/27/2022-19:12:12] [V] [TRT] Tactic: 4 Time: 9.79392
[03/27/2022-19:12:12] [V] [TRT] Tactic: 5 Time: 0.71706
[03/27/2022-19:12:12] [V] [TRT] Fastest Tactic: 1 Time: 0.145792
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: Conv_254 (CublasConvolution)
[03/27/2022-19:12:12] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: Conv_254 (CaskConvolution)
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:12] [V] [TRT] Tactic: 1062367460111450758 Time: 0.10688
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:12:12] [V] [TRT] Tactic: 1698681053543049347 Time: 0.09408
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:12] [V] [TRT] Tactic: 4501471010995462441 Time: 0.09088
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:12] [V] [TRT] Tactic: 5137655947464784826 Time: 0.09254
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:12] [V] [TRT] Tactic: 5288347012147084929 Time: 0.089344
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:12:12] [V] [TRT] Tactic: 5326823351883942011 Time: 0.087808
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:12:12] [V] [TRT] Tactic: 5500448035057547314 Time: 0.097284
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:12] [V] [TRT] Tactic: 6645123197870846056 Time: 0.094848
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:12] [V] [TRT] Tactic: 7144526460361122478 Time: 0.113152
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:12] [V] [TRT] Tactic: -8262349710178828730 Time: 0.08986
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:12:12] [V] [TRT] Tactic: -6576203419454146580 Time: 0.097792
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:12] [V] [TRT] Tactic: -4787320710726427159 Time: 0.115308
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:12] [V] [TRT] Tactic: -3456450830548107839 Time: 0.102656
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:12] [V] [TRT] Tactic: -1218658103698133241 Time: 0.101888
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:12] [V] [TRT] Tactic: -836875257600482091 Time: 0.101252
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:12] [V] [TRT] Tactic: -410470605513481746 Time: 0.08896
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:12:12] [V] [TRT] Tactic: -377491875521947884 Time: 0.087672
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:12:12] [V] [TRT] Tactic: -37215280111360163 Time: 0.089728
[03/27/2022-19:12:12] [V] [TRT] Fastest Tactic: -377491875521947884 Time: 0.087672
[03/27/2022-19:12:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -377491875521947884
[03/27/2022-19:12:12] [V] [TRT] *************** Autotuning format combination: Float(53248,1,3328,208) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: Conv_254 (CublasConvolution)
[03/27/2022-19:12:12] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: Conv_254 (CaskConvolution)
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:12:12] [V] [TRT] Tactic: 3886731678879822788 Time: 0.088448
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:12:12] [V] [TRT] Tactic: 6629944304117643200 Time: 0.103552
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:12:12] [V] [TRT] Tactic: -9153228964338181824 Time: 0.104704
[03/27/2022-19:12:12] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:12:12] [V] [TRT] Tactic: -7394439838318485025 Time: 0.089088
[03/27/2022-19:12:12] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.088448
[03/27/2022-19:12:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:12:12] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:12] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_255), Mul_256) (PointWiseV2)
[03/27/2022-19:12:12] [V] [TRT] Tactic: 0 Time: 0.035452
[03/27/2022-19:12:12] [V] [TRT] Tactic: 1 Time: 0.030976
[03/27/2022-19:12:12] [V] [TRT] Tactic: 2 Time: 0.029696
[03/27/2022-19:12:12] [V] [TRT] Tactic: 3 Time: 0.030976
[03/27/2022-19:12:12] [V] [TRT] Tactic: 4 Time: 0.030336
[03/27/2022-19:12:12] [V] [TRT] Tactic: 5 Time: 0.029696
[03/27/2022-19:12:12] [V] [TRT] Tactic: 6 Time: 0.031488
[03/27/2022-19:12:12] [V] [TRT] Tactic: 7 Time: 0.030196
[03/27/2022-19:12:12] [V] [TRT] Tactic: 8 Time: 0.029696
[03/27/2022-19:12:12] [V] [TRT] Tactic: 9 Time: 0.029952
[03/27/2022-19:12:12] [V] [TRT] Tactic: 28 Time: 0.035072
[03/27/2022-19:12:12] [V] [TRT] Fastest Tactic: 5 Time: 0.029696
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_255), Mul_256) (PointWise)
[03/27/2022-19:12:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:12:12] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_255), Mul_256) (PointWiseV2)
[03/27/2022-19:12:12] [V] [TRT] Tactic: 0 Time: 0.03494
[03/27/2022-19:12:12] [V] [TRT] Tactic: 1 Time: 0.030596
[03/27/2022-19:12:12] [V] [TRT] Tactic: 2 Time: 0.029824
[03/27/2022-19:12:12] [V] [TRT] Tactic: 3 Time: 0.030852
[03/27/2022-19:12:12] [V] [TRT] Tactic: 4 Time: 0.030336
[03/27/2022-19:12:12] [V] [TRT] Tactic: 5 Time: 0.029824
[03/27/2022-19:12:12] [V] [TRT] Tactic: 6 Time: 0.03174
[03/27/2022-19:12:12] [V] [TRT] Tactic: 7 Time: 0.030464
[03/27/2022-19:12:12] [V] [TRT] Tactic: 8 Time: 0.029696
[03/27/2022-19:12:12] [V] [TRT] Tactic: 9 Time: 0.030208
[03/27/2022-19:12:12] [V] [TRT] Tactic: 28 Time: 0.034816
[03/27/2022-19:12:12] [V] [TRT] Fastest Tactic: 8 Time: 0.029696
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_255), Mul_256) (PointWise)
[03/27/2022-19:12:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:12:12] [V] [TRT] *************** Autotuning format combination: Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_255), Mul_256) (PointWiseV2)
[03/27/2022-19:12:12] [V] [TRT] Tactic: 24 Time: 0.0297
[03/27/2022-19:12:12] [V] [TRT] Tactic: 25 Time: 0.029952
[03/27/2022-19:12:12] [V] [TRT] Tactic: 26 Time: 0.030464
[03/27/2022-19:12:12] [V] [TRT] Tactic: 27 Time: 0.030848
[03/27/2022-19:12:12] [V] [TRT] Tactic: 31 Time: 0.029568
[03/27/2022-19:12:12] [V] [TRT] Fastest Tactic: 31 Time: 0.029568
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_255), Mul_256) (PointWise)
[03/27/2022-19:12:12] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:12:12] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:12] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: Conv_257 (CudaDepthwiseConvolution)
[03/27/2022-19:12:12] [V] [TRT] Tactic: -1 Time: 0.15232
[03/27/2022-19:12:12] [V] [TRT] Fastest Tactic: -1 Time: 0.15232
[03/27/2022-19:12:12] [V] [TRT] --------------- Timing Runner: Conv_257 (CudnnConvolution)
[03/27/2022-19:12:12] [V] [TRT] Tactic: 0 Time: 0.238208
[03/27/2022-19:12:12] [V] [TRT] Tactic: 1 Time: 0.238336
[03/27/2022-19:12:13] [V] [TRT] Tactic: 2 Time: 0.238208
[03/27/2022-19:12:14] [V] [TRT] Tactic: 4 Time: 102.234
[03/27/2022-19:12:17] [V] [TRT] Tactic: 5 Time: 117.337
[03/27/2022-19:12:17] [V] [TRT] Fastest Tactic: 0 Time: 0.238208
[03/27/2022-19:12:17] [V] [TRT] --------------- Timing Runner: Conv_257 (CaskConvolution)
[03/27/2022-19:12:17] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:17] [V] [TRT] Tactic: 1062367460111450758 Time: 18.8863
[03/27/2022-19:12:17] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:12:18] [V] [TRT] Tactic: 1754984623894446479 Time: 12.5197
[03/27/2022-19:12:18] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:12:18] [V] [TRT] Tactic: 3611739942397549984 Time: 29.0625
[03/27/2022-19:12:18] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:12:19] [V] [TRT] Tactic: 4337000649858996379 Time: 23.0362
[03/27/2022-19:12:19] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:19] [V] [TRT] Tactic: 4501471010995462441 Time: 16.2276
[03/27/2022-19:12:20] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:20] [V] [TRT] Tactic: 5137655947464784826 Time: 21.7549
[03/27/2022-19:12:20] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:21] [V] [TRT] Tactic: 5288347012147084929 Time: 16.5679
[03/27/2022-19:12:21] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:21] [V] [TRT] Tactic: 6645123197870846056 Time: 19.8141
[03/27/2022-19:12:21] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:22] [V] [TRT] Tactic: 7144526460361122478 Time: 11.1158
[03/27/2022-19:12:22] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:12:22] [V] [TRT] Tactic: -9137461792520977713 Time: 27.036
[03/27/2022-19:12:22] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:23] [V] [TRT] Tactic: -8262349710178828730 Time: 16.5885
[03/27/2022-19:12:23] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:12:23] [V] [TRT] Tactic: -8133971918129952780 Time: 19.9368
[03/27/2022-19:12:23] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:12:24] [V] [TRT] Tactic: -6092040395344634144 Time: 21.0116
[03/27/2022-19:12:24] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:25] [V] [TRT] Tactic: -4787320710726427159 Time: 20.1759
[03/27/2022-19:12:25] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:25] [V] [TRT] Tactic: -3456450830548107839 Time: 19.3283
[03/27/2022-19:12:25] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:25] [V] [TRT] Tactic: -1218658103698133241 Time: 15.1789
[03/27/2022-19:12:25] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:26] [V] [TRT] Tactic: -836875257600482091 Time: 14.25
[03/27/2022-19:12:26] [V] [TRT] Conv_257 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:26] [V] [TRT] Tactic: -410470605513481746 Time: 17.1539
[03/27/2022-19:12:26] [V] [TRT] Fastest Tactic: 7144526460361122478 Time: 11.1158
[03/27/2022-19:12:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:12:26] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:26] [V] [TRT] --------------- Timing Runner: Conv_257 (CaskConvolution)
[03/27/2022-19:12:26] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:26] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:26] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:26] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:26] [V] [TRT] *************** Autotuning format combination: Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:26] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:26] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:12:26] [V] [TRT] --------------- Timing Runner: ReduceMean_260 (TiledPooling)
[03/27/2022-19:12:26] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:12:26] [V] [TRT] --------------- Timing Runner: ReduceMean_260 (CudnnPooling)
[03/27/2022-19:12:26] [V] [TRT] Tactic: -1 Time: 0.0288
[03/27/2022-19:12:26] [V] [TRT] Fastest Tactic: -1 Time: 0.0288
[03/27/2022-19:12:26] [V] [TRT] --------------- Timing Runner: ReduceMean_260 (CaskPooling)
[03/27/2022-19:12:26] [V] [TRT] ReduceMean_260 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:12:26] [V] [TRT] Tactic: 6119644359078410246 Time: 0.026368
[03/27/2022-19:12:26] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.026368
[03/27/2022-19:12:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 6119644359078410246
[03/27/2022-19:12:26] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:26] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:12:26] [V] [TRT] --------------- Timing Runner: Conv_261 (CudaDepthwiseConvolution)
[03/27/2022-19:12:26] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:26] [V] [TRT] --------------- Timing Runner: Conv_261 (FusedConvActConvolution)
[03/27/2022-19:12:26] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:26] [V] [TRT] --------------- Timing Runner: Conv_261 (CudnnConvolution)
[03/27/2022-19:12:26] [V] [TRT] Tactic: 0 Time: 0.100604
[03/27/2022-19:12:26] [V] [TRT] Tactic: 1 Time: 0.015328
[03/27/2022-19:12:26] [V] [TRT] Tactic: 2 Time: 0.52838
[03/27/2022-19:12:26] [V] [TRT] Tactic: 4 Time: 1.04358
[03/27/2022-19:12:26] [V] [TRT] Tactic: 5 Time: 0.255868
[03/27/2022-19:12:26] [V] [TRT] Fastest Tactic: 1 Time: 0.015328
[03/27/2022-19:12:26] [V] [TRT] --------------- Timing Runner: Conv_261 (CublasConvolution)
[03/27/2022-19:12:26] [V] [TRT] Tactic: 0 Time: 0.015232
[03/27/2022-19:12:26] [V] [TRT] Tactic: 1 Time: 0.022016
[03/27/2022-19:12:26] [V] [TRT] Fastest Tactic: 0 Time: 0.015232
[03/27/2022-19:12:26] [V] [TRT] --------------- Timing Runner: Conv_261 (CaskConvolution)
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:26] [V] [TRT] Tactic: 1062367460111450758 Time: 0.140292
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:12:26] [V] [TRT] Tactic: 1698681053543049347 Time: 0.10304
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:26] [V] [TRT] Tactic: 4501471010995462441 Time: 0.151296
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:26] [V] [TRT] Tactic: 5137655947464784826 Time: 0.101884
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:26] [V] [TRT] Tactic: 5288347012147084929 Time: 0.147708
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:12:26] [V] [TRT] Tactic: 5326823351883942011 Time: 0.146944
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:12:26] [V] [TRT] Tactic: 5500448035057547314 Time: 0.1321
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:26] [V] [TRT] Tactic: 6645123197870846056 Time: 0.110976
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:26] [V] [TRT] Tactic: 7144526460361122478 Time: 0.107008
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:26] [V] [TRT] Tactic: -8262349710178828730 Time: 0.14976
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:12:26] [V] [TRT] Tactic: -6576203419454146580 Time: 0.1134
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:26] [V] [TRT] Tactic: -4787320710726427159 Time: 0.116096
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:26] [V] [TRT] Tactic: -3456450830548107839 Time: 0.11968
[03/27/2022-19:12:26] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:27] [V] [TRT] Tactic: -1218658103698133241 Time: 0.143744
[03/27/2022-19:12:27] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:27] [V] [TRT] Tactic: -836875257600482091 Time: 0.135684
[03/27/2022-19:12:27] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:27] [V] [TRT] Tactic: -410470605513481746 Time: 0.145024
[03/27/2022-19:12:27] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:12:27] [V] [TRT] Tactic: -377491875521947884 Time: 0.145024
[03/27/2022-19:12:27] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:12:27] [V] [TRT] Tactic: -37215280111360163 Time: 0.099708
[03/27/2022-19:12:27] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.099708
[03/27/2022-19:12:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0
[03/27/2022-19:12:27] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1248,1248) -> Float(52,1,52,52) ***************
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: Conv_261 (CublasConvolution)
[03/27/2022-19:12:27] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: Conv_261 (CaskConvolution)
[03/27/2022-19:12:27] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:12:27] [V] [TRT] Tactic: 3886731678879822788 Time: 0.077568
[03/27/2022-19:12:27] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:12:27] [V] [TRT] Tactic: 6629944304117643200 Time: 0.045312
[03/27/2022-19:12:27] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:12:27] [V] [TRT] Tactic: -9153228964338181824 Time: 0.045696
[03/27/2022-19:12:27] [V] [TRT] Conv_261 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:12:27] [V] [TRT] Tactic: -7394439838318485025 Time: 0.080384
[03/27/2022-19:12:27] [V] [TRT] Fastest Tactic: 6629944304117643200 Time: 0.045312
[03/27/2022-19:12:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200
[03/27/2022-19:12:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:27] [V] [TRT] *************** Autotuning format combination: Float(52,1,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_262), Mul_263) (PointWiseV2)
[03/27/2022-19:12:27] [V] [TRT] Tactic: 0 Time: 0.005764
[03/27/2022-19:12:27] [V] [TRT] Tactic: 1 Time: 0.006016
[03/27/2022-19:12:27] [V] [TRT] Tactic: 2 Time: 0.005508
[03/27/2022-19:12:27] [V] [TRT] Tactic: 3 Time: 0.006656
[03/27/2022-19:12:27] [V] [TRT] Tactic: 4 Time: 0.006144
[03/27/2022-19:12:27] [V] [TRT] Tactic: 5 Time: 0.006016
[03/27/2022-19:12:27] [V] [TRT] Tactic: 6 Time: 0.007424
[03/27/2022-19:12:27] [V] [TRT] Tactic: 7 Time: 0.006784
[03/27/2022-19:12:27] [V] [TRT] Tactic: 8 Time: 0.006396
[03/27/2022-19:12:27] [V] [TRT] Tactic: 9 Time: 0.006656
[03/27/2022-19:12:27] [V] [TRT] Tactic: 28 Time: 0.005756
[03/27/2022-19:12:27] [V] [TRT] Fastest Tactic: 2 Time: 0.005508
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_262), Mul_263) (PointWise)
[03/27/2022-19:12:27] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:12:27] [V] [TRT] *************** Autotuning format combination: Float(52,1,52,52) -> Float(52,1,52,52) ***************
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_262), Mul_263) (PointWiseV2)
[03/27/2022-19:12:27] [V] [TRT] Tactic: 0 Time: 0.005756
[03/27/2022-19:12:27] [V] [TRT] Tactic: 1 Time: 0.006272
[03/27/2022-19:12:27] [V] [TRT] Tactic: 2 Time: 0.006144
[03/27/2022-19:12:27] [V] [TRT] Tactic: 3 Time: 0.0064
[03/27/2022-19:12:27] [V] [TRT] Tactic: 4 Time: 0.006272
[03/27/2022-19:12:27] [V] [TRT] Tactic: 5 Time: 0.006272
[03/27/2022-19:12:27] [V] [TRT] Tactic: 6 Time: 0.007548
[03/27/2022-19:12:27] [V] [TRT] Tactic: 7 Time: 0.006784
[03/27/2022-19:12:27] [V] [TRT] Tactic: 8 Time: 0.006272
[03/27/2022-19:12:27] [V] [TRT] Tactic: 9 Time: 0.006652
[03/27/2022-19:12:27] [V] [TRT] Tactic: 28 Time: 0.005504
[03/27/2022-19:12:27] [V] [TRT] Fastest Tactic: 28 Time: 0.005504
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_262), Mul_263) (PointWise)
[03/27/2022-19:12:27] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:12:27] [V] [TRT] *************** Autotuning format combination: Float(2,1:32,1,1) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_262), Mul_263) (PointWiseV2)
[03/27/2022-19:12:27] [V] [TRT] Tactic: 24 Time: 0.006396
[03/27/2022-19:12:27] [V] [TRT] Tactic: 25 Time: 0.0064
[03/27/2022-19:12:27] [V] [TRT] Tactic: 26 Time: 0.006784
[03/27/2022-19:12:27] [V] [TRT] Tactic: 27 Time: 0.007296
[03/27/2022-19:12:27] [V] [TRT] Tactic: 31 Time: 0.006272
[03/27/2022-19:12:27] [V] [TRT] Fastest Tactic: 31 Time: 0.006272
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_262), Mul_263) (PointWise)
[03/27/2022-19:12:27] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:12:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:27] [V] [TRT] *************** Autotuning format combination: Float(52,1,1,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: Conv_264 (CudaDepthwiseConvolution)
[03/27/2022-19:12:27] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: Conv_264 (FusedConvActConvolution)
[03/27/2022-19:12:27] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: Conv_264 (CudnnConvolution)
[03/27/2022-19:12:27] [V] [TRT] Tactic: 0 Time: 0.01574
[03/27/2022-19:12:27] [V] [TRT] Tactic: 1 Time: 0.015104
[03/27/2022-19:12:27] [V] [TRT] Tactic: 2 Time: 0.03456
[03/27/2022-19:12:27] [V] [TRT] Tactic: 4 Time: 0.752896
[03/27/2022-19:12:27] [V] [TRT] Tactic: 5 Time: 0.153856
[03/27/2022-19:12:27] [V] [TRT] Fastest Tactic: 1 Time: 0.015104
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: Conv_264 (CublasConvolution)
[03/27/2022-19:12:27] [V] [TRT] Tactic: 0 Time: 0.010876
[03/27/2022-19:12:27] [V] [TRT] Tactic: 1 Time: 0.010244
[03/27/2022-19:12:27] [V] [TRT] Fastest Tactic: 1 Time: 0.010244
[03/27/2022-19:12:27] [V] [TRT] --------------- Timing Runner: Conv_264 (CaskConvolution)
[03/27/2022-19:12:27] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:27] [V] [TRT] Tactic: 1062367460111450758 Time: 0.019068
[03/27/2022-19:12:27] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:12:28] [V] [TRT] Tactic: 1698681053543049347 Time: 0.015488
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:28] [V] [TRT] Tactic: 4501471010995462441 Time: 0.018816
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:28] [V] [TRT] Tactic: 5137655947464784826 Time: 0.016896
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:28] [V] [TRT] Tactic: 5288347012147084929 Time: 0.019072
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:12:28] [V] [TRT] Tactic: 5326823351883942011 Time: 0.018304
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:12:28] [V] [TRT] Tactic: 5500448035057547314 Time: 0.017024
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:28] [V] [TRT] Tactic: 6645123197870846056 Time: 0.016768
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:28] [V] [TRT] Tactic: 7144526460361122478 Time: 0.015616
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:28] [V] [TRT] Tactic: -8262349710178828730 Time: 0.019072
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:12:28] [V] [TRT] Tactic: -6576203419454146580 Time: 0.01728
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:28] [V] [TRT] Tactic: -4787320710726427159 Time: 0.015872
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:28] [V] [TRT] Tactic: -3456450830548107839 Time: 0.017788
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:28] [V] [TRT] Tactic: -1218658103698133241 Time: 0.01792
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:28] [V] [TRT] Tactic: -836875257600482091 Time: 0.017408
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:28] [V] [TRT] Tactic: -410470605513481746 Time: 0.01856
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:12:28] [V] [TRT] Tactic: -377491875521947884 Time: 0.018816
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:12:28] [V] [TRT] Tactic: -37215280111360163 Time: 0.016256
[03/27/2022-19:12:28] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.015488
[03/27/2022-19:12:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1
[03/27/2022-19:12:28] [V] [TRT] *************** Autotuning format combination: Float(52,1,52,52) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:12:28] [V] [TRT] --------------- Timing Runner: Conv_264 (CublasConvolution)
[03/27/2022-19:12:28] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:28] [V] [TRT] --------------- Timing Runner: Conv_264 (CaskConvolution)
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:12:28] [V] [TRT] Tactic: 3886731678879822788 Time: 0.01446
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:12:28] [V] [TRT] Tactic: 6629944304117643200 Time: 0.01472
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:12:28] [V] [TRT] Tactic: -9153228964338181824 Time: 0.014848
[03/27/2022-19:12:28] [V] [TRT] Conv_264 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:12:28] [V] [TRT] Tactic: -7394439838318485025 Time: 0.014976
[03/27/2022-19:12:28] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.01446
[03/27/2022-19:12:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:12:28] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:28] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1,1), Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_265), Mul_266) (PointWiseV2)
[03/27/2022-19:12:28] [V] [TRT] Tactic: 0 Time: 0.105088
[03/27/2022-19:12:28] [V] [TRT] Tactic: 1 Time: 0.12544
[03/27/2022-19:12:28] [V] [TRT] Tactic: 2 Time: 0.114688
[03/27/2022-19:12:28] [V] [TRT] Tactic: 3 Time: 0.142592
[03/27/2022-19:12:28] [V] [TRT] Tactic: 4 Time: 0.14848
[03/27/2022-19:12:28] [V] [TRT] Tactic: 5 Time: 0.12954
[03/27/2022-19:12:28] [V] [TRT] Tactic: 6 Time: 0.17792
[03/27/2022-19:12:28] [V] [TRT] Tactic: 7 Time: 0.187264
[03/27/2022-19:12:28] [V] [TRT] Tactic: 8 Time: 0.182388
[03/27/2022-19:12:28] [V] [TRT] Tactic: 9 Time: 0.156032
[03/27/2022-19:12:28] [V] [TRT] Tactic: 28 Time: 0.054268
[03/27/2022-19:12:28] [V] [TRT] Fastest Tactic: 28 Time: 0.054268
[03/27/2022-19:12:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_265), Mul_266) (PointWise)
[03/27/2022-19:12:28] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:12:28] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1248,1248), Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_265), Mul_266) (PointWiseV2)
[03/27/2022-19:12:28] [V] [TRT] Tactic: 0 Time: 0.06784
[03/27/2022-19:12:28] [V] [TRT] Tactic: 1 Time: 0.0466
[03/27/2022-19:12:28] [V] [TRT] Tactic: 2 Time: 0.043264
[03/27/2022-19:12:28] [V] [TRT] Tactic: 3 Time: 0.034176
[03/27/2022-19:12:28] [V] [TRT] Tactic: 4 Time: 0.033792
[03/27/2022-19:12:28] [V] [TRT] Tactic: 5 Time: 0.032768
[03/27/2022-19:12:28] [V] [TRT] Tactic: 6 Time: 0.033924
[03/27/2022-19:12:28] [V] [TRT] Tactic: 7 Time: 0.03264
[03/27/2022-19:12:28] [V] [TRT] Tactic: 8 Time: 0.032384
[03/27/2022-19:12:28] [V] [TRT] Tactic: 9 Time: 0.032896
[03/27/2022-19:12:28] [V] [TRT] Tactic: 28 Time: 0.066048
[03/27/2022-19:12:28] [V] [TRT] Fastest Tactic: 8 Time: 0.032384
[03/27/2022-19:12:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_265), Mul_266) (PointWise)
[03/27/2022-19:12:28] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:12:28] [V] [TRT] *************** Autotuning format combination: Float(39,1:32,1,1), Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_265), Mul_266) (PointWiseV2)
[03/27/2022-19:12:28] [V] [TRT] Tactic: 24 Time: 0.031232
[03/27/2022-19:12:28] [V] [TRT] Tactic: 25 Time: 0.031616
[03/27/2022-19:12:28] [V] [TRT] Tactic: 26 Time: 0.031488
[03/27/2022-19:12:28] [V] [TRT] Tactic: 27 Time: 0.032132
[03/27/2022-19:12:28] [V] [TRT] Tactic: 31 Time: 0.031232
[03/27/2022-19:12:28] [V] [TRT] Fastest Tactic: 24 Time: 0.031232
[03/27/2022-19:12:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_265), Mul_266) (PointWise)
[03/27/2022-19:12:28] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[03/27/2022-19:12:28] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:28] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1), Float(53248,256,16,1) -> Float(53248,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] --------------- Timing Runner: Conv_267 + Add_268 (CudaDepthwiseConvolution)
[03/27/2022-19:12:29] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:29] [V] [TRT] --------------- Timing Runner: Conv_267 + Add_268 (FusedConvActConvolution)
[03/27/2022-19:12:29] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:29] [V] [TRT] --------------- Timing Runner: Conv_267 + Add_268 (CudnnConvolution)
[03/27/2022-19:12:29] [V] [TRT] Tactic: 0 Time: 0.275324
[03/27/2022-19:12:29] [V] [TRT] Tactic: 1 Time: 0.250112
[03/27/2022-19:12:29] [V] [TRT] Tactic: 2 Time: 0.4009
[03/27/2022-19:12:29] [V] [TRT] Tactic: 4 Time: 3.60102
[03/27/2022-19:12:29] [V] [TRT] Tactic: 5 Time: 0.567552
[03/27/2022-19:12:29] [V] [TRT] Fastest Tactic: 1 Time: 0.250112
[03/27/2022-19:12:29] [V] [TRT] --------------- Timing Runner: Conv_267 + Add_268 (CublasConvolution)
[03/27/2022-19:12:29] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:29] [V] [TRT] --------------- Timing Runner: Conv_267 + Add_268 (CaskConvolution)
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:29] [V] [TRT] Tactic: 1062367460111450758 Time: 0.169472
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:12:29] [V] [TRT] Tactic: 1698681053543049347 Time: 0.185468
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:29] [V] [TRT] Tactic: 4501471010995462441 Time: 0.160644
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:29] [V] [TRT] Tactic: 5137655947464784826 Time: 0.157312
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:29] [V] [TRT] Tactic: 5288347012147084929 Time: 0.162304
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:12:29] [V] [TRT] Tactic: 5326823351883942011 Time: 0.163192
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:12:29] [V] [TRT] Tactic: 5500448035057547314 Time: 0.199424
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:29] [V] [TRT] Tactic: 6645123197870846056 Time: 0.165504
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:29] [V] [TRT] Tactic: 7144526460361122478 Time: 0.186112
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:29] [V] [TRT] Tactic: -8262349710178828730 Time: 0.161668
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:12:29] [V] [TRT] Tactic: -6576203419454146580 Time: 0.146944
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:29] [V] [TRT] Tactic: -4787320710726427159 Time: 0.186884
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:29] [V] [TRT] Tactic: -3456450830548107839 Time: 0.156032
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:29] [V] [TRT] Tactic: -1218658103698133241 Time: 0.2112
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:29] [V] [TRT] Tactic: -836875257600482091 Time: 0.207104
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:29] [V] [TRT] Tactic: -410470605513481746 Time: 0.16038
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:12:29] [V] [TRT] Tactic: -377491875521947884 Time: 0.160768
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:12:29] [V] [TRT] Tactic: -37215280111360163 Time: 0.151932
[03/27/2022-19:12:29] [V] [TRT] Fastest Tactic: -6576203419454146580 Time: 0.146944
[03/27/2022-19:12:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6576203419454146580
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248), Float(53248,1,3328,208) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:12:29] [V] [TRT] --------------- Timing Runner: Conv_267 + Add_268 (CublasConvolution)
[03/27/2022-19:12:29] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:29] [V] [TRT] --------------- Timing Runner: Conv_267 + Add_268 (CaskConvolution)
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:12:29] [V] [TRT] Tactic: 3886731678879822788 Time: 0.1408
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:12:29] [V] [TRT] Tactic: 6629944304117643200 Time: 0.082684
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:12:29] [V] [TRT] Tactic: -9153228964338181824 Time: 0.083836
[03/27/2022-19:12:29] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:12:29] [V] [TRT] Tactic: -7394439838318485025 Time: 0.141952
[03/27/2022-19:12:29] [V] [TRT] Fastest Tactic: 6629944304117643200 Time: 0.082684
[03/27/2022-19:12:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(53248,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(53248,1,3328,208) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1248,1248) -> Float(52,1,52,52) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,52,52) -> Float(52,1,52,52) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(2,1:32,1,1) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,1,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,52,52) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1,1), Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1248,1248), Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(39,1:32,1,1), Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1), Float(53248,256,16,1) -> Float(53248,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248), Float(53248,1,3328,208) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(53248,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(53248,1,3328,208) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1248,1248) -> Float(52,1,52,52) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,52,52) -> Float(52,1,52,52) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(2,1:32,1,1) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,1,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,52,52) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1,1), Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1248,1248), Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(39,1:32,1,1), Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1), Float(53248,256,16,1) -> Float(53248,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248), Float(53248,1,3328,208) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(53248,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(53248,1,3328,208) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1248,1248) -> Float(52,1,52,52) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,52,52) -> Float(52,1,52,52) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(2,1:32,1,1) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,1,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(52,1,52,52) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1,1), Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1248,1248), Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(39,1:32,1,1), Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1), Float(53248,256,16,1) -> Float(53248,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248), Float(53248,1,3328,208) -> Float(53248,1,3328,208) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(53248,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(53248,1,3328,208) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:29] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:29] [V] [TRT] --------------- Timing Runner: Conv_317 (CudaDepthwiseConvolution)
[03/27/2022-19:12:29] [V] [TRT] Tactic: -1 Time: 0.063476
[03/27/2022-19:12:29] [V] [TRT] Fastest Tactic: -1 Time: 0.063476
[03/27/2022-19:12:29] [V] [TRT] --------------- Timing Runner: Conv_317 (CudnnConvolution)
[03/27/2022-19:12:29] [V] [TRT] Tactic: 0 Time: 0.09818
[03/27/2022-19:12:29] [V] [TRT] Tactic: 1 Time: 0.098556
[03/27/2022-19:12:29] [V] [TRT] Tactic: 2 Time: 0.147712
[03/27/2022-19:12:31] [V] [TRT] Tactic: 4 Time: 115.096
[03/27/2022-19:12:33] [V] [TRT] Tactic: 5 Time: 96.4303
[03/27/2022-19:12:34] [V] [TRT] Tactic: 6 Time: 31.157
[03/27/2022-19:12:34] [V] [TRT] Fastest Tactic: 0 Time: 0.09818
[03/27/2022-19:12:34] [V] [TRT] --------------- Timing Runner: Conv_317 (CaskConvolution)
[03/27/2022-19:12:34] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:34] [V] [TRT] Tactic: 1062367460111450758 Time: 13.9983
[03/27/2022-19:12:34] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:12:34] [V] [TRT] Tactic: 1754984623894446479 Time: 9.09478
[03/27/2022-19:12:34] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:12:34] [V] [TRT] Tactic: 3611739942397549984 Time: 13.7306
[03/27/2022-19:12:34] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:12:35] [V] [TRT] Tactic: 3827454225649558724 Time: 8.11366
[03/27/2022-19:12:35] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:12:35] [V] [TRT] Tactic: 4337000649858996379 Time: 12.5462
[03/27/2022-19:12:35] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:35] [V] [TRT] Tactic: 4501471010995462441 Time: 15.4194
[03/27/2022-19:12:36] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:36] [V] [TRT] Tactic: 5137655947464784826 Time: 19.8273
[03/27/2022-19:12:36] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:36] [V] [TRT] Tactic: 5288347012147084929 Time: 14.327
[03/27/2022-19:12:36] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:12:36] [V] [TRT] Tactic: 5921334924264294896 Time: 8.87053
[03/27/2022-19:12:37] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:37] [V] [TRT] Tactic: 6645123197870846056 Time: 12.6793
[03/27/2022-19:12:37] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:37] [V] [TRT] Tactic: 7144526460361122478 Time: 10.2857
[03/27/2022-19:12:38] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:12:38] [V] [TRT] Tactic: 7852627285308570038 Time: 14.2792
[03/27/2022-19:12:38] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:12:38] [V] [TRT] Tactic: -9137461792520977713 Time: 14.1231
[03/27/2022-19:12:38] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:12:38] [V] [TRT] Tactic: -8776506421218919509 Time: 7.93229
[03/27/2022-19:12:38] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:39] [V] [TRT] Tactic: -8262349710178828730 Time: 17.9589
[03/27/2022-19:12:39] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:12:39] [V] [TRT] Tactic: -8133971918129952780 Time: 12.3734
[03/27/2022-19:12:39] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:12:39] [V] [TRT] Tactic: -6092040395344634144 Time: 15.6929
[03/27/2022-19:12:40] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:40] [V] [TRT] Tactic: -4787320710726427159 Time: 9.08749
[03/27/2022-19:12:40] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:40] [V] [TRT] Tactic: -3456450830548107839 Time: 14.7773
[03/27/2022-19:12:40] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:12:40] [V] [TRT] Tactic: -2318106587342035239 Time: 8.09562
[03/27/2022-19:12:41] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:12:41] [V] [TRT] Tactic: -1343271414618805657 Time: 8.17626
[03/27/2022-19:12:41] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:41] [V] [TRT] Tactic: -1218658103698133241 Time: 11.7834
[03/27/2022-19:12:41] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:41] [V] [TRT] Tactic: -836875257600482091 Time: 13.3956
[03/27/2022-19:12:41] [V] [TRT] Conv_317 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:42] [V] [TRT] Tactic: -410470605513481746 Time: 16.5051
[03/27/2022-19:12:42] [V] [TRT] Fastest Tactic: -8776506421218919509 Time: 7.93229
[03/27/2022-19:12:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:42] [V] [TRT] --------------- Timing Runner: Conv_317 (CaskConvolution)
[03/27/2022-19:12:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:12:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1248,1248) -> Float(52,1,52,52) ***************
[03/27/2022-19:12:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(52,1,1,1) -> Float(52,1,1,1) ***************
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(52,1,52,52) -> Float(52,1,52,52) ***************
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(2,1:32,1,1) -> Float(2,1:32,1,1) ***************
[03/27/2022-19:12:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(52,1,1,1) -> Float(1248,1,1,1) ***************
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(52,1,52,52) -> Float(1248,1,1248,1248) ***************
[03/27/2022-19:12:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1,1), Float(319488,256,16,1) -> Float(319488,256,16,1) ***************
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(1248,1,1248,1248), Float(319488,1,19968,1248) -> Float(319488,1,19968,1248) ***************
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(39,1:32,1,1), Float(9984,256:32,16,1) -> Float(9984,256:32,16,1) ***************
[03/27/2022-19:12:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(319488,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:12:42] [V] [TRT] --------------- Timing Runner: Conv_327 (CudaDepthwiseConvolution)
[03/27/2022-19:12:42] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:42] [V] [TRT] --------------- Timing Runner: Conv_327 (FusedConvActConvolution)
[03/27/2022-19:12:42] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:42] [V] [TRT] --------------- Timing Runner: Conv_327 (CudnnConvolution)
[03/27/2022-19:12:42] [V] [TRT] Tactic: 0 Time: 0.284032
[03/27/2022-19:12:42] [V] [TRT] Tactic: 1 Time: 0.180992
[03/27/2022-19:12:42] [V] [TRT] Tactic: 2 Time: 0.33856
[03/27/2022-19:12:42] [V] [TRT] Tactic: 4 Time: 5.83654
[03/27/2022-19:12:42] [V] [TRT] Tactic: 5 Time: 0.941828
[03/27/2022-19:12:42] [V] [TRT] Fastest Tactic: 1 Time: 0.180992
[03/27/2022-19:12:42] [V] [TRT] --------------- Timing Runner: Conv_327 (CublasConvolution)
[03/27/2022-19:12:42] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:42] [V] [TRT] --------------- Timing Runner: Conv_327 (CaskConvolution)
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:42] [V] [TRT] Tactic: 1062367460111450758 Time: 0.20032
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:12:42] [V] [TRT] Tactic: 1698681053543049347 Time: 0.178296
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:42] [V] [TRT] Tactic: 4501471010995462441 Time: 0.163204
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:42] [V] [TRT] Tactic: 5137655947464784826 Time: 0.162944
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:42] [V] [TRT] Tactic: 5288347012147084929 Time: 0.16422
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:12:42] [V] [TRT] Tactic: 5326823351883942011 Time: 0.161408
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:12:42] [V] [TRT] Tactic: 5500448035057547314 Time: 0.215552
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:42] [V] [TRT] Tactic: 6645123197870846056 Time: 0.172544
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:42] [V] [TRT] Tactic: 7144526460361122478 Time: 0.185472
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:42] [V] [TRT] Tactic: -8262349710178828730 Time: 0.166144
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:12:42] [V] [TRT] Tactic: -6576203419454146580 Time: 0.172416
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:42] [V] [TRT] Tactic: -4787320710726427159 Time: 0.1952
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:42] [V] [TRT] Tactic: -3456450830548107839 Time: 0.183808
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:42] [V] [TRT] Tactic: -1218658103698133241 Time: 0.231808
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:42] [V] [TRT] Tactic: -836875257600482091 Time: 0.21952
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:42] [V] [TRT] Tactic: -410470605513481746 Time: 0.160892
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:12:42] [V] [TRT] Tactic: -377491875521947884 Time: 0.164096
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:12:42] [V] [TRT] Tactic: -37215280111360163 Time: 0.16358
[03/27/2022-19:12:42] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.160892
[03/27/2022-19:12:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(319488,1,19968,1248) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:12:42] [V] [TRT] --------------- Timing Runner: Conv_327 (CublasConvolution)
[03/27/2022-19:12:42] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:42] [V] [TRT] --------------- Timing Runner: Conv_327 (CaskConvolution)
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:12:42] [V] [TRT] Tactic: 3886731678879822788 Time: 0.139904
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:12:42] [V] [TRT] Tactic: 6629944304117643200 Time: 0.129412
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:12:42] [V] [TRT] Tactic: -9153228964338181824 Time: 0.129024
[03/27/2022-19:12:42] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:12:42] [V] [TRT] Tactic: -7394439838318485025 Time: 0.141188
[03/27/2022-19:12:42] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.129024
[03/27/2022-19:12:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:12:42] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:42] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:12:42] [V] [TRT] --------------- Timing Runner: Conv_328 (CudaDepthwiseConvolution)
[03/27/2022-19:12:42] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:42] [V] [TRT] --------------- Timing Runner: Conv_328 (FusedConvActConvolution)
[03/27/2022-19:12:42] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:42] [V] [TRT] --------------- Timing Runner: Conv_328 (CudnnConvolution)
[03/27/2022-19:12:42] [V] [TRT] Tactic: 0 Time: 0.379392
[03/27/2022-19:12:42] [V] [TRT] Tactic: 1 Time: 0.290172
[03/27/2022-19:12:43] [V] [TRT] Tactic: 2 Time: 0.543232
[03/27/2022-19:12:43] [V] [TRT] Tactic: 4 Time: 10.6394
[03/27/2022-19:12:43] [V] [TRT] Tactic: 5 Time: 1.5296
[03/27/2022-19:12:43] [V] [TRT] Fastest Tactic: 1 Time: 0.290172
[03/27/2022-19:12:43] [V] [TRT] --------------- Timing Runner: Conv_328 (CublasConvolution)
[03/27/2022-19:12:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:43] [V] [TRT] --------------- Timing Runner: Conv_328 (CaskConvolution)
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:43] [V] [TRT] Tactic: 1062367460111450758 Time: 0.27776
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:12:43] [V] [TRT] Tactic: 1698681053543049347 Time: 0.227964
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:43] [V] [TRT] Tactic: 4501471010995462441 Time: 0.239104
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:43] [V] [TRT] Tactic: 5137655947464784826 Time: 0.217856
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:43] [V] [TRT] Tactic: 5288347012147084929 Time: 0.227072
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:12:43] [V] [TRT] Tactic: 5326823351883942011 Time: 0.230016
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:12:43] [V] [TRT] Tactic: 5500448035057547314 Time: 0.228352
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:43] [V] [TRT] Tactic: 6645123197870846056 Time: 0.222456
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:43] [V] [TRT] Tactic: 7144526460361122478 Time: 0.256896
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:12:43] [V] [TRT] Tactic: -8262349710178828730 Time: 0.221056
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:12:43] [V] [TRT] Tactic: -6576203419454146580 Time: 0.226048
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:12:43] [V] [TRT] Tactic: -4787320710726427159 Time: 0.265464
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:12:43] [V] [TRT] Tactic: -3456450830548107839 Time: 0.241412
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:12:43] [V] [TRT] Tactic: -1218658103698133241 Time: 0.241028
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:12:43] [V] [TRT] Tactic: -836875257600482091 Time: 0.234368
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:12:43] [V] [TRT] Tactic: -410470605513481746 Time: 0.21568
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:12:43] [V] [TRT] Tactic: -377491875521947884 Time: 0.214656
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:12:43] [V] [TRT] Tactic: -37215280111360163 Time: 0.209664
[03/27/2022-19:12:43] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.209664
[03/27/2022-19:12:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[03/27/2022-19:12:43] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:12:43] [V] [TRT] --------------- Timing Runner: Conv_328 (CublasConvolution)
[03/27/2022-19:12:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:12:43] [V] [TRT] --------------- Timing Runner: Conv_328 (CaskConvolution)
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:12:43] [V] [TRT] Tactic: 3886731678879822788 Time: 0.200448
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:12:43] [V] [TRT] Tactic: 6629944304117643200 Time: 0.221952
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:12:43] [V] [TRT] Tactic: -9153228964338181824 Time: 0.224384
[03/27/2022-19:12:43] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:12:43] [V] [TRT] Tactic: -7394439838318485025 Time: 0.20288
[03/27/2022-19:12:43] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.200448
[03/27/2022-19:12:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:12:43] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:43] [V] [TRT] *************** Autotuning format combination: Float(540672,256,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:12:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_329), Mul_330) (PointWiseV2)
[03/27/2022-19:12:43] [V] [TRT] Tactic: 0 Time: 0.05504
[03/27/2022-19:12:43] [V] [TRT] Tactic: 1 Time: 0.047616
[03/27/2022-19:12:43] [V] [TRT] Tactic: 2 Time: 0.046856
[03/27/2022-19:12:43] [V] [TRT] Tactic: 3 Time: 0.047488
[03/27/2022-19:12:43] [V] [TRT] Tactic: 4 Time: 0.046976
[03/27/2022-19:12:43] [V] [TRT] Tactic: 5 Time: 0.04608
[03/27/2022-19:12:43] [V] [TRT] Tactic: 6 Time: 0.048896
[03/27/2022-19:12:43] [V] [TRT] Tactic: 7 Time: 0.04736
[03/27/2022-19:12:43] [V] [TRT] Tactic: 8 Time: 0.046464
[03/27/2022-19:12:43] [V] [TRT] Tactic: 9 Time: 0.04672
[03/27/2022-19:12:43] [V] [TRT] Tactic: 28 Time: 0.05504
[03/27/2022-19:12:43] [V] [TRT] Fastest Tactic: 5 Time: 0.04608
[03/27/2022-19:12:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_329), Mul_330) (PointWise)
[03/27/2022-19:12:43] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:12:43] [V] [TRT] *************** Autotuning format combination: Float(540672,1,33792,2112) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:12:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_329), Mul_330) (PointWiseV2)
[03/27/2022-19:12:43] [V] [TRT] Tactic: 0 Time: 0.055292
[03/27/2022-19:12:43] [V] [TRT] Tactic: 1 Time: 0.047744
[03/27/2022-19:12:43] [V] [TRT] Tactic: 2 Time: 0.047104
[03/27/2022-19:12:43] [V] [TRT] Tactic: 3 Time: 0.047616
[03/27/2022-19:12:43] [V] [TRT] Tactic: 4 Time: 0.046724
[03/27/2022-19:12:43] [V] [TRT] Tactic: 5 Time: 0.046464
[03/27/2022-19:12:43] [V] [TRT] Tactic: 6 Time: 0.049532
[03/27/2022-19:12:44] [V] [TRT] Tactic: 7 Time: 0.046976
[03/27/2022-19:12:44] [V] [TRT] Tactic: 8 Time: 0.046848
[03/27/2022-19:12:44] [V] [TRT] Tactic: 9 Time: 0.046592
[03/27/2022-19:12:44] [V] [TRT] Tactic: 28 Time: 0.055424
[03/27/2022-19:12:44] [V] [TRT] Fastest Tactic: 5 Time: 0.046464
[03/27/2022-19:12:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_329), Mul_330) (PointWise)
[03/27/2022-19:12:44] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[03/27/2022-19:12:44] [V] [TRT] *************** Autotuning format combination: Float(16896,256:32,16,1) -> Float(16896,256:32,16,1) ***************
[03/27/2022-19:12:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_329), Mul_330) (PointWiseV2)
[03/27/2022-19:12:44] [V] [TRT] Tactic: 24 Time: 0.04672
[03/27/2022-19:12:44] [V] [TRT] Tactic: 25 Time: 0.046712
[03/27/2022-19:12:44] [V] [TRT] Tactic: 26 Time: 0.047244
[03/27/2022-19:12:44] [V] [TRT] Tactic: 27 Time: 0.049536
[03/27/2022-19:12:44] [V] [TRT] Tactic: 31 Time: 0.046464
[03/27/2022-19:12:44] [V] [TRT] Fastest Tactic: 31 Time: 0.046464
[03/27/2022-19:12:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_329), Mul_330) (PointWise)
[03/27/2022-19:12:44] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:12:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:12:44] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:12:44] [V] [TRT] *************** Autotuning format combination: Float(540672,256,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:12:44] [V] [TRT] --------------- Timing Runner: Conv_331 (CudaDepthwiseConvolution)
[03/27/2022-19:12:44] [V] [TRT] Tactic: -1 Time: 0.102016
[03/27/2022-19:12:44] [V] [TRT] Fastest Tactic: -1 Time: 0.102016
[03/27/2022-19:12:44] [V] [TRT] --------------- Timing Runner: Conv_331 (CudnnConvolution)
[03/27/2022-19:12:44] [V] [TRT] Tactic: 0 Time: 0.157948
[03/27/2022-19:12:44] [V] [TRT] Tactic: 1 Time: 0.157444
[03/27/2022-19:12:44] [V] [TRT] Tactic: 2 Time: 0.245112
[03/27/2022-19:12:47] [V] [TRT] Tactic: 4 Time: 186.172
[03/27/2022-19:12:51] [V] [TRT] Tactic: 5 Time: 271.887
[03/27/2022-19:12:52] [V] [TRT] Tactic: 6 Time: 78.0067
[03/27/2022-19:12:52] [V] [TRT] Fastest Tactic: 1 Time: 0.157444
[03/27/2022-19:12:52] [V] [TRT] --------------- Timing Runner: Conv_331 (CaskConvolution)
[03/27/2022-19:12:53] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:12:53] [V] [TRT] Tactic: 1062367460111450758 Time: 23.6746
[03/27/2022-19:12:53] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:12:54] [V] [TRT] Tactic: 1754984623894446479 Time: 22.759
[03/27/2022-19:12:54] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:12:55] [V] [TRT] Tactic: 3611739942397549984 Time: 24.3196
[03/27/2022-19:12:55] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:12:55] [V] [TRT] Tactic: 3827454225649558724 Time: 14.625
[03/27/2022-19:12:55] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:12:56] [V] [TRT] Tactic: 4337000649858996379 Time: 26.646
[03/27/2022-19:12:56] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:12:56] [V] [TRT] Tactic: 4501471010995462441 Time: 26.3277
[03/27/2022-19:12:57] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:12:57] [V] [TRT] Tactic: 5137655947464784826 Time: 29.7846
[03/27/2022-19:12:57] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:12:58] [V] [TRT] Tactic: 5288347012147084929 Time: 22.8557
[03/27/2022-19:12:58] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:12:58] [V] [TRT] Tactic: 5921334924264294896 Time: 15.0922
[03/27/2022-19:12:58] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:12:59] [V] [TRT] Tactic: 6645123197870846056 Time: 25.522
[03/27/2022-19:12:59] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:12:59] [V] [TRT] Tactic: 7144526460361122478 Time: 15.3736
[03/27/2022-19:12:59] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:12:59] [V] [TRT] Tactic: 7852627285308570038 Time: 17.9636
[03/27/2022-19:13:00] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:00] [V] [TRT] Tactic: -9137461792520977713 Time: 23.1311
[03/27/2022-19:13:00] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:00] [V] [TRT] Tactic: -8776506421218919509 Time: 13.7498
[03/27/2022-19:13:00] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:01] [V] [TRT] Tactic: -8262349710178828730 Time: 23.4145
[03/27/2022-19:13:01] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:01] [V] [TRT] Tactic: -8133971918129952780 Time: 21.6952
[03/27/2022-19:13:02] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:02] [V] [TRT] Tactic: -6092040395344634144 Time: 28.417
[03/27/2022-19:13:02] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:03] [V] [TRT] Tactic: -4787320710726427159 Time: 21.5028
[03/27/2022-19:13:03] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:03] [V] [TRT] Tactic: -3456450830548107839 Time: 25.564
[03/27/2022-19:13:03] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:04] [V] [TRT] Tactic: -2318106587342035239 Time: 14.1773
[03/27/2022-19:13:04] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:04] [V] [TRT] Tactic: -1343271414618805657 Time: 15.1813
[03/27/2022-19:13:04] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:05] [V] [TRT] Tactic: -1218658103698133241 Time: 26.9132
[03/27/2022-19:13:05] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:05] [V] [TRT] Tactic: -836875257600482091 Time: 19.6274
[03/27/2022-19:13:05] [V] [TRT] Conv_331 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:05] [V] [TRT] Tactic: -410470605513481746 Time: 22.1311
[03/27/2022-19:13:05] [V] [TRT] Fastest Tactic: -8776506421218919509 Time: 13.7498
[03/27/2022-19:13:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaDepthwiseConvolution Tactic: -1
[03/27/2022-19:13:05] [V] [TRT] *************** Autotuning format combination: Float(540672,1,33792,2112) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:13:05] [V] [TRT] --------------- Timing Runner: Conv_331 (CaskConvolution)
[03/27/2022-19:13:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:05] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:05] [V] [TRT] *************** Autotuning format combination: Float(540672,256,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:13:05] [V] [TRT] *************** Autotuning format combination: Float(540672,1,33792,2112) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:13:05] [V] [TRT] *************** Autotuning format combination: Float(16896,256:32,16,1) -> Float(16896,256:32,16,1) ***************
[03/27/2022-19:13:05] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:05] [V] [TRT] *************** Autotuning format combination: Float(540672,256,16,1) -> Float(2112,1,1,1) ***************
[03/27/2022-19:13:05] [V] [TRT] --------------- Timing Runner: ReduceMean_334 (TiledPooling)
[03/27/2022-19:13:05] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[03/27/2022-19:13:05] [V] [TRT] --------------- Timing Runner: ReduceMean_334 (CudnnPooling)
[03/27/2022-19:13:05] [V] [TRT] Tactic: -1 Time: 0.037376
[03/27/2022-19:13:05] [V] [TRT] Fastest Tactic: -1 Time: 0.037376
[03/27/2022-19:13:05] [V] [TRT] --------------- Timing Runner: ReduceMean_334 (CaskPooling)
[03/27/2022-19:13:05] [V] [TRT] ReduceMean_334 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:13:05] [V] [TRT] Tactic: 6119644359078410246 Time: 0.040448
[03/27/2022-19:13:05] [V] [TRT] Fastest Tactic: 6119644359078410246 Time: 0.040448
[03/27/2022-19:13:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[03/27/2022-19:13:05] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:05] [V] [TRT] *************** Autotuning format combination: Float(2112,1,1,1) -> Float(88,1,1,1) ***************
[03/27/2022-19:13:05] [V] [TRT] --------------- Timing Runner: Conv_335 (CudaDepthwiseConvolution)
[03/27/2022-19:13:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:05] [V] [TRT] --------------- Timing Runner: Conv_335 (FusedConvActConvolution)
[03/27/2022-19:13:05] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:05] [V] [TRT] --------------- Timing Runner: Conv_335 (CudnnConvolution)
[03/27/2022-19:13:05] [V] [TRT] Tactic: 0 Time: 0.163144
[03/27/2022-19:13:05] [V] [TRT] Tactic: 1 Time: 0.024692
[03/27/2022-19:13:05] [V] [TRT] Tactic: 2 Time: 0.236416
[03/27/2022-19:13:06] [V] [TRT] Tactic: 4 Time: 2.41459
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5 Time: 0.36864
[03/27/2022-19:13:06] [V] [TRT] Fastest Tactic: 1 Time: 0.024692
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: Conv_335 (CublasConvolution)
[03/27/2022-19:13:06] [V] [TRT] Tactic: 0 Time: 0.019332
[03/27/2022-19:13:06] [V] [TRT] Tactic: 1 Time: 0.031232
[03/27/2022-19:13:06] [V] [TRT] Fastest Tactic: 0 Time: 0.019332
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: Conv_335 (CaskConvolution)
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:06] [V] [TRT] Tactic: 1062367460111450758 Time: 0.235516
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:13:06] [V] [TRT] Tactic: 1698681053543049347 Time: 0.16934
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:06] [V] [TRT] Tactic: 4501471010995462441 Time: 0.24768
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5137655947464784826 Time: 0.163968
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5288347012147084929 Time: 0.241412
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5326823351883942011 Time: 0.240512
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5500448035057547314 Time: 0.217472
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:06] [V] [TRT] Tactic: 6645123197870846056 Time: 0.178816
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:06] [V] [TRT] Tactic: 7144526460361122478 Time: 0.176768
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:06] [V] [TRT] Tactic: -8262349710178828730 Time: 0.245124
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:13:06] [V] [TRT] Tactic: -6576203419454146580 Time: 0.185344
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:06] [V] [TRT] Tactic: -4787320710726427159 Time: 0.191872
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:06] [V] [TRT] Tactic: -3456450830548107839 Time: 0.197508
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:06] [V] [TRT] Tactic: -1218658103698133241 Time: 0.236672
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:06] [V] [TRT] Tactic: -836875257600482091 Time: 0.223484
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:06] [V] [TRT] Tactic: -410470605513481746 Time: 0.23808
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:13:06] [V] [TRT] Tactic: -377491875521947884 Time: 0.237184
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:13:06] [V] [TRT] Tactic: -37215280111360163 Time: 0.15962
[03/27/2022-19:13:06] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.15962
[03/27/2022-19:13:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0
[03/27/2022-19:13:06] [V] [TRT] *************** Autotuning format combination: Float(2112,1,2112,2112) -> Float(88,1,88,88) ***************
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: Conv_335 (CublasConvolution)
[03/27/2022-19:13:06] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: Conv_335 (CaskConvolution)
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:13:06] [V] [TRT] Tactic: 3886731678879822788 Time: 0.123904
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:13:06] [V] [TRT] Tactic: 6629944304117643200 Time: 0.070276
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:06] [V] [TRT] Tactic: -9153228964338181824 Time: 0.070272
[03/27/2022-19:13:06] [V] [TRT] Conv_335 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:06] [V] [TRT] Tactic: -7394439838318485025 Time: 0.12928
[03/27/2022-19:13:06] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.070272
[03/27/2022-19:13:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:06] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:06] [V] [TRT] *************** Autotuning format combination: Float(88,1,1,1) -> Float(88,1,1,1) ***************
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_336), Mul_337) (PointWiseV2)
[03/27/2022-19:13:06] [V] [TRT] Tactic: 0 Time: 0.005884
[03/27/2022-19:13:06] [V] [TRT] Tactic: 1 Time: 0.00614
[03/27/2022-19:13:06] [V] [TRT] Tactic: 2 Time: 0.006016
[03/27/2022-19:13:06] [V] [TRT] Tactic: 3 Time: 0.006656
[03/27/2022-19:13:06] [V] [TRT] Tactic: 4 Time: 0.005888
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5 Time: 0.006144
[03/27/2022-19:13:06] [V] [TRT] Tactic: 6 Time: 0.007808
[03/27/2022-19:13:06] [V] [TRT] Tactic: 7 Time: 0.006912
[03/27/2022-19:13:06] [V] [TRT] Tactic: 8 Time: 0.006532
[03/27/2022-19:13:06] [V] [TRT] Tactic: 9 Time: 0.006528
[03/27/2022-19:13:06] [V] [TRT] Tactic: 28 Time: 0.005504
[03/27/2022-19:13:06] [V] [TRT] Fastest Tactic: 28 Time: 0.005504
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_336), Mul_337) (PointWise)
[03/27/2022-19:13:06] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:13:06] [V] [TRT] *************** Autotuning format combination: Float(88,1,88,88) -> Float(88,1,88,88) ***************
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_336), Mul_337) (PointWiseV2)
[03/27/2022-19:13:06] [V] [TRT] Tactic: 0 Time: 0.00538
[03/27/2022-19:13:06] [V] [TRT] Tactic: 1 Time: 0.006012
[03/27/2022-19:13:06] [V] [TRT] Tactic: 2 Time: 0.005504
[03/27/2022-19:13:06] [V] [TRT] Tactic: 3 Time: 0.0064
[03/27/2022-19:13:06] [V] [TRT] Tactic: 4 Time: 0.006016
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5 Time: 0.00576
[03/27/2022-19:13:06] [V] [TRT] Tactic: 6 Time: 0.007556
[03/27/2022-19:13:06] [V] [TRT] Tactic: 7 Time: 0.006784
[03/27/2022-19:13:06] [V] [TRT] Tactic: 8 Time: 0.006396
[03/27/2022-19:13:06] [V] [TRT] Tactic: 9 Time: 0.0064
[03/27/2022-19:13:06] [V] [TRT] Tactic: 28 Time: 0.005504
[03/27/2022-19:13:06] [V] [TRT] Fastest Tactic: 0 Time: 0.00538
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_336), Mul_337) (PointWise)
[03/27/2022-19:13:06] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0
[03/27/2022-19:13:06] [V] [TRT] *************** Autotuning format combination: Float(3,1:32,1,1) -> Float(3,1:32,1,1) ***************
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_336), Mul_337) (PointWiseV2)
[03/27/2022-19:13:06] [V] [TRT] Tactic: 24 Time: 0.00614
[03/27/2022-19:13:06] [V] [TRT] Tactic: 25 Time: 0.006268
[03/27/2022-19:13:06] [V] [TRT] Tactic: 26 Time: 0.006908
[03/27/2022-19:13:06] [V] [TRT] Tactic: 27 Time: 0.007172
[03/27/2022-19:13:06] [V] [TRT] Tactic: 31 Time: 0.006016
[03/27/2022-19:13:06] [V] [TRT] Fastest Tactic: 31 Time: 0.006016
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_336), Mul_337) (PointWise)
[03/27/2022-19:13:06] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:13:06] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:06] [V] [TRT] *************** Autotuning format combination: Float(88,1,1,1) -> Float(2112,1,1,1) ***************
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: Conv_338 (CudaDepthwiseConvolution)
[03/27/2022-19:13:06] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: Conv_338 (FusedConvActConvolution)
[03/27/2022-19:13:06] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: Conv_338 (CudnnConvolution)
[03/27/2022-19:13:06] [V] [TRT] Tactic: 0 Time: 0.018824
[03/27/2022-19:13:06] [V] [TRT] Tactic: 1 Time: 0.019196
[03/27/2022-19:13:06] [V] [TRT] Tactic: 2 Time: 0.049788
[03/27/2022-19:13:06] [V] [TRT] Tactic: 4 Time: 1.77715
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5 Time: 0.296448
[03/27/2022-19:13:06] [V] [TRT] Fastest Tactic: 0 Time: 0.018824
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: Conv_338 (CublasConvolution)
[03/27/2022-19:13:06] [V] [TRT] Tactic: 0 Time: 0.012284
[03/27/2022-19:13:06] [V] [TRT] Tactic: 1 Time: 0.010624
[03/27/2022-19:13:06] [V] [TRT] Fastest Tactic: 1 Time: 0.010624
[03/27/2022-19:13:06] [V] [TRT] --------------- Timing Runner: Conv_338 (CaskConvolution)
[03/27/2022-19:13:06] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:06] [V] [TRT] Tactic: 1062367460111450758 Time: 0.026748
[03/27/2022-19:13:06] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:13:06] [V] [TRT] Tactic: 1698681053543049347 Time: 0.01984
[03/27/2022-19:13:06] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:06] [V] [TRT] Tactic: 4501471010995462441 Time: 0.022396
[03/27/2022-19:13:06] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5137655947464784826 Time: 0.022396
[03/27/2022-19:13:06] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5288347012147084929 Time: 0.022268
[03/27/2022-19:13:06] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5326823351883942011 Time: 0.022144
[03/27/2022-19:13:06] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:13:06] [V] [TRT] Tactic: 5500448035057547314 Time: 0.023552
[03/27/2022-19:13:06] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:06] [V] [TRT] Tactic: 6645123197870846056 Time: 0.022908
[03/27/2022-19:13:06] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:06] [V] [TRT] Tactic: 7144526460361122478 Time: 0.020608
[03/27/2022-19:13:06] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:06] [V] [TRT] Tactic: -8262349710178828730 Time: 0.022404
[03/27/2022-19:13:06] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:13:07] [V] [TRT] Tactic: -6576203419454146580 Time: 0.024832
[03/27/2022-19:13:07] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:07] [V] [TRT] Tactic: -4787320710726427159 Time: 0.021892
[03/27/2022-19:13:07] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:07] [V] [TRT] Tactic: -3456450830548107839 Time: 0.072192
[03/27/2022-19:13:07] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:07] [V] [TRT] Tactic: -1218658103698133241 Time: 0.024328
[03/27/2022-19:13:07] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:07] [V] [TRT] Tactic: -836875257600482091 Time: 0.024192
[03/27/2022-19:13:07] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:07] [V] [TRT] Tactic: -410470605513481746 Time: 0.021888
[03/27/2022-19:13:07] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:13:07] [V] [TRT] Tactic: -377491875521947884 Time: 0.022016
[03/27/2022-19:13:07] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:13:07] [V] [TRT] Tactic: -37215280111360163 Time: 0.022016
[03/27/2022-19:13:07] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.01984
[03/27/2022-19:13:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 1
[03/27/2022-19:13:07] [V] [TRT] *************** Autotuning format combination: Float(88,1,88,88) -> Float(2112,1,2112,2112) ***************
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: Conv_338 (CublasConvolution)
[03/27/2022-19:13:07] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: Conv_338 (CaskConvolution)
[03/27/2022-19:13:07] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:13:07] [V] [TRT] Tactic: 3886731678879822788 Time: 0.021244
[03/27/2022-19:13:07] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:13:07] [V] [TRT] Tactic: 6629944304117643200 Time: 0.023808
[03/27/2022-19:13:07] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:07] [V] [TRT] Tactic: -9153228964338181824 Time: 0.02368
[03/27/2022-19:13:07] [V] [TRT] Conv_338 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:07] [V] [TRT] Tactic: -7394439838318485025 Time: 0.021632
[03/27/2022-19:13:07] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.021244
[03/27/2022-19:13:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:13:07] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:07] [V] [TRT] *************** Autotuning format combination: Float(2112,1,1,1), Float(540672,256,16,1) -> Float(540672,256,16,1) ***************
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_339), Mul_340) (PointWiseV2)
[03/27/2022-19:13:07] [V] [TRT] Tactic: 0 Time: 0.171648
[03/27/2022-19:13:07] [V] [TRT] Tactic: 1 Time: 0.205444
[03/27/2022-19:13:07] [V] [TRT] Tactic: 2 Time: 0.188536
[03/27/2022-19:13:07] [V] [TRT] Tactic: 3 Time: 0.234616
[03/27/2022-19:13:07] [V] [TRT] Tactic: 4 Time: 0.245248
[03/27/2022-19:13:07] [V] [TRT] Tactic: 5 Time: 0.213496
[03/27/2022-19:13:07] [V] [TRT] Tactic: 6 Time: 0.295296
[03/27/2022-19:13:07] [V] [TRT] Tactic: 7 Time: 0.310528
[03/27/2022-19:13:07] [V] [TRT] Tactic: 8 Time: 0.302464
[03/27/2022-19:13:07] [V] [TRT] Tactic: 9 Time: 0.258684
[03/27/2022-19:13:07] [V] [TRT] Tactic: 28 Time: 0.086272
[03/27/2022-19:13:07] [V] [TRT] Fastest Tactic: 28 Time: 0.086272
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_339), Mul_340) (PointWise)
[03/27/2022-19:13:07] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:13:07] [V] [TRT] *************** Autotuning format combination: Float(2112,1,2112,2112), Float(540672,1,33792,2112) -> Float(540672,1,33792,2112) ***************
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_339), Mul_340) (PointWiseV2)
[03/27/2022-19:13:07] [V] [TRT] Tactic: 0 Time: 0.108672
[03/27/2022-19:13:07] [V] [TRT] Tactic: 1 Time: 0.07194
[03/27/2022-19:13:07] [V] [TRT] Tactic: 2 Time: 0.067208
[03/27/2022-19:13:07] [V] [TRT] Tactic: 3 Time: 0.051588
[03/27/2022-19:13:07] [V] [TRT] Tactic: 4 Time: 0.050048
[03/27/2022-19:13:07] [V] [TRT] Tactic: 5 Time: 0.048128
[03/27/2022-19:13:07] [V] [TRT] Tactic: 6 Time: 0.0512
[03/27/2022-19:13:07] [V] [TRT] Tactic: 7 Time: 0.04864
[03/27/2022-19:13:07] [V] [TRT] Tactic: 8 Time: 0.047872
[03/27/2022-19:13:07] [V] [TRT] Tactic: 9 Time: 0.047616
[03/27/2022-19:13:07] [V] [TRT] Tactic: 28 Time: 0.105724
[03/27/2022-19:13:07] [V] [TRT] Fastest Tactic: 9 Time: 0.047616
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_339), Mul_340) (PointWise)
[03/27/2022-19:13:07] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[03/27/2022-19:13:07] [V] [TRT] *************** Autotuning format combination: Float(66,1:32,1,1), Float(16896,256:32,16,1) -> Float(16896,256:32,16,1) ***************
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_339), Mul_340) (PointWiseV2)
[03/27/2022-19:13:07] [V] [TRT] Tactic: 24 Time: 0.047872
[03/27/2022-19:13:07] [V] [TRT] Tactic: 25 Time: 0.047872
[03/27/2022-19:13:07] [V] [TRT] Tactic: 26 Time: 0.047872
[03/27/2022-19:13:07] [V] [TRT] Tactic: 27 Time: 0.049148
[03/27/2022-19:13:07] [V] [TRT] Tactic: 31 Time: 0.047744
[03/27/2022-19:13:07] [V] [TRT] Fastest Tactic: 31 Time: 0.047744
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(Sigmoid_339), Mul_340) (PointWise)
[03/27/2022-19:13:07] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 31
[03/27/2022-19:13:07] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:07] [V] [TRT] *************** Autotuning format combination: Float(540672,256,16,1), Float(90112,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: Conv_341 + Add_342 (CudaDepthwiseConvolution)
[03/27/2022-19:13:07] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: Conv_341 + Add_342 (FusedConvActConvolution)
[03/27/2022-19:13:07] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: Conv_341 + Add_342 (CudnnConvolution)
[03/27/2022-19:13:07] [V] [TRT] Tactic: 0 Time: 0.453504
[03/27/2022-19:13:07] [V] [TRT] Tactic: 1 Time: 0.299768
[03/27/2022-19:13:07] [V] [TRT] Tactic: 2 Time: 0.476032
[03/27/2022-19:13:07] [V] [TRT] Tactic: 4 Time: 9.38918
[03/27/2022-19:13:07] [V] [TRT] Tactic: 5 Time: 1.56634
[03/27/2022-19:13:07] [V] [TRT] Fastest Tactic: 1 Time: 0.299768
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: Conv_341 + Add_342 (CublasConvolution)
[03/27/2022-19:13:07] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:07] [V] [TRT] --------------- Timing Runner: Conv_341 + Add_342 (CaskConvolution)
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:07] [V] [TRT] Tactic: 1062367460111450758 Time: 0.325376
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:13:07] [V] [TRT] Tactic: 1698681053543049347 Time: 0.289276
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:07] [V] [TRT] Tactic: 4501471010995462441 Time: 0.268028
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:07] [V] [TRT] Tactic: 5137655947464784826 Time: 0.266888
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:07] [V] [TRT] Tactic: 5288347012147084929 Time: 0.268808
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:13:07] [V] [TRT] Tactic: 5326823351883942011 Time: 0.265472
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:13:07] [V] [TRT] Tactic: 5500448035057547314 Time: 0.362496
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:07] [V] [TRT] Tactic: 6645123197870846056 Time: 0.280064
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:07] [V] [TRT] Tactic: 7144526460361122478 Time: 0.301308
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:07] [V] [TRT] Tactic: -8262349710178828730 Time: 0.270208
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:13:07] [V] [TRT] Tactic: -6576203419454146580 Time: 0.280064
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:07] [V] [TRT] Tactic: -4787320710726427159 Time: 0.289152
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:07] [V] [TRT] Tactic: -3456450830548107839 Time: 0.26828
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:07] [V] [TRT] Tactic: -1218658103698133241 Time: 0.345604
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:07] [V] [TRT] Tactic: -836875257600482091 Time: 0.340348
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:07] [V] [TRT] Tactic: -410470605513481746 Time: 0.237312
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:13:07] [V] [TRT] Tactic: -377491875521947884 Time: 0.243968
[03/27/2022-19:13:07] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:13:08] [V] [TRT] Tactic: -37215280111360163 Time: 0.23616
[03/27/2022-19:13:08] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.23616
[03/27/2022-19:13:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[03/27/2022-19:13:08] [V] [TRT] *************** Autotuning format combination: Float(540672,1,33792,2112), Float(90112,1,5632,352) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_341 + Add_342 (CublasConvolution)
[03/27/2022-19:13:08] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_341 + Add_342 (CaskConvolution)
[03/27/2022-19:13:08] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:13:08] [V] [TRT] Tactic: 3886731678879822788 Time: 0.204284
[03/27/2022-19:13:08] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:13:08] [V] [TRT] Tactic: 6629944304117643200 Time: 0.218752
[03/27/2022-19:13:08] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:08] [V] [TRT] Tactic: -9153228964338181824 Time: 0.220928
[03/27/2022-19:13:08] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:08] [V] [TRT] Tactic: -7394439838318485025 Time: 0.205952
[03/27/2022-19:13:08] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.204284
[03/27/2022-19:13:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:13:08] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:08] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(360448,256,16,1) ***************
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_343 || Conv_344 || Conv_348 || Conv_352 (CudaDepthwiseConvolution)
[03/27/2022-19:13:08] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_343 || Conv_344 || Conv_348 || Conv_352 (FusedConvActConvolution)
[03/27/2022-19:13:08] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_343 || Conv_344 || Conv_348 || Conv_352 (CudnnConvolution)
[03/27/2022-19:13:08] [V] [TRT] Tactic: 0 Time: 0.237948
[03/27/2022-19:13:08] [V] [TRT] Tactic: 1 Time: 0.173444
[03/27/2022-19:13:08] [V] [TRT] Tactic: 2 Time: 0.35008
[03/27/2022-19:13:08] [V] [TRT] Tactic: 4 Time: 5.42707
[03/27/2022-19:13:08] [V] [TRT] Tactic: 5 Time: 1.00659
[03/27/2022-19:13:08] [V] [TRT] Fastest Tactic: 1 Time: 0.173444
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_343 || Conv_344 || Conv_348 || Conv_352 (CublasConvolution)
[03/27/2022-19:13:08] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_343 || Conv_344 || Conv_348 || Conv_352 (CaskConvolution)
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:08] [V] [TRT] Tactic: 1062367460111450758 Time: 0.16384
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:13:08] [V] [TRT] Tactic: 1698681053543049347 Time: 0.1445
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:08] [V] [TRT] Tactic: 4501471010995462441 Time: 0.146672
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:08] [V] [TRT] Tactic: 5137655947464784826 Time: 0.141792
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:08] [V] [TRT] Tactic: 5288347012147084929 Time: 0.135796
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:13:08] [V] [TRT] Tactic: 5326823351883942011 Time: 0.139372
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:13:08] [V] [TRT] Tactic: 5500448035057547314 Time: 0.148968
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:08] [V] [TRT] Tactic: 6645123197870846056 Time: 0.135908
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:08] [V] [TRT] Tactic: 7144526460361122478 Time: 0.174316
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:08] [V] [TRT] Tactic: -8262349710178828730 Time: 0.134636
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:13:08] [V] [TRT] Tactic: -6576203419454146580 Time: 0.146536
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:08] [V] [TRT] Tactic: -4787320710726427159 Time: 0.175856
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:08] [V] [TRT] Tactic: -3456450830548107839 Time: 0.157544
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:08] [V] [TRT] Tactic: -1218658103698133241 Time: 0.155108
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:08] [V] [TRT] Tactic: -836875257600482091 Time: 0.151284
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:08] [V] [TRT] Tactic: -410470605513481746 Time: 0.147056
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:13:08] [V] [TRT] Tactic: -377491875521947884 Time: 0.137056
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:13:08] [V] [TRT] Tactic: -37215280111360163 Time: 0.13808
[03/27/2022-19:13:08] [V] [TRT] Fastest Tactic: -8262349710178828730 Time: 0.134636
[03/27/2022-19:13:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -8262349710178828730
[03/27/2022-19:13:08] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_343 || Conv_344 || Conv_348 || Conv_352 (CublasConvolution)
[03/27/2022-19:13:08] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_343 || Conv_344 || Conv_348 || Conv_352 (CaskConvolution)
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:13:08] [V] [TRT] Tactic: 3886731678879822788 Time: 0.121968
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:13:08] [V] [TRT] Tactic: 6629944304117643200 Time: 0.1381
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:08] [V] [TRT] Tactic: -9153228964338181824 Time: 0.141296
[03/27/2022-19:13:08] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:08] [V] [TRT] Tactic: -7394439838318485025 Time: 0.125312
[03/27/2022-19:13:08] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.121968
[03/27/2022-19:13:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:13:08] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:08] [V] [TRT] *************** Autotuning format combination: Float(360448,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_345 (CudaDepthwiseConvolution)
[03/27/2022-19:13:08] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_345 (FusedConvActConvolution)
[03/27/2022-19:13:08] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_345 (CudnnConvolution)
[03/27/2022-19:13:08] [V] [TRT] Tactic: 0 Time: 0.294144
[03/27/2022-19:13:08] [V] [TRT] Tactic: 1 Time: 0.166916
[03/27/2022-19:13:08] [V] [TRT] Tactic: 2 Time: 0.275056
[03/27/2022-19:13:08] [V] [TRT] Tactic: 4 Time: 5.05958
[03/27/2022-19:13:08] [V] [TRT] Tactic: 5 Time: 0.353664
[03/27/2022-19:13:08] [V] [TRT] Fastest Tactic: 1 Time: 0.166916
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_345 (CaskConvolution)
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:08] [V] [TRT] Tactic: 1062367460111450758 Time: 0.180732
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:08] [V] [TRT] Tactic: 4501471010995462441 Time: 0.144512
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:08] [V] [TRT] Tactic: 5137655947464784826 Time: 0.140544
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:08] [V] [TRT] Tactic: 5288347012147084929 Time: 0.141184
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:08] [V] [TRT] Tactic: 6645123197870846056 Time: 0.154244
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:08] [V] [TRT] Tactic: 7144526460361122478 Time: 0.154624
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:08] [V] [TRT] Tactic: -8262349710178828730 Time: 0.145792
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:08] [V] [TRT] Tactic: -4787320710726427159 Time: 0.169216
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:08] [V] [TRT] Tactic: -3456450830548107839 Time: 0.157056
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:08] [V] [TRT] Tactic: -1218658103698133241 Time: 0.19392
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:08] [V] [TRT] Tactic: -836875257600482091 Time: 0.185732
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:08] [V] [TRT] Tactic: -410470605513481746 Time: 0.136832
[03/27/2022-19:13:08] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.136832
[03/27/2022-19:13:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[03/27/2022-19:13:08] [V] [TRT] *************** Autotuning format combination: Float(360448,1,22528,1408) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_345 (CaskConvolution)
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:08] [V] [TRT] Tactic: -9153228964338181824 Time: 0.103808
[03/27/2022-19:13:08] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:08] [V] [TRT] Tactic: -7394439838318485025 Time: 0.120324
[03/27/2022-19:13:08] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.103808
[03/27/2022-19:13:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:08] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:08] [V] [TRT] *************** Autotuning format combination: Float(360448,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_349 (CudaDepthwiseConvolution)
[03/27/2022-19:13:08] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_349 (FusedConvActConvolution)
[03/27/2022-19:13:08] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:08] [V] [TRT] --------------- Timing Runner: Conv_349 (CudnnConvolution)
[03/27/2022-19:13:09] [V] [TRT] Tactic: 0 Time: 0.385408
[03/27/2022-19:13:09] [V] [TRT] Tactic: 1 Time: 0.360448
[03/27/2022-19:13:09] [V] [TRT] Tactic: 2 Time: 0.353924
[03/27/2022-19:13:09] [V] [TRT] Tactic: 4 Time: 5.08442
[03/27/2022-19:13:09] [V] [TRT] Tactic: 5 Time: 0.329088
[03/27/2022-19:13:09] [V] [TRT] Fastest Tactic: 5 Time: 0.329088
[03/27/2022-19:13:09] [V] [TRT] --------------- Timing Runner: Conv_349 (CaskConvolution)
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:09] [V] [TRT] Tactic: 1062367460111450758 Time: 0.313856
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:09] [V] [TRT] Tactic: 4501471010995462441 Time: 0.238848
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:09] [V] [TRT] Tactic: 5137655947464784826 Time: 0.222208
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:09] [V] [TRT] Tactic: 5288347012147084929 Time: 0.223488
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:09] [V] [TRT] Tactic: 6645123197870846056 Time: 0.25996
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:09] [V] [TRT] Tactic: 7144526460361122478 Time: 0.238592
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:09] [V] [TRT] Tactic: -8262349710178828730 Time: 0.238976
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:09] [V] [TRT] Tactic: -4787320710726427159 Time: 0.276608
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:09] [V] [TRT] Tactic: -3456450830548107839 Time: 0.2496
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:09] [V] [TRT] Tactic: -1218658103698133241 Time: 0.322936
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:09] [V] [TRT] Tactic: -836875257600482091 Time: 0.302464
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:09] [V] [TRT] Tactic: -410470605513481746 Time: 0.219776
[03/27/2022-19:13:09] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.219776
[03/27/2022-19:13:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[03/27/2022-19:13:09] [V] [TRT] *************** Autotuning format combination: Float(360448,1,22528,1408) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:09] [V] [TRT] --------------- Timing Runner: Conv_349 (CaskConvolution)
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:09] [V] [TRT] Tactic: -9153228964338181824 Time: 0.197632
[03/27/2022-19:13:09] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:09] [V] [TRT] Tactic: -7394439838318485025 Time: 0.19174
[03/27/2022-19:13:09] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.19174
[03/27/2022-19:13:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[03/27/2022-19:13:09] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:09] [V] [TRT] *************** Autotuning format combination: Float(360448,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:09] [V] [TRT] --------------- Timing Runner: Conv_353 (CudaDepthwiseConvolution)
[03/27/2022-19:13:09] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:09] [V] [TRT] --------------- Timing Runner: Conv_353 (FusedConvActConvolution)
[03/27/2022-19:13:09] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:09] [V] [TRT] --------------- Timing Runner: Conv_353 (CudnnConvolution)
[03/27/2022-19:13:09] [V] [TRT] Tactic: 0 Time: 0.506488
[03/27/2022-19:13:09] [V] [TRT] Tactic: 1 Time: 0.496768
[03/27/2022-19:13:09] [V] [TRT] Tactic: 2 Time: 0.448644
[03/27/2022-19:13:09] [V] [TRT] Tactic: 4 Time: 5.08659
[03/27/2022-19:13:09] [V] [TRT] Tactic: 5 Time: 0.3305
[03/27/2022-19:13:09] [V] [TRT] Fastest Tactic: 5 Time: 0.3305
[03/27/2022-19:13:09] [V] [TRT] --------------- Timing Runner: Conv_353 (CaskConvolution)
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:09] [V] [TRT] Tactic: 1062367460111450758 Time: 0.470272
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:09] [V] [TRT] Tactic: 4501471010995462441 Time: 0.338944
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:09] [V] [TRT] Tactic: 5137655947464784826 Time: 0.30592
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:09] [V] [TRT] Tactic: 5288347012147084929 Time: 0.304896
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:09] [V] [TRT] Tactic: 6645123197870846056 Time: 0.373248
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:09] [V] [TRT] Tactic: 7144526460361122478 Time: 0.321404
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:09] [V] [TRT] Tactic: -8262349710178828730 Time: 0.345728
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:09] [V] [TRT] Tactic: -4787320710726427159 Time: 0.408708
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:09] [V] [TRT] Tactic: -3456450830548107839 Time: 0.341884
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:09] [V] [TRT] Tactic: -1218658103698133241 Time: 0.427904
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:09] [V] [TRT] Tactic: -836875257600482091 Time: 0.416376
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:09] [V] [TRT] Tactic: -410470605513481746 Time: 0.302976
[03/27/2022-19:13:09] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.302976
[03/27/2022-19:13:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[03/27/2022-19:13:09] [V] [TRT] *************** Autotuning format combination: Float(360448,1,22528,1408) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:09] [V] [TRT] --------------- Timing Runner: Conv_353 (CaskConvolution)
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:09] [V] [TRT] Tactic: -9153228964338181824 Time: 0.235264
[03/27/2022-19:13:09] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:09] [V] [TRT] Tactic: -7394439838318485025 Time: 0.262528
[03/27/2022-19:13:09] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.235264
[03/27/2022-19:13:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:09] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:09] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:09] [V] [TRT] --------------- Timing Runner: Conv_346 (CudaDepthwiseConvolution)
[03/27/2022-19:13:09] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:09] [V] [TRT] --------------- Timing Runner: Conv_346 (FusedConvActConvolution)
[03/27/2022-19:13:09] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:09] [V] [TRT] --------------- Timing Runner: Conv_346 (CudnnConvolution)
[03/27/2022-19:13:09] [V] [TRT] Tactic: 0 Time: 0.246912
[03/27/2022-19:13:09] [V] [TRT] Tactic: 1 Time: 0.24588
[03/27/2022-19:13:10] [V] [TRT] Tactic: 2 Time: 0.280956
[03/27/2022-19:13:10] [V] [TRT] Tactic: 4 Time: 4.77568
[03/27/2022-19:13:10] [V] [TRT] Tactic: 5 Time: 0.316032
[03/27/2022-19:13:10] [V] [TRT] Fastest Tactic: 1 Time: 0.24588
[03/27/2022-19:13:10] [V] [TRT] --------------- Timing Runner: Conv_346 (CaskConvolution)
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:10] [V] [TRT] Tactic: 1062367460111450758 Time: 0.172288
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:10] [V] [TRT] Tactic: 4501471010995462441 Time: 0.139012
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:10] [V] [TRT] Tactic: 5137655947464784826 Time: 0.140924
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:10] [V] [TRT] Tactic: 5288347012147084929 Time: 0.140416
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:10] [V] [TRT] Tactic: 6645123197870846056 Time: 0.14872
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:10] [V] [TRT] Tactic: 7144526460361122478 Time: 0.15514
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:10] [V] [TRT] Tactic: -8262349710178828730 Time: 0.141824
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:10] [V] [TRT] Tactic: -4787320710726427159 Time: 0.164992
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:10] [V] [TRT] Tactic: -3456450830548107839 Time: 0.1559
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:10] [V] [TRT] Tactic: -1218658103698133241 Time: 0.198148
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:10] [V] [TRT] Tactic: -836875257600482091 Time: 0.18624
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:10] [V] [TRT] Tactic: -410470605513481746 Time: 0.136828
[03/27/2022-19:13:10] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.136828
[03/27/2022-19:13:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[03/27/2022-19:13:10] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:10] [V] [TRT] --------------- Timing Runner: Conv_346 (CaskConvolution)
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:10] [V] [TRT] Tactic: -9153228964338181824 Time: 0.106112
[03/27/2022-19:13:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:10] [V] [TRT] Tactic: -7394439838318485025 Time: 0.120448
[03/27/2022-19:13:10] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.106112
[03/27/2022-19:13:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:10] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:10] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:10] [V] [TRT] --------------- Timing Runner: Conv_350 (CudaDepthwiseConvolution)
[03/27/2022-19:13:10] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:10] [V] [TRT] --------------- Timing Runner: Conv_350 (FusedConvActConvolution)
[03/27/2022-19:13:10] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:10] [V] [TRT] --------------- Timing Runner: Conv_350 (CudnnConvolution)
[03/27/2022-19:13:10] [V] [TRT] Tactic: 0 Time: 0.384516
[03/27/2022-19:13:10] [V] [TRT] Tactic: 1 Time: 0.383232
[03/27/2022-19:13:10] [V] [TRT] Tactic: 2 Time: 0.374144
[03/27/2022-19:13:10] [V] [TRT] Tactic: 4 Time: 4.93798
[03/27/2022-19:13:10] [V] [TRT] Tactic: 5 Time: 0.874628
[03/27/2022-19:13:10] [V] [TRT] Fastest Tactic: 2 Time: 0.374144
[03/27/2022-19:13:10] [V] [TRT] --------------- Timing Runner: Conv_350 (CaskConvolution)
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:10] [V] [TRT] Tactic: 1062367460111450758 Time: 0.273408
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:10] [V] [TRT] Tactic: 4501471010995462441 Time: 0.223488
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:10] [V] [TRT] Tactic: 5137655947464784826 Time: 0.22336
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:10] [V] [TRT] Tactic: 5288347012147084929 Time: 0.220288
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:10] [V] [TRT] Tactic: 6645123197870846056 Time: 0.227584
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:10] [V] [TRT] Tactic: 7144526460361122478 Time: 0.234368
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:10] [V] [TRT] Tactic: -8262349710178828730 Time: 0.220288
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:10] [V] [TRT] Tactic: -4787320710726427159 Time: 0.250748
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:10] [V] [TRT] Tactic: -3456450830548107839 Time: 0.240256
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:10] [V] [TRT] Tactic: -1218658103698133241 Time: 0.307716
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:10] [V] [TRT] Tactic: -836875257600482091 Time: 0.29722
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:10] [V] [TRT] Tactic: -410470605513481746 Time: 0.216072
[03/27/2022-19:13:10] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.216072
[03/27/2022-19:13:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[03/27/2022-19:13:10] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:10] [V] [TRT] --------------- Timing Runner: Conv_350 (CaskConvolution)
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:10] [V] [TRT] Tactic: -9153228964338181824 Time: 0.189176
[03/27/2022-19:13:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:10] [V] [TRT] Tactic: -7394439838318485025 Time: 0.18368
[03/27/2022-19:13:10] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.18368
[03/27/2022-19:13:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[03/27/2022-19:13:10] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:10] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:10] [V] [TRT] --------------- Timing Runner: Conv_354 (CudaDepthwiseConvolution)
[03/27/2022-19:13:10] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:10] [V] [TRT] --------------- Timing Runner: Conv_354 (FusedConvActConvolution)
[03/27/2022-19:13:10] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:10] [V] [TRT] --------------- Timing Runner: Conv_354 (CudnnConvolution)
[03/27/2022-19:13:10] [V] [TRT] Tactic: 0 Time: 0.487676
[03/27/2022-19:13:10] [V] [TRT] Tactic: 1 Time: 0.591744
[03/27/2022-19:13:10] [V] [TRT] Tactic: 2 Time: 0.46502
[03/27/2022-19:13:10] [V] [TRT] Tactic: 4 Time: 4.72435
[03/27/2022-19:13:10] [V] [TRT] Tactic: 5 Time: 0.318464
[03/27/2022-19:13:10] [V] [TRT] Fastest Tactic: 5 Time: 0.318464
[03/27/2022-19:13:10] [V] [TRT] --------------- Timing Runner: Conv_354 (CaskConvolution)
[03/27/2022-19:13:10] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:10] [V] [TRT] Tactic: 1062367460111450758 Time: 0.376448
[03/27/2022-19:13:10] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:10] [V] [TRT] Tactic: 4501471010995462441 Time: 0.304256
[03/27/2022-19:13:10] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:10] [V] [TRT] Tactic: 5137655947464784826 Time: 0.304768
[03/27/2022-19:13:11] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:11] [V] [TRT] Tactic: 5288347012147084929 Time: 0.304388
[03/27/2022-19:13:11] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:11] [V] [TRT] Tactic: 6645123197870846056 Time: 0.324744
[03/27/2022-19:13:11] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:11] [V] [TRT] Tactic: 7144526460361122478 Time: 0.330372
[03/27/2022-19:13:11] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:11] [V] [TRT] Tactic: -8262349710178828730 Time: 0.30784
[03/27/2022-19:13:11] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:11] [V] [TRT] Tactic: -4787320710726427159 Time: 0.355068
[03/27/2022-19:13:11] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:11] [V] [TRT] Tactic: -3456450830548107839 Time: 0.341504
[03/27/2022-19:13:11] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:11] [V] [TRT] Tactic: -1218658103698133241 Time: 0.437632
[03/27/2022-19:13:11] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:11] [V] [TRT] Tactic: -836875257600482091 Time: 0.409468
[03/27/2022-19:13:11] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:11] [V] [TRT] Tactic: -410470605513481746 Time: 0.3031
[03/27/2022-19:13:11] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.3031
[03/27/2022-19:13:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[03/27/2022-19:13:11] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_354 (CaskConvolution)
[03/27/2022-19:13:11] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:11] [V] [TRT] Tactic: -9153228964338181824 Time: 0.229492
[03/27/2022-19:13:11] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:11] [V] [TRT] Tactic: -7394439838318485025 Time: 0.262268
[03/27/2022-19:13:11] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.229492
[03/27/2022-19:13:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:11] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(360448,256,16,1) ***************
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_347 (CudaDepthwiseConvolution)
[03/27/2022-19:13:11] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_347 (CudnnConvolution)
[03/27/2022-19:13:11] [V] [TRT] Tactic: 0 Time: 0.841856
[03/27/2022-19:13:11] [V] [TRT] Tactic: 1 Time: 0.404208
[03/27/2022-19:13:11] [V] [TRT] Tactic: 2 Time: 0.56256
[03/27/2022-19:13:11] [V] [TRT] Fastest Tactic: 1 Time: 0.404208
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_347 (CaskConvolution)
[03/27/2022-19:13:11] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:11] [V] [TRT] Tactic: 1062367460111450758 Time: 0.707328
[03/27/2022-19:13:11] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:11] [V] [TRT] Tactic: 4337000649858996379 Time: 0.543616
[03/27/2022-19:13:11] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:11] [V] [TRT] Tactic: 4501471010995462441 Time: 0.458368
[03/27/2022-19:13:11] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:11] [V] [TRT] Tactic: 5137655947464784826 Time: 0.388736
[03/27/2022-19:13:11] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:11] [V] [TRT] Tactic: 6645123197870846056 Time: 0.525056
[03/27/2022-19:13:11] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:11] [V] [TRT] Tactic: -9137461792520977713 Time: 0.47936
[03/27/2022-19:13:11] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:11] [V] [TRT] Tactic: -6092040395344634144 Time: 0.73984
[03/27/2022-19:13:11] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:11] [V] [TRT] Tactic: -3456450830548107839 Time: 0.434688
[03/27/2022-19:13:11] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:11] [V] [TRT] Tactic: -410470605513481746 Time: 0.386944
[03/27/2022-19:13:11] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.386944
[03/27/2022-19:13:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[03/27/2022-19:13:11] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_347 (CaskConvolution)
[03/27/2022-19:13:11] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:11] [V] [TRT] Tactic: -9153228964338181824 Time: 0.297092
[03/27/2022-19:13:11] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:11] [V] [TRT] Tactic: -7394439838318485025 Time: 0.331776
[03/27/2022-19:13:11] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.297092
[03/27/2022-19:13:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:11] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(360448,256,16,1) ***************
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_351 (CudaDepthwiseConvolution)
[03/27/2022-19:13:11] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_351 (CudnnConvolution)
[03/27/2022-19:13:11] [V] [TRT] Tactic: 0 Time: 0.840832
[03/27/2022-19:13:11] [V] [TRT] Tactic: 1 Time: 1.00698
[03/27/2022-19:13:11] [V] [TRT] Tactic: 2 Time: 0.562816
[03/27/2022-19:13:11] [V] [TRT] Fastest Tactic: 2 Time: 0.562816
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_351 (CaskConvolution)
[03/27/2022-19:13:11] [V] [TRT] Conv_351 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:11] [V] [TRT] Tactic: 1062367460111450758 Time: 0.9879
[03/27/2022-19:13:11] [V] [TRT] Conv_351 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:11] [V] [TRT] Tactic: 4337000649858996379 Time: 0.669056
[03/27/2022-19:13:11] [V] [TRT] Conv_351 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:11] [V] [TRT] Tactic: 4501471010995462441 Time: 0.529024
[03/27/2022-19:13:11] [V] [TRT] Conv_351 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:11] [V] [TRT] Tactic: 6645123197870846056 Time: 0.6688
[03/27/2022-19:13:11] [V] [TRT] Conv_351 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:11] [V] [TRT] Tactic: -9137461792520977713 Time: 0.562188
[03/27/2022-19:13:11] [V] [TRT] Conv_351 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:11] [V] [TRT] Tactic: -6092040395344634144 Time: 1.01439
[03/27/2022-19:13:11] [V] [TRT] Fastest Tactic: 4501471010995462441 Time: 0.529024
[03/27/2022-19:13:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4501471010995462441
[03/27/2022-19:13:11] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_351 (CaskConvolution)
[03/27/2022-19:13:11] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:11] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:11] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(360448,256,16,1) ***************
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_355 (CudaDepthwiseConvolution)
[03/27/2022-19:13:11] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_355 (CudnnConvolution)
[03/27/2022-19:13:11] [V] [TRT] Tactic: 0 Time: 0.839936
[03/27/2022-19:13:11] [V] [TRT] Tactic: 1 Time: 1.38624
[03/27/2022-19:13:11] [V] [TRT] Tactic: 2 Time: 0.562564
[03/27/2022-19:13:11] [V] [TRT] Fastest Tactic: 2 Time: 0.562564
[03/27/2022-19:13:11] [V] [TRT] --------------- Timing Runner: Conv_355 (CaskConvolution)
[03/27/2022-19:13:11] [V] [TRT] Conv_355 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:11] [V] [TRT] Tactic: 1062367460111450758 Time: 1.36627
[03/27/2022-19:13:11] [V] [TRT] Conv_355 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:11] [V] [TRT] Tactic: 4337000649858996379 Time: 0.819836
[03/27/2022-19:13:11] [V] [TRT] Conv_355 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:11] [V] [TRT] Tactic: 4501471010995462441 Time: 0.616192
[03/27/2022-19:13:11] [V] [TRT] Conv_355 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:12] [V] [TRT] Tactic: 6645123197870846056 Time: 0.81088
[03/27/2022-19:13:12] [V] [TRT] Conv_355 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:12] [V] [TRT] Tactic: -9137461792520977713 Time: 0.66624
[03/27/2022-19:13:12] [V] [TRT] Conv_355 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:12] [V] [TRT] Tactic: -6092040395344634144 Time: 1.37318
[03/27/2022-19:13:12] [V] [TRT] Fastest Tactic: 4501471010995462441 Time: 0.616192
[03/27/2022-19:13:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[03/27/2022-19:13:12] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(360448,1,22528,1408) ***************
[03/27/2022-19:13:12] [V] [TRT] --------------- Timing Runner: Conv_355 (CaskConvolution)
[03/27/2022-19:13:12] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:12] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:12] [V] [TRT] *************** Autotuning format combination: Float(360448,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:12] [V] [TRT] --------------- Timing Runner: Conv_357 (CudaDepthwiseConvolution)
[03/27/2022-19:13:12] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:12] [V] [TRT] --------------- Timing Runner: Conv_357 (FusedConvActConvolution)
[03/27/2022-19:13:12] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:12] [V] [TRT] --------------- Timing Runner: Conv_357 (CudnnConvolution)
[03/27/2022-19:13:12] [V] [TRT] Tactic: 0 Time: 3.19834
[03/27/2022-19:13:12] [V] [TRT] Tactic: 1 Time: 1.53294
[03/27/2022-19:13:12] [V] [TRT] Tactic: 2 Time: 2.06413
[03/27/2022-19:13:12] [V] [TRT] Tactic: 4 Time: 22.0797
[03/27/2022-19:13:12] [V] [TRT] Tactic: 5 Time: 13.4949
[03/27/2022-19:13:12] [V] [TRT] Tactic: 6 Time: 0.792332
[03/27/2022-19:13:12] [V] [TRT] Fastest Tactic: 6 Time: 0.792332
[03/27/2022-19:13:12] [V] [TRT] --------------- Timing Runner: Conv_357 (CaskConvolution)
[03/27/2022-19:13:12] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:13] [V] [TRT] Tactic: 1062367460111450758 Time: 1.87212
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:13] [V] [TRT] Tactic: 1754984623894446479 Time: 1.6599
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:13] [V] [TRT] Tactic: 3611739942397549984 Time: 1.50362
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:13] [V] [TRT] Tactic: 3827454225649558724 Time: 0.5449
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:13] [V] [TRT] Tactic: 4337000649858996379 Time: 1.59603
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:13] [V] [TRT] Tactic: 4501471010995462441 Time: 1.4592
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:13] [V] [TRT] Tactic: 5137655947464784826 Time: 1.28461
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:13] [V] [TRT] Tactic: 5288347012147084929 Time: 1.30304
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:13] [V] [TRT] Tactic: 5921334924264294896 Time: 0.535424
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:13] [V] [TRT] Tactic: 6645123197870846056 Time: 1.45779
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:13] [V] [TRT] Tactic: 7144526460361122478 Time: 1.38867
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:13] [V] [TRT] Tactic: 7852627285308570038 Time: 0.611192
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:13] [V] [TRT] Tactic: -9137461792520977713 Time: 1.51027
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:13] [V] [TRT] Tactic: -8776506421218919509 Time: 0.604028
[03/27/2022-19:13:13] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:13] [V] [TRT] Tactic: -8262349710178828730 Time: 1.54982
[03/27/2022-19:13:14] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:14] [V] [TRT] Tactic: -8133971918129952780 Time: 2.22848
[03/27/2022-19:13:14] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:14] [V] [TRT] Tactic: -6092040395344634144 Time: 2.19968
[03/27/2022-19:13:14] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:14] [V] [TRT] Tactic: -4787320710726427159 Time: 1.8263
[03/27/2022-19:13:14] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:14] [V] [TRT] Tactic: -3456450830548107839 Time: 1.69037
[03/27/2022-19:13:14] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:14] [V] [TRT] Tactic: -2318106587342035239 Time: 0.665724
[03/27/2022-19:13:14] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:14] [V] [TRT] Tactic: -1343271414618805657 Time: 0.591104
[03/27/2022-19:13:14] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:14] [V] [TRT] Tactic: -1218658103698133241 Time: 2.19199
[03/27/2022-19:13:14] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:14] [V] [TRT] Tactic: -836875257600482091 Time: 2.07718
[03/27/2022-19:13:14] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:14] [V] [TRT] Tactic: -410470605513481746 Time: 1.50848
[03/27/2022-19:13:14] [V] [TRT] Fastest Tactic: 5921334924264294896 Time: 0.535424
[03/27/2022-19:13:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5921334924264294896
[03/27/2022-19:13:14] [V] [TRT] *************** Autotuning format combination: Float(360448,1,22528,1408) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:14] [V] [TRT] --------------- Timing Runner: Conv_357 (CaskConvolution)
[03/27/2022-19:13:14] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:14] [V] [TRT] Tactic: -9153228964338181824 Time: 1.29766
[03/27/2022-19:13:15] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:15] [V] [TRT] Tactic: -7394439838318485025 Time: 1.28448
[03/27/2022-19:13:15] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.28448
[03/27/2022-19:13:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[03/27/2022-19:13:15] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:15] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1), Float(90112,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_358 + Add_359 + Relu_360 (CudaDepthwiseConvolution)
[03/27/2022-19:13:15] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_358 + Add_359 + Relu_360 (FusedConvActConvolution)
[03/27/2022-19:13:15] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_358 + Add_359 + Relu_360 (CudnnConvolution)
[03/27/2022-19:13:15] [V] [TRT] Tactic: 0 Time: 0.114688
[03/27/2022-19:13:15] [V] [TRT] Tactic: 1 Time: 0.084096
[03/27/2022-19:13:15] [V] [TRT] Tactic: 2 Time: 0.219392
[03/27/2022-19:13:15] [V] [TRT] Tactic: 4 Time: 1.504
[03/27/2022-19:13:15] [V] [TRT] Tactic: 5 Time: 0.341888
[03/27/2022-19:13:15] [V] [TRT] Fastest Tactic: 1 Time: 0.084096
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_358 + Add_359 + Relu_360 (CublasConvolution)
[03/27/2022-19:13:15] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_358 + Add_359 + Relu_360 (CaskConvolution)
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:15] [V] [TRT] Tactic: 1062367460111450758 Time: 0.071032
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:13:15] [V] [TRT] Tactic: 1698681053543049347 Time: 0.062976
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:15] [V] [TRT] Tactic: 4501471010995462441 Time: 0.057088
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:15] [V] [TRT] Tactic: 5137655947464784826 Time: 0.057728
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:15] [V] [TRT] Tactic: 5288347012147084929 Time: 0.058752
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:13:15] [V] [TRT] Tactic: 5326823351883942011 Time: 0.057604
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:13:15] [V] [TRT] Tactic: 5500448035057547314 Time: 0.072956
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:15] [V] [TRT] Tactic: 6645123197870846056 Time: 0.060412
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:15] [V] [TRT] Tactic: 7144526460361122478 Time: 0.064896
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:15] [V] [TRT] Tactic: -8262349710178828730 Time: 0.060544
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:13:15] [V] [TRT] Tactic: -6576203419454146580 Time: 0.061696
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:15] [V] [TRT] Tactic: -4787320710726427159 Time: 0.067972
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:15] [V] [TRT] Tactic: -3456450830548107839 Time: 0.066432
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:15] [V] [TRT] Tactic: -1218658103698133241 Time: 0.076292
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:15] [V] [TRT] Tactic: -836875257600482091 Time: 0.074368
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:15] [V] [TRT] Tactic: -410470605513481746 Time: 0.055936
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:13:15] [V] [TRT] Tactic: -377491875521947884 Time: 0.057728
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:13:15] [V] [TRT] Tactic: -37215280111360163 Time: 0.061056
[03/27/2022-19:13:15] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.055936
[03/27/2022-19:13:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[03/27/2022-19:13:15] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352), Float(90112,1,5632,352) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_358 + Add_359 + Relu_360 (CublasConvolution)
[03/27/2022-19:13:15] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_358 + Add_359 + Relu_360 (CaskConvolution)
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:13:15] [V] [TRT] Tactic: 3886731678879822788 Time: 0.052736
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:13:15] [V] [TRT] Tactic: 6629944304117643200 Time: 0.052864
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:15] [V] [TRT] Tactic: -9153228964338181824 Time: 0.055428
[03/27/2022-19:13:15] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:15] [V] [TRT] Tactic: -7394439838318485025 Time: 0.053112
[03/27/2022-19:13:15] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.052736
[03/27/2022-19:13:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[03/27/2022-19:13:15] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:15] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_361 + Relu_362 (CudaDepthwiseConvolution)
[03/27/2022-19:13:15] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_361 + Relu_362 (CudnnConvolution)
[03/27/2022-19:13:15] [V] [TRT] Tactic: 0 Time: 0.84838
[03/27/2022-19:13:15] [V] [TRT] Tactic: 1 Time: 0.40922
[03/27/2022-19:13:15] [V] [TRT] Tactic: 2 Time: 0.583552
[03/27/2022-19:13:15] [V] [TRT] Fastest Tactic: 1 Time: 0.40922
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_361 + Relu_362 (CaskConvolution)
[03/27/2022-19:13:15] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:15] [V] [TRT] Tactic: 1062367460111450758 Time: 0.598272
[03/27/2022-19:13:15] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:15] [V] [TRT] Tactic: 4337000649858996379 Time: 0.490112
[03/27/2022-19:13:15] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:15] [V] [TRT] Tactic: 4501471010995462441 Time: 0.421756
[03/27/2022-19:13:15] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:15] [V] [TRT] Tactic: 5137655947464784826 Time: 0.38912
[03/27/2022-19:13:15] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:15] [V] [TRT] Tactic: 6645123197870846056 Time: 0.478592
[03/27/2022-19:13:15] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:15] [V] [TRT] Tactic: -9137461792520977713 Time: 0.439424
[03/27/2022-19:13:15] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:15] [V] [TRT] Tactic: -6092040395344634144 Time: 0.627072
[03/27/2022-19:13:15] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:15] [V] [TRT] Tactic: -3456450830548107839 Time: 0.432892
[03/27/2022-19:13:15] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:15] [V] [TRT] Tactic: -410470605513481746 Time: 0.38668
[03/27/2022-19:13:15] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.38668
[03/27/2022-19:13:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[03/27/2022-19:13:15] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_361 + Relu_362 (CaskConvolution)
[03/27/2022-19:13:15] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:15] [V] [TRT] Tactic: -9153228964338181824 Time: 0.299516
[03/27/2022-19:13:15] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:15] [V] [TRT] Tactic: -7394439838318485025 Time: 0.332796
[03/27/2022-19:13:15] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.299516
[03/27/2022-19:13:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:15] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:15] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:15] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:15] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:15] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(180224,256,16,1) ***************
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_365 + Relu_366 (CudaDepthwiseConvolution)
[03/27/2022-19:13:15] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_365 + Relu_366 (CudnnConvolution)
[03/27/2022-19:13:15] [V] [TRT] Tactic: 0 Time: 0.851968
[03/27/2022-19:13:15] [V] [TRT] Tactic: 1 Time: 0.411008
[03/27/2022-19:13:15] [V] [TRT] Tactic: 2 Time: 0.568576
[03/27/2022-19:13:15] [V] [TRT] Fastest Tactic: 1 Time: 0.411008
[03/27/2022-19:13:15] [V] [TRT] --------------- Timing Runner: Conv_365 + Relu_366 (CaskConvolution)
[03/27/2022-19:13:15] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:16] [V] [TRT] Tactic: 1062367460111450758 Time: 0.600448
[03/27/2022-19:13:16] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:16] [V] [TRT] Tactic: 4337000649858996379 Time: 0.491
[03/27/2022-19:13:16] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:16] [V] [TRT] Tactic: 4501471010995462441 Time: 0.427264
[03/27/2022-19:13:16] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:16] [V] [TRT] Tactic: 5137655947464784826 Time: 0.390012
[03/27/2022-19:13:16] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:16] [V] [TRT] Tactic: 6645123197870846056 Time: 0.47782
[03/27/2022-19:13:16] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:16] [V] [TRT] Tactic: -9137461792520977713 Time: 0.43904
[03/27/2022-19:13:16] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:16] [V] [TRT] Tactic: -6092040395344634144 Time: 0.627584
[03/27/2022-19:13:16] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:16] [V] [TRT] Tactic: -3456450830548107839 Time: 0.433024
[03/27/2022-19:13:16] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:16] [V] [TRT] Tactic: -410470605513481746 Time: 0.386556
[03/27/2022-19:13:16] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.386556
[03/27/2022-19:13:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[03/27/2022-19:13:16] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(180224,1,11264,704) ***************
[03/27/2022-19:13:16] [V] [TRT] --------------- Timing Runner: Conv_365 + Relu_366 (CaskConvolution)
[03/27/2022-19:13:16] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:16] [V] [TRT] Tactic: -9153228964338181824 Time: 0.307584
[03/27/2022-19:13:16] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:16] [V] [TRT] Tactic: -7394439838318485025 Time: 0.332928
[03/27/2022-19:13:16] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.307584
[03/27/2022-19:13:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:16] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:16] [V] [TRT] *************** Autotuning format combination: Float(180224,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:16] [V] [TRT] --------------- Timing Runner: Conv_368 + Relu_369 (CudaDepthwiseConvolution)
[03/27/2022-19:13:16] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:16] [V] [TRT] --------------- Timing Runner: Conv_368 + Relu_369 (FusedConvActConvolution)
[03/27/2022-19:13:16] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:16] [V] [TRT] --------------- Timing Runner: Conv_368 + Relu_369 (CudnnConvolution)
[03/27/2022-19:13:16] [V] [TRT] Tactic: 0 Time: 1.62829
[03/27/2022-19:13:16] [V] [TRT] Tactic: 1 Time: 0.78656
[03/27/2022-19:13:16] [V] [TRT] Tactic: 2 Time: 1.10515
[03/27/2022-19:13:16] [V] [TRT] Tactic: 4 Time: 9.5808
[03/27/2022-19:13:16] [V] [TRT] Tactic: 5 Time: 6.92147
[03/27/2022-19:13:16] [V] [TRT] Tactic: 6 Time: 0.381052
[03/27/2022-19:13:16] [V] [TRT] Fastest Tactic: 6 Time: 0.381052
[03/27/2022-19:13:16] [V] [TRT] --------------- Timing Runner: Conv_368 + Relu_369 (CaskConvolution)
[03/27/2022-19:13:16] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:17] [V] [TRT] Tactic: 1062367460111450758 Time: 1.01005
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:17] [V] [TRT] Tactic: 1754984623894446479 Time: 0.900352
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:17] [V] [TRT] Tactic: 3611739942397549984 Time: 0.7776
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:17] [V] [TRT] Tactic: 3827454225649558724 Time: 0.29402
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:17] [V] [TRT] Tactic: 4337000649858996379 Time: 0.900992
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:17] [V] [TRT] Tactic: 4501471010995462441 Time: 0.79322
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:17] [V] [TRT] Tactic: 5137655947464784826 Time: 0.764416
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:17] [V] [TRT] Tactic: 5288347012147084929 Time: 0.763904
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:17] [V] [TRT] Tactic: 5921334924264294896 Time: 0.310272
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:17] [V] [TRT] Tactic: 6645123197870846056 Time: 0.866176
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:17] [V] [TRT] Tactic: 7144526460361122478 Time: 0.808064
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:17] [V] [TRT] Tactic: 7852627285308570038 Time: 0.366976
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:17] [V] [TRT] Tactic: -9137461792520977713 Time: 0.83456
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:17] [V] [TRT] Tactic: -8776506421218919509 Time: 0.301052
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:17] [V] [TRT] Tactic: -8262349710178828730 Time: 0.787968
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:17] [V] [TRT] Tactic: -8133971918129952780 Time: 1.12499
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:17] [V] [TRT] Tactic: -6092040395344634144 Time: 1.10861
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:17] [V] [TRT] Tactic: -4787320710726427159 Time: 0.921852
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:17] [V] [TRT] Tactic: -3456450830548107839 Time: 0.852224
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:17] [V] [TRT] Tactic: -2318106587342035239 Time: 0.302848
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:17] [V] [TRT] Tactic: -1343271414618805657 Time: 0.296316
[03/27/2022-19:13:17] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:18] [V] [TRT] Tactic: -1218658103698133241 Time: 1.10554
[03/27/2022-19:13:18] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:18] [V] [TRT] Tactic: -836875257600482091 Time: 1.03449
[03/27/2022-19:13:18] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:18] [V] [TRT] Tactic: -410470605513481746 Time: 0.760448
[03/27/2022-19:13:18] [V] [TRT] Fastest Tactic: 3827454225649558724 Time: 0.29402
[03/27/2022-19:13:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3827454225649558724
[03/27/2022-19:13:18] [V] [TRT] *************** Autotuning format combination: Float(180224,1,11264,704) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:18] [V] [TRT] --------------- Timing Runner: Conv_368 + Relu_369 (CaskConvolution)
[03/27/2022-19:13:18] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:18] [V] [TRT] Tactic: -9153228964338181824 Time: 0.626808
[03/27/2022-19:13:18] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:18] [V] [TRT] Tactic: -7394439838318485025 Time: 0.6496
[03/27/2022-19:13:18] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.626808
[03/27/2022-19:13:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:18] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:18] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(90112,256,16,1) ***************
[03/27/2022-19:13:18] [V] [TRT] --------------- Timing Runner: Conv_370 + Relu_371 (CudaDepthwiseConvolution)
[03/27/2022-19:13:18] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:18] [V] [TRT] --------------- Timing Runner: Conv_370 + Relu_371 (FusedConvActConvolution)
[03/27/2022-19:13:18] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:18] [V] [TRT] --------------- Timing Runner: Conv_370 + Relu_371 (CudnnConvolution)
[03/27/2022-19:13:18] [V] [TRT] Tactic: 0 Time: 0.838016
[03/27/2022-19:13:18] [V] [TRT] Tactic: 1 Time: 0.409856
[03/27/2022-19:13:18] [V] [TRT] Tactic: 2 Time: 0.5696
[03/27/2022-19:13:18] [V] [TRT] Tactic: 4 Time: 4.93926
[03/27/2022-19:13:18] [V] [TRT] Tactic: 5 Time: 3.55891
[03/27/2022-19:13:18] [V] [TRT] Tactic: 6 Time: 0.208512
[03/27/2022-19:13:18] [V] [TRT] Fastest Tactic: 6 Time: 0.208512
[03/27/2022-19:13:18] [V] [TRT] --------------- Timing Runner: Conv_370 + Relu_371 (CaskConvolution)
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:18] [V] [TRT] Tactic: 1062367460111450758 Time: 0.536444
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:18] [V] [TRT] Tactic: 1754984623894446479 Time: 0.471296
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:18] [V] [TRT] Tactic: 3611739942397549984 Time: 0.40474
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:18] [V] [TRT] Tactic: 3827454225649558724 Time: 0.152064
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:18] [V] [TRT] Tactic: 4337000649858996379 Time: 0.458112
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:18] [V] [TRT] Tactic: 4501471010995462441 Time: 0.404864
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:18] [V] [TRT] Tactic: 5137655947464784826 Time: 0.389888
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:18] [V] [TRT] Tactic: 5288347012147084929 Time: 0.389504
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:18] [V] [TRT] Tactic: 5921334924264294896 Time: 0.156416
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:18] [V] [TRT] Tactic: 6645123197870846056 Time: 0.44032
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:18] [V] [TRT] Tactic: 7144526460361122478 Time: 0.411652
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:18] [V] [TRT] Tactic: 7852627285308570038 Time: 0.19328
[03/27/2022-19:13:18] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:19] [V] [TRT] Tactic: -9137461792520977713 Time: 0.4256
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:19] [V] [TRT] Tactic: -8776506421218919509 Time: 0.153088
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:19] [V] [TRT] Tactic: -8262349710178828730 Time: 0.406144
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:19] [V] [TRT] Tactic: -8133971918129952780 Time: 0.57024
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:19] [V] [TRT] Tactic: -6092040395344634144 Time: 0.564484
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:19] [V] [TRT] Tactic: -4787320710726427159 Time: 0.468864
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:19] [V] [TRT] Tactic: -3456450830548107839 Time: 0.4352
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:19] [V] [TRT] Tactic: -2318106587342035239 Time: 0.168832
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:19] [V] [TRT] Tactic: -1343271414618805657 Time: 0.156676
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:19] [V] [TRT] Tactic: -1218658103698133241 Time: 0.556296
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:19] [V] [TRT] Tactic: -836875257600482091 Time: 0.52596
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:19] [V] [TRT] Tactic: -410470605513481746 Time: 0.386688
[03/27/2022-19:13:19] [V] [TRT] Fastest Tactic: 3827454225649558724 Time: 0.152064
[03/27/2022-19:13:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3827454225649558724
[03/27/2022-19:13:19] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(90112,1,5632,352) ***************
[03/27/2022-19:13:19] [V] [TRT] --------------- Timing Runner: Conv_370 + Relu_371 (CaskConvolution)
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:19] [V] [TRT] Tactic: -9153228964338181824 Time: 0.306048
[03/27/2022-19:13:19] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:19] [V] [TRT] Tactic: -7394439838318485025 Time: 0.332928
[03/27/2022-19:13:19] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.306048
[03/27/2022-19:13:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:19] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:19] [V] [TRT] *************** Autotuning format combination: Float(90112,256,16,1) -> Float(30720,256,16,1) ***************
[03/27/2022-19:13:19] [V] [TRT] --------------- Timing Runner: Conv_372 + Relu_373 (CudaDepthwiseConvolution)
[03/27/2022-19:13:19] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:19] [V] [TRT] --------------- Timing Runner: Conv_372 + Relu_373 (FusedConvActConvolution)
[03/27/2022-19:13:19] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:19] [V] [TRT] --------------- Timing Runner: Conv_372 + Relu_373 (CudnnConvolution)
[03/27/2022-19:13:19] [V] [TRT] Tactic: 0 Time: 0.517248
[03/27/2022-19:13:19] [V] [TRT] Tactic: 1 Time: 0.308736
[03/27/2022-19:13:19] [V] [TRT] Tactic: 2 Time: 0.38912
[03/27/2022-19:13:19] [V] [TRT] Tactic: 4 Time: 1.78483
[03/27/2022-19:13:19] [V] [TRT] Tactic: 5 Time: 1.30765
[03/27/2022-19:13:19] [V] [TRT] Tactic: 6 Time: 0.118404
[03/27/2022-19:13:19] [V] [TRT] Fastest Tactic: 6 Time: 0.118404
[03/27/2022-19:13:19] [V] [TRT] --------------- Timing Runner: Conv_372 + Relu_373 (CaskConvolution)
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:19] [V] [TRT] Tactic: 1062367460111450758 Time: 0.444672
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:19] [V] [TRT] Tactic: 1754984623894446479 Time: 0.423808
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:19] [V] [TRT] Tactic: 3611739942397549984 Time: 0.393216
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:19] [V] [TRT] Tactic: 3827454225649558724 Time: 0.091264
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:19] [V] [TRT] Tactic: 4337000649858996379 Time: 0.385792
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:19] [V] [TRT] Tactic: 4501471010995462441 Time: 0.392832
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:19] [V] [TRT] Tactic: 5137655947464784826 Time: 0.29632
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:19] [V] [TRT] Tactic: 5288347012147084929 Time: 0.38336
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:19] [V] [TRT] Tactic: 5921334924264294896 Time: 0.09792
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:19] [V] [TRT] Tactic: 6645123197870846056 Time: 0.34202
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:19] [V] [TRT] Tactic: 7144526460361122478 Time: 0.378624
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:19] [V] [TRT] Tactic: 7852627285308570038 Time: 0.100608
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:19] [V] [TRT] Tactic: -9137461792520977713 Time: 0.410112
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:19] [V] [TRT] Tactic: -8776506421218919509 Time: 0.090112
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:19] [V] [TRT] Tactic: -8262349710178828730 Time: 0.38976
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:19] [V] [TRT] Tactic: -8133971918129952780 Time: 0.495616
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:19] [V] [TRT] Tactic: -6092040395344634144 Time: 0.522496
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:19] [V] [TRT] Tactic: -4787320710726427159 Time: 0.416896
[03/27/2022-19:13:19] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:20] [V] [TRT] Tactic: -3456450830548107839 Time: 0.345344
[03/27/2022-19:13:20] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:20] [V] [TRT] Tactic: -2318106587342035239 Time: 0.097152
[03/27/2022-19:13:20] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:20] [V] [TRT] Tactic: -1343271414618805657 Time: 0.097152
[03/27/2022-19:13:20] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:20] [V] [TRT] Tactic: -1218658103698133241 Time: 0.492416
[03/27/2022-19:13:20] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:20] [V] [TRT] Tactic: -836875257600482091 Time: 0.448
[03/27/2022-19:13:20] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:20] [V] [TRT] Tactic: -410470605513481746 Time: 0.380928
[03/27/2022-19:13:20] [V] [TRT] Fastest Tactic: -8776506421218919509 Time: 0.090112
[03/27/2022-19:13:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -8776506421218919509
[03/27/2022-19:13:20] [V] [TRT] *************** Autotuning format combination: Float(90112,1,5632,352) -> Float(30720,1,1920,120) ***************
[03/27/2022-19:13:20] [V] [TRT] --------------- Timing Runner: Conv_372 + Relu_373 (CaskConvolution)
[03/27/2022-19:13:20] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:20] [V] [TRT] Tactic: -9153228964338181824 Time: 0.17574
[03/27/2022-19:13:20] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:20] [V] [TRT] Tactic: -7394439838318485025 Time: 0.197884
[03/27/2022-19:13:20] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.17574
[03/27/2022-19:13:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:20] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:20] [V] [TRT] *************** Autotuning format combination: Float(30720,256,16,1) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:13:20] [V] [TRT] --------------- Timing Runner: Resize_375 (Resize)
[03/27/2022-19:13:20] [V] [TRT] Tactic: 1 Time: 0.0192
[03/27/2022-19:13:20] [V] [TRT] Fastest Tactic: 1 Time: 0.0192
[03/27/2022-19:13:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 1
[03/27/2022-19:13:20] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:20] [V] [TRT] *************** Autotuning format combination: Float(245760,1024,32,1) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:13:20] [V] [TRT] --------------- Timing Runner: Conv_377 + Relu_378 (CudaDepthwiseConvolution)
[03/27/2022-19:13:20] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:20] [V] [TRT] --------------- Timing Runner: Conv_377 + Relu_378 (FusedConvActConvolution)
[03/27/2022-19:13:20] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:20] [V] [TRT] --------------- Timing Runner: Conv_377 + Relu_378 (CudnnConvolution)
[03/27/2022-19:13:20] [V] [TRT] Tactic: 0 Time: 0.92096
[03/27/2022-19:13:20] [V] [TRT] Tactic: 1 Time: 0.414468
[03/27/2022-19:13:20] [V] [TRT] Tactic: 2 Time: 0.716668
[03/27/2022-19:13:20] [V] [TRT] Tactic: 4 Time: 7.27334
[03/27/2022-19:13:20] [V] [TRT] Tactic: 5 Time: 2.30605
[03/27/2022-19:13:20] [V] [TRT] Tactic: 6 Time: 0.215424
[03/27/2022-19:13:20] [V] [TRT] Fastest Tactic: 6 Time: 0.215424
[03/27/2022-19:13:20] [V] [TRT] --------------- Timing Runner: Conv_377 + Relu_378 (CaskConvolution)
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:20] [V] [TRT] Tactic: 1062367460111450758 Time: 0.439556
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:20] [V] [TRT] Tactic: 1754984623894446479 Time: 0.409216
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:20] [V] [TRT] Tactic: 3611739942397549984 Time: 0.45696
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:20] [V] [TRT] Tactic: 3827454225649558724 Time: 0.1536
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:20] [V] [TRT] Tactic: 4337000649858996379 Time: 0.387968
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:20] [V] [TRT] Tactic: 4501471010995462441 Time: 0.455424
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:20] [V] [TRT] Tactic: 5137655947464784826 Time: 0.365312
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:20] [V] [TRT] Tactic: 5288347012147084929 Time: 0.445828
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:20] [V] [TRT] Tactic: 5921334924264294896 Time: 0.17152
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:20] [V] [TRT] Tactic: 6645123197870846056 Time: 0.393592
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:20] [V] [TRT] Tactic: 7144526460361122478 Time: 0.366976
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:20] [V] [TRT] Tactic: 7852627285308570038 Time: 0.17792
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:20] [V] [TRT] Tactic: -9137461792520977713 Time: 0.47296
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:20] [V] [TRT] Tactic: -8776506421218919509 Time: 0.158844
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:20] [V] [TRT] Tactic: -8262349710178828730 Time: 0.467328
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:20] [V] [TRT] Tactic: -8133971918129952780 Time: 0.423288
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:20] [V] [TRT] Tactic: -6092040395344634144 Time: 0.463236
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:20] [V] [TRT] Tactic: -4787320710726427159 Time: 0.416768
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:20] [V] [TRT] Tactic: -3456450830548107839 Time: 0.408312
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:20] [V] [TRT] Tactic: -2318106587342035239 Time: 0.1696
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:20] [V] [TRT] Tactic: -1343271414618805657 Time: 0.16512
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:20] [V] [TRT] Tactic: -1218658103698133241 Time: 0.421372
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:20] [V] [TRT] Tactic: -836875257600482091 Time: 0.397572
[03/27/2022-19:13:20] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:21] [V] [TRT] Tactic: -410470605513481746 Time: 0.456336
[03/27/2022-19:13:21] [V] [TRT] Fastest Tactic: 3827454225649558724 Time: 0.1536
[03/27/2022-19:13:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3827454225649558724
[03/27/2022-19:13:21] [V] [TRT] *************** Autotuning format combination: Float(245760,1,7680,240) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:13:21] [V] [TRT] --------------- Timing Runner: Conv_377 + Relu_378 (CaskConvolution)
[03/27/2022-19:13:21] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:21] [V] [TRT] Tactic: -9153228964338181824 Time: 0.324992
[03/27/2022-19:13:21] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:21] [V] [TRT] Tactic: -7394439838318485025 Time: 0.355968
[03/27/2022-19:13:21] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.324992
[03/27/2022-19:13:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:21] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:21] [V] [TRT] *************** Autotuning format combination: Float(122880,1024,32,1) -> Float(122880,1024,32,1) ***************
[03/27/2022-19:13:21] [V] [TRT] --------------- Timing Runner: Conv_379 + Relu_380 (CudaDepthwiseConvolution)
[03/27/2022-19:13:21] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:21] [V] [TRT] --------------- Timing Runner: Conv_379 + Relu_380 (FusedConvActConvolution)
[03/27/2022-19:13:21] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:21] [V] [TRT] --------------- Timing Runner: Conv_379 + Relu_380 (CudnnConvolution)
[03/27/2022-19:13:21] [V] [TRT] Tactic: 0 Time: 0.387328
[03/27/2022-19:13:21] [V] [TRT] Tactic: 1 Time: 0.243584
[03/27/2022-19:13:21] [V] [TRT] Tactic: 2 Time: 0.422656
[03/27/2022-19:13:21] [V] [TRT] Tactic: 4 Time: 3.03513
[03/27/2022-19:13:21] [V] [TRT] Tactic: 5 Time: 1.30432
[03/27/2022-19:13:21] [V] [TRT] Tactic: 6 Time: 0.180608
[03/27/2022-19:13:21] [V] [TRT] Fastest Tactic: 6 Time: 0.180608
[03/27/2022-19:13:21] [V] [TRT] --------------- Timing Runner: Conv_379 + Relu_380 (CaskConvolution)
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:21] [V] [TRT] Tactic: 1062367460111450758 Time: 0.236288
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:21] [V] [TRT] Tactic: 1754984623894446479 Time: 0.215936
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:21] [V] [TRT] Tactic: 3611739942397549984 Time: 0.242684
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:21] [V] [TRT] Tactic: 3827454225649558724 Time: 0.090112
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:21] [V] [TRT] Tactic: 4337000649858996379 Time: 0.209152
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:21] [V] [TRT] Tactic: 4501471010995462441 Time: 0.242688
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:21] [V] [TRT] Tactic: 5137655947464784826 Time: 0.195836
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:21] [V] [TRT] Tactic: 5288347012147084929 Time: 0.2368
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:21] [V] [TRT] Tactic: 5921334924264294896 Time: 0.096128
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:21] [V] [TRT] Tactic: 6645123197870846056 Time: 0.207744
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:21] [V] [TRT] Tactic: 7144526460361122478 Time: 0.193152
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:21] [V] [TRT] Tactic: 7852627285308570038 Time: 0.099836
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:21] [V] [TRT] Tactic: -9137461792520977713 Time: 0.245376
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:21] [V] [TRT] Tactic: -8776506421218919509 Time: 0.089728
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:21] [V] [TRT] Tactic: -8262349710178828730 Time: 0.2423
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:21] [V] [TRT] Tactic: -8133971918129952780 Time: 0.219652
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:21] [V] [TRT] Tactic: -6092040395344634144 Time: 0.24384
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:21] [V] [TRT] Tactic: -4787320710726427159 Time: 0.216064
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:21] [V] [TRT] Tactic: -3456450830548107839 Time: 0.216448
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:21] [V] [TRT] Tactic: -2318106587342035239 Time: 0.09536
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:21] [V] [TRT] Tactic: -1343271414618805657 Time: 0.094084
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:21] [V] [TRT] Tactic: -1218658103698133241 Time: 0.218748
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:21] [V] [TRT] Tactic: -836875257600482091 Time: 0.206208
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:21] [V] [TRT] Tactic: -410470605513481746 Time: 0.23552
[03/27/2022-19:13:21] [V] [TRT] Fastest Tactic: -8776506421218919509 Time: 0.089728
[03/27/2022-19:13:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -8776506421218919509
[03/27/2022-19:13:21] [V] [TRT] *************** Autotuning format combination: Float(122880,1,3840,120) -> Float(122880,1,3840,120) ***************
[03/27/2022-19:13:21] [V] [TRT] --------------- Timing Runner: Conv_379 + Relu_380 (CaskConvolution)
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:21] [V] [TRT] Tactic: -9153228964338181824 Time: 0.176
[03/27/2022-19:13:21] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:21] [V] [TRT] Tactic: -7394439838318485025 Time: 0.199044
[03/27/2022-19:13:21] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.176
[03/27/2022-19:13:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:21] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:21] [V] [TRT] *************** Autotuning format combination: Float(122880,1024,32,1) -> Float(49152,1024,32,1) ***************
[03/27/2022-19:13:21] [V] [TRT] --------------- Timing Runner: Conv_381 + Relu_382 (CudaDepthwiseConvolution)
[03/27/2022-19:13:21] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:21] [V] [TRT] --------------- Timing Runner: Conv_381 + Relu_382 (FusedConvActConvolution)
[03/27/2022-19:13:21] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:21] [V] [TRT] --------------- Timing Runner: Conv_381 + Relu_382 (CudnnConvolution)
[03/27/2022-19:13:21] [V] [TRT] Tactic: 0 Time: 0.215296
[03/27/2022-19:13:21] [V] [TRT] Tactic: 1 Time: 0.172168
[03/27/2022-19:13:21] [V] [TRT] Tactic: 2 Time: 0.250244
[03/27/2022-19:13:21] [V] [TRT] Tactic: 4 Time: 1.36717
[03/27/2022-19:13:21] [V] [TRT] Tactic: 5 Time: 0.682236
[03/27/2022-19:13:21] [V] [TRT] Tactic: 6 Time: 0.086272
[03/27/2022-19:13:21] [V] [TRT] Fastest Tactic: 6 Time: 0.086272
[03/27/2022-19:13:21] [V] [TRT] --------------- Timing Runner: Conv_381 + Relu_382 (CaskConvolution)
[03/27/2022-19:13:21] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:21] [V] [TRT] Tactic: 1062367460111450758 Time: 0.182404
[03/27/2022-19:13:21] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:21] [V] [TRT] Tactic: 1754984623894446479 Time: 0.164596
[03/27/2022-19:13:21] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:21] [V] [TRT] Tactic: 3611739942397549984 Time: 0.24128
[03/27/2022-19:13:21] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:21] [V] [TRT] Tactic: 3827454225649558724 Time: 0.056448
[03/27/2022-19:13:21] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:21] [V] [TRT] Tactic: 4337000649858996379 Time: 0.15552
[03/27/2022-19:13:21] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:22] [V] [TRT] Tactic: 4501471010995462441 Time: 0.240896
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:22] [V] [TRT] Tactic: 5137655947464784826 Time: 0.136064
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:22] [V] [TRT] Tactic: 5288347012147084929 Time: 0.23552
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:22] [V] [TRT] Tactic: 5921334924264294896 Time: 0.060288
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:22] [V] [TRT] Tactic: 6645123197870846056 Time: 0.148992
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:22] [V] [TRT] Tactic: 7144526460361122478 Time: 0.138368
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:22] [V] [TRT] Tactic: 7852627285308570038 Time: 0.062976
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:22] [V] [TRT] Tactic: -9137461792520977713 Time: 0.24384
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:22] [V] [TRT] Tactic: -8776506421218919509 Time: 0.055936
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:22] [V] [TRT] Tactic: -8262349710178828730 Time: 0.240128
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:22] [V] [TRT] Tactic: -8133971918129952780 Time: 0.187904
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:22] [V] [TRT] Tactic: -6092040395344634144 Time: 0.19086
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:22] [V] [TRT] Tactic: -4787320710726427159 Time: 0.1536
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:22] [V] [TRT] Tactic: -3456450830548107839 Time: 0.155004
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:22] [V] [TRT] Tactic: -2318106587342035239 Time: 0.060156
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:22] [V] [TRT] Tactic: -1343271414618805657 Time: 0.059392
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:22] [V] [TRT] Tactic: -1218658103698133241 Time: 0.186496
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:22] [V] [TRT] Tactic: -836875257600482091 Time: 0.179584
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:22] [V] [TRT] Tactic: -410470605513481746 Time: 0.233216
[03/27/2022-19:13:22] [V] [TRT] Fastest Tactic: -8776506421218919509 Time: 0.055936
[03/27/2022-19:13:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -8776506421218919509
[03/27/2022-19:13:22] [V] [TRT] *************** Autotuning format combination: Float(122880,1,3840,120) -> Float(49152,1,1536,48) ***************
[03/27/2022-19:13:22] [V] [TRT] --------------- Timing Runner: Conv_381 + Relu_382 (CaskConvolution)
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:22] [V] [TRT] Tactic: -9153228964338181824 Time: 0.109056
[03/27/2022-19:13:22] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:22] [V] [TRT] Tactic: -7394439838318485025 Time: 0.128252
[03/27/2022-19:13:22] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.109056
[03/27/2022-19:13:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:22] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:22] [V] [TRT] *************** Autotuning format combination: Float(49152,1024,32,1) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:13:22] [V] [TRT] --------------- Timing Runner: Resize_384 (Resize)
[03/27/2022-19:13:22] [V] [TRT] Tactic: 1 Time: 0.027392
[03/27/2022-19:13:22] [V] [TRT] Fastest Tactic: 1 Time: 0.027392
[03/27/2022-19:13:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 1
[03/27/2022-19:13:22] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:22] [V] [TRT] *************** Autotuning format combination: Float(393216,4096,64,1) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:13:22] [V] [TRT] --------------- Timing Runner: Conv_386 + Relu_387 (CudaDepthwiseConvolution)
[03/27/2022-19:13:22] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:22] [V] [TRT] --------------- Timing Runner: Conv_386 + Relu_387 (FusedConvActConvolution)
[03/27/2022-19:13:22] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:22] [V] [TRT] --------------- Timing Runner: Conv_386 + Relu_387 (CudnnConvolution)
[03/27/2022-19:13:22] [V] [TRT] Tactic: 0 Time: 0.567544
[03/27/2022-19:13:22] [V] [TRT] Tactic: 1 Time: 0.60634
[03/27/2022-19:13:22] [V] [TRT] Tactic: 2 Time: 0.78016
[03/27/2022-19:13:22] [V] [TRT] Tactic: 4 Time: 6.3712
[03/27/2022-19:13:22] [V] [TRT] Tactic: 5 Time: 1.32339
[03/27/2022-19:13:22] [V] [TRT] Tactic: 6 Time: 0.331904
[03/27/2022-19:13:22] [V] [TRT] Fastest Tactic: 6 Time: 0.331904
[03/27/2022-19:13:22] [V] [TRT] --------------- Timing Runner: Conv_386 + Relu_387 (CaskConvolution)
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:22] [V] [TRT] Tactic: 1062367460111450758 Time: 0.335232
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:22] [V] [TRT] Tactic: 1754984623894446479 Time: 0.324864
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:22] [V] [TRT] Tactic: 3611739942397549984 Time: 0.493568
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:22] [V] [TRT] Tactic: 3827454225649558724 Time: 0.130688
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:22] [V] [TRT] Tactic: 4337000649858996379 Time: 0.31872
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:22] [V] [TRT] Tactic: 4501471010995462441 Time: 0.553216
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:22] [V] [TRT] Tactic: 5137655947464784826 Time: 0.299264
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:22] [V] [TRT] Tactic: 5288347012147084929 Time: 0.473212
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:22] [V] [TRT] Tactic: 5921334924264294896 Time: 0.138496
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:22] [V] [TRT] Tactic: 6645123197870846056 Time: 0.312832
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:22] [V] [TRT] Tactic: 7144526460361122478 Time: 0.298496
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:22] [V] [TRT] Tactic: 7852627285308570038 Time: 0.145664
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:22] [V] [TRT] Tactic: -9137461792520977713 Time: 0.564608
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:22] [V] [TRT] Tactic: -8776506421218919509 Time: 0.132484
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:22] [V] [TRT] Tactic: -8262349710178828730 Time: 0.493824
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:22] [V] [TRT] Tactic: -8133971918129952780 Time: 0.34714
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:22] [V] [TRT] Tactic: -6092040395344634144 Time: 0.340864
[03/27/2022-19:13:22] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:23] [V] [TRT] Tactic: -4787320710726427159 Time: 0.325632
[03/27/2022-19:13:23] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:23] [V] [TRT] Tactic: -3456450830548107839 Time: 0.302468
[03/27/2022-19:13:23] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:23] [V] [TRT] Tactic: -2318106587342035239 Time: 0.137728
[03/27/2022-19:13:23] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:23] [V] [TRT] Tactic: -1343271414618805657 Time: 0.134784
[03/27/2022-19:13:23] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:23] [V] [TRT] Tactic: -1218658103698133241 Time: 0.35354
[03/27/2022-19:13:23] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:23] [V] [TRT] Tactic: -836875257600482091 Time: 0.343808
[03/27/2022-19:13:23] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:23] [V] [TRT] Tactic: -410470605513481746 Time: 0.500608
[03/27/2022-19:13:23] [V] [TRT] Fastest Tactic: 3827454225649558724 Time: 0.130688
[03/27/2022-19:13:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3827454225649558724
[03/27/2022-19:13:23] [V] [TRT] *************** Autotuning format combination: Float(393216,1,6144,96) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:13:23] [V] [TRT] --------------- Timing Runner: Conv_386 + Relu_387 (CaskConvolution)
[03/27/2022-19:13:23] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:23] [V] [TRT] Tactic: -9153228964338181824 Time: 0.236028
[03/27/2022-19:13:23] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:23] [V] [TRT] Tactic: -7394439838318485025 Time: 0.277888
[03/27/2022-19:13:23] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.236028
[03/27/2022-19:13:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:23] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:23] [V] [TRT] *************** Autotuning format combination: Float(196608,4096,64,1) -> Float(196608,4096,64,1) ***************
[03/27/2022-19:13:23] [V] [TRT] --------------- Timing Runner: Conv_388 + Relu_389 (CudaDepthwiseConvolution)
[03/27/2022-19:13:23] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:23] [V] [TRT] --------------- Timing Runner: Conv_388 + Relu_389 (FusedConvActConvolution)
[03/27/2022-19:13:23] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:23] [V] [TRT] --------------- Timing Runner: Conv_388 + Relu_389 (CudnnConvolution)
[03/27/2022-19:13:23] [V] [TRT] Tactic: 0 Time: 0.310272
[03/27/2022-19:13:23] [V] [TRT] Tactic: 1 Time: 0.27584
[03/27/2022-19:13:23] [V] [TRT] Tactic: 2 Time: 0.368256
[03/27/2022-19:13:23] [V] [TRT] Tactic: 4 Time: 3.49811
[03/27/2022-19:13:23] [V] [TRT] Tactic: 5 Time: 0.937856
[03/27/2022-19:13:23] [V] [TRT] Tactic: 6 Time: 0.12992
[03/27/2022-19:13:23] [V] [TRT] Fastest Tactic: 6 Time: 0.12992
[03/27/2022-19:13:23] [V] [TRT] --------------- Timing Runner: Conv_388 + Relu_389 (CaskConvolution)
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:23] [V] [TRT] Tactic: 1062367460111450758 Time: 0.176256
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:23] [V] [TRT] Tactic: 1754984623894446479 Time: 0.168192
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:23] [V] [TRT] Tactic: 3611739942397549984 Time: 0.288256
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:23] [V] [TRT] Tactic: 3827454225649558724 Time: 0.08128
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:23] [V] [TRT] Tactic: 4337000649858996379 Time: 0.154624
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:23] [V] [TRT] Tactic: 4501471010995462441 Time: 0.297472
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:23] [V] [TRT] Tactic: 5137655947464784826 Time: 0.145024
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:23] [V] [TRT] Tactic: 5288347012147084929 Time: 0.262908
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:23] [V] [TRT] Tactic: 5921334924264294896 Time: 0.084984
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:23] [V] [TRT] Tactic: 6645123197870846056 Time: 0.167292
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:23] [V] [TRT] Tactic: 7144526460361122478 Time: 0.158336
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:23] [V] [TRT] Tactic: 7852627285308570038 Time: 0.088064
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:23] [V] [TRT] Tactic: -9137461792520977713 Time: 0.304252
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:23] [V] [TRT] Tactic: -8776506421218919509 Time: 0.08038
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:23] [V] [TRT] Tactic: -8262349710178828730 Time: 0.268156
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:23] [V] [TRT] Tactic: -8133971918129952780 Time: 0.183544
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:23] [V] [TRT] Tactic: -6092040395344634144 Time: 0.182912
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:23] [V] [TRT] Tactic: -4787320710726427159 Time: 0.16768
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:23] [V] [TRT] Tactic: -3456450830548107839 Time: 0.164224
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:23] [V] [TRT] Tactic: -2318106587342035239 Time: 0.084224
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:23] [V] [TRT] Tactic: -1343271414618805657 Time: 0.083968
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:23] [V] [TRT] Tactic: -1218658103698133241 Time: 0.189056
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:23] [V] [TRT] Tactic: -836875257600482091 Time: 0.17088
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:23] [V] [TRT] Tactic: -410470605513481746 Time: 0.304516
[03/27/2022-19:13:23] [V] [TRT] Fastest Tactic: -8776506421218919509 Time: 0.08038
[03/27/2022-19:13:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -8776506421218919509
[03/27/2022-19:13:23] [V] [TRT] *************** Autotuning format combination: Float(196608,1,3072,48) -> Float(196608,1,3072,48) ***************
[03/27/2022-19:13:23] [V] [TRT] --------------- Timing Runner: Conv_388 + Relu_389 (CaskConvolution)
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:23] [V] [TRT] Tactic: -9153228964338181824 Time: 0.172544
[03/27/2022-19:13:23] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:23] [V] [TRT] Tactic: -7394439838318485025 Time: 0.133376
[03/27/2022-19:13:23] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.133376
[03/27/2022-19:13:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[03/27/2022-19:13:23] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:23] [V] [TRT] *************** Autotuning format combination: Float(196608,4096,64,1) -> Float(98304,4096,64,1) ***************
[03/27/2022-19:13:23] [V] [TRT] --------------- Timing Runner: Conv_390 + Relu_391 (CudaDepthwiseConvolution)
[03/27/2022-19:13:23] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:23] [V] [TRT] --------------- Timing Runner: Conv_390 + Relu_391 (FusedConvActConvolution)
[03/27/2022-19:13:23] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:23] [V] [TRT] --------------- Timing Runner: Conv_390 + Relu_391 (CudnnConvolution)
[03/27/2022-19:13:23] [V] [TRT] Tactic: 0 Time: 0.17856
[03/27/2022-19:13:23] [V] [TRT] Tactic: 1 Time: 0.276736
[03/27/2022-19:13:23] [V] [TRT] Tactic: 2 Time: 0.26496
[03/27/2022-19:13:23] [V] [TRT] Tactic: 4 Time: 1.92883
[03/27/2022-19:13:23] [V] [TRT] Tactic: 5 Time: 1.21485
[03/27/2022-19:13:23] [V] [TRT] Tactic: 6 Time: 0.315912
[03/27/2022-19:13:23] [V] [TRT] Fastest Tactic: 0 Time: 0.17856
[03/27/2022-19:13:23] [V] [TRT] --------------- Timing Runner: Conv_390 + Relu_391 (CaskConvolution)
[03/27/2022-19:13:23] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:23] [V] [TRT] Tactic: 1062367460111450758 Time: 0.10624
[03/27/2022-19:13:23] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:23] [V] [TRT] Tactic: 1754984623894446479 Time: 0.096764
[03/27/2022-19:13:23] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:23] [V] [TRT] Tactic: 3611739942397549984 Time: 0.287232
[03/27/2022-19:13:23] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:23] [V] [TRT] Tactic: 3827454225649558724 Time: 0.049024
[03/27/2022-19:13:23] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:23] [V] [TRT] Tactic: 4337000649858996379 Time: 0.153344
[03/27/2022-19:13:23] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:24] [V] [TRT] Tactic: 4501471010995462441 Time: 0.296192
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:24] [V] [TRT] Tactic: 5137655947464784826 Time: 0.143488
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:24] [V] [TRT] Tactic: 5288347012147084929 Time: 0.282624
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:24] [V] [TRT] Tactic: 5921334924264294896 Time: 0.051072
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:24] [V] [TRT] Tactic: 6645123197870846056 Time: 0.151556
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:24] [V] [TRT] Tactic: 7144526460361122478 Time: 0.09088
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:24] [V] [TRT] Tactic: 7852627285308570038 Time: 0.05312
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:24] [V] [TRT] Tactic: -9137461792520977713 Time: 0.294784
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:24] [V] [TRT] Tactic: -8776506421218919509 Time: 0.049024
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:24] [V] [TRT] Tactic: -8262349710178828730 Time: 0.272128
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:24] [V] [TRT] Tactic: -8133971918129952780 Time: 0.174976
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:24] [V] [TRT] Tactic: -6092040395344634144 Time: 0.110208
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:24] [V] [TRT] Tactic: -4787320710726427159 Time: 0.096
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:24] [V] [TRT] Tactic: -3456450830548107839 Time: 0.102528
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:24] [V] [TRT] Tactic: -2318106587342035239 Time: 0.051584
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:24] [V] [TRT] Tactic: -1343271414618805657 Time: 0.049536
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:24] [V] [TRT] Tactic: -1218658103698133241 Time: 0.175104
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:24] [V] [TRT] Tactic: -836875257600482091 Time: 0.166144
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:24] [V] [TRT] Tactic: -410470605513481746 Time: 0.2912
[03/27/2022-19:13:24] [V] [TRT] Fastest Tactic: 3827454225649558724 Time: 0.049024
[03/27/2022-19:13:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3827454225649558724
[03/27/2022-19:13:24] [V] [TRT] *************** Autotuning format combination: Float(196608,1,3072,48) -> Float(98304,1,1536,24) ***************
[03/27/2022-19:13:24] [V] [TRT] --------------- Timing Runner: Conv_390 + Relu_391 (CaskConvolution)
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:24] [V] [TRT] Tactic: -9153228964338181824 Time: 0.102144
[03/27/2022-19:13:24] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:24] [V] [TRT] Tactic: -7394439838318485025 Time: 0.13952
[03/27/2022-19:13:24] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.102144
[03/27/2022-19:13:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:24] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:24] [V] [TRT] *************** Autotuning format combination: Float(98304,4096,64,1) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:13:24] [V] [TRT] --------------- Timing Runner: Resize_393 (Resize)
[03/27/2022-19:13:24] [V] [TRT] Tactic: 1 Time: 0.047872
[03/27/2022-19:13:24] [V] [TRT] Fastest Tactic: 1 Time: 0.047872
[03/27/2022-19:13:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 1
[03/27/2022-19:13:24] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:24] [V] [TRT] *************** Autotuning format combination: Float(786432,16384,128,1) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:13:24] [V] [TRT] --------------- Timing Runner: Conv_395 + Relu_396 (CudaDepthwiseConvolution)
[03/27/2022-19:13:24] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:24] [V] [TRT] --------------- Timing Runner: Conv_395 + Relu_396 (FusedConvActConvolution)
[03/27/2022-19:13:24] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:24] [V] [TRT] --------------- Timing Runner: Conv_395 + Relu_396 (CudnnConvolution)
[03/27/2022-19:13:24] [V] [TRT] Tactic: 0 Time: 0.65152
[03/27/2022-19:13:24] [V] [TRT] Tactic: 1 Time: 1.12243
[03/27/2022-19:13:24] [V] [TRT] Tactic: 2 Time: 0.8238
[03/27/2022-19:13:24] [V] [TRT] Tactic: 4 Time: 7.37613
[03/27/2022-19:13:24] [V] [TRT] Tactic: 5 Time: 1.54522
[03/27/2022-19:13:24] [V] [TRT] Tactic: 6 Time: 0.246656
[03/27/2022-19:13:24] [V] [TRT] Fastest Tactic: 6 Time: 0.246656
[03/27/2022-19:13:24] [V] [TRT] --------------- Timing Runner: Conv_395 + Relu_396 (CaskConvolution)
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:24] [V] [TRT] Tactic: 1062367460111450758 Time: 0.29632
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:24] [V] [TRT] Tactic: 1754984623894446479 Time: 0.314756
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:24] [V] [TRT] Tactic: 3611739942397549984 Time: 0.879872
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:24] [V] [TRT] Tactic: 3827454225649558724 Time: 0.159616
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:24] [V] [TRT] Tactic: 4337000649858996379 Time: 0.481788
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:24] [V] [TRT] Tactic: 4501471010995462441 Time: 0.867072
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:24] [V] [TRT] Tactic: 5137655947464784826 Time: 0.454528
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:24] [V] [TRT] Tactic: 5288347012147084929 Time: 0.854144
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:24] [V] [TRT] Tactic: 5921334924264294896 Time: 0.158464
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:24] [V] [TRT] Tactic: 6645123197870846056 Time: 0.465408
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:24] [V] [TRT] Tactic: 7144526460361122478 Time: 0.295808
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:24] [V] [TRT] Tactic: 7852627285308570038 Time: 0.165504
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:24] [V] [TRT] Tactic: -9137461792520977713 Time: 0.873472
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:24] [V] [TRT] Tactic: -8776506421218919509 Time: 0.158844
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:24] [V] [TRT] Tactic: -8262349710178828730 Time: 0.891136
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:24] [V] [TRT] Tactic: -8133971918129952780 Time: 0.513536
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:24] [V] [TRT] Tactic: -6092040395344634144 Time: 0.306816
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:24] [V] [TRT] Tactic: -4787320710726427159 Time: 0.313856
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:24] [V] [TRT] Tactic: -3456450830548107839 Time: 0.286076
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:24] [V] [TRT] Tactic: -2318106587342035239 Time: 0.163072
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:24] [V] [TRT] Tactic: -1343271414618805657 Time: 0.156288
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:24] [V] [TRT] Tactic: -1218658103698133241 Time: 0.511232
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:24] [V] [TRT] Tactic: -836875257600482091 Time: 0.495104
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:24] [V] [TRT] Tactic: -410470605513481746 Time: 0.859776
[03/27/2022-19:13:24] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.156288
[03/27/2022-19:13:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[03/27/2022-19:13:24] [V] [TRT] *************** Autotuning format combination: Float(786432,1,6144,48) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:13:24] [V] [TRT] --------------- Timing Runner: Conv_395 + Relu_396 (CaskConvolution)
[03/27/2022-19:13:24] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:25] [V] [TRT] Tactic: -9153228964338181824 Time: 0.331
[03/27/2022-19:13:25] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:25] [V] [TRT] Tactic: -7394439838318485025 Time: 0.44544
[03/27/2022-19:13:25] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.331
[03/27/2022-19:13:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:25] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:25] [V] [TRT] *************** Autotuning format combination: Float(393216,16384,128,1) -> Float(393216,16384,128,1) ***************
[03/27/2022-19:13:25] [V] [TRT] --------------- Timing Runner: Conv_397 + Relu_398 (CudaDepthwiseConvolution)
[03/27/2022-19:13:25] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:25] [V] [TRT] --------------- Timing Runner: Conv_397 + Relu_398 (FusedConvActConvolution)
[03/27/2022-19:13:25] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:25] [V] [TRT] --------------- Timing Runner: Conv_397 + Relu_398 (CudnnConvolution)
[03/27/2022-19:13:25] [V] [TRT] Tactic: 0 Time: 0.347776
[03/27/2022-19:13:25] [V] [TRT] Tactic: 1 Time: 0.336128
[03/27/2022-19:13:25] [V] [TRT] Tactic: 2 Time: 0.502528
[03/27/2022-19:13:25] [V] [TRT] Tactic: 4 Time: 4.21325
[03/27/2022-19:13:25] [V] [TRT] Tactic: 5 Time: 1.17568
[03/27/2022-19:13:25] [V] [TRT] Tactic: 6 Time: 0.196612
[03/27/2022-19:13:25] [V] [TRT] Fastest Tactic: 6 Time: 0.196612
[03/27/2022-19:13:25] [V] [TRT] --------------- Timing Runner: Conv_397 + Relu_398 (CaskConvolution)
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:25] [V] [TRT] Tactic: 1062367460111450758 Time: 0.160248
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:25] [V] [TRT] Tactic: 1754984623894446479 Time: 0.172672
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:25] [V] [TRT] Tactic: 3611739942397549984 Time: 0.478336
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:25] [V] [TRT] Tactic: 3827454225649558724 Time: 0.106748
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:25] [V] [TRT] Tactic: 4337000649858996379 Time: 0.260352
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:25] [V] [TRT] Tactic: 4501471010995462441 Time: 0.476032
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:25] [V] [TRT] Tactic: 5137655947464784826 Time: 0.250368
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:25] [V] [TRT] Tactic: 5288347012147084929 Time: 0.470016
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:25] [V] [TRT] Tactic: 5921334924264294896 Time: 0.105984
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:25] [V] [TRT] Tactic: 6645123197870846056 Time: 0.279416
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:25] [V] [TRT] Tactic: 7144526460361122478 Time: 0.168696
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:25] [V] [TRT] Tactic: 7852627285308570038 Time: 0.110464
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:25] [V] [TRT] Tactic: -9137461792520977713 Time: 0.479872
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:25] [V] [TRT] Tactic: -8776506421218919509 Time: 0.106624
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:25] [V] [TRT] Tactic: -8262349710178828730 Time: 0.47846
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:25] [V] [TRT] Tactic: -8133971918129952780 Time: 0.272
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:25] [V] [TRT] Tactic: -6092040395344634144 Time: 0.171392
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:25] [V] [TRT] Tactic: -4787320710726427159 Time: 0.171648
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:25] [V] [TRT] Tactic: -3456450830548107839 Time: 0.15232
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:25] [V] [TRT] Tactic: -2318106587342035239 Time: 0.10854
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:25] [V] [TRT] Tactic: -1343271414618805657 Time: 0.103296
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:25] [V] [TRT] Tactic: -1218658103698133241 Time: 0.272
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:25] [V] [TRT] Tactic: -836875257600482091 Time: 0.26368
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:25] [V] [TRT] Tactic: -410470605513481746 Time: 0.465664
[03/27/2022-19:13:25] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.103296
[03/27/2022-19:13:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[03/27/2022-19:13:25] [V] [TRT] *************** Autotuning format combination: Float(393216,1,3072,24) -> Float(393216,1,3072,24) ***************
[03/27/2022-19:13:25] [V] [TRT] --------------- Timing Runner: Conv_397 + Relu_398 (CaskConvolution)
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:25] [V] [TRT] Tactic: -9153228964338181824 Time: 0.197888
[03/27/2022-19:13:25] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:25] [V] [TRT] Tactic: -7394439838318485025 Time: 0.323328
[03/27/2022-19:13:25] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.197888
[03/27/2022-19:13:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:25] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:25] [V] [TRT] *************** Autotuning format combination: Float(393216,16384,128,1) -> Float(262144,16384,128,1) ***************
[03/27/2022-19:13:25] [V] [TRT] --------------- Timing Runner: Conv_399 + Relu_400 (CudaDepthwiseConvolution)
[03/27/2022-19:13:25] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:25] [V] [TRT] --------------- Timing Runner: Conv_399 + Relu_400 (FusedConvActConvolution)
[03/27/2022-19:13:25] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:25] [V] [TRT] --------------- Timing Runner: Conv_399 + Relu_400 (CudnnConvolution)
[03/27/2022-19:13:25] [V] [TRT] Tactic: 0 Time: 0.375168
[03/27/2022-19:13:25] [V] [TRT] Tactic: 1 Time: 0.950784
[03/27/2022-19:13:25] [V] [TRT] Tactic: 2 Time: 0.692604
[03/27/2022-19:13:25] [V] [TRT] Tactic: 4 Time: 3.35398
[03/27/2022-19:13:25] [V] [TRT] Tactic: 5 Time: 1.06995
[03/27/2022-19:13:25] [V] [TRT] Tactic: 6 Time: 0.169088
[03/27/2022-19:13:25] [V] [TRT] Fastest Tactic: 6 Time: 0.169088
[03/27/2022-19:13:25] [V] [TRT] --------------- Timing Runner: Conv_399 + Relu_400 (CaskConvolution)
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:25] [V] [TRT] Tactic: 1062367460111450758 Time: 0.159744
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:25] [V] [TRT] Tactic: 1754984623894446479 Time: 0.170368
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:25] [V] [TRT] Tactic: 3611739942397549984 Time: 0.47616
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:25] [V] [TRT] Tactic: 3827454225649558724 Time: 0.104444
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:25] [V] [TRT] Tactic: 4337000649858996379 Time: 0.259712
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:25] [V] [TRT] Tactic: 4501471010995462441 Time: 0.47514
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:25] [V] [TRT] Tactic: 5137655947464784826 Time: 0.249728
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:25] [V] [TRT] Tactic: 5288347012147084929 Time: 0.46912
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:25] [V] [TRT] Tactic: 5921334924264294896 Time: 0.104448
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:25] [V] [TRT] Tactic: 6645123197870846056 Time: 0.257148
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:25] [V] [TRT] Tactic: 7144526460361122478 Time: 0.163456
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:25] [V] [TRT] Tactic: 7852627285308570038 Time: 0.108804
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:25] [V] [TRT] Tactic: -9137461792520977713 Time: 0.47974
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:25] [V] [TRT] Tactic: -8776506421218919509 Time: 0.10394
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:25] [V] [TRT] Tactic: -8262349710178828730 Time: 0.476164
[03/27/2022-19:13:25] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:26] [V] [TRT] Tactic: -8133971918129952780 Time: 0.272
[03/27/2022-19:13:26] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:26] [V] [TRT] Tactic: -6092040395344634144 Time: 0.164868
[03/27/2022-19:13:26] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:26] [V] [TRT] Tactic: -4787320710726427159 Time: 0.170244
[03/27/2022-19:13:26] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:26] [V] [TRT] Tactic: -3456450830548107839 Time: 0.152576
[03/27/2022-19:13:26] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:26] [V] [TRT] Tactic: -2318106587342035239 Time: 0.107008
[03/27/2022-19:13:26] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:26] [V] [TRT] Tactic: -1343271414618805657 Time: 0.101888
[03/27/2022-19:13:26] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:26] [V] [TRT] Tactic: -1218658103698133241 Time: 0.27008
[03/27/2022-19:13:26] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:26] [V] [TRT] Tactic: -836875257600482091 Time: 0.261504
[03/27/2022-19:13:26] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:26] [V] [TRT] Tactic: -410470605513481746 Time: 0.464128
[03/27/2022-19:13:26] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.101888
[03/27/2022-19:13:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[03/27/2022-19:13:26] [V] [TRT] *************** Autotuning format combination: Float(393216,1,3072,24) -> Float(262144,1,2048,16) ***************
[03/27/2022-19:13:26] [V] [TRT] --------------- Timing Runner: Conv_399 + Relu_400 (CaskConvolution)
[03/27/2022-19:13:26] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:26] [V] [TRT] Tactic: -9153228964338181824 Time: 0.197376
[03/27/2022-19:13:26] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:26] [V] [TRT] Tactic: -7394439838318485025 Time: 0.32192
[03/27/2022-19:13:26] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.197376
[03/27/2022-19:13:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:26] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:26] [V] [TRT] *************** Autotuning format combination: Float(262144,16384,128,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:13:26] [V] [TRT] --------------- Timing Runner: Resize_402 (Resize)
[03/27/2022-19:13:26] [V] [TRT] Tactic: 1 Time: 0.115456
[03/27/2022-19:13:26] [V] [TRT] Fastest Tactic: 1 Time: 0.115456
[03/27/2022-19:13:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 1
[03/27/2022-19:13:26] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:26] [V] [TRT] *************** Autotuning format combination: Float(2097152,65536,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:13:26] [V] [TRT] --------------- Timing Runner: Conv_404 + Relu_405 (CudaDepthwiseConvolution)
[03/27/2022-19:13:26] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:26] [V] [TRT] --------------- Timing Runner: Conv_404 + Relu_405 (FusedConvActConvolution)
[03/27/2022-19:13:26] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:26] [V] [TRT] --------------- Timing Runner: Conv_404 + Relu_405 (CudnnConvolution)
[03/27/2022-19:13:26] [V] [TRT] Tactic: 0 Time: 1.50374
[03/27/2022-19:13:26] [V] [TRT] Tactic: 1 Time: 1.41683
[03/27/2022-19:13:26] [V] [TRT] Tactic: 2 Time: 2.05184
[03/27/2022-19:13:26] [V] [TRT] Tactic: 5 Time: 3.7792
[03/27/2022-19:13:26] [V] [TRT] Tactic: 6 Time: 0.658816
[03/27/2022-19:13:26] [V] [TRT] Fastest Tactic: 6 Time: 0.658816
[03/27/2022-19:13:26] [V] [TRT] --------------- Timing Runner: Conv_404 + Relu_405 (CaskConvolution)
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:26] [V] [TRT] Tactic: 1062367460111450758 Time: 0.705024
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:26] [V] [TRT] Tactic: 1754984623894446479 Time: 0.79168
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:26] [V] [TRT] Tactic: 3611739942397549984 Time: 2.3223
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:26] [V] [TRT] Tactic: 3827454225649558724 Time: 0.462208
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:26] [V] [TRT] Tactic: 4337000649858996379 Time: 1.22445
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:26] [V] [TRT] Tactic: 4501471010995462441 Time: 2.31769
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:26] [V] [TRT] Tactic: 5137655947464784826 Time: 1.18745
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:26] [V] [TRT] Tactic: 5288347012147084929 Time: 2.28224
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:26] [V] [TRT] Tactic: 5921334924264294896 Time: 0.461184
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:26] [V] [TRT] Tactic: 6645123197870846056 Time: 1.21677
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:26] [V] [TRT] Tactic: 7144526460361122478 Time: 0.759296
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:26] [V] [TRT] Tactic: 7852627285308570038 Time: 0.47808
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:26] [V] [TRT] Tactic: -9137461792520977713 Time: 2.33997
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:26] [V] [TRT] Tactic: -8776506421218919509 Time: 0.464256
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:26] [V] [TRT] Tactic: -8262349710178828730 Time: 2.31654
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:26] [V] [TRT] Tactic: -8133971918129952780 Time: 1.29267
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:26] [V] [TRT] Tactic: -6092040395344634144 Time: 0.7232
[03/27/2022-19:13:26] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:27] [V] [TRT] Tactic: -4787320710726427159 Time: 0.788096
[03/27/2022-19:13:27] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:27] [V] [TRT] Tactic: -3456450830548107839 Time: 0.671872
[03/27/2022-19:13:27] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:27] [V] [TRT] Tactic: -2318106587342035239 Time: 0.466944
[03/27/2022-19:13:27] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:27] [V] [TRT] Tactic: -1343271414618805657 Time: 0.443008
[03/27/2022-19:13:27] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:27] [V] [TRT] Tactic: -1218658103698133241 Time: 1.28346
[03/27/2022-19:13:27] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:27] [V] [TRT] Tactic: -836875257600482091 Time: 1.24595
[03/27/2022-19:13:27] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:27] [V] [TRT] Tactic: -410470605513481746 Time: 2.26688
[03/27/2022-19:13:27] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.443008
[03/27/2022-19:13:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[03/27/2022-19:13:27] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,8192,32) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:13:27] [V] [TRT] --------------- Timing Runner: Conv_404 + Relu_405 (CaskConvolution)
[03/27/2022-19:13:27] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:27] [V] [TRT] Tactic: -9153228964338181824 Time: 0.706304
[03/27/2022-19:13:27] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:27] [V] [TRT] Tactic: -7394439838318485025 Time: 1.18413
[03/27/2022-19:13:27] [V] [TRT] Fastest Tactic: -9153228964338181824 Time: 0.706304
[03/27/2022-19:13:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -9153228964338181824
[03/27/2022-19:13:27] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:27] [V] [TRT] *************** Autotuning format combination: Float(1048576,65536,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:13:27] [V] [TRT] --------------- Timing Runner: Conv_406 + Relu_407 (CudaDepthwiseConvolution)
[03/27/2022-19:13:27] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:27] [V] [TRT] --------------- Timing Runner: Conv_406 + Relu_407 (FusedConvActConvolution)
[03/27/2022-19:13:27] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:27] [V] [TRT] --------------- Timing Runner: Conv_406 + Relu_407 (CudnnConvolution)
[03/27/2022-19:13:27] [V] [TRT] Tactic: 0 Time: 0.888448
[03/27/2022-19:13:27] [V] [TRT] Tactic: 1 Time: 1.00544
[03/27/2022-19:13:27] [V] [TRT] Tactic: 2 Time: 1.18426
[03/27/2022-19:13:27] [V] [TRT] Tactic: 5 Time: 6.60019
[03/27/2022-19:13:27] [V] [TRT] Tactic: 6 Time: 0.892796
[03/27/2022-19:13:27] [V] [TRT] Fastest Tactic: 0 Time: 0.888448
[03/27/2022-19:13:27] [V] [TRT] --------------- Timing Runner: Conv_406 + Relu_407 (CaskConvolution)
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:27] [V] [TRT] Tactic: 1062367460111450758 Time: 0.39488
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:27] [V] [TRT] Tactic: 1754984623894446479 Time: 0.441348
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:27] [V] [TRT] Tactic: 3611739942397549984 Time: 1.29856
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:27] [V] [TRT] Tactic: 3827454225649558724 Time: 0.316672
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:27] [V] [TRT] Tactic: 4337000649858996379 Time: 0.678788
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:27] [V] [TRT] Tactic: 4501471010995462441 Time: 1.28165
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:27] [V] [TRT] Tactic: 5137655947464784826 Time: 0.65472
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:27] [V] [TRT] Tactic: 5288347012147084929 Time: 1.27936
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:27] [V] [TRT] Tactic: 5921334924264294896 Time: 0.315644
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:27] [V] [TRT] Tactic: 6645123197870846056 Time: 0.66368
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:27] [V] [TRT] Tactic: 7144526460361122478 Time: 0.418944
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:27] [V] [TRT] Tactic: 7852627285308570038 Time: 0.322432
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:27] [V] [TRT] Tactic: -9137461792520977713 Time: 1.29139
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:27] [V] [TRT] Tactic: -8776506421218919509 Time: 0.315392
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:27] [V] [TRT] Tactic: -8262349710178828730 Time: 1.29933
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:27] [V] [TRT] Tactic: -8133971918129952780 Time: 0.733312
[03/27/2022-19:13:27] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:28] [V] [TRT] Tactic: -6092040395344634144 Time: 0.406016
[03/27/2022-19:13:28] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:28] [V] [TRT] Tactic: -4787320710726427159 Time: 0.439428
[03/27/2022-19:13:28] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:28] [V] [TRT] Tactic: -3456450830548107839 Time: 0.37696
[03/27/2022-19:13:28] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:28] [V] [TRT] Tactic: -2318106587342035239 Time: 0.321024
[03/27/2022-19:13:28] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:28] [V] [TRT] Tactic: -1343271414618805657 Time: 0.30822
[03/27/2022-19:13:28] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:28] [V] [TRT] Tactic: -1218658103698133241 Time: 0.710272
[03/27/2022-19:13:28] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:28] [V] [TRT] Tactic: -836875257600482091 Time: 0.694912
[03/27/2022-19:13:28] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:28] [V] [TRT] Tactic: -410470605513481746 Time: 1.25312
[03/27/2022-19:13:28] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.30822
[03/27/2022-19:13:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[03/27/2022-19:13:28] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,4096,16) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:13:28] [V] [TRT] --------------- Timing Runner: Conv_406 + Relu_407 (CaskConvolution)
[03/27/2022-19:13:28] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:28] [V] [TRT] Tactic: -9153228964338181824 Time: 0.723456
[03/27/2022-19:13:28] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:28] [V] [TRT] Tactic: -7394439838318485025 Time: 0.68992
[03/27/2022-19:13:28] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.68992
[03/27/2022-19:13:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[03/27/2022-19:13:28] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:28] [V] [TRT] *************** Autotuning format combination: Float(1048576,65536,256,1) -> Float(1048576,65536,256,1) ***************
[03/27/2022-19:13:28] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,4096,16) -> Float(1048576,1,4096,16) ***************
[03/27/2022-19:13:28] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:28] [V] [TRT] *************** Autotuning format combination: Float(1048576,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:13:28] [V] [TRT] --------------- Timing Runner: Conv_410 (CudaDepthwiseConvolution)
[03/27/2022-19:13:28] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:28] [V] [TRT] --------------- Timing Runner: Conv_410 (FusedConvActConvolution)
[03/27/2022-19:13:28] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:28] [V] [TRT] --------------- Timing Runner: Conv_410 (CudnnConvolution)
[03/27/2022-19:13:28] [V] [TRT] Tactic: 0 Time: 0.756096
[03/27/2022-19:13:28] [V] [TRT] Tactic: 1 Time: 1.03309
[03/27/2022-19:13:28] [V] [TRT] Tactic: 2 Time: 0.944384
[03/27/2022-19:13:28] [V] [TRT] Tactic: 5 Time: 6.16538
[03/27/2022-19:13:28] [V] [TRT] Tactic: 6 Time: 0.524928
[03/27/2022-19:13:28] [V] [TRT] Fastest Tactic: 6 Time: 0.524928
[03/27/2022-19:13:28] [V] [TRT] --------------- Timing Runner: Conv_410 (CaskConvolution)
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:28] [V] [TRT] Tactic: 1062367460111450758 Time: 0.391808
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[03/27/2022-19:13:28] [V] [TRT] Tactic: 1754984623894446479 Time: 0.432
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[03/27/2022-19:13:28] [V] [TRT] Tactic: 3611739942397549984 Time: 1.29741
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:13:28] [V] [TRT] Tactic: 3827454225649558724 Time: 0.299776
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[03/27/2022-19:13:28] [V] [TRT] Tactic: 4337000649858996379 Time: 0.67648
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:28] [V] [TRT] Tactic: 4501471010995462441 Time: 1.27923
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:28] [V] [TRT] Tactic: 5137655947464784826 Time: 0.653568
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:28] [V] [TRT] Tactic: 5288347012147084929 Time: 1.27667
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:13:28] [V] [TRT] Tactic: 5921334924264294896 Time: 0.305664
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:28] [V] [TRT] Tactic: 6645123197870846056 Time: 0.670204
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:28] [V] [TRT] Tactic: 7144526460361122478 Time: 0.414336
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[03/27/2022-19:13:28] [V] [TRT] Tactic: 7852627285308570038 Time: 0.31936
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[03/27/2022-19:13:28] [V] [TRT] Tactic: -9137461792520977713 Time: 1.29344
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:13:28] [V] [TRT] Tactic: -8776506421218919509 Time: 0.299268
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:28] [V] [TRT] Tactic: -8262349710178828730 Time: 1.29549
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[03/27/2022-19:13:28] [V] [TRT] Tactic: -8133971918129952780 Time: 0.705152
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[03/27/2022-19:13:28] [V] [TRT] Tactic: -6092040395344634144 Time: 0.400512
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:28] [V] [TRT] Tactic: -4787320710726427159 Time: 0.43046
[03/27/2022-19:13:28] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:28] [V] [TRT] Tactic: -3456450830548107839 Time: 0.37402
[03/27/2022-19:13:29] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[03/27/2022-19:13:29] [V] [TRT] Tactic: -2318106587342035239 Time: 0.309756
[03/27/2022-19:13:29] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:13:29] [V] [TRT] Tactic: -1343271414618805657 Time: 0.30016
[03/27/2022-19:13:29] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:29] [V] [TRT] Tactic: -1218658103698133241 Time: 0.702208
[03/27/2022-19:13:29] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:29] [V] [TRT] Tactic: -836875257600482091 Time: 0.686336
[03/27/2022-19:13:29] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:29] [V] [TRT] Tactic: -410470605513481746 Time: 1.2503
[03/27/2022-19:13:29] [V] [TRT] Fastest Tactic: -8776506421218919509 Time: 0.299268
[03/27/2022-19:13:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -8776506421218919509
[03/27/2022-19:13:29] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,4096,16) -> Float(196608,1,768,3) ***************
[03/27/2022-19:13:29] [V] [TRT] --------------- Timing Runner: Conv_410 (CaskConvolution)
[03/27/2022-19:13:29] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:29] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:13:29] [V] [TRT] *************** Autotuning format combination: Float(196608,1,768,3) -> Float(196608,1,768,3) ***************
[03/27/2022-19:13:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:29] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1), Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:13:29] [V] [TRT] --------------- Timing Runner: Mul_450 (ElementWise)
[03/27/2022-19:13:29] [V] [TRT] Tactic: 1 Time: 0.027648
[03/27/2022-19:13:29] [V] [TRT] Fastest Tactic: 1 Time: 0.027648
[03/27/2022-19:13:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1
[03/27/2022-19:13:29] [V] [TRT] *************** Autotuning format combination: Float(65536,65536:32,256,1), Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:13:29] [V] [TRT] --------------- Timing Runner: Mul_450 (ElementWise)
[03/27/2022-19:13:29] [V] [TRT] Tactic: 1 Time: 0.23206
[03/27/2022-19:13:29] [V] [TRT] Fastest Tactic: 1 Time: 0.23206
[03/27/2022-19:13:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1
[03/27/2022-19:13:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:29] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1), Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:13:29] [V] [TRT] --------------- Timing Runner: Div_449 (ElementWise)
[03/27/2022-19:13:29] [V] [TRT] Tactic: 1 Time: 0.028544
[03/27/2022-19:13:29] [V] [TRT] Fastest Tactic: 1 Time: 0.028544
[03/27/2022-19:13:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1
[03/27/2022-19:13:29] [V] [TRT] *************** Autotuning format combination: Float(65536,65536:32,256,1), Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:13:29] [V] [TRT] --------------- Timing Runner: Div_449 (ElementWise)
[03/27/2022-19:13:29] [V] [TRT] Tactic: 1 Time: 0.237696
[03/27/2022-19:13:29] [V] [TRT] Fastest Tactic: 1 Time: 0.237696
[03/27/2022-19:13:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ElementWise Tactic: 1
[03/27/2022-19:13:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:29] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:13:29] [V] [TRT] *************** Autotuning format combination: Float(196608,1,768,3) -> Float(196608,1,768,3) ***************
[03/27/2022-19:13:29] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:29] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1), Float(196608,65536,256,1), Float(196608,65536,256,1), Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:13:29] [V] [TRT] --------------- Timing Runner: PWN(Div_452, PWN(Mul_453, Sub_454)) (PointWiseV2)
[03/27/2022-19:13:29] [V] [TRT] Tactic: 0 Time: 0.043904
[03/27/2022-19:13:30] [V] [TRT] Tactic: 1 Time: 0.04352
[03/27/2022-19:13:30] [V] [TRT] Tactic: 2 Time: 0.043508
[03/27/2022-19:13:31] [V] [TRT] Tactic: 3 Time: 0.044544
[03/27/2022-19:13:32] [V] [TRT] Tactic: 4 Time: 0.04352
[03/27/2022-19:13:33] [V] [TRT] Tactic: 5 Time: 0.04416
[03/27/2022-19:13:33] [V] [TRT] Tactic: 6 Time: 0.044404
[03/27/2022-19:13:34] [V] [TRT] Tactic: 7 Time: 0.043772
[03/27/2022-19:13:35] [V] [TRT] Tactic: 8 Time: 0.04442
[03/27/2022-19:13:36] [V] [TRT] Tactic: 9 Time: 0.044924
[03/27/2022-19:13:36] [V] [TRT] Tactic: 28 Time: 0.0439
[03/27/2022-19:13:36] [V] [TRT] Fastest Tactic: 2 Time: 0.043508
[03/27/2022-19:13:36] [V] [TRT] --------------- Timing Runner: PWN(Div_452, PWN(Mul_453, Sub_454)) (PointWise)
[03/27/2022-19:13:36] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:13:36] [V] [TRT] *************** Autotuning format combination: Float(196608,1,768,3), Float(196608,1,768,3), Float(196608,1,768,3), Float(196608,1,768,3) -> Float(196608,1,768,3) ***************
[03/27/2022-19:13:36] [V] [TRT] --------------- Timing Runner: PWN(Div_452, PWN(Mul_453, Sub_454)) (PointWiseV2)
[03/27/2022-19:13:36] [V] [TRT] Tactic: 0 Time: 0.043904
[03/27/2022-19:13:36] [V] [TRT] Tactic: 1 Time: 0.04314
[03/27/2022-19:13:36] [V] [TRT] Tactic: 2 Time: 0.043264
[03/27/2022-19:13:36] [V] [TRT] Tactic: 3 Time: 0.044416
[03/27/2022-19:13:36] [V] [TRT] Tactic: 4 Time: 0.043648
[03/27/2022-19:13:36] [V] [TRT] Tactic: 5 Time: 0.044032
[03/27/2022-19:13:36] [V] [TRT] Tactic: 6 Time: 0.044672
[03/27/2022-19:13:36] [V] [TRT] Tactic: 7 Time: 0.043648
[03/27/2022-19:13:36] [V] [TRT] Tactic: 8 Time: 0.044032
[03/27/2022-19:13:36] [V] [TRT] Tactic: 9 Time: 0.04544
[03/27/2022-19:13:36] [V] [TRT] Tactic: 28 Time: 0.0439
[03/27/2022-19:13:36] [V] [TRT] Fastest Tactic: 1 Time: 0.04314
[03/27/2022-19:13:36] [V] [TRT] --------------- Timing Runner: PWN(Div_452, PWN(Mul_453, Sub_454)) (PointWise)
[03/27/2022-19:13:36] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 1
[03/27/2022-19:13:36] [V] [TRT] *************** Autotuning format combination: Float(65536,65536:32,256,1), Float(65536,65536:32,256,1), Float(65536,65536:32,256,1), Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:13:36] [V] [TRT] --------------- Timing Runner: PWN(Div_452, PWN(Mul_453, Sub_454)) (PointWiseV2)
[03/27/2022-19:13:37] [V] [TRT] Tactic: 24 Time: 0.385408
[03/27/2022-19:13:37] [V] [TRT] Tactic: 25 Time: 0.385408
[03/27/2022-19:13:38] [V] [TRT] Tactic: 26 Time: 0.388352
[03/27/2022-19:13:38] [V] [TRT] Tactic: 27 Time: 0.391168
[03/27/2022-19:13:39] [V] [TRT] Tactic: 31 Time: 0.386432
[03/27/2022-19:13:39] [V] [TRT] Fastest Tactic: 24 Time: 0.385408
[03/27/2022-19:13:39] [V] [TRT] --------------- Timing Runner: PWN(Div_452, PWN(Mul_453, Sub_454)) (PointWise)
[03/27/2022-19:13:39] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[03/27/2022-19:13:39] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:39] [V] [TRT] *************** Autotuning format combination: Float(393216,65536,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:13:39] [V] [TRT] --------------- Timing Runner: Conv_461 + Relu_462 (CudaDepthwiseConvolution)
[03/27/2022-19:13:39] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:39] [V] [TRT] --------------- Timing Runner: Conv_461 + Relu_462 (FusedConvActConvolution)
[03/27/2022-19:13:39] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:39] [V] [TRT] --------------- Timing Runner: Conv_461 + Relu_462 (CudnnConvolution)
[03/27/2022-19:13:40] [V] [TRT] Tactic: 0 Time: 0.62848
[03/27/2022-19:13:40] [V] [TRT] Tactic: 1 Time: 0.533632
[03/27/2022-19:13:40] [V] [TRT] Tactic: 2 Time: 0.707072
[03/27/2022-19:13:40] [V] [TRT] Tactic: 4 Time: 2.71654
[03/27/2022-19:13:40] [V] [TRT] Tactic: 5 Time: 0.887168
[03/27/2022-19:13:40] [V] [TRT] Fastest Tactic: 1 Time: 0.533632
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_461 + Relu_462 (CublasConvolution)
[03/27/2022-19:13:40] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_461 + Relu_462 (CaskConvolution)
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:40] [V] [TRT] Tactic: 1062367460111450758 Time: 0.122368
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:13:40] [V] [TRT] Tactic: 1698681053543049347 Time: 0.128256
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:40] [V] [TRT] Tactic: 4501471010995462441 Time: 0.32382
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:40] [V] [TRT] Tactic: 5137655947464784826 Time: 0.16576
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:40] [V] [TRT] Tactic: 5288347012147084929 Time: 0.338556
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:13:40] [V] [TRT] Tactic: 5326823351883942011 Time: 0.316288
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:13:40] [V] [TRT] Tactic: 5500448035057547314 Time: 0.176256
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:40] [V] [TRT] Tactic: 6645123197870846056 Time: 0.168192
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:40] [V] [TRT] Tactic: 7144526460361122478 Time: 0.13658
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:40] [V] [TRT] Tactic: -8262349710178828730 Time: 0.3392
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:13:40] [V] [TRT] Tactic: -6576203419454146580 Time: 0.118788
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:40] [V] [TRT] Tactic: -4787320710726427159 Time: 0.138108
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:40] [V] [TRT] Tactic: -3456450830548107839 Time: 0.121348
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:40] [V] [TRT] Tactic: -1218658103698133241 Time: 0.18112
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:40] [V] [TRT] Tactic: -836875257600482091 Time: 0.180608
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:40] [V] [TRT] Tactic: -410470605513481746 Time: 0.32128
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:13:40] [V] [TRT] Tactic: -377491875521947884 Time: 0.338304
[03/27/2022-19:13:40] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:13:40] [V] [TRT] Tactic: -37215280111360163 Time: 0.164352
[03/27/2022-19:13:40] [V] [TRT] Fastest Tactic: -6576203419454146580 Time: 0.118788
[03/27/2022-19:13:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6576203419454146580
[03/27/2022-19:13:40] [V] [TRT] *************** Autotuning format combination: Float(393216,1,1536,6) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_461 + Relu_462 (CublasConvolution)
[03/27/2022-19:13:40] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_461 + Relu_462 (CaskConvolution)
[03/27/2022-19:13:40] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:40] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:40] [V] [TRT] *************** Autotuning format combination: Float(2097152,65536,256,1) -> Float(2097152,65536,256,1) ***************
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_463 + Relu_464 (CudaDepthwiseConvolution)
[03/27/2022-19:13:40] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_463 + Relu_464 (FusedConvActConvolution)
[03/27/2022-19:13:40] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_463 + Relu_464 (CudnnConvolution)
[03/27/2022-19:13:40] [V] [TRT] Tactic: 0 Time: 0.658176
[03/27/2022-19:13:40] [V] [TRT] Tactic: 1 Time: 0.605952
[03/27/2022-19:13:40] [V] [TRT] Tactic: 2 Time: 0.843132
[03/27/2022-19:13:40] [V] [TRT] Tactic: 4 Time: 6.64141
[03/27/2022-19:13:40] [V] [TRT] Tactic: 5 Time: 1.21319
[03/27/2022-19:13:40] [V] [TRT] Fastest Tactic: 1 Time: 0.605952
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_463 + Relu_464 (CublasConvolution)
[03/27/2022-19:13:40] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_463 + Relu_464 (CaskConvolution)
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:40] [V] [TRT] Tactic: 1062367460111450758 Time: 0.193024
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:13:40] [V] [TRT] Tactic: 1698681053543049347 Time: 0.19392
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:40] [V] [TRT] Tactic: 4501471010995462441 Time: 0.490368
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:40] [V] [TRT] Tactic: 5137655947464784826 Time: 0.257792
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:40] [V] [TRT] Tactic: 5288347012147084929 Time: 0.504192
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:13:40] [V] [TRT] Tactic: 5326823351883942011 Time: 0.479228
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:13:40] [V] [TRT] Tactic: 5500448035057547314 Time: 0.273792
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:40] [V] [TRT] Tactic: 6645123197870846056 Time: 0.2624
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:40] [V] [TRT] Tactic: 7144526460361122478 Time: 0.204928
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:40] [V] [TRT] Tactic: -8262349710178828730 Time: 0.50944
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:13:40] [V] [TRT] Tactic: -6576203419454146580 Time: 0.190464
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:40] [V] [TRT] Tactic: -4787320710726427159 Time: 0.2048
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:40] [V] [TRT] Tactic: -3456450830548107839 Time: 0.191872
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:40] [V] [TRT] Tactic: -1218658103698133241 Time: 0.283904
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:40] [V] [TRT] Tactic: -836875257600482091 Time: 0.276608
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:40] [V] [TRT] Tactic: -410470605513481746 Time: 0.485504
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:13:40] [V] [TRT] Tactic: -377491875521947884 Time: 0.504704
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:13:40] [V] [TRT] Tactic: -37215280111360163 Time: 0.256256
[03/27/2022-19:13:40] [V] [TRT] Fastest Tactic: -6576203419454146580 Time: 0.190464
[03/27/2022-19:13:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6576203419454146580
[03/27/2022-19:13:40] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,8192,32) -> Float(2097152,1,8192,32) ***************
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_463 + Relu_464 (CublasConvolution)
[03/27/2022-19:13:40] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_463 + Relu_464 (CaskConvolution)
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:13:40] [V] [TRT] Tactic: 3886731678879822788 Time: 0.319104
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:13:40] [V] [TRT] Tactic: 6629944304117643200 Time: 0.270208
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:13:40] [V] [TRT] Tactic: -9153228964338181824 Time: 0.274944
[03/27/2022-19:13:40] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:13:40] [V] [TRT] Tactic: -7394439838318485025 Time: 0.319996
[03/27/2022-19:13:40] [V] [TRT] Fastest Tactic: 6629944304117643200 Time: 0.270208
[03/27/2022-19:13:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6629944304117643200
[03/27/2022-19:13:40] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:40] [V] [TRT] *************** Autotuning format combination: Float(2097152,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_465 (CudaDepthwiseConvolution)
[03/27/2022-19:13:40] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_465 (FusedConvActConvolution)
[03/27/2022-19:13:40] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:40] [V] [TRT] --------------- Timing Runner: Conv_465 (CudnnConvolution)
[03/27/2022-19:13:40] [V] [TRT] Tactic: 0 Time: 0.203776
[03/27/2022-19:13:41] [V] [TRT] Tactic: 1 Time: 0.099456
[03/27/2022-19:13:41] [V] [TRT] Tactic: 2 Time: 0.390272
[03/27/2022-19:13:41] [V] [TRT] Tactic: 4 Time: 2.54387
[03/27/2022-19:13:41] [V] [TRT] Tactic: 5 Time: 0.562688
[03/27/2022-19:13:41] [V] [TRT] Fastest Tactic: 1 Time: 0.099456
[03/27/2022-19:13:41] [V] [TRT] --------------- Timing Runner: Conv_465 (CublasConvolution)
[03/27/2022-19:13:41] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:41] [V] [TRT] --------------- Timing Runner: Conv_465 (CaskConvolution)
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:41] [V] [TRT] Tactic: 1062367460111450758 Time: 0.156544
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:13:41] [V] [TRT] Tactic: 1698681053543049347 Time: 0.150912
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:41] [V] [TRT] Tactic: 4501471010995462441 Time: 0.486144
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:41] [V] [TRT] Tactic: 5137655947464784826 Time: 0.251648
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:41] [V] [TRT] Tactic: 5288347012147084929 Time: 0.495868
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:13:41] [V] [TRT] Tactic: 5326823351883942011 Time: 0.472824
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:13:41] [V] [TRT] Tactic: 5500448035057547314 Time: 0.261628
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:41] [V] [TRT] Tactic: 6645123197870846056 Time: 0.257152
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:41] [V] [TRT] Tactic: 7144526460361122478 Time: 0.170368
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:41] [V] [TRT] Tactic: -8262349710178828730 Time: 0.501888
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:13:41] [V] [TRT] Tactic: -6576203419454146580 Time: 0.14746
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:41] [V] [TRT] Tactic: -4787320710726427159 Time: 0.17216
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:41] [V] [TRT] Tactic: -3456450830548107839 Time: 0.151292
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:41] [V] [TRT] Tactic: -1218658103698133241 Time: 0.272256
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:41] [V] [TRT] Tactic: -836875257600482091 Time: 0.268928
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:41] [V] [TRT] Tactic: -410470605513481746 Time: 0.479104
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:13:41] [V] [TRT] Tactic: -377491875521947884 Time: 0.488192
[03/27/2022-19:13:41] [V] [TRT] Conv_465 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:13:41] [V] [TRT] Tactic: -37215280111360163 Time: 0.250624
[03/27/2022-19:13:41] [V] [TRT] Fastest Tactic: -6576203419454146580 Time: 0.14746
[03/27/2022-19:13:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/27/2022-19:13:41] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,8192,32) -> Float(196608,1,768,3) ***************
[03/27/2022-19:13:41] [V] [TRT] --------------- Timing Runner: Conv_465 (CublasConvolution)
[03/27/2022-19:13:41] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:41] [V] [TRT] --------------- Timing Runner: Conv_465 (CaskConvolution)
[03/27/2022-19:13:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:41] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:41] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1), Float(196608,65536,256,1), Float(196608,65536,256,1) -> Float(196608,65536,256,1) ***************
[03/27/2022-19:13:41] [V] [TRT] --------------- Timing Runner: PWN(Mul_466, Sub_467) (PointWiseV2)
[03/27/2022-19:13:42] [V] [TRT] Tactic: 0 Time: 0.03546
[03/27/2022-19:13:42] [V] [TRT] Tactic: 1 Time: 0.0352
[03/27/2022-19:13:42] [V] [TRT] Tactic: 2 Time: 0.034816
[03/27/2022-19:13:43] [V] [TRT] Tactic: 3 Time: 0.03532
[03/27/2022-19:13:43] [V] [TRT] Tactic: 4 Time: 0.0352
[03/27/2022-19:13:44] [V] [TRT] Tactic: 5 Time: 0.034944
[03/27/2022-19:13:44] [V] [TRT] Tactic: 6 Time: 0.034944
[03/27/2022-19:13:44] [V] [TRT] Tactic: 7 Time: 0.035328
[03/27/2022-19:13:45] [V] [TRT] Tactic: 8 Time: 0.035456
[03/27/2022-19:13:45] [V] [TRT] Tactic: 9 Time: 0.034944
[03/27/2022-19:13:45] [V] [TRT] Tactic: 28 Time: 0.035324
[03/27/2022-19:13:45] [V] [TRT] Fastest Tactic: 2 Time: 0.034816
[03/27/2022-19:13:45] [V] [TRT] --------------- Timing Runner: PWN(Mul_466, Sub_467) (PointWise)
[03/27/2022-19:13:45] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:13:45] [V] [TRT] *************** Autotuning format combination: Float(196608,1,768,3), Float(196608,1,768,3), Float(196608,1,768,3) -> Float(196608,1,768,3) ***************
[03/27/2022-19:13:45] [V] [TRT] --------------- Timing Runner: PWN(Mul_466, Sub_467) (PointWiseV2)
[03/27/2022-19:13:46] [V] [TRT] Tactic: 0 Time: 0.035968
[03/27/2022-19:13:46] [V] [TRT] Tactic: 1 Time: 0.035072
[03/27/2022-19:13:46] [V] [TRT] Tactic: 2 Time: 0.034696
[03/27/2022-19:13:46] [V] [TRT] Tactic: 3 Time: 0.0352
[03/27/2022-19:13:46] [V] [TRT] Tactic: 4 Time: 0.03532
[03/27/2022-19:13:46] [V] [TRT] Tactic: 5 Time: 0.035324
[03/27/2022-19:13:46] [V] [TRT] Tactic: 6 Time: 0.034944
[03/27/2022-19:13:46] [V] [TRT] Tactic: 7 Time: 0.03584
[03/27/2022-19:13:46] [V] [TRT] Tactic: 8 Time: 0.034944
[03/27/2022-19:13:46] [V] [TRT] Tactic: 9 Time: 0.035192
[03/27/2022-19:13:46] [V] [TRT] Tactic: 28 Time: 0.034816
[03/27/2022-19:13:46] [V] [TRT] Fastest Tactic: 2 Time: 0.034696
[03/27/2022-19:13:46] [V] [TRT] --------------- Timing Runner: PWN(Mul_466, Sub_467) (PointWise)
[03/27/2022-19:13:46] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[03/27/2022-19:13:46] [V] [TRT] *************** Autotuning format combination: Float(65536,65536:32,256,1), Float(65536,65536:32,256,1), Float(65536,65536:32,256,1) -> Float(65536,65536:32,256,1) ***************
[03/27/2022-19:13:46] [V] [TRT] --------------- Timing Runner: PWN(Mul_466, Sub_467) (PointWiseV2)
[03/27/2022-19:13:47] [V] [TRT] Tactic: 24 Time: 0.308096
[03/27/2022-19:13:47] [V] [TRT] Tactic: 25 Time: 0.529536
[03/27/2022-19:13:48] [V] [TRT] Tactic: 26 Time: 0.5344
[03/27/2022-19:13:48] [V] [TRT] Tactic: 27 Time: 0.535808
[03/27/2022-19:13:49] [V] [TRT] Tactic: 31 Time: 0.309248
[03/27/2022-19:13:49] [V] [TRT] Fastest Tactic: 24 Time: 0.308096
[03/27/2022-19:13:49] [V] [TRT] --------------- Timing Runner: PWN(Mul_466, Sub_467) (PointWise)
[03/27/2022-19:13:49] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[03/27/2022-19:13:49] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:49] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1) -> Float(2764800,921600,720,1) ***************
[03/27/2022-19:13:49] [V] [TRT] --------------- Timing Runner: Resize_476 (Resize)
[03/27/2022-19:13:49] [V] [TRT] Tactic: 1 Time: 0.26944
[03/27/2022-19:13:49] [V] [TRT] Fastest Tactic: 1 Time: 0.26944
[03/27/2022-19:13:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 1
[03/27/2022-19:13:49] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:49] [V] [TRT] *************** Autotuning format combination: Float(196608,65536,256,1) -> Float(2764800,921600,720,1) ***************
[03/27/2022-19:13:49] [V] [TRT] --------------- Timing Runner: Resize_485 (Resize)
[03/27/2022-19:13:49] [V] [TRT] Tactic: 1 Time: 0.269312
[03/27/2022-19:13:49] [V] [TRT] Fastest Tactic: 1 Time: 0.269312
[03/27/2022-19:13:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 1
[03/27/2022-19:13:49] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:49] [V] [TRT] *************** Autotuning format combination: Float(2764800,921600,720,1), Float(2764800,921600,720,1), Float(2764800,921600,720,1) -> Float(2764800,921600,720,1) ***************
[03/27/2022-19:13:49] [V] [TRT] --------------- Timing Runner: PWN(Mul_486, Add_487) (PointWiseV2)
[03/27/2022-19:13:49] [V] [TRT] Tactic: 0 Time: 0.40282
[03/27/2022-19:13:50] [V] [TRT] Tactic: 1 Time: 0.404608
[03/27/2022-19:13:50] [V] [TRT] Tactic: 2 Time: 0.40384
[03/27/2022-19:13:50] [V] [TRT] Tactic: 3 Time: 0.404992
[03/27/2022-19:13:51] [V] [TRT] Tactic: 4 Time: 0.405244
[03/27/2022-19:13:51] [V] [TRT] Tactic: 5 Time: 0.404736
[03/27/2022-19:13:52] [V] [TRT] Tactic: 6 Time: 0.407424
[03/27/2022-19:13:52] [V] [TRT] Tactic: 7 Time: 0.405504
[03/27/2022-19:13:53] [V] [TRT] Tactic: 8 Time: 0.404992
[03/27/2022-19:13:54] [V] [TRT] Tactic: 9 Time: 0.406148
[03/27/2022-19:13:54] [V] [TRT] Tactic: 28 Time: 0.402308
[03/27/2022-19:13:54] [V] [TRT] Fastest Tactic: 28 Time: 0.402308
[03/27/2022-19:13:54] [V] [TRT] --------------- Timing Runner: PWN(Mul_486, Add_487) (PointWise)
[03/27/2022-19:13:54] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:13:54] [V] [TRT] *************** Autotuning format combination: Float(2764800,1,2160,3), Float(2764800,1,2160,3), Float(2764800,1,2160,3) -> Float(2764800,1,2160,3) ***************
[03/27/2022-19:13:54] [V] [TRT] --------------- Timing Runner: PWN(Mul_486, Add_487) (PointWiseV2)
[03/27/2022-19:13:54] [V] [TRT] Tactic: 0 Time: 0.40384
[03/27/2022-19:13:54] [V] [TRT] Tactic: 1 Time: 0.404736
[03/27/2022-19:13:54] [V] [TRT] Tactic: 2 Time: 0.403712
[03/27/2022-19:13:54] [V] [TRT] Tactic: 3 Time: 0.405504
[03/27/2022-19:13:54] [V] [TRT] Tactic: 4 Time: 0.404996
[03/27/2022-19:13:54] [V] [TRT] Tactic: 5 Time: 0.40512
[03/27/2022-19:13:55] [V] [TRT] Tactic: 6 Time: 0.407424
[03/27/2022-19:13:55] [V] [TRT] Tactic: 7 Time: 0.405508
[03/27/2022-19:13:55] [V] [TRT] Tactic: 8 Time: 0.405632
[03/27/2022-19:13:55] [V] [TRT] Tactic: 9 Time: 0.405636
[03/27/2022-19:13:55] [V] [TRT] Tactic: 28 Time: 0.40256
[03/27/2022-19:13:55] [V] [TRT] Fastest Tactic: 28 Time: 0.40256
[03/27/2022-19:13:55] [V] [TRT] --------------- Timing Runner: PWN(Mul_486, Add_487) (PointWise)
[03/27/2022-19:13:55] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[03/27/2022-19:13:55] [V] [TRT] *************** Autotuning format combination: Float(921600,921600:32,720,1), Float(921600,921600:32,720,1), Float(921600,921600:32,720,1) -> Float(921600,921600:32,720,1) ***************
[03/27/2022-19:13:55] [V] [TRT] --------------- Timing Runner: PWN(Mul_486, Add_487) (PointWiseV2)
[03/27/2022-19:13:55] [V] [TRT] Tactic: 24 Time: 4.21926
[03/27/2022-19:13:56] [V] [TRT] Tactic: 25 Time: 7.32045
[03/27/2022-19:13:57] [V] [TRT] Tactic: 26 Time: 7.38073
[03/27/2022-19:13:58] [V] [TRT] Tactic: 27 Time: 7.42976
[03/27/2022-19:13:58] [V] [TRT] Tactic: 31 Time: 4.25011
[03/27/2022-19:13:58] [V] [TRT] Fastest Tactic: 24 Time: 4.21926
[03/27/2022-19:13:58] [V] [TRT] --------------- Timing Runner: PWN(Mul_486, Add_487) (PointWise)
[03/27/2022-19:13:58] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:13:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[03/27/2022-19:13:58] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:58] [V] [TRT] *************** Autotuning format combination: Float(2764800,921600,720,1) -> Float(921600,921600,720,1) ***************
[03/27/2022-19:13:58] [V] [TRT] --------------- Timing Runner: Conv_488 (CudaDepthwiseConvolution)
[03/27/2022-19:13:58] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:58] [V] [TRT] --------------- Timing Runner: Conv_488 (FusedConvActConvolution)
[03/27/2022-19:13:58] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:58] [V] [TRT] --------------- Timing Runner: Conv_488 (CudnnConvolution)
[03/27/2022-19:13:58] [V] [TRT] Tactic: 0 Time: 1.33913
[03/27/2022-19:13:58] [V] [TRT] Tactic: 1 Time: 0.401024
[03/27/2022-19:13:58] [V] [TRT] Tactic: 2 Time: 1.30676
[03/27/2022-19:13:58] [V] [TRT] Tactic: 5 Time: 1.75603
[03/27/2022-19:13:58] [V] [TRT] Fastest Tactic: 1 Time: 0.401024
[03/27/2022-19:13:58] [V] [TRT] --------------- Timing Runner: Conv_488 (CublasConvolution)
[03/27/2022-19:13:58] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:58] [V] [TRT] --------------- Timing Runner: Conv_488 (CaskConvolution)
[03/27/2022-19:13:58] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[03/27/2022-19:13:58] [V] [TRT] Tactic: 1062367460111450758 Time: 1.16787
[03/27/2022-19:13:58] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:13:58] [V] [TRT] Tactic: 1698681053543049347 Time: 1.05126
[03/27/2022-19:13:58] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:13:58] [V] [TRT] Tactic: 4501471010995462441 Time: 4.2935
[03/27/2022-19:13:58] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:13:59] [V] [TRT] Tactic: 5137655947464784826 Time: 2.11098
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[03/27/2022-19:13:59] [V] [TRT] Tactic: 5288347012147084929 Time: 4.50458
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[03/27/2022-19:13:59] [V] [TRT] Tactic: 5326823351883942011 Time: 4.19405
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[03/27/2022-19:13:59] [V] [TRT] Tactic: 5500448035057547314 Time: 1.9328
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:13:59] [V] [TRT] Tactic: 6645123197870846056 Time: 2.16026
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[03/27/2022-19:13:59] [V] [TRT] Tactic: 7144526460361122478 Time: 1.16186
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[03/27/2022-19:13:59] [V] [TRT] Tactic: -8262349710178828730 Time: 4.4905
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:13:59] [V] [TRT] Tactic: -6576203419454146580 Time: 1.10758
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[03/27/2022-19:13:59] [V] [TRT] Tactic: -4787320710726427159 Time: 1.17773
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:13:59] [V] [TRT] Tactic: -3456450830548107839 Time: 1.12858
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[03/27/2022-19:13:59] [V] [TRT] Tactic: -1218658103698133241 Time: 1.93946
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[03/27/2022-19:13:59] [V] [TRT] Tactic: -836875257600482091 Time: 1.94457
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:13:59] [V] [TRT] Tactic: -410470605513481746 Time: 4.26048
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:13:59] [V] [TRT] Tactic: -377491875521947884 Time: 4.47373
[03/27/2022-19:13:59] [V] [TRT] Conv_488 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:13:59] [V] [TRT] Tactic: -37215280111360163 Time: 2.09011
[03/27/2022-19:13:59] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 1.05126
[03/27/2022-19:13:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/27/2022-19:13:59] [V] [TRT] *************** Autotuning format combination: Float(2764800,1,2160,3) -> Float(921600,1,720,1) ***************
[03/27/2022-19:13:59] [V] [TRT] --------------- Timing Runner: Conv_488 (CublasConvolution)
[03/27/2022-19:13:59] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:59] [V] [TRT] --------------- Timing Runner: Conv_488 (CaskConvolution)
[03/27/2022-19:13:59] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/27/2022-19:13:59] [V] [TRT] =============== Computing costs for 
[03/27/2022-19:13:59] [V] [TRT] *************** Autotuning format combination: Float(921600,921600,720,1) -> Float(921600,921600,720,1) ***************
[03/27/2022-19:13:59] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_490) (PointWiseV2)
[03/27/2022-19:14:00] [V] [TRT] Tactic: 0 Time: 0.089344
[03/27/2022-19:14:01] [V] [TRT] Tactic: 1 Time: 0.076032
[03/27/2022-19:14:01] [V] [TRT] Tactic: 2 Time: 0.074348
[03/27/2022-19:14:02] [V] [TRT] Tactic: 3 Time: 0.075772
[03/27/2022-19:14:02] [V] [TRT] Tactic: 4 Time: 0.074632
[03/27/2022-19:14:03] [V] [TRT] Tactic: 5 Time: 0.074496
[03/27/2022-19:14:04] [V] [TRT] Tactic: 6 Time: 0.077308
[03/27/2022-19:14:04] [V] [TRT] Tactic: 7 Time: 0.075388
[03/27/2022-19:14:05] [V] [TRT] Tactic: 8 Time: 0.074112
[03/27/2022-19:14:05] [V] [TRT] Tactic: 9 Time: 0.074752
[03/27/2022-19:14:06] [V] [TRT] Tactic: 28 Time: 0.088064
[03/27/2022-19:14:06] [V] [TRT] Fastest Tactic: 8 Time: 0.074112
[03/27/2022-19:14:06] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_490) (PointWise)
[03/27/2022-19:14:06] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[03/27/2022-19:14:06] [V] [TRT] *************** Autotuning format combination: Float(921600,1,720,1) -> Float(921600,1,720,1) ***************
[03/27/2022-19:14:06] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_490) (PointWiseV2)
[03/27/2022-19:14:06] [V] [TRT] Tactic: 0 Time: 0.089856
[03/27/2022-19:14:06] [V] [TRT] Tactic: 1 Time: 0.07616
[03/27/2022-19:14:06] [V] [TRT] Tactic: 2 Time: 0.074372
[03/27/2022-19:14:06] [V] [TRT] Tactic: 3 Time: 0.07616
[03/27/2022-19:14:06] [V] [TRT] Tactic: 4 Time: 0.07488
[03/27/2022-19:14:06] [V] [TRT] Tactic: 5 Time: 0.074624
[03/27/2022-19:14:06] [V] [TRT] Tactic: 6 Time: 0.077696
[03/27/2022-19:14:06] [V] [TRT] Tactic: 7 Time: 0.075012
[03/27/2022-19:14:06] [V] [TRT] Tactic: 8 Time: 0.074368
[03/27/2022-19:14:06] [V] [TRT] Tactic: 9 Time: 0.074356
[03/27/2022-19:14:06] [V] [TRT] Tactic: 28 Time: 0.08768
[03/27/2022-19:14:06] [V] [TRT] Fastest Tactic: 9 Time: 0.074356
[03/27/2022-19:14:06] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_490) (PointWise)
[03/27/2022-19:14:06] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[03/27/2022-19:14:06] [V] [TRT] *************** Autotuning format combination: Float(921600,921600:32,720,1) -> Float(921600,921600:32,720,1) ***************
[03/27/2022-19:14:06] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_490) (PointWiseV2)
[03/27/2022-19:14:07] [V] [TRT] Tactic: 24 Time: 2.22682
[03/27/2022-19:14:08] [V] [TRT] Tactic: 25 Time: 2.1651
[03/27/2022-19:14:08] [V] [TRT] Tactic: 26 Time: 2.17331
[03/27/2022-19:14:09] [V] [TRT] Tactic: 27 Time: 2.17485
[03/27/2022-19:14:09] [V] [TRT] Tactic: 31 Time: 2.16525
[03/27/2022-19:14:09] [V] [TRT] Fastest Tactic: 25 Time: 2.1651
[03/27/2022-19:14:09] [V] [TRT] --------------- Timing Runner: PWN(Sigmoid_490) (PointWise)
[03/27/2022-19:14:09] [V] [TRT] PointWise has no valid tactics for this config, skipping
[03/27/2022-19:14:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_251), Mul_252) (1045) from Float(720,1,1,1) to Float(720,1,720,720)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_251), Mul_252) (1040) from Float(184320,256,16,1) to Float(184320,1,11520,720)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_254 (1503) from Float(53248,1,3328,208) to Float(53248,256,16,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_262), Mul_263) (1059) from Float(52,1,1,1) to Float(52,1,52,52)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_264 (1061) from Float(52,1,52,52) to Float(52,1,1,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_265), Mul_266) (1062) from Float(1248,1,1,1) to Float(1248,1,1248,1248)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_265), Mul_266) (1057) from Float(319488,256,16,1) to Float(319488,1,19968,1248)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_269 (1067) from Float(53248,1,3328,208) to Float(53248,256,16,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_277), Mul_278) (1077) from Float(52,1,1,1) to Float(52,1,52,52)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_279 (1079) from Float(52,1,52,52) to Float(52,1,1,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_280), Mul_281) (1080) from Float(1248,1,1,1) to Float(1248,1,1248,1248)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_280), Mul_281) (1075) from Float(319488,256,16,1) to Float(319488,1,19968,1248)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_284 (1085) from Float(53248,1,3328,208) to Float(53248,256,16,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_292), Mul_293) (1095) from Float(52,1,1,1) to Float(52,1,52,52)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_294 (1097) from Float(52,1,52,52) to Float(52,1,1,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_295), Mul_296) (1098) from Float(1248,1,1,1) to Float(1248,1,1248,1248)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_295), Mul_296) (1093) from Float(319488,256,16,1) to Float(319488,1,19968,1248)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_299 (1103) from Float(53248,1,3328,208) to Float(53248,256,16,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_307), Mul_308) (1113) from Float(52,1,1,1) to Float(52,1,52,52)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_309 (1115) from Float(52,1,52,52) to Float(52,1,1,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_310), Mul_311) (1116) from Float(1248,1,1,1) to Float(1248,1,1248,1248)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_310), Mul_311) (1111) from Float(319488,256,16,1) to Float(319488,1,19968,1248)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_314 (1121) from Float(53248,1,3328,208) to Float(53248,256,16,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_322), Mul_323) (1131) from Float(52,1,1,1) to Float(52,1,52,52)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_324 (1133) from Float(52,1,52,52) to Float(52,1,1,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_336), Mul_337) (1148) from Float(88,1,1,1) to Float(88,1,88,88)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_338 (1150) from Float(88,1,88,88) to Float(88,1,1,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_343 || Conv_344 || Conv_348 || Conv_352 (1156) from Float(90112,256,16,1) to Float(90112,1,5632,352)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_347 (1572) from Float(360448,1,22528,1408) to Float(360448,256,16,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_351 (1581) from Float(90112,1,5632,352) to Float(90112,256,16,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_355 (1593) from Float(90112,1,5632,352) to Float(90112,256,16,1)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_361 + Relu_362 (1189) from Float(90112,256,16,1) to Float(90112,1,5632,352)
[03/27/2022-19:14:09] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_365 + Relu_366 (1198) from Float(180224,1,11264,704) to Float(180224,256,16,1)
[03/27/2022-19:14:09] [V] [TRT] Formats and tactics selection completed in 266.299 seconds.
[03/27/2022-19:14:09] [V] [TRT] After reformat layers: 331 layers
[03/27/2022-19:14:09] [V] [TRT] Pre-optimized block assignment.
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 33554432
[03/27/2022-19:14:09] [V] [TRT] Block size 33554432
[03/27/2022-19:14:09] [V] [TRT] Block size 33554432
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 33554432
[03/27/2022-19:14:09] [V] [TRT] Block size 16777216
[03/27/2022-19:14:09] [V] [TRT] Block size 16777216
[03/27/2022-19:14:09] [V] [TRT] Block size 16777216
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 16777216
[03/27/2022-19:14:09] [V] [TRT] Block size 16777216
[03/27/2022-19:14:09] [V] [TRT] Block size 100663296
[03/27/2022-19:14:09] [V] [TRT] Block size 100663296
[03/27/2022-19:14:09] [V] [TRT] Block size 25165824
[03/27/2022-19:14:09] [V] [TRT] Block size 25165824
[03/27/2022-19:14:09] [V] [TRT] Block size 1536
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 1536
[03/27/2022-19:14:09] [V] [TRT] Block size 25165824
[03/27/2022-19:14:09] [V] [TRT] Block size 6291456
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 2560
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 2560
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 6291456
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 2560
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 2560
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 6291456
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 37748736
[03/27/2022-19:14:09] [V] [TRT] Block size 9437184
[03/27/2022-19:14:09] [V] [TRT] Block size 9437184
[03/27/2022-19:14:09] [V] [TRT] Block size 2560
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 2560
[03/27/2022-19:14:09] [V] [TRT] Block size 9437184
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 4608
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 4608
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 4608
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 4608
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 18874368
[03/27/2022-19:14:09] [V] [TRT] Block size 4718592
[03/27/2022-19:14:09] [V] [TRT] Block size 4718592
[03/27/2022-19:14:09] [V] [TRT] Block size 4608
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 4608
[03/27/2022-19:14:09] [V] [TRT] Block size 4718592
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8704
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 8704
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8704
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 8704
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8704
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 8704
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8704
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 8704
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 1966080
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11776
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 11776
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 1966080
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11776
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 11776
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 1966080
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11776
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 11776
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 1966080
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 11796480
[03/27/2022-19:14:09] [V] [TRT] Block size 2949120
[03/27/2022-19:14:09] [V] [TRT] Block size 2949120
[03/27/2022-19:14:09] [V] [TRT] Block size 11776
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 512
[03/27/2022-19:14:09] [V] [TRT] Block size 11776
[03/27/2022-19:14:09] [V] [TRT] Block size 2949120
[03/27/2022-19:14:09] [V] [TRT] Block size 851968
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 19968
[03/27/2022-19:14:09] [V] [TRT] Block size 1024
[03/27/2022-19:14:09] [V] [TRT] Block size 1024
[03/27/2022-19:14:09] [V] [TRT] Block size 19968
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 851968
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 19968
[03/27/2022-19:14:09] [V] [TRT] Block size 1024
[03/27/2022-19:14:09] [V] [TRT] Block size 1024
[03/27/2022-19:14:09] [V] [TRT] Block size 19968
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 851968
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 19968
[03/27/2022-19:14:09] [V] [TRT] Block size 1024
[03/27/2022-19:14:09] [V] [TRT] Block size 1024
[03/27/2022-19:14:09] [V] [TRT] Block size 19968
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 851968
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 19968
[03/27/2022-19:14:09] [V] [TRT] Block size 1024
[03/27/2022-19:14:09] [V] [TRT] Block size 1024
[03/27/2022-19:14:09] [V] [TRT] Block size 19968
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 851968
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 19968
[03/27/2022-19:14:09] [V] [TRT] Block size 1024
[03/27/2022-19:14:09] [V] [TRT] Block size 1024
[03/27/2022-19:14:09] [V] [TRT] Block size 19968
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 33792
[03/27/2022-19:14:09] [V] [TRT] Block size 1536
[03/27/2022-19:14:09] [V] [TRT] Block size 1536
[03/27/2022-19:14:09] [V] [TRT] Block size 33792
[03/27/2022-19:14:09] [V] [TRT] Block size 8650752
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 5767168
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 2883584
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 491520
[03/27/2022-19:14:09] [V] [TRT] Block size 1966080
[03/27/2022-19:14:09] [V] [TRT] Block size 3932160
[03/27/2022-19:14:09] [V] [TRT] Block size 1966080
[03/27/2022-19:14:09] [V] [TRT] Block size 1966080
[03/27/2022-19:14:09] [V] [TRT] Block size 786432
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 6291456
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 1572864
[03/27/2022-19:14:09] [V] [TRT] Block size 6291456
[03/27/2022-19:14:09] [V] [TRT] Block size 12582912
[03/27/2022-19:14:09] [V] [TRT] Block size 6291456
[03/27/2022-19:14:09] [V] [TRT] Block size 6291456
[03/27/2022-19:14:09] [V] [TRT] Block size 4194304
[03/27/2022-19:14:09] [V] [TRT] Block size 16777216
[03/27/2022-19:14:09] [V] [TRT] Block size 33554432
[03/27/2022-19:14:09] [V] [TRT] Block size 16777216
[03/27/2022-19:14:09] [V] [TRT] Block size 16777216
[03/27/2022-19:14:09] [V] [TRT] Block size 16777216
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 6291456
[03/27/2022-19:14:09] [V] [TRT] Block size 33554432
[03/27/2022-19:14:09] [V] [TRT] Block size 33554432
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 3145728
[03/27/2022-19:14:09] [V] [TRT] Block size 44236800
[03/27/2022-19:14:09] [V] [TRT] Block size 44236800
[03/27/2022-19:14:09] [V] [TRT] Block size 44236800
[03/27/2022-19:14:09] [V] [TRT] Block size 14745600
[03/27/2022-19:14:09] [V] [TRT] Block size 5767168
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 2949120
[03/27/2022-19:14:09] [V] [TRT] Block size 851968
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 851968
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 851968
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 851968
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 5111808
[03/27/2022-19:14:09] [V] [TRT] Block size 851968
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 4
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 1441792
[03/27/2022-19:14:09] [V] [TRT] Block size 12785418240
[03/27/2022-19:14:09] [V] [TRT] Total Activation Memory: 15106132036
[03/27/2022-19:14:09] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[03/27/2022-19:14:09] [V] [TRT] Conv_9 + Relu_10 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:14:09] [V] [TRT] Conv_446 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:14:09] [V] [TRT] Conv_456 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:14:09] [V] [TRT] ReduceMean_14 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:14:09] [V] [TRT] Conv_445 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:14:10] [V] [TRT] Conv_21 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:14:10] [V] [TRT] Conv_32 + Add_33 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:14:10] [V] [TRT] Conv_34 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:14:10] [V] [TRT] Conv_47 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:14:10] [V] [TRT] Conv_48 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_61 + Add_62 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:14:10] [V] [TRT] Conv_63 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_76 + Add_77 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:14:10] [V] [TRT] Conv_78 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_91 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_92 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:14:10] [V] [TRT] Conv_105 + Add_106 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:14:10] [V] [TRT] Conv_107 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:14:10] [V] [TRT] Conv_120 + Add_121 Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[03/27/2022-19:14:10] [V] [TRT] Conv_122 Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[03/27/2022-19:14:10] [V] [TRT] Conv_135 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:14:10] [V] [TRT] Conv_136 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_149 + Add_150 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:14:10] [V] [TRT] Conv_151 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_164 + Add_165 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:14:10] [V] [TRT] Conv_166 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_179 + Add_180 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:14:10] [V] [TRT] Conv_181 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_194 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:14:10] [V] [TRT] Conv_195 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_208 + Add_209 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:14:10] [V] [TRT] Conv_210 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_223 + Add_224 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:14:10] [V] [TRT] Conv_225 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_238 + Add_239 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[03/27/2022-19:14:10] [V] [TRT] Conv_240 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_253 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:14:10] [V] [TRT] Conv_254 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:14:10] [V] [TRT] ReduceMean_260 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:14:10] [V] [TRT] Conv_267 + Add_268 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:14:10] [V] [TRT] Conv_269 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:14:10] [V] [TRT] ReduceMean_275 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:14:10] [V] [TRT] Conv_282 + Add_283 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:14:10] [V] [TRT] Conv_284 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:14:10] [V] [TRT] ReduceMean_290 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:14:10] [V] [TRT] Conv_297 + Add_298 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:14:10] [V] [TRT] Conv_299 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:14:10] [V] [TRT] ReduceMean_305 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:14:10] [V] [TRT] Conv_312 + Add_313 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[03/27/2022-19:14:10] [V] [TRT] Conv_314 Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[03/27/2022-19:14:10] [V] [TRT] ReduceMean_320 Set Tactic Name: sm50_xmma_pooling_fw_4d_FP32FP32NCHW_Average Tactic: 6119644359078410246
[03/27/2022-19:14:10] [V] [TRT] Conv_327 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:14:10] [V] [TRT] Conv_328 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_341 + Add_342 Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[03/27/2022-19:14:10] [V] [TRT] Conv_343 || Conv_344 || Conv_348 || Conv_352 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[03/27/2022-19:14:10] [V] [TRT] Conv_345 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:14:10] [V] [TRT] Conv_349 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:14:10] [V] [TRT] Conv_353 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:14:10] [V] [TRT] Conv_346 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:14:10] [V] [TRT] Conv_350 Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[03/27/2022-19:14:10] [V] [TRT] Conv_354 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:14:10] [V] [TRT] Conv_347 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:14:10] [V] [TRT] Conv_351 Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[03/27/2022-19:14:10] [V] [TRT] Conv_357 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[03/27/2022-19:14:10] [V] [TRT] Conv_358 + Add_359 + Relu_360 Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[03/27/2022-19:14:10] [V] [TRT] Conv_361 + Relu_362 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:14:10] [V] [TRT] Conv_363 + Relu_364 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:14:10] [V] [TRT] Conv_365 + Relu_366 Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[03/27/2022-19:14:10] [V] [TRT] Conv_368 + Relu_369 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:14:10] [V] [TRT] Conv_370 + Relu_371 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:14:10] [V] [TRT] Conv_372 + Relu_373 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:14:10] [V] [TRT] Conv_377 + Relu_378 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:14:10] [V] [TRT] Conv_379 + Relu_380 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:14:10] [V] [TRT] Conv_381 + Relu_382 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:14:10] [V] [TRT] Conv_386 + Relu_387 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:14:10] [V] [TRT] Conv_388 + Relu_389 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:14:10] [V] [TRT] Conv_390 + Relu_391 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[03/27/2022-19:14:10] [V] [TRT] Conv_395 + Relu_396 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:14:10] [V] [TRT] Conv_397 + Relu_398 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:14:10] [V] [TRT] Conv_399 + Relu_400 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:14:10] [V] [TRT] Conv_404 + Relu_405 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:14:10] [V] [TRT] Conv_406 + Relu_407 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:14:10] [V] [TRT] Conv_408 + Relu_409 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[03/27/2022-19:14:10] [V] [TRT] Conv_410 Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[03/27/2022-19:14:10] [V] [TRT] Conv_448 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:14:10] [V] [TRT] Conv_451 Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[03/27/2022-19:14:10] [V] [TRT] Conv_461 + Relu_462 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:14:10] [V] [TRT] Conv_463 + Relu_464 Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[03/27/2022-19:14:10] [V] [TRT] Layer: (Unnamed Layer* 424) [Constant] + (Unnamed Layer* 425) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Resize_8 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_9 + Relu_10 Host Persistent: 1664 Device Persistent: 393728 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_446 Host Persistent: 1664 Device Persistent: 393728 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Mul_455 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_11 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_456 Host Persistent: 1664 Device Persistent: 393728 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_12), Mul_13) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_14 Host Persistent: 1312 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ConstantOfShape_444 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_15 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_445 Host Persistent: 1664 Device Persistent: 393728 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Div_447 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_16), Mul_17) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_18 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(Mul_458, PWN(Div_457, Sub_459)) Host Persistent: 436 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_19), Mul_20) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_21 Host Persistent: 3200 Device Persistent: 393728 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_22 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_23), Mul_24) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_25 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_26 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_27), Mul_28) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_29 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_30), Mul_31) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_32 + Add_33 Host Persistent: 3200 Device Persistent: 393728 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_34 Host Persistent: 2176 Device Persistent: 393728 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_35), Mul_36) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_37 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_38), Mul_39) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_40 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_41 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_42), Mul_43) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_44 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_45), Mul_46) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_47 Host Persistent: 3200 Device Persistent: 98816 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_48 Host Persistent: 3200 Device Persistent: 98816 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_49), Mul_50) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_51 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_52), Mul_53) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_54 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_55 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_56), Mul_57) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_58 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_59), Mul_60) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_61 + Add_62 Host Persistent: 3200 Device Persistent: 98816 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_63 Host Persistent: 3200 Device Persistent: 98816 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_64), Mul_65) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_66 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_67), Mul_68) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_69 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_70 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_71), Mul_72) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_73 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_74), Mul_75) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_76 + Add_77 Host Persistent: 3200 Device Persistent: 98816 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_78 Host Persistent: 3200 Device Persistent: 98816 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_79), Mul_80) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_81 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_82), Mul_83) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_84 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_85 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_86), Mul_87) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_88 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_89), Mul_90) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_91 Host Persistent: 3200 Device Persistent: 25088 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_92 Host Persistent: 1664 Device Persistent: 25088 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_93), Mul_94) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_95 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_96), Mul_97) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_98 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_99 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 1536
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_100), Mul_101) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_102 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 512
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_103), Mul_104) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_105 + Add_106 Host Persistent: 2176 Device Persistent: 25088 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_107 Host Persistent: 1664 Device Persistent: 25088 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_108), Mul_109) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_110 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_111), Mul_112) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_113 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_114 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 1536
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_115), Mul_116) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_117 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 512
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_118), Mul_119) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_120 + Add_121 Host Persistent: 2176 Device Persistent: 25088 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_122 Host Persistent: 1664 Device Persistent: 25088 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_123), Mul_124) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_125 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_126), Mul_127) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_128 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_129 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 1536
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_130), Mul_131) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_132 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 512
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_133), Mul_134) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_135 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_136 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_137), Mul_138) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_139 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_140), Mul_141) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_142 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_143 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 2560
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_144), Mul_145) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_146 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_147), Mul_148) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_149 + Add_150 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_151 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_152), Mul_153) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_154 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_155), Mul_156) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_157 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_158 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 2560
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_159), Mul_160) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_161 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_162), Mul_163) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_164 + Add_165 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_166 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_167), Mul_168) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_169 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_170), Mul_171) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_172 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_173 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 2560
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_174), Mul_175) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_176 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_177), Mul_178) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_179 + Add_180 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_181 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_182), Mul_183) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_184 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_185), Mul_186) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_187 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_188 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 2560
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_189), Mul_190) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_191 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_192), Mul_193) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_194 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_195 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_196), Mul_197) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_198 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_199), Mul_200) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_201 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_202 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_203), Mul_204) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_205 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_206), Mul_207) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_208 + Add_209 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_210 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_211), Mul_212) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_213 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_214), Mul_215) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_216 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_217 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_218), Mul_219) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_220 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_221), Mul_222) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_223 + Add_224 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_225 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_226), Mul_227) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_228 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_229), Mul_230) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_231 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_232 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_233), Mul_234) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_235 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_236), Mul_237) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_238 + Add_239 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_240 Host Persistent: 3200 Device Persistent: 6656 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_241), Mul_242) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_243 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_244), Mul_245) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_246 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_247 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_248), Mul_249) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_250 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_251), Mul_252) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_251), Mul_252) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_251), Mul_252) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_253 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_254 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_254 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_255), Mul_256) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_257 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_258), Mul_259) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_260 Host Persistent: 1312 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_261 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_262), Mul_263) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_262), Mul_263) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_264 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_264 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_265), Mul_266) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_265), Mul_266) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_265), Mul_266) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_267 + Add_268 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_269 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_269 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_270), Mul_271) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_272 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_273), Mul_274) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_275 Host Persistent: 1312 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_276 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_277), Mul_278) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_277), Mul_278) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_279 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_279 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_280), Mul_281) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_280), Mul_281) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_280), Mul_281) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_282 + Add_283 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_284 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_284 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_285), Mul_286) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_287 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_288), Mul_289) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_290 Host Persistent: 1312 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_291 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_292), Mul_293) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_292), Mul_293) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_294 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_294 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_295), Mul_296) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_295), Mul_296) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_295), Mul_296) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_297 + Add_298 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_299 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_299 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_300), Mul_301) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_302 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_303), Mul_304) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_305 Host Persistent: 1312 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_306 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_307), Mul_308) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_307), Mul_308) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_309 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_309 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_310), Mul_311) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_310), Mul_311) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_310), Mul_311) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_312 + Add_313 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_314 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_314 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_315), Mul_316) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_317 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_318), Mul_319) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_320 Host Persistent: 1312 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_321 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_322), Mul_323) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_322), Mul_323) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_324 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_324 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_325), Mul_326) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_327 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_328 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_329), Mul_330) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_331 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_332), Mul_333) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: ReduceMean_334 Host Persistent: 48 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_335 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_336), Mul_337) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_336), Mul_337) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_338 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_338 Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(PWN(Sigmoid_339), Mul_340) Host Persistent: 372 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_341 + Add_342 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_343 || Conv_344 || Conv_348 || Conv_352 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_343 || Conv_344 || Conv_348 || Conv_352 Host Persistent: 3200 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_345 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_349 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_353 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_346 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_350 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_354 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_347 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_347 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_351 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_351 Host Persistent: 2176 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_355 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_355 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 12976128
[03/27/2022-19:14:10] [V] [TRT] Layer: 1560 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_357 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_358 + Add_359 + Relu_360 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_361 + Relu_362 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_361 + Relu_362 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_363 + Relu_364 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_365 + Relu_366 Host Persistent: 1664 Device Persistent: 2048 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_365 + Relu_366 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 1156 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_368 + Relu_369 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_370 + Relu_371 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_372 + Relu_373 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Resize_375 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 1213 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 1032 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_377 + Relu_378 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_379 + Relu_380 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_381 + Relu_382 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Resize_384 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 1228 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 890 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_386 + Relu_387 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_388 + Relu_389 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_390 + Relu_391 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Resize_393 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 1243 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 837 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_395 + Relu_396 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_397 + Relu_398 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_399 + Relu_400 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Resize_402 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 1258 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 784 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_404 + Relu_405 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_406 + Relu_407 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_408 + Relu_409 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_410 Host Persistent: 512 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 1269 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 1269 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_448 Host Persistent: 1664 Device Persistent: 393728 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Mul_450 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Div_449 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_451 Host Persistent: 1664 Device Persistent: 393728 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(Div_452, PWN(Mul_453, Sub_454)) Host Persistent: 532 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: 1313 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_461 + Relu_462 Host Persistent: 3200 Device Persistent: 393728 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_463 + Relu_464 Host Persistent: 3200 Device Persistent: 393728 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_465 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 394752
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(Mul_466, Sub_467) Host Persistent: 436 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Resize_476 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Resize_485 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(Mul_486, Add_487) Host Persistent: 436 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [V] [TRT] Layer: Conv_488 Host Persistent: 32 Device Persistent: 0 Scratch Memory: 5531136
[03/27/2022-19:14:10] [V] [TRT] Layer: PWN(Sigmoid_490) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[03/27/2022-19:14:10] [I] [TRT] Total Host Persistent Memory: 230256
[03/27/2022-19:14:10] [I] [TRT] Total Device Persistent Memory: 5234176
[03/27/2022-19:14:10] [I] [TRT] Total Scratch Memory: 12976128
[03/27/2022-19:14:10] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 49 MiB, GPU 4275 MiB
[03/27/2022-19:14:10] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 194.757ms to assign 14 blocks to 331 nodes requiring 284491776 bytes.
[03/27/2022-19:14:10] [V] [TRT] Optimized block assignment.
[03/27/2022-19:14:10] [V] [TRT] Block size 100663296
[03/27/2022-19:14:10] [V] [TRT] Block size 100663296
[03/27/2022-19:14:10] [V] [TRT] Block size 44236800
[03/27/2022-19:14:10] [V] [TRT] Block size 6291456
[03/27/2022-19:14:10] [V] [TRT] Block size 6291456
[03/27/2022-19:14:10] [V] [TRT] Block size 6291456
[03/27/2022-19:14:10] [V] [TRT] Block size 3145728
[03/27/2022-19:14:10] [V] [TRT] Block size 3145728
[03/27/2022-19:14:10] [V] [TRT] Block size 3145728
[03/27/2022-19:14:10] [V] [TRT] Block size 3145728
[03/27/2022-19:14:10] [V] [TRT] Block size 3145728
[03/27/2022-19:14:10] [V] [TRT] Block size 1441792
[03/27/2022-19:14:10] [V] [TRT] Block size 1441792
[03/27/2022-19:14:10] [V] [TRT] Block size 1441792
[03/27/2022-19:14:10] [I] [TRT] Total Activation Memory: 284491776
[03/27/2022-19:14:10] [V] [TRT] Using cublas as a tactic source
[03/27/2022-19:14:10] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1036, GPU 1046 (MiB)
[03/27/2022-19:14:10] [V] [TRT] Using cuDNN as a tactic source
[03/27/2022-19:14:10] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 1037, GPU 1056 (MiB)
[03/27/2022-19:14:10] [V] [TRT] Engine generation completed in 269.331 seconds.
[03/27/2022-19:14:10] [V] [TRT] Deleting timing cache: 683 entries, served 1547 hits since creation.
[03/27/2022-19:14:10] [V] [TRT] Engine Layer Information:
Layer(Constant): (Unnamed Layer* 424) [Constant] + (Unnamed Layer* 425) [Shuffle], Tactic: 0,  -> (Unnamed Layer* 425) [Shuffle]_output[Float(1,1,1,1)]
Layer(Resize): Resize_8, Tactic: 1, x_orig[Float(4,3,1280,720)] -> 754[Float(4,3,256,256)]
Layer(CaskConvolution): Conv_9 + Relu_10, Tactic: -3456450830548107839, 754[Float(4,3,256,256)] -> 757[Float(4,32,256,256)]
Layer(CaskConvolution): Conv_446, Tactic: -3456450830548107839, 754[Float(4,3,256,256)] -> 1305[Float(4,3,256,256)]
Layer(ElementWise): Mul_455, Tactic: 1, 754[Float(4,3,256,256)], 754[Float(4,3,256,256)] -> 1314[Float(4,3,256,256)]
Layer(CudaDepthwiseConvolution): Conv_11, Tactic: -1, 757[Float(4,32,256,256)] -> 1359[Float(4,32,256,256)]
Layer(CaskConvolution): Conv_456, Tactic: -3456450830548107839, 1314[Float(4,3,256,256)] -> 1315[Float(4,3,256,256)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_12), Mul_13), Tactic: 2, 1359[Float(4,32,256,256)] -> 761[Float(4,32,256,256)]
Layer(CaskPooling): ReduceMean_14, Tactic: 6119644359078410246, 761[Float(4,32,256,256)] -> 762[Float(4,32,1,1)]
Layer(Slice): ConstantOfShape_444, Tactic: 0, (Unnamed Layer* 425) [Shuffle]_output[Float(1,1,1,1)] -> 1303[Float(4,3,256,256)]
Layer(CublasConvolution): Conv_15, Tactic: 1, 762[Float(4,32,1,1)] -> 763[Float(4,8,1,1)]
Layer(CaskConvolution): Conv_445, Tactic: -3456450830548107839, 1303[Float(4,3,256,256)] -> 1304[Float(4,3,256,256)]
Layer(ElementWise): Div_447, Tactic: 1, 1305[Float(4,3,256,256)], 1304[Float(4,3,256,256)] -> 1306[Float(4,3,256,256)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_16), Mul_17), Tactic: 4, 763[Float(4,8,1,1)] -> 765[Float(4,8,1,1)]
Layer(CublasConvolution): Conv_18, Tactic: 0, 765[Float(4,8,1,1)] -> 766[Float(4,32,1,1)]
Layer(PointWiseV2): PWN(Mul_458, PWN(Div_457, Sub_459)), Tactic: 2, 1306[Float(4,3,256,256)], 1315[Float(4,3,256,256)], 1304[Float(4,3,256,256)] -> 1319[Float(4,3,256,256)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_19), Mul_20), Tactic: 6, 766[Float(4,32,1,1)], 761[Float(4,32,256,256)] -> 768[Float(4,32,256,256)]
Layer(CaskConvolution): Conv_21, Tactic: -6576203419454146580, 768[Float(4,32,256,256)] -> 1362[Float(4,16,256,256)]
Layer(CudaDepthwiseConvolution): Conv_22, Tactic: -1, 1362[Float(4,16,256,256)] -> 1365[Float(4,16,256,256)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_23), Mul_24), Tactic: 8, 1365[Float(4,16,256,256)] -> 774[Float(4,16,256,256)]
Layer(CudnnPooling): ReduceMean_25, Tactic: -1, 774[Float(4,16,256,256)] -> 775[Float(4,16,1,1)]
Layer(CublasConvolution): Conv_26, Tactic: 1, 775[Float(4,16,1,1)] -> 776[Float(4,4,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_27), Mul_28), Tactic: 9, 776[Float(4,4,1,1)] -> 778[Float(4,4,1,1)]
Layer(CublasConvolution): Conv_29, Tactic: 1, 778[Float(4,4,1,1)] -> 779[Float(4,16,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_30), Mul_31), Tactic: 8, 779[Float(4,16,1,1)], 774[Float(4,16,256,256)] -> 781[Float(4,16,256,256)]
Layer(CaskConvolution): Conv_32 + Add_33, Tactic: 1698681053543049347, 781[Float(4,16,256,256)], 1362[Float(4,16,256,256)] -> 784[Float(4,16,256,256)]
Layer(CaskConvolution): Conv_34, Tactic: 4501471010995462441, 784[Float(4,16,256,256)] -> 1371[Float(4,96,256,256)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_35), Mul_36), Tactic: 2, 1371[Float(4,96,256,256)] -> 788[Float(4,96,256,256)]
Layer(CudaDepthwiseConvolution): Conv_37, Tactic: -1, 788[Float(4,96,256,256)] -> 1374[Float(4,96,128,128)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_38), Mul_39), Tactic: 2, 1374[Float(4,96,128,128)] -> 792[Float(4,96,128,128)]
Layer(CudnnPooling): ReduceMean_40, Tactic: -1, 792[Float(4,96,128,128)] -> 793[Float(4,96,1,1)]
Layer(CublasConvolution): Conv_41, Tactic: 1, 793[Float(4,96,1,1)] -> 794[Float(4,4,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_42), Mul_43), Tactic: 9, 794[Float(4,4,1,1)] -> 796[Float(4,4,1,1)]
Layer(CublasConvolution): Conv_44, Tactic: 0, 796[Float(4,4,1,1)] -> 797[Float(4,96,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_45), Mul_46), Tactic: 4, 797[Float(4,96,1,1)], 792[Float(4,96,128,128)] -> 799[Float(4,96,128,128)]
Layer(CaskConvolution): Conv_47, Tactic: 1698681053543049347, 799[Float(4,96,128,128)] -> 1377[Float(4,24,128,128)]
Layer(CaskConvolution): Conv_48, Tactic: -37215280111360163, 1377[Float(4,24,128,128)] -> 1380[Float(4,144,128,128)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_49), Mul_50), Tactic: 2, 1380[Float(4,144,128,128)] -> 805[Float(4,144,128,128)]
Layer(CudaDepthwiseConvolution): Conv_51, Tactic: -1, 805[Float(4,144,128,128)] -> 1383[Float(4,144,128,128)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_52), Mul_53), Tactic: 2, 1383[Float(4,144,128,128)] -> 809[Float(4,144,128,128)]
Layer(CudnnPooling): ReduceMean_54, Tactic: -1, 809[Float(4,144,128,128)] -> 810[Float(4,144,1,1)]
Layer(CublasConvolution): Conv_55, Tactic: 0, 810[Float(4,144,1,1)] -> 811[Float(4,6,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_56), Mul_57), Tactic: 0, 811[Float(4,6,1,1)] -> 813[Float(4,6,1,1)]
Layer(CublasConvolution): Conv_58, Tactic: 0, 813[Float(4,6,1,1)] -> 814[Float(4,144,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_59), Mul_60), Tactic: 4, 814[Float(4,144,1,1)], 809[Float(4,144,128,128)] -> 816[Float(4,144,128,128)]
Layer(CaskConvolution): Conv_61 + Add_62, Tactic: 1698681053543049347, 816[Float(4,144,128,128)], 1377[Float(4,24,128,128)] -> 819[Float(4,24,128,128)]
Layer(CaskConvolution): Conv_63, Tactic: -37215280111360163, 819[Float(4,24,128,128)] -> 1389[Float(4,144,128,128)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_64), Mul_65), Tactic: 2, 1389[Float(4,144,128,128)] -> 823[Float(4,144,128,128)]
Layer(CudaDepthwiseConvolution): Conv_66, Tactic: -1, 823[Float(4,144,128,128)] -> 1392[Float(4,144,128,128)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_67), Mul_68), Tactic: 2, 1392[Float(4,144,128,128)] -> 827[Float(4,144,128,128)]
Layer(CudnnPooling): ReduceMean_69, Tactic: -1, 827[Float(4,144,128,128)] -> 828[Float(4,144,1,1)]
Layer(CublasConvolution): Conv_70, Tactic: 0, 828[Float(4,144,1,1)] -> 829[Float(4,6,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_71), Mul_72), Tactic: 0, 829[Float(4,6,1,1)] -> 831[Float(4,6,1,1)]
Layer(CublasConvolution): Conv_73, Tactic: 0, 831[Float(4,6,1,1)] -> 832[Float(4,144,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_74), Mul_75), Tactic: 4, 832[Float(4,144,1,1)], 827[Float(4,144,128,128)] -> 834[Float(4,144,128,128)]
Layer(CaskConvolution): Conv_76 + Add_77, Tactic: 1698681053543049347, 834[Float(4,144,128,128)], 819[Float(4,24,128,128)] -> 837[Float(4,24,128,128)]
Layer(CaskConvolution): Conv_78, Tactic: -37215280111360163, 837[Float(4,24,128,128)] -> 1398[Float(4,144,128,128)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_79), Mul_80), Tactic: 2, 1398[Float(4,144,128,128)] -> 841[Float(4,144,128,128)]
Layer(CudaDepthwiseConvolution): Conv_81, Tactic: -1, 841[Float(4,144,128,128)] -> 1401[Float(4,144,64,64)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_82), Mul_83), Tactic: 5, 1401[Float(4,144,64,64)] -> 845[Float(4,144,64,64)]
Layer(CudnnPooling): ReduceMean_84, Tactic: -1, 845[Float(4,144,64,64)] -> 846[Float(4,144,1,1)]
Layer(CublasConvolution): Conv_85, Tactic: 0, 846[Float(4,144,1,1)] -> 847[Float(4,6,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_86), Mul_87), Tactic: 0, 847[Float(4,6,1,1)] -> 849[Float(4,6,1,1)]
Layer(CublasConvolution): Conv_88, Tactic: 0, 849[Float(4,6,1,1)] -> 850[Float(4,144,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_89), Mul_90), Tactic: 2, 850[Float(4,144,1,1)], 845[Float(4,144,64,64)] -> 852[Float(4,144,64,64)]
Layer(CaskConvolution): Conv_91, Tactic: -37215280111360163, 852[Float(4,144,64,64)] -> 1404[Float(4,48,64,64)]
Layer(CaskConvolution): Conv_92, Tactic: 5137655947464784826, 1404[Float(4,48,64,64)] -> 1407[Float(4,288,64,64)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_93), Mul_94), Tactic: 8, 1407[Float(4,288,64,64)] -> 858[Float(4,288,64,64)]
Layer(CudaDepthwiseConvolution): Conv_95, Tactic: -1, 858[Float(4,288,64,64)] -> 1410[Float(4,288,64,64)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_96), Mul_97), Tactic: 8, 1410[Float(4,288,64,64)] -> 862[Float(4,288,64,64)]
Layer(CudnnPooling): ReduceMean_98, Tactic: -1, 862[Float(4,288,64,64)] -> 863[Float(4,288,1,1)]
Layer(CudnnConvolution): Conv_99, Tactic: 1, 863[Float(4,288,1,1)] -> 864[Float(4,12,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_100), Mul_101), Tactic: 0, 864[Float(4,12,1,1)] -> 866[Float(4,12,1,1)]
Layer(CudnnConvolution): Conv_102, Tactic: 1, 866[Float(4,12,1,1)] -> 867[Float(4,288,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_103), Mul_104), Tactic: 2, 867[Float(4,288,1,1)], 862[Float(4,288,64,64)] -> 869[Float(4,288,64,64)]
Layer(CaskConvolution): Conv_105 + Add_106, Tactic: 6645123197870846056, 869[Float(4,288,64,64)], 1404[Float(4,48,64,64)] -> 872[Float(4,48,64,64)]
Layer(CaskConvolution): Conv_107, Tactic: 5137655947464784826, 872[Float(4,48,64,64)] -> 1416[Float(4,288,64,64)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_108), Mul_109), Tactic: 8, 1416[Float(4,288,64,64)] -> 876[Float(4,288,64,64)]
Layer(CudaDepthwiseConvolution): Conv_110, Tactic: -1, 876[Float(4,288,64,64)] -> 1419[Float(4,288,64,64)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_111), Mul_112), Tactic: 8, 1419[Float(4,288,64,64)] -> 880[Float(4,288,64,64)]
Layer(CudnnPooling): ReduceMean_113, Tactic: -1, 880[Float(4,288,64,64)] -> 881[Float(4,288,1,1)]
Layer(CudnnConvolution): Conv_114, Tactic: 1, 881[Float(4,288,1,1)] -> 882[Float(4,12,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_115), Mul_116), Tactic: 0, 882[Float(4,12,1,1)] -> 884[Float(4,12,1,1)]
Layer(CudnnConvolution): Conv_117, Tactic: 1, 884[Float(4,12,1,1)] -> 885[Float(4,288,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_118), Mul_119), Tactic: 2, 885[Float(4,288,1,1)], 880[Float(4,288,64,64)] -> 887[Float(4,288,64,64)]
Layer(CaskConvolution): Conv_120 + Add_121, Tactic: 6645123197870846056, 887[Float(4,288,64,64)], 872[Float(4,48,64,64)] -> 890[Float(4,48,64,64)]
Layer(CaskConvolution): Conv_122, Tactic: 5137655947464784826, 890[Float(4,48,64,64)] -> 1425[Float(4,288,64,64)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_123), Mul_124), Tactic: 8, 1425[Float(4,288,64,64)] -> 894[Float(4,288,64,64)]
Layer(CudaDepthwiseConvolution): Conv_125, Tactic: -1, 894[Float(4,288,64,64)] -> 1428[Float(4,288,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_126), Mul_127), Tactic: 5, 1428[Float(4,288,32,32)] -> 898[Float(4,288,32,32)]
Layer(CudnnPooling): ReduceMean_128, Tactic: -1, 898[Float(4,288,32,32)] -> 899[Float(4,288,1,1)]
Layer(CudnnConvolution): Conv_129, Tactic: 1, 899[Float(4,288,1,1)] -> 900[Float(4,12,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_130), Mul_131), Tactic: 0, 900[Float(4,12,1,1)] -> 902[Float(4,12,1,1)]
Layer(CudnnConvolution): Conv_132, Tactic: 1, 902[Float(4,12,1,1)] -> 903[Float(4,288,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_133), Mul_134), Tactic: 28, 903[Float(4,288,1,1)], 898[Float(4,288,32,32)] -> 905[Float(4,288,32,32)]
Layer(CaskConvolution): Conv_135, Tactic: -6576203419454146580, 905[Float(4,288,32,32)] -> 1431[Float(4,88,32,32)]
Layer(CaskConvolution): Conv_136, Tactic: -37215280111360163, 1431[Float(4,88,32,32)] -> 1434[Float(4,528,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_137), Mul_138), Tactic: 9, 1434[Float(4,528,32,32)] -> 911[Float(4,528,32,32)]
Layer(CudaDepthwiseConvolution): Conv_139, Tactic: -1, 911[Float(4,528,32,32)] -> 1437[Float(4,528,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_140), Mul_141), Tactic: 9, 1437[Float(4,528,32,32)] -> 915[Float(4,528,32,32)]
Layer(CudnnPooling): ReduceMean_142, Tactic: -1, 915[Float(4,528,32,32)] -> 916[Float(4,528,1,1)]
Layer(CudnnConvolution): Conv_143, Tactic: 1, 916[Float(4,528,1,1)] -> 917[Float(4,22,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_144), Mul_145), Tactic: 28, 917[Float(4,22,1,1)] -> 919[Float(4,22,1,1)]
Layer(CublasConvolution): Conv_146, Tactic: 0, 919[Float(4,22,1,1)] -> 920[Float(4,528,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_147), Mul_148), Tactic: 28, 920[Float(4,528,1,1)], 915[Float(4,528,32,32)] -> 922[Float(4,528,32,32)]
Layer(CaskConvolution): Conv_149 + Add_150, Tactic: -6576203419454146580, 922[Float(4,528,32,32)], 1431[Float(4,88,32,32)] -> 925[Float(4,88,32,32)]
Layer(CaskConvolution): Conv_151, Tactic: -37215280111360163, 925[Float(4,88,32,32)] -> 1443[Float(4,528,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_152), Mul_153), Tactic: 9, 1443[Float(4,528,32,32)] -> 929[Float(4,528,32,32)]
Layer(CudaDepthwiseConvolution): Conv_154, Tactic: -1, 929[Float(4,528,32,32)] -> 1446[Float(4,528,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_155), Mul_156), Tactic: 9, 1446[Float(4,528,32,32)] -> 933[Float(4,528,32,32)]
Layer(CudnnPooling): ReduceMean_157, Tactic: -1, 933[Float(4,528,32,32)] -> 934[Float(4,528,1,1)]
Layer(CudnnConvolution): Conv_158, Tactic: 1, 934[Float(4,528,1,1)] -> 935[Float(4,22,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_159), Mul_160), Tactic: 28, 935[Float(4,22,1,1)] -> 937[Float(4,22,1,1)]
Layer(CublasConvolution): Conv_161, Tactic: 0, 937[Float(4,22,1,1)] -> 938[Float(4,528,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_162), Mul_163), Tactic: 28, 938[Float(4,528,1,1)], 933[Float(4,528,32,32)] -> 940[Float(4,528,32,32)]
Layer(CaskConvolution): Conv_164 + Add_165, Tactic: -6576203419454146580, 940[Float(4,528,32,32)], 925[Float(4,88,32,32)] -> 943[Float(4,88,32,32)]
Layer(CaskConvolution): Conv_166, Tactic: -37215280111360163, 943[Float(4,88,32,32)] -> 1452[Float(4,528,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_167), Mul_168), Tactic: 9, 1452[Float(4,528,32,32)] -> 947[Float(4,528,32,32)]
Layer(CudaDepthwiseConvolution): Conv_169, Tactic: -1, 947[Float(4,528,32,32)] -> 1455[Float(4,528,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_170), Mul_171), Tactic: 9, 1455[Float(4,528,32,32)] -> 951[Float(4,528,32,32)]
Layer(CudnnPooling): ReduceMean_172, Tactic: -1, 951[Float(4,528,32,32)] -> 952[Float(4,528,1,1)]
Layer(CudnnConvolution): Conv_173, Tactic: 1, 952[Float(4,528,1,1)] -> 953[Float(4,22,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_174), Mul_175), Tactic: 28, 953[Float(4,22,1,1)] -> 955[Float(4,22,1,1)]
Layer(CublasConvolution): Conv_176, Tactic: 0, 955[Float(4,22,1,1)] -> 956[Float(4,528,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_177), Mul_178), Tactic: 28, 956[Float(4,528,1,1)], 951[Float(4,528,32,32)] -> 958[Float(4,528,32,32)]
Layer(CaskConvolution): Conv_179 + Add_180, Tactic: -6576203419454146580, 958[Float(4,528,32,32)], 943[Float(4,88,32,32)] -> 961[Float(4,88,32,32)]
Layer(CaskConvolution): Conv_181, Tactic: -37215280111360163, 961[Float(4,88,32,32)] -> 1461[Float(4,528,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_182), Mul_183), Tactic: 9, 1461[Float(4,528,32,32)] -> 965[Float(4,528,32,32)]
Layer(CudaDepthwiseConvolution): Conv_184, Tactic: -1, 965[Float(4,528,32,32)] -> 1464[Float(4,528,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_185), Mul_186), Tactic: 9, 1464[Float(4,528,32,32)] -> 969[Float(4,528,32,32)]
Layer(CudnnPooling): ReduceMean_187, Tactic: -1, 969[Float(4,528,32,32)] -> 970[Float(4,528,1,1)]
Layer(CudnnConvolution): Conv_188, Tactic: 1, 970[Float(4,528,1,1)] -> 971[Float(4,22,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_189), Mul_190), Tactic: 28, 971[Float(4,22,1,1)] -> 973[Float(4,22,1,1)]
Layer(CublasConvolution): Conv_191, Tactic: 0, 973[Float(4,22,1,1)] -> 974[Float(4,528,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_192), Mul_193), Tactic: 28, 974[Float(4,528,1,1)], 969[Float(4,528,32,32)] -> 976[Float(4,528,32,32)]
Layer(CaskConvolution): Conv_194, Tactic: 1698681053543049347, 976[Float(4,528,32,32)] -> 1467[Float(4,120,32,32)]
Layer(CaskConvolution): Conv_195, Tactic: -37215280111360163, 1467[Float(4,120,32,32)] -> 1470[Float(4,720,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_196), Mul_197), Tactic: 8, 1470[Float(4,720,32,32)] -> 982[Float(4,720,32,32)]
Layer(CudaDepthwiseConvolution): Conv_198, Tactic: -1, 982[Float(4,720,32,32)] -> 1473[Float(4,720,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_199), Mul_200), Tactic: 8, 1473[Float(4,720,32,32)] -> 986[Float(4,720,32,32)]
Layer(CudnnPooling): ReduceMean_201, Tactic: -1, 986[Float(4,720,32,32)] -> 987[Float(4,720,1,1)]
Layer(CublasConvolution): Conv_202, Tactic: 0, 987[Float(4,720,1,1)] -> 988[Float(4,30,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_203), Mul_204), Tactic: 0, 988[Float(4,30,1,1)] -> 990[Float(4,30,1,1)]
Layer(CublasConvolution): Conv_205, Tactic: 0, 990[Float(4,30,1,1)] -> 991[Float(4,720,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_206), Mul_207), Tactic: 28, 991[Float(4,720,1,1)], 986[Float(4,720,32,32)] -> 993[Float(4,720,32,32)]
Layer(CaskConvolution): Conv_208 + Add_209, Tactic: 1698681053543049347, 993[Float(4,720,32,32)], 1467[Float(4,120,32,32)] -> 996[Float(4,120,32,32)]
Layer(CaskConvolution): Conv_210, Tactic: -37215280111360163, 996[Float(4,120,32,32)] -> 1479[Float(4,720,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_211), Mul_212), Tactic: 8, 1479[Float(4,720,32,32)] -> 1000[Float(4,720,32,32)]
Layer(CudaDepthwiseConvolution): Conv_213, Tactic: -1, 1000[Float(4,720,32,32)] -> 1482[Float(4,720,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_214), Mul_215), Tactic: 8, 1482[Float(4,720,32,32)] -> 1004[Float(4,720,32,32)]
Layer(CudnnPooling): ReduceMean_216, Tactic: -1, 1004[Float(4,720,32,32)] -> 1005[Float(4,720,1,1)]
Layer(CublasConvolution): Conv_217, Tactic: 0, 1005[Float(4,720,1,1)] -> 1006[Float(4,30,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_218), Mul_219), Tactic: 0, 1006[Float(4,30,1,1)] -> 1008[Float(4,30,1,1)]
Layer(CublasConvolution): Conv_220, Tactic: 0, 1008[Float(4,30,1,1)] -> 1009[Float(4,720,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_221), Mul_222), Tactic: 28, 1009[Float(4,720,1,1)], 1004[Float(4,720,32,32)] -> 1011[Float(4,720,32,32)]
Layer(CaskConvolution): Conv_223 + Add_224, Tactic: 1698681053543049347, 1011[Float(4,720,32,32)], 996[Float(4,120,32,32)] -> 1014[Float(4,120,32,32)]
Layer(CaskConvolution): Conv_225, Tactic: -37215280111360163, 1014[Float(4,120,32,32)] -> 1488[Float(4,720,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_226), Mul_227), Tactic: 8, 1488[Float(4,720,32,32)] -> 1018[Float(4,720,32,32)]
Layer(CudaDepthwiseConvolution): Conv_228, Tactic: -1, 1018[Float(4,720,32,32)] -> 1491[Float(4,720,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_229), Mul_230), Tactic: 8, 1491[Float(4,720,32,32)] -> 1022[Float(4,720,32,32)]
Layer(CudnnPooling): ReduceMean_231, Tactic: -1, 1022[Float(4,720,32,32)] -> 1023[Float(4,720,1,1)]
Layer(CublasConvolution): Conv_232, Tactic: 0, 1023[Float(4,720,1,1)] -> 1024[Float(4,30,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_233), Mul_234), Tactic: 0, 1024[Float(4,30,1,1)] -> 1026[Float(4,30,1,1)]
Layer(CublasConvolution): Conv_235, Tactic: 0, 1026[Float(4,30,1,1)] -> 1027[Float(4,720,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_236), Mul_237), Tactic: 28, 1027[Float(4,720,1,1)], 1022[Float(4,720,32,32)] -> 1029[Float(4,720,32,32)]
Layer(CaskConvolution): Conv_238 + Add_239, Tactic: 1698681053543049347, 1029[Float(4,720,32,32)], 1014[Float(4,120,32,32)] -> 1032[Float(4,120,32,32)]
Layer(CaskConvolution): Conv_240, Tactic: -37215280111360163, 1032[Float(4,120,32,32)] -> 1497[Float(4,720,32,32)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_241), Mul_242), Tactic: 8, 1497[Float(4,720,32,32)] -> 1036[Float(4,720,32,32)]
Layer(CudaDepthwiseConvolution): Conv_243, Tactic: -1, 1036[Float(4,720,32,32)] -> 1500[Float(4,720,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_244), Mul_245), Tactic: 8, 1500[Float(4,720,16,16)] -> 1040[Float(4,720,16,16)]
Layer(CudnnPooling): ReduceMean_246, Tactic: -1, 1040[Float(4,720,16,16)] -> 1041[Float(4,720,1,1)]
Layer(CublasConvolution): Conv_247, Tactic: 0, 1041[Float(4,720,1,1)] -> 1042[Float(4,30,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_248), Mul_249), Tactic: 0, 1042[Float(4,30,1,1)] -> 1044[Float(4,30,1,1)]
Layer(CublasConvolution): Conv_250, Tactic: 0, 1044[Float(4,30,1,1)] -> 1045[Float(4,720,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_251), Mul_252), Tactic: 0, 1045[Float(4,720,1,1)] -> Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_251), Mul_252)[Float(4,720,1,1)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_251), Mul_252), Tactic: 0, 1040[Float(4,720,16,16)] -> Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_251), Mul_252)[Float(4,720,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_251), Mul_252), Tactic: 8, Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_251), Mul_252)[Float(4,720,1,1)], Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_251), Mul_252)[Float(4,720,16,16)] -> 1047[Float(4,720,16,16)]
Layer(CaskConvolution): Conv_253, Tactic: 6629944304117643200, 1047[Float(4,720,16,16)] -> 1503[Float(4,208,16,16)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_254, Tactic: 0, 1503[Float(4,208,16,16)] -> Reformatted Input Tensor 0 to Conv_254[Float(4,208,16,16)]
Layer(CaskConvolution): Conv_254, Tactic: -377491875521947884, Reformatted Input Tensor 0 to Conv_254[Float(4,208,16,16)] -> 1506[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_255), Mul_256), Tactic: 5, 1506[Float(4,1248,16,16)] -> 1053[Float(4,1248,16,16)]
Layer(CudaDepthwiseConvolution): Conv_257, Tactic: -1, 1053[Float(4,1248,16,16)] -> 1509[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_258), Mul_259), Tactic: 5, 1509[Float(4,1248,16,16)] -> 1057[Float(4,1248,16,16)]
Layer(CaskPooling): ReduceMean_260, Tactic: 6119644359078410246, 1057[Float(4,1248,16,16)] -> 1058[Float(4,1248,1,1)]
Layer(CublasConvolution): Conv_261, Tactic: 0, 1058[Float(4,1248,1,1)] -> 1059[Float(4,52,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_262), Mul_263), Tactic: 0, 1059[Float(4,52,1,1)] -> Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_262), Mul_263)[Float(4,52,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_262), Mul_263), Tactic: 28, Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_262), Mul_263)[Float(4,52,1,1)] -> 1061[Float(4,52,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to Conv_264, Tactic: 0, 1061[Float(4,52,1,1)] -> Reformatted Input Tensor 0 to Conv_264[Float(4,52,1,1)]
Layer(CublasConvolution): Conv_264, Tactic: 1, Reformatted Input Tensor 0 to Conv_264[Float(4,52,1,1)] -> 1062[Float(4,1248,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_265), Mul_266), Tactic: 0, 1062[Float(4,1248,1,1)] -> Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_265), Mul_266)[Float(4,1248,1,1)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_265), Mul_266), Tactic: 0, 1057[Float(4,1248,16,16)] -> Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_265), Mul_266)[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_265), Mul_266), Tactic: 8, Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_265), Mul_266)[Float(4,1248,1,1)], Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_265), Mul_266)[Float(4,1248,16,16)] -> 1064[Float(4,1248,16,16)]
Layer(CaskConvolution): Conv_267 + Add_268, Tactic: 6629944304117643200, 1064[Float(4,1248,16,16)], 1503[Float(4,208,16,16)] -> 1067[Float(4,208,16,16)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_269, Tactic: 0, 1067[Float(4,208,16,16)] -> Reformatted Input Tensor 0 to Conv_269[Float(4,208,16,16)]
Layer(CaskConvolution): Conv_269, Tactic: -377491875521947884, Reformatted Input Tensor 0 to Conv_269[Float(4,208,16,16)] -> 1515[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_270), Mul_271), Tactic: 5, 1515[Float(4,1248,16,16)] -> 1071[Float(4,1248,16,16)]
Layer(CudaDepthwiseConvolution): Conv_272, Tactic: -1, 1071[Float(4,1248,16,16)] -> 1518[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_273), Mul_274), Tactic: 5, 1518[Float(4,1248,16,16)] -> 1075[Float(4,1248,16,16)]
Layer(CaskPooling): ReduceMean_275, Tactic: 6119644359078410246, 1075[Float(4,1248,16,16)] -> 1076[Float(4,1248,1,1)]
Layer(CublasConvolution): Conv_276, Tactic: 0, 1076[Float(4,1248,1,1)] -> 1077[Float(4,52,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_277), Mul_278), Tactic: 0, 1077[Float(4,52,1,1)] -> Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_277), Mul_278)[Float(4,52,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_277), Mul_278), Tactic: 28, Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_277), Mul_278)[Float(4,52,1,1)] -> 1079[Float(4,52,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to Conv_279, Tactic: 0, 1079[Float(4,52,1,1)] -> Reformatted Input Tensor 0 to Conv_279[Float(4,52,1,1)]
Layer(CublasConvolution): Conv_279, Tactic: 1, Reformatted Input Tensor 0 to Conv_279[Float(4,52,1,1)] -> 1080[Float(4,1248,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_280), Mul_281), Tactic: 0, 1080[Float(4,1248,1,1)] -> Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_280), Mul_281)[Float(4,1248,1,1)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_280), Mul_281), Tactic: 0, 1075[Float(4,1248,16,16)] -> Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_280), Mul_281)[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_280), Mul_281), Tactic: 8, Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_280), Mul_281)[Float(4,1248,1,1)], Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_280), Mul_281)[Float(4,1248,16,16)] -> 1082[Float(4,1248,16,16)]
Layer(CaskConvolution): Conv_282 + Add_283, Tactic: 6629944304117643200, 1082[Float(4,1248,16,16)], 1067[Float(4,208,16,16)] -> 1085[Float(4,208,16,16)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_284, Tactic: 0, 1085[Float(4,208,16,16)] -> Reformatted Input Tensor 0 to Conv_284[Float(4,208,16,16)]
Layer(CaskConvolution): Conv_284, Tactic: -377491875521947884, Reformatted Input Tensor 0 to Conv_284[Float(4,208,16,16)] -> 1524[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_285), Mul_286), Tactic: 5, 1524[Float(4,1248,16,16)] -> 1089[Float(4,1248,16,16)]
Layer(CudaDepthwiseConvolution): Conv_287, Tactic: -1, 1089[Float(4,1248,16,16)] -> 1527[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_288), Mul_289), Tactic: 5, 1527[Float(4,1248,16,16)] -> 1093[Float(4,1248,16,16)]
Layer(CaskPooling): ReduceMean_290, Tactic: 6119644359078410246, 1093[Float(4,1248,16,16)] -> 1094[Float(4,1248,1,1)]
Layer(CublasConvolution): Conv_291, Tactic: 0, 1094[Float(4,1248,1,1)] -> 1095[Float(4,52,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_292), Mul_293), Tactic: 0, 1095[Float(4,52,1,1)] -> Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_292), Mul_293)[Float(4,52,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_292), Mul_293), Tactic: 28, Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_292), Mul_293)[Float(4,52,1,1)] -> 1097[Float(4,52,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to Conv_294, Tactic: 0, 1097[Float(4,52,1,1)] -> Reformatted Input Tensor 0 to Conv_294[Float(4,52,1,1)]
Layer(CublasConvolution): Conv_294, Tactic: 1, Reformatted Input Tensor 0 to Conv_294[Float(4,52,1,1)] -> 1098[Float(4,1248,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_295), Mul_296), Tactic: 0, 1098[Float(4,1248,1,1)] -> Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_295), Mul_296)[Float(4,1248,1,1)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_295), Mul_296), Tactic: 0, 1093[Float(4,1248,16,16)] -> Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_295), Mul_296)[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_295), Mul_296), Tactic: 8, Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_295), Mul_296)[Float(4,1248,1,1)], Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_295), Mul_296)[Float(4,1248,16,16)] -> 1100[Float(4,1248,16,16)]
Layer(CaskConvolution): Conv_297 + Add_298, Tactic: 6629944304117643200, 1100[Float(4,1248,16,16)], 1085[Float(4,208,16,16)] -> 1103[Float(4,208,16,16)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_299, Tactic: 0, 1103[Float(4,208,16,16)] -> Reformatted Input Tensor 0 to Conv_299[Float(4,208,16,16)]
Layer(CaskConvolution): Conv_299, Tactic: -377491875521947884, Reformatted Input Tensor 0 to Conv_299[Float(4,208,16,16)] -> 1533[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_300), Mul_301), Tactic: 5, 1533[Float(4,1248,16,16)] -> 1107[Float(4,1248,16,16)]
Layer(CudaDepthwiseConvolution): Conv_302, Tactic: -1, 1107[Float(4,1248,16,16)] -> 1536[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_303), Mul_304), Tactic: 5, 1536[Float(4,1248,16,16)] -> 1111[Float(4,1248,16,16)]
Layer(CaskPooling): ReduceMean_305, Tactic: 6119644359078410246, 1111[Float(4,1248,16,16)] -> 1112[Float(4,1248,1,1)]
Layer(CublasConvolution): Conv_306, Tactic: 0, 1112[Float(4,1248,1,1)] -> 1113[Float(4,52,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_307), Mul_308), Tactic: 0, 1113[Float(4,52,1,1)] -> Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_307), Mul_308)[Float(4,52,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_307), Mul_308), Tactic: 28, Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_307), Mul_308)[Float(4,52,1,1)] -> 1115[Float(4,52,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to Conv_309, Tactic: 0, 1115[Float(4,52,1,1)] -> Reformatted Input Tensor 0 to Conv_309[Float(4,52,1,1)]
Layer(CublasConvolution): Conv_309, Tactic: 1, Reformatted Input Tensor 0 to Conv_309[Float(4,52,1,1)] -> 1116[Float(4,1248,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_310), Mul_311), Tactic: 0, 1116[Float(4,1248,1,1)] -> Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_310), Mul_311)[Float(4,1248,1,1)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_310), Mul_311), Tactic: 0, 1111[Float(4,1248,16,16)] -> Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_310), Mul_311)[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_310), Mul_311), Tactic: 8, Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_310), Mul_311)[Float(4,1248,1,1)], Reformatted Input Tensor 1 to PWN(PWN(Sigmoid_310), Mul_311)[Float(4,1248,16,16)] -> 1118[Float(4,1248,16,16)]
Layer(CaskConvolution): Conv_312 + Add_313, Tactic: 6629944304117643200, 1118[Float(4,1248,16,16)], 1103[Float(4,208,16,16)] -> 1121[Float(4,208,16,16)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_314, Tactic: 0, 1121[Float(4,208,16,16)] -> Reformatted Input Tensor 0 to Conv_314[Float(4,208,16,16)]
Layer(CaskConvolution): Conv_314, Tactic: -377491875521947884, Reformatted Input Tensor 0 to Conv_314[Float(4,208,16,16)] -> 1542[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_315), Mul_316), Tactic: 5, 1542[Float(4,1248,16,16)] -> 1125[Float(4,1248,16,16)]
Layer(CudaDepthwiseConvolution): Conv_317, Tactic: -1, 1125[Float(4,1248,16,16)] -> 1545[Float(4,1248,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_318), Mul_319), Tactic: 5, 1545[Float(4,1248,16,16)] -> 1129[Float(4,1248,16,16)]
Layer(CaskPooling): ReduceMean_320, Tactic: 6119644359078410246, 1129[Float(4,1248,16,16)] -> 1130[Float(4,1248,1,1)]
Layer(CublasConvolution): Conv_321, Tactic: 0, 1130[Float(4,1248,1,1)] -> 1131[Float(4,52,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_322), Mul_323), Tactic: 0, 1131[Float(4,52,1,1)] -> Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_322), Mul_323)[Float(4,52,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_322), Mul_323), Tactic: 28, Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_322), Mul_323)[Float(4,52,1,1)] -> 1133[Float(4,52,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to Conv_324, Tactic: 0, 1133[Float(4,52,1,1)] -> Reformatted Input Tensor 0 to Conv_324[Float(4,52,1,1)]
Layer(CublasConvolution): Conv_324, Tactic: 1, Reformatted Input Tensor 0 to Conv_324[Float(4,52,1,1)] -> 1134[Float(4,1248,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_325), Mul_326), Tactic: 28, 1134[Float(4,1248,1,1)], 1129[Float(4,1248,16,16)] -> 1136[Float(4,1248,16,16)]
Layer(CaskConvolution): Conv_327, Tactic: -410470605513481746, 1136[Float(4,1248,16,16)] -> 1548[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_328, Tactic: -37215280111360163, 1548[Float(4,352,16,16)] -> 1551[Float(4,2112,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_329), Mul_330), Tactic: 5, 1551[Float(4,2112,16,16)] -> 1142[Float(4,2112,16,16)]
Layer(CudaDepthwiseConvolution): Conv_331, Tactic: -1, 1142[Float(4,2112,16,16)] -> 1554[Float(4,2112,16,16)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_332), Mul_333), Tactic: 5, 1554[Float(4,2112,16,16)] -> 1146[Float(4,2112,16,16)]
Layer(CudnnPooling): ReduceMean_334, Tactic: -1, 1146[Float(4,2112,16,16)] -> 1147[Float(4,2112,1,1)]
Layer(CublasConvolution): Conv_335, Tactic: 0, 1147[Float(4,2112,1,1)] -> 1148[Float(4,88,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_336), Mul_337), Tactic: 0, 1148[Float(4,88,1,1)] -> Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_336), Mul_337)[Float(4,88,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_336), Mul_337), Tactic: 0, Reformatted Input Tensor 0 to PWN(PWN(Sigmoid_336), Mul_337)[Float(4,88,1,1)] -> 1150[Float(4,88,1,1)]
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to Conv_338, Tactic: 0, 1150[Float(4,88,1,1)] -> Reformatted Input Tensor 0 to Conv_338[Float(4,88,1,1)]
Layer(CublasConvolution): Conv_338, Tactic: 1, Reformatted Input Tensor 0 to Conv_338[Float(4,88,1,1)] -> 1151[Float(4,2112,1,1)]
Layer(PointWiseV2): PWN(PWN(Sigmoid_339), Mul_340), Tactic: 28, 1151[Float(4,2112,1,1)], 1146[Float(4,2112,16,16)] -> 1153[Float(4,2112,16,16)]
Layer(CaskConvolution): Conv_341 + Add_342, Tactic: -37215280111360163, 1153[Float(4,2112,16,16)], 1548[Float(4,352,16,16)] -> 1156[Float(4,352,16,16)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_343 || Conv_344 || Conv_348 || Conv_352, Tactic: 0, 1156[Float(4,352,16,16)] -> Reformatted Input Tensor 0 to Conv_343 || Conv_344 || Conv_348 || Conv_352[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_343 || Conv_344 || Conv_348 || Conv_352, Tactic: 3886731678879822788, Reformatted Input Tensor 0 to Conv_343 || Conv_344 || Conv_348 || Conv_352[Float(4,352,16,16)] -> Conv_343 || Conv_344 || Conv_348 || Conv_352[Float(4,1408,16,16)]
Layer(CaskConvolution): Conv_345, Tactic: -9153228964338181824, Conv_343 || Conv_344 || Conv_348 || Conv_352[Float(4,352,16,16)] -> 1566[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_349, Tactic: -7394439838318485025, Conv_343 || Conv_344 || Conv_348 || Conv_352[Float(4,352,16,16)] -> 1578[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_353, Tactic: -9153228964338181824, Conv_343 || Conv_344 || Conv_348 || Conv_352[Float(4,352,16,16)] -> 1590[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_346, Tactic: -9153228964338181824, 1566[Float(4,352,16,16)] -> 1569[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_350, Tactic: -7394439838318485025, 1578[Float(4,352,16,16)] -> 1581[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_354, Tactic: -9153228964338181824, 1590[Float(4,352,16,16)] -> 1593[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_347, Tactic: -9153228964338181824, 1569[Float(4,352,16,16)] -> Reformatted Output Tensor 0 to Conv_347[Float(4,352,16,16)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_347, Tactic: 0, Reformatted Output Tensor 0 to Conv_347[Float(4,352,16,16)] -> 1183[Float(4,352,16,16)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_351, Tactic: 0, 1581[Float(4,352,16,16)] -> Reformatted Input Tensor 0 to Conv_351[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_351, Tactic: 4501471010995462441, Reformatted Input Tensor 0 to Conv_351[Float(4,352,16,16)] -> 1183[Float(4,352,16,16)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_355, Tactic: 0, 1593[Float(4,352,16,16)] -> Reformatted Input Tensor 0 to Conv_355[Float(4,352,16,16)]
Layer(CudnnConvolution): Conv_355, Tactic: 2, Reformatted Input Tensor 0 to Conv_355[Float(4,352,16,16)] -> 1183[Float(4,352,16,16)]
Layer(Reformat): 1560 copy, Tactic: 0, Conv_343 || Conv_344 || Conv_348 || Conv_352[Float(4,352,16,16)] -> 1183[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_357, Tactic: 5921334924264294896, 1183[Float(4,1408,16,16)] -> 1599[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_358 + Add_359 + Relu_360, Tactic: -410470605513481746, 1156[Float(4,352,16,16)], 1599[Float(4,352,16,16)] -> 1189[Float(4,352,16,16)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_361 + Relu_362, Tactic: 0, 1189[Float(4,352,16,16)] -> Reformatted Input Tensor 0 to Conv_361 + Relu_362[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_361 + Relu_362, Tactic: -9153228964338181824, Reformatted Input Tensor 0 to Conv_361 + Relu_362[Float(4,352,16,16)] -> 1192[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_363 + Relu_364, Tactic: -9153228964338181824, 1192[Float(4,352,16,16)] -> 1195[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_365 + Relu_366, Tactic: -9153228964338181824, 1195[Float(4,352,16,16)] -> Reformatted Output Tensor 0 to Conv_365 + Relu_366[Float(4,352,16,16)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_365 + Relu_366, Tactic: 0, Reformatted Output Tensor 0 to Conv_365 + Relu_366[Float(4,352,16,16)] -> 1199[Float(4,352,16,16)]
Layer(Reformat): 1156 copy, Tactic: 0, 1156[Float(4,352,16,16)] -> 1199[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_368 + Relu_369, Tactic: 3827454225649558724, 1199[Float(4,704,16,16)] -> 1202[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_370 + Relu_371, Tactic: 3827454225649558724, 1202[Float(4,352,16,16)] -> 1205[Float(4,352,16,16)]
Layer(CaskConvolution): Conv_372 + Relu_373, Tactic: -8776506421218919509, 1205[Float(4,352,16,16)] -> 1208[Float(4,120,16,16)]
Layer(Resize): Resize_375, Tactic: 1, 1208[Float(4,120,16,16)] -> 1213[Float(4,120,32,32)]
Layer(Reformat): 1213 copy, Tactic: 0, 1213[Float(4,120,32,32)] -> 1214[Float(4,120,32,32)]
Layer(Reformat): 1032 copy, Tactic: 0, 1032[Float(4,120,32,32)] -> 1214[Float(4,120,32,32)]
Layer(CaskConvolution): Conv_377 + Relu_378, Tactic: 3827454225649558724, 1214[Float(4,240,32,32)] -> 1217[Float(4,120,32,32)]
Layer(CaskConvolution): Conv_379 + Relu_380, Tactic: -8776506421218919509, 1217[Float(4,120,32,32)] -> 1220[Float(4,120,32,32)]
Layer(CaskConvolution): Conv_381 + Relu_382, Tactic: -8776506421218919509, 1220[Float(4,120,32,32)] -> 1223[Float(4,48,32,32)]
Layer(Resize): Resize_384, Tactic: 1, 1223[Float(4,48,32,32)] -> 1228[Float(4,48,64,64)]
Layer(Reformat): 1228 copy, Tactic: 0, 1228[Float(4,48,64,64)] -> 1229[Float(4,48,64,64)]
Layer(Reformat): 890 copy, Tactic: 0, 890[Float(4,48,64,64)] -> 1229[Float(4,48,64,64)]
Layer(CaskConvolution): Conv_386 + Relu_387, Tactic: 3827454225649558724, 1229[Float(4,96,64,64)] -> 1232[Float(4,48,64,64)]
Layer(CaskConvolution): Conv_388 + Relu_389, Tactic: -8776506421218919509, 1232[Float(4,48,64,64)] -> 1235[Float(4,48,64,64)]
Layer(CaskConvolution): Conv_390 + Relu_391, Tactic: 3827454225649558724, 1235[Float(4,48,64,64)] -> 1238[Float(4,24,64,64)]
Layer(Resize): Resize_393, Tactic: 1, 1238[Float(4,24,64,64)] -> 1243[Float(4,24,128,128)]
Layer(Reformat): 1243 copy, Tactic: 0, 1243[Float(4,24,128,128)] -> 1244[Float(4,24,128,128)]
Layer(Reformat): 837 copy, Tactic: 0, 837[Float(4,24,128,128)] -> 1244[Float(4,24,128,128)]
Layer(CaskConvolution): Conv_395 + Relu_396, Tactic: -1343271414618805657, 1244[Float(4,48,128,128)] -> 1247[Float(4,24,128,128)]
Layer(CaskConvolution): Conv_397 + Relu_398, Tactic: -1343271414618805657, 1247[Float(4,24,128,128)] -> 1250[Float(4,24,128,128)]
Layer(CaskConvolution): Conv_399 + Relu_400, Tactic: -1343271414618805657, 1250[Float(4,24,128,128)] -> 1253[Float(4,16,128,128)]
Layer(Resize): Resize_402, Tactic: 1, 1253[Float(4,16,128,128)] -> 1258[Float(4,16,256,256)]
Layer(Reformat): 1258 copy, Tactic: 0, 1258[Float(4,16,256,256)] -> 1259[Float(4,16,256,256)]
Layer(Reformat): 784 copy, Tactic: 0, 784[Float(4,16,256,256)] -> 1259[Float(4,16,256,256)]
Layer(CaskConvolution): Conv_404 + Relu_405, Tactic: -1343271414618805657, 1259[Float(4,32,256,256)] -> 1262[Float(4,16,256,256)]
Layer(CaskConvolution): Conv_406 + Relu_407, Tactic: -1343271414618805657, 1262[Float(4,16,256,256)] -> 1265[Float(4,16,256,256)]
Layer(CaskConvolution): Conv_408 + Relu_409, Tactic: -1343271414618805657, 1265[Float(4,16,256,256)] -> 1268[Float(4,16,256,256)]
Layer(CaskConvolution): Conv_410, Tactic: -8776506421218919509, 1268[Float(4,16,256,256)] -> 1285[Float(4,1,256,256)]
Layer(Reformat): 1269 copy, Tactic: 0, 1285[Float(4,1,256,256)] -> 1285[Float(4,1,256,256)]
Layer(Reformat): 1269 copy, Tactic: 0, 1285[Float(4,1,256,256)] -> 1285[Float(4,1,256,256)]
Layer(CaskConvolution): Conv_448, Tactic: -3456450830548107839, 1285[Float(4,3,256,256)] -> 1307[Float(4,3,256,256)]
Layer(ElementWise): Mul_450, Tactic: 1, 754[Float(4,3,256,256)], 1285[Float(4,3,256,256)] -> 1309[Float(4,3,256,256)]
Layer(ElementWise): Div_449, Tactic: 1, 1307[Float(4,3,256,256)], 1304[Float(4,3,256,256)] -> 1308[Float(4,3,256,256)]
Layer(CaskConvolution): Conv_451, Tactic: -3456450830548107839, 1309[Float(4,3,256,256)] -> 1310[Float(4,3,256,256)]
Layer(PointWiseV2): PWN(Div_452, PWN(Mul_453, Sub_454)), Tactic: 2, 1310[Float(4,3,256,256)], 1304[Float(4,3,256,256)], 1306[Float(4,3,256,256)], 1308[Float(4,3,256,256)] -> 1313[Float(4,3,256,256)]
Layer(Reformat): 1313 copy, Tactic: 0, 1313[Float(4,3,256,256)] -> 1319[Float(4,3,256,256)]
Layer(CaskConvolution): Conv_461 + Relu_462, Tactic: -6576203419454146580, 1319[Float(4,6,256,256)] -> 1322[Float(4,32,256,256)]
Layer(CaskConvolution): Conv_463 + Relu_464, Tactic: -6576203419454146580, 1322[Float(4,32,256,256)] -> 1325[Float(4,32,256,256)]
Layer(CudnnConvolution): Conv_465, Tactic: 1, 1325[Float(4,32,256,256)] -> 1326[Float(4,3,256,256)]
Layer(PointWiseV2): PWN(Mul_466, Sub_467), Tactic: 2, 1326[Float(4,3,256,256)], 1306[Float(4,3,256,256)], 1308[Float(4,3,256,256)] -> 1328[Float(4,3,256,256)]
Layer(Resize): Resize_476, Tactic: 1, 1326[Float(4,3,256,256)] -> 1339[Float(4,3,1280,720)]
Layer(Resize): Resize_485, Tactic: 1, 1328[Float(4,3,256,256)] -> 1350[Float(4,3,1280,720)]
Layer(PointWiseV2): PWN(Mul_486, Add_487), Tactic: 28, 1339[Float(4,3,1280,720)], x_orig[Float(4,3,1280,720)], 1350[Float(4,3,1280,720)] -> 1352[Float(4,3,1280,720)]
Layer(CudnnConvolution): Conv_488, Tactic: 1, 1352[Float(4,3,1280,720)] -> 1354[Float(4,1,1280,720)]
Layer(PointWiseV2): PWN(Sigmoid_490), Tactic: 8, 1354[Float(4,1,1280,720)] -> 1355[Float(4,1,1280,720)]
[03/27/2022-19:14:10] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +2, GPU +134, now: CPU 2, GPU 134 (MiB)
[03/27/2022-19:14:11] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 1278, GPU 890 (MiB)
[03/27/2022-19:14:11] [I] [TRT] Loaded engine size: 132 MiB
[03/27/2022-19:14:11] [V] [TRT] Using cublas as a tactic source
[03/27/2022-19:14:11] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 1298, GPU 1032 (MiB)
[03/27/2022-19:14:11] [V] [TRT] Using cuDNN as a tactic source
[03/27/2022-19:14:11] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1298, GPU 1040 (MiB)
[03/27/2022-19:14:11] [V] [TRT] Deserialization required 135446 microseconds.
[03/27/2022-19:14:11] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +134, now: CPU 0, GPU 134 (MiB)
[03/27/2022-19:14:11] [I] Engine built in 276.919 sec.
[03/27/2022-19:14:11] [V] [TRT] Using cublas as a tactic source
[03/27/2022-19:14:11] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 921, GPU 1036 (MiB)
[03/27/2022-19:14:11] [V] [TRT] Using cuDNN as a tactic source
[03/27/2022-19:14:11] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 921, GPU 1044 (MiB)
[03/27/2022-19:14:11] [V] [TRT] Total per-runner device persistent memory is 5234176
[03/27/2022-19:14:11] [V] [TRT] Total per-runner host persistent memory is 230256
[03/27/2022-19:14:11] [V] [TRT] Allocated activation device memory of size 284491776
[03/27/2022-19:14:11] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +276, now: CPU 0, GPU 410 (MiB)
[03/27/2022-19:14:11] [I] Using random values for input x_orig
[03/27/2022-19:14:11] [I] Created input binding for x_orig with dimensions 4x3x1280x720
[03/27/2022-19:14:11] [I] Using random values for output 1355
[03/27/2022-19:14:11] [I] Created output binding for 1355 with dimensions 4x1x1280x720
[03/27/2022-19:14:11] [I] Starting inference
[03/27/2022-19:14:14] [I] Warmup completed 6 queries over 200 ms
[03/27/2022-19:14:14] [I] Timing trace has 106 queries over 3.0771 s
[03/27/2022-19:14:14] [I] 
[03/27/2022-19:14:14] [I] === Trace details ===
[03/27/2022-19:14:14] [I] Trace averages of 10 runs:
[03/27/2022-19:14:14] [I] Average on 10 runs - GPU latency: 28.9055 ms - Host latency: 28.9055 ms (end to end 28.9055 ms, enqueue 0.380623 ms)
[03/27/2022-19:14:14] [I] Average on 10 runs - GPU latency: 29.0975 ms - Host latency: 29.0975 ms (end to end 29.0975 ms, enqueue 0.537637 ms)
[03/27/2022-19:14:14] [I] Average on 10 runs - GPU latency: 28.9714 ms - Host latency: 28.9714 ms (end to end 28.9714 ms, enqueue 0.387952 ms)
[03/27/2022-19:14:14] [I] Average on 10 runs - GPU latency: 29.1315 ms - Host latency: 29.1315 ms (end to end 29.1315 ms, enqueue 0.311047 ms)
[03/27/2022-19:14:14] [I] Average on 10 runs - GPU latency: 28.8897 ms - Host latency: 28.8897 ms (end to end 28.8897 ms, enqueue 0.183423 ms)
[03/27/2022-19:14:14] [I] Average on 10 runs - GPU latency: 29.1169 ms - Host latency: 29.1169 ms (end to end 29.1169 ms, enqueue 0.426428 ms)
[03/27/2022-19:14:14] [I] Average on 10 runs - GPU latency: 28.8903 ms - Host latency: 28.8903 ms (end to end 28.8903 ms, enqueue 0.85531 ms)
[03/27/2022-19:14:14] [I] Average on 10 runs - GPU latency: 29.3163 ms - Host latency: 29.3163 ms (end to end 29.3163 ms, enqueue 0.69104 ms)
[03/27/2022-19:14:14] [I] Average on 10 runs - GPU latency: 28.9144 ms - Host latency: 28.9144 ms (end to end 28.9144 ms, enqueue 0.612207 ms)
[03/27/2022-19:14:14] [I] Average on 10 runs - GPU latency: 29.1009 ms - Host latency: 29.1009 ms (end to end 29.1009 ms, enqueue 0.940063 ms)
[03/27/2022-19:14:14] [I] 
[03/27/2022-19:14:14] [I] === Performance summary ===
[03/27/2022-19:14:14] [I] Throughput: 34.448 qps
[03/27/2022-19:14:14] [I] Latency: min = 28.6659 ms, max = 31.2136 ms, mean = 29.0264 ms, median = 28.9372 ms, percentile(99%) = 30.6453 ms
[03/27/2022-19:14:14] [I] End-to-End Host Latency: min = 28.6659 ms, max = 31.2136 ms, mean = 29.0264 ms, median = 28.9372 ms, percentile(99%) = 30.6453 ms
[03/27/2022-19:14:14] [I] Enqueue Time: min = 0.0889893 ms, max = 2.69458 ms, mean = 0.535407 ms, median = 0.537964 ms, percentile(99%) = 1.37158 ms
[03/27/2022-19:14:14] [I] H2D Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(99%) = 0 ms
[03/27/2022-19:14:14] [I] GPU Compute Time: min = 28.6659 ms, max = 31.2136 ms, mean = 29.0264 ms, median = 28.9372 ms, percentile(99%) = 30.6453 ms
[03/27/2022-19:14:14] [I] D2H Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(99%) = 0 ms
[03/27/2022-19:14:14] [I] Total Host Walltime: 3.0771 s
[03/27/2022-19:14:14] [I] Total GPU Compute Time: 3.0768 s
[03/27/2022-19:14:14] [I] Explanations of the performance metrics are printed in the verbose logs.
[03/27/2022-19:14:14] [V] 
[03/27/2022-19:14:14] [V] === Explanations of the performance metrics ===
[03/27/2022-19:14:14] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[03/27/2022-19:14:14] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[03/27/2022-19:14:14] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[03/27/2022-19:14:14] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[03/27/2022-19:14:14] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[03/27/2022-19:14:14] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[03/27/2022-19:14:14] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[03/27/2022-19:14:14] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[03/27/2022-19:14:14] [V] End-to-End Host Latency: the duration from when the H2D of a query is called to when the D2H of the same query is completed, which includes the latency to wait for the completion of the previous query. This is the latency of a query if multiple queries are enqueued consecutively.
[03/27/2022-19:14:14] [I] 
[03/27/2022-19:14:18] [I] 
[03/27/2022-19:14:18] [I] === Profile (97 iterations ) ===
[03/27/2022-19:14:18] [I]                                                                                     Layer   Time (ms)   Avg. Time (ms)   Time %
[03/27/2022-19:14:18] [I]                          (Unnamed Layer* 424) [Constant] + (Unnamed Layer* 425) [Shuffle]        1.09           0.0112      0.0
[03/27/2022-19:14:18] [I]                                                                                  Resize_8       10.66           0.1099      0.3
[03/27/2022-19:14:18] [I]                                                                          Conv_9 + Relu_10       15.96           0.1645      0.5
[03/27/2022-19:14:18] [I]                                                                                  Conv_446       13.85           0.1427      0.4
[03/27/2022-19:14:18] [I]                                                                                   Mul_455        2.11           0.0218      0.1
[03/27/2022-19:14:18] [I]                                                                                   Conv_11       35.13           0.3621      1.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_456       14.01           0.1445      0.4
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_12), Mul_13)       15.76           0.1625      0.5
[03/27/2022-19:14:18] [I]                                                                             ReduceMean_14       11.72           0.1209      0.4
[03/27/2022-19:14:18] [I]                                                                       ConstantOfShape_444        2.69           0.0278      0.1
[03/27/2022-19:14:18] [I]                                                                                   Conv_15        1.17           0.0120      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_445       14.12           0.1456      0.5
[03/27/2022-19:14:18] [I]                                                                                   Div_447        3.03           0.0313      0.1
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_16), Mul_17)        1.10           0.0114      0.0
[03/27/2022-19:14:18] [I]                                                                                   Conv_18        1.63           0.0168      0.1
[03/27/2022-19:14:18] [I]                                                       PWN(Mul_458, PWN(Div_457, Sub_459))        3.95           0.0407      0.1
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_19), Mul_20)       24.66           0.2542      0.8
[03/27/2022-19:14:18] [I]                                                                                   Conv_21       16.40           0.1691      0.5
[03/27/2022-19:14:18] [I]                                                                                   Conv_22       18.76           0.1934      0.6
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_23), Mul_24)        8.55           0.0881      0.3
[03/27/2022-19:14:18] [I]                                                                             ReduceMean_25       11.85           0.1222      0.4
[03/27/2022-19:14:18] [I]                                                                                   Conv_26        1.25           0.0129      0.0
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_27), Mul_28)        0.79           0.0081      0.0
[03/27/2022-19:14:18] [I]                                                                                   Conv_29        0.97           0.0100      0.0
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_30), Mul_31)       13.15           0.1356      0.4
[03/27/2022-19:14:18] [I]                                                                          Conv_32 + Add_33       14.20           0.1464      0.5
[03/27/2022-19:14:18] [I]                                                                                   Conv_34       42.58           0.4390      1.4
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_35), Mul_36)       45.62           0.4703      1.5
[03/27/2022-19:14:18] [I]                                                                                   Conv_37       44.23           0.4560      1.4
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_38), Mul_39)       12.00           0.1237      0.4
[03/27/2022-19:14:18] [I]                                                                             ReduceMean_40        7.75           0.0799      0.2
[03/27/2022-19:14:18] [I]                                                                                   Conv_41        1.21           0.0124      0.0
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_42), Mul_43)        0.75           0.0077      0.0
[03/27/2022-19:14:18] [I]                                                                                   Conv_44        1.29           0.0133      0.0
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_45), Mul_46)       20.34           0.2097      0.7
[03/27/2022-19:14:18] [I]                                                                                   Conv_47       10.11           0.1042      0.3
[03/27/2022-19:14:18] [I]                                                                                   Conv_48       20.09           0.2071      0.6
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_49), Mul_50)       17.58           0.1813      0.6
[03/27/2022-19:14:18] [I]                                                                                   Conv_51       28.21           0.2908      0.9
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_52), Mul_53)       17.60           0.1815      0.6
[03/27/2022-19:14:18] [I]                                                                             ReduceMean_54       10.04           0.1036      0.3
[03/27/2022-19:14:18] [I]                                                                                   Conv_55        1.38           0.0142      0.0
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_56), Mul_57)        0.66           0.0068      0.0
[03/27/2022-19:14:18] [I]                                                                                   Conv_58        1.09           0.0113      0.0
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_59), Mul_60)       26.11           0.2692      0.8
[03/27/2022-19:14:18] [I]                                                                          Conv_61 + Add_62       13.48           0.1390      0.4
[03/27/2022-19:14:18] [I]                                                                                   Conv_63       20.08           0.2070      0.6
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_64), Mul_65)       17.58           0.1813      0.6
[03/27/2022-19:14:18] [I]                                                                                   Conv_66       29.99           0.3092      1.0
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_67), Mul_68)       17.89           0.1844      0.6
[03/27/2022-19:14:18] [I]                                                                             ReduceMean_69       10.05           0.1036      0.3
[03/27/2022-19:14:18] [I]                                                                                   Conv_70        1.41           0.0145      0.0
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_71), Mul_72)        0.67           0.0069      0.0
[03/27/2022-19:14:18] [I]                                                                                   Conv_73        1.08           0.0112      0.0
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_74), Mul_75)       26.08           0.2688      0.8
[03/27/2022-19:14:18] [I]                                                                          Conv_76 + Add_77       13.48           0.1390      0.4
[03/27/2022-19:14:18] [I]                                                                                   Conv_78       20.07           0.2069      0.6
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_79), Mul_80)       17.57           0.1812      0.6
[03/27/2022-19:14:18] [I]                                                                                   Conv_81       33.68           0.3472      1.1
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_82), Mul_83)        4.92           0.0508      0.2
[03/27/2022-19:14:18] [I]                                                                             ReduceMean_84        3.94           0.0406      0.1
[03/27/2022-19:14:18] [I]                                                                                   Conv_85        1.40           0.0145      0.0
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_86), Mul_87)        0.70           0.0072      0.0
[03/27/2022-19:14:18] [I]                                                                                   Conv_88        1.10           0.0113      0.0
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_89), Mul_90)        6.99           0.0720      0.2
[03/27/2022-19:14:18] [I]                                                                                   Conv_91        6.83           0.0704      0.2
[03/27/2022-19:14:18] [I]                                                                                   Conv_92       13.33           0.1375      0.4
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_93), Mul_94)        9.21           0.0950      0.3
[03/27/2022-19:14:18] [I]                                                                                   Conv_95       49.57           0.5110      1.6
[03/27/2022-19:14:18] [I]                                                              PWN(PWN(Sigmoid_96), Mul_97)        9.31           0.0960      0.3
[03/27/2022-19:14:18] [I]                                                                             ReduceMean_98        5.83           0.0601      0.2
[03/27/2022-19:14:18] [I]                                                                                   Conv_99        1.27           0.0131      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_100), Mul_101)        0.67           0.0070      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_102        0.97           0.0100      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_103), Mul_104)       12.88           0.1328      0.4
[03/27/2022-19:14:18] [I]                                                                        Conv_105 + Add_106       11.68           0.1204      0.4
[03/27/2022-19:14:18] [I]                                                                                  Conv_107       12.34           0.1272      0.4
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_108), Mul_109)        9.23           0.0952      0.3
[03/27/2022-19:14:18] [I]                                                                                  Conv_110       44.63           0.4601      1.4
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_111), Mul_112)        9.31           0.0960      0.3
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_113        5.82           0.0600      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_114        1.26           0.0130      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_115), Mul_116)        0.65           0.0067      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_117        7.35           0.0758      0.2
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_118), Mul_119)       18.49           0.1906      0.6
[03/27/2022-19:14:18] [I]                                                                        Conv_120 + Add_121       11.70           0.1207      0.4
[03/27/2022-19:14:18] [I]                                                                                  Conv_122       12.39           0.1277      0.4
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_123), Mul_124)        9.90           0.1020      0.3
[03/27/2022-19:14:18] [I]                                                                                  Conv_125       10.86           0.1120      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_126), Mul_127)        3.09           0.0319      0.1
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_128        2.86           0.0295      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_129        1.42           0.0147      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_130), Mul_131)        0.68           0.0071      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_132        1.04           0.0107      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_133), Mul_134)        5.11           0.0527      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_135        5.99           0.0617      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_136        8.20           0.0846      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_137), Mul_138)        4.72           0.0487      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_139        6.60           0.0681      0.2
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_140), Mul_141)        4.65           0.0480      0.1
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_142        3.80           0.0391      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_143        1.39           0.0144      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_144), Mul_145)        0.68           0.0070      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_146        1.31           0.0135      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_147), Mul_148)        8.56           0.0883      0.3
[03/27/2022-19:14:18] [I]                                                                        Conv_149 + Add_150        8.99           0.0927      0.3
[03/27/2022-19:14:18] [I]                                                                                  Conv_151        8.14           0.0840      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_152), Mul_153)        4.73           0.0487      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_154        6.58           0.0678      0.2
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_155), Mul_156)        4.71           0.0486      0.2
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_157        3.43           0.0354      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_158        1.38           0.0142      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_159), Mul_160)        1.29           0.0133      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_161        1.32           0.0136      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_162), Mul_163)       32.97           0.3399      1.1
[03/27/2022-19:14:18] [I]                                                                        Conv_164 + Add_165        8.98           0.0926      0.3
[03/27/2022-19:14:18] [I]                                                                                  Conv_166        8.13           0.0838      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_167), Mul_168)        4.74           0.0489      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_169        6.58           0.0678      0.2
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_170), Mul_171)        4.73           0.0488      0.2
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_172        3.47           0.0357      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_173        1.38           0.0143      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_174), Mul_175)        0.66           0.0068      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_176        1.29           0.0133      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_177), Mul_178)       27.39           0.2824      0.9
[03/27/2022-19:14:18] [I]                                                                        Conv_179 + Add_180        9.07           0.0935      0.3
[03/27/2022-19:14:18] [I]                                                                                  Conv_181        8.19           0.0844      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_182), Mul_183)        4.75           0.0490      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_184       22.54           0.2323      0.7
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_185), Mul_186)        4.79           0.0494      0.2
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_187        4.88           0.0503      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_188        9.50           0.0979      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_189), Mul_190)        1.04           0.0108      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_191        1.36           0.0140      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_192), Mul_193)       19.50           0.2010      0.6
[03/27/2022-19:14:18] [I]                                                                                  Conv_194       10.16           0.1047      0.3
[03/27/2022-19:14:18] [I]                                                                                  Conv_195       12.75           0.1314      0.4
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_196), Mul_197)        6.10           0.0629      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_198       28.49           0.2937      0.9
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_199), Mul_200)        6.06           0.0625      0.2
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_201        4.12           0.0425      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_202        1.77           0.0183      0.1
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_203), Mul_204)        1.31           0.0135      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_205        1.19           0.0123      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_206), Mul_207)       11.39           0.1175      0.4
[03/27/2022-19:14:18] [I]                                                                        Conv_208 + Add_209       13.27           0.1368      0.4
[03/27/2022-19:14:18] [I]                                                                                  Conv_210       13.02           0.1342      0.4
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_211), Mul_212)        6.06           0.0624      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_213       28.44           0.2932      0.9
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_214), Mul_215)        6.10           0.0629      0.2
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_216       12.94           0.1334      0.4
[03/27/2022-19:14:18] [I]                                                                                  Conv_217        3.98           0.0410      0.1
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_218), Mul_219)        1.03           0.0106      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_220        1.16           0.0120      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_221), Mul_222)       11.38           0.1173      0.4
[03/27/2022-19:14:18] [I]                                                                        Conv_223 + Add_224       13.24           0.1365      0.4
[03/27/2022-19:14:18] [I]                                                                                  Conv_225       14.63           0.1508      0.5
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_226), Mul_227)        6.90           0.0711      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_228       28.52           0.2940      0.9
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_229), Mul_230)        6.08           0.0627      0.2
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_231        4.12           0.0425      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_232        4.14           0.0427      0.1
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_233), Mul_234)        0.71           0.0073      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_235        1.18           0.0122      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_236), Mul_237)       11.34           0.1169      0.4
[03/27/2022-19:14:18] [I]                                                                        Conv_238 + Add_239       13.25           0.1366      0.4
[03/27/2022-19:14:18] [I]                                                                                  Conv_240       12.69           0.1308      0.4
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_241), Mul_242)        6.06           0.0625      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_243        9.92           0.1022      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_244), Mul_245)        1.88           0.0194      0.1
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_246        1.82           0.0188      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_247        1.76           0.0181      0.1
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_248), Mul_249)        1.52           0.0157      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_250        1.73           0.0178      0.1
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_251), Mul_252)        0.29           0.0029      0.0
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_251), Mul_252)        3.82           0.0394      0.1
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_251), Mul_252)        2.66           0.0274      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_253        5.74           0.0592      0.2
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_254        1.65           0.0170      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_254        9.20           0.0949      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_255), Mul_256)        2.97           0.0306      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_257       18.10           0.1866      0.6
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_258), Mul_259)        2.98           0.0308      0.1
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_260        2.75           0.0284      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_261        2.09           0.0215      0.1
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_262), Mul_263)        0.26           0.0027      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_262), Mul_263)        1.04           0.0107      0.0
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_264        0.29           0.0030      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_264        1.33           0.0137      0.0
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_265), Mul_266)        0.28           0.0029      0.0
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_265), Mul_266)       14.26           0.1470      0.5
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_265), Mul_266)        3.76           0.0388      0.1
[03/27/2022-19:14:18] [I]                                                                        Conv_267 + Add_268        8.65           0.0892      0.3
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_269        1.66           0.0172      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_269       17.00           0.1753      0.5
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_270), Mul_271)       15.07           0.1554      0.5
[03/27/2022-19:14:18] [I]                                                                                  Conv_272       15.41           0.1589      0.5
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_273), Mul_274)        3.79           0.0391      0.1
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_275        2.98           0.0307      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_276        2.13           0.0220      0.1
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_277), Mul_278)        0.28           0.0028      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_277), Mul_278)        0.66           0.0068      0.0
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_279        0.29           0.0030      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_279        1.36           0.0140      0.0
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_280), Mul_281)        3.49           0.0359      0.1
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_280), Mul_281)        5.87           0.0606      0.2
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_280), Mul_281)        3.68           0.0379      0.1
[03/27/2022-19:14:18] [I]                                                                        Conv_282 + Add_283        8.72           0.0899      0.3
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_284        1.84           0.0189      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_284        9.30           0.0958      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_285), Mul_286)        2.97           0.0307      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_287       14.77           0.1522      0.5
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_288), Mul_289)        3.17           0.0327      0.1
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_290        3.04           0.0313      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_291        2.24           0.0231      0.1
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_292), Mul_293)        0.30           0.0031      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_292), Mul_293)        0.85           0.0087      0.0
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_294        0.29           0.0030      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_294        1.50           0.0155      0.0
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_295), Mul_296)        0.29           0.0030      0.0
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_295), Mul_296)        5.93           0.0612      0.2
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_295), Mul_296)        3.74           0.0385      0.1
[03/27/2022-19:14:18] [I]                                                                        Conv_297 + Add_298        9.59           0.0989      0.3
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_299        2.81           0.0290      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_299        9.82           0.1013      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_300), Mul_301)        2.98           0.0308      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_302       14.86           0.1532      0.5
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_303), Mul_304)        3.00           0.0309      0.1
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_305        2.76           0.0284      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_306        2.08           0.0215      0.1
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_307), Mul_308)        0.28           0.0029      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_307), Mul_308)        0.67           0.0069      0.0
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_309        0.28           0.0029      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_309        1.32           0.0136      0.0
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_310), Mul_311)        0.27           0.0028      0.0
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 1 to PWN(PWN(Sigmoid_310), Mul_311)        5.79           0.0597      0.2
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_310), Mul_311)        3.63           0.0374      0.1
[03/27/2022-19:14:18] [I]                                                                        Conv_312 + Add_313        8.65           0.0892      0.3
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_314        1.82           0.0188      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_314        9.21           0.0950      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_315), Mul_316)        3.07           0.0316      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_317        6.30           0.0650      0.2
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_318), Mul_319)        3.11           0.0321      0.1
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_320        2.83           0.0292      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_321        2.17           0.0224      0.1
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_322), Mul_323)        0.28           0.0029      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_322), Mul_323)        0.80           0.0082      0.0
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_324        0.40           0.0041      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_324        1.44           0.0149      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_325), Mul_326)        5.49           0.0566      0.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_327       16.95           0.1748      0.5
[03/27/2022-19:14:18] [I]                                                                                  Conv_328       21.54           0.2221      0.7
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_329), Mul_330)       13.39           0.1380      0.4
[03/27/2022-19:14:18] [I]                                                                                  Conv_331        9.96           0.1027      0.3
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_332), Mul_333)        4.65           0.0479      0.1
[03/27/2022-19:14:18] [I]                                                                            ReduceMean_334        4.22           0.0436      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_335        2.68           0.0276      0.1
[03/27/2022-19:14:18] [I]                Reformatting CopyNode for Input Tensor 0 to PWN(PWN(Sigmoid_336), Mul_337)        0.34           0.0035      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_336), Mul_337)        0.70           0.0072      0.0
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_338        0.32           0.0033      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_338        1.44           0.0149      0.0
[03/27/2022-19:14:18] [I]                                                            PWN(PWN(Sigmoid_339), Mul_340)        9.56           0.0986      0.3
[03/27/2022-19:14:18] [I]                                                                        Conv_341 + Add_342       26.23           0.2704      0.8
[03/27/2022-19:14:18] [I]  Reformatting CopyNode for Input Tensor 0 to Conv_343 || Conv_344 || Conv_348 || Conv_352        5.70           0.0587      0.2
[03/27/2022-19:14:18] [I]                                              Conv_343 || Conv_344 || Conv_348 || Conv_352       13.58           0.1399      0.4
[03/27/2022-19:14:18] [I]                                                                                  Conv_345       11.58           0.1194      0.4
[03/27/2022-19:14:18] [I]                                                                                  Conv_349       19.17           0.1976      0.6
[03/27/2022-19:14:18] [I]                                                                                  Conv_353       23.13           0.2385      0.7
[03/27/2022-19:14:18] [I]                                                                                  Conv_346       10.89           0.1123      0.3
[03/27/2022-19:14:18] [I]                                                                                  Conv_350       18.61           0.1919      0.6
[03/27/2022-19:14:18] [I]                                                                                  Conv_354       22.76           0.2346      0.7
[03/27/2022-19:14:18] [I]                                                                                  Conv_347       31.20           0.3216      1.0
[03/27/2022-19:14:18] [I]                                     Reformatting CopyNode for Output Tensor 0 to Conv_347        2.37           0.0245      0.1
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_351        2.09           0.0215      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_351       53.07           0.5471      1.7
[03/27/2022-19:14:18] [I]                                      Reformatting CopyNode for Input Tensor 0 to Conv_355        2.13           0.0220      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_355       57.28           0.5905      1.8
[03/27/2022-19:14:18] [I]                                                                                 1560 copy        2.27           0.0234      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_357       64.88           0.6689      2.1
[03/27/2022-19:14:18] [I]                                                             Conv_358 + Add_359 + Relu_360        6.38           0.0658      0.2
[03/27/2022-19:14:18] [I]                           Reformatting CopyNode for Input Tensor 0 to Conv_361 + Relu_362        2.24           0.0230      0.1
[03/27/2022-19:14:18] [I]                                                                       Conv_361 + Relu_362       29.31           0.3022      0.9
[03/27/2022-19:14:18] [I]                                                                       Conv_363 + Relu_364       29.91           0.3084      1.0
[03/27/2022-19:14:18] [I]                                                                       Conv_365 + Relu_366       30.83           0.3179      1.0
[03/27/2022-19:14:18] [I]                          Reformatting CopyNode for Output Tensor 0 to Conv_365 + Relu_366        2.38           0.0246      0.1
[03/27/2022-19:14:18] [I]                                                                                 1156 copy        1.22           0.0126      0.0
[03/27/2022-19:14:18] [I]                                                                       Conv_368 + Relu_369       29.77           0.3069      1.0
[03/27/2022-19:14:18] [I]                                                                       Conv_370 + Relu_371       15.33           0.1580      0.5
[03/27/2022-19:14:18] [I]                                                                       Conv_372 + Relu_373        9.26           0.0955      0.3
[03/27/2022-19:14:18] [I]                                                                                Resize_375        1.99           0.0205      0.1
[03/27/2022-19:14:18] [I]                                                                                 1213 copy        1.30           0.0134      0.0
[03/27/2022-19:14:18] [I]                                                                                 1032 copy        1.47           0.0152      0.0
[03/27/2022-19:14:18] [I]                                                                       Conv_377 + Relu_378       15.89           0.1638      0.5
[03/27/2022-19:14:18] [I]                                                                       Conv_379 + Relu_380        9.26           0.0955      0.3
[03/27/2022-19:14:18] [I]                                                                       Conv_381 + Relu_382        5.44           0.0561      0.2
[03/27/2022-19:14:18] [I]                                                                                Resize_384        2.70           0.0278      0.1
[03/27/2022-19:14:18] [I]                                                                                 1228 copy        1.97           0.0203      0.1
[03/27/2022-19:14:18] [I]                                                                                  890 copy        2.00           0.0206      0.1
[03/27/2022-19:14:18] [I]                                                                       Conv_386 + Relu_387       13.32           0.1373      0.4
[03/27/2022-19:14:18] [I]                                                                       Conv_388 + Relu_389        8.74           0.0902      0.3
[03/27/2022-19:14:18] [I]                                                                       Conv_390 + Relu_391        4.87           0.0502      0.2
[03/27/2022-19:14:18] [I]                                                                                Resize_393        4.70           0.0484      0.2
[03/27/2022-19:14:18] [I]                                                                                 1243 copy        4.29           0.0442      0.1
[03/27/2022-19:14:18] [I]                                                                                  837 copy        3.48           0.0358      0.1
[03/27/2022-19:14:18] [I]                                                                       Conv_395 + Relu_396       16.32           0.1683      0.5
[03/27/2022-19:14:18] [I]                                                                       Conv_397 + Relu_398        9.94           0.1025      0.3
[03/27/2022-19:14:18] [I]                                                                       Conv_399 + Relu_400        9.88           0.1018      0.3
[03/27/2022-19:14:18] [I]                                                                                Resize_402       11.09           0.1143      0.4
[03/27/2022-19:14:18] [I]                                                                                 1258 copy        7.95           0.0819      0.3
[03/27/2022-19:14:18] [I]                                                                                  784 copy        8.05           0.0830      0.3
[03/27/2022-19:14:18] [I]                                                                       Conv_404 + Relu_405       43.21           0.4455      1.4
[03/27/2022-19:14:18] [I]                                                                       Conv_406 + Relu_407       29.67           0.3059      0.9
[03/27/2022-19:14:18] [I]                                                                       Conv_408 + Relu_409       29.70           0.3062      1.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_410       30.14           0.3107      1.0
[03/27/2022-19:14:18] [I]                                                                                 1269 copy        0.98           0.0101      0.0
[03/27/2022-19:14:18] [I]                                                                                 1269 copy        0.91           0.0094      0.0
[03/27/2022-19:14:18] [I]                                                                                  Conv_448       14.80           0.1525      0.5
[03/27/2022-19:14:18] [I]                                                                                   Mul_450        2.79           0.0288      0.1
[03/27/2022-19:14:18] [I]                                                                                   Div_449        2.79           0.0288      0.1
[03/27/2022-19:14:18] [I]                                                                                  Conv_451       14.56           0.1501      0.5
[03/27/2022-19:14:18] [I]                                                       PWN(Div_452, PWN(Mul_453, Sub_454))        4.25           0.0438      0.1
[03/27/2022-19:14:18] [I]                                                                                 1313 copy        1.91           0.0197      0.1
[03/27/2022-19:14:18] [I]                                                                       Conv_461 + Relu_462       12.83           0.1322      0.4
[03/27/2022-19:14:18] [I]                                                                       Conv_463 + Relu_464       18.55           0.1913      0.6
[03/27/2022-19:14:18] [I]                                                                                  Conv_465       10.15           0.1046      0.3
[03/27/2022-19:14:18] [I]                                                                     PWN(Mul_466, Sub_467)        3.44           0.0354      0.1
[03/27/2022-19:14:18] [I]                                                                                Resize_476       26.26           0.2707      0.8
[03/27/2022-19:14:18] [I]                                                                                Resize_485       25.92           0.2673      0.8
[03/27/2022-19:14:18] [I]                                                                     PWN(Mul_486, Add_487)       38.99           0.4020      1.2
[03/27/2022-19:14:18] [I]                                                                                  Conv_488       37.09           0.3824      1.2
[03/27/2022-19:14:18] [I]                                                                          PWN(Sigmoid_490)        7.51           0.0774      0.2
[03/27/2022-19:14:18] [I]                                                                                     Total     3124.66          32.2130    100.0
[03/27/2022-19:14:18] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8400] # trtexec --onnx=effnetb2.onnx --verbose --noDataTransfers --separateProfileRun --dumpProfile --useCudaGraph
